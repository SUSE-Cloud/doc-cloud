<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic8339">
<title>HPE Helion <tm tmtype="reg">OpenStack</tm> 1.1: Troubleshooting VSA</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HPE Helion Openstack"/>
<othermeta name="product-version" content="HPE Helion Openstack 1.1"/>
<othermeta name="role" content="Systems Administrator"/>
<othermeta name="role" content="Cloud Architect"/>
<othermeta name="role" content="Storage Administrator"/>
<othermeta name="role" content="Network Administrator"/>
<othermeta name="role" content="Service Developer"/>
<othermeta name="role" content="Cloud Administrator"/>
<othermeta name="role" content="Application Developer"/>
<othermeta name="role" content="Network Engineer"/>
<othermeta name="role" content="Paul F"/>
<othermeta name="product-version1" content="HPE Helion Openstack"/>
<othermeta name="product-version2" content="HPE Helion Openstack 1.1"/>
</metadata>
</prolog>
<body>
<p>
<!--PUBLISHED-->
 <!--./commercial/GA1/1.1commercial.troubleshooting.vsa.md-->
 <!--permalink: /helion/openstack/1.1/services/troubleshooting/vsa/--></p>
<p>HPE Helion OpenStack is an OpenStack technology coupled with a version of <tm tmtype="reg">Linux</tm> provided by HP. This topic describes all the known issues that you might encounter. To help you resolve these issues, we have provided possible solutions.</p>
<p>Troubleshooting issues related to HPE StoreVirtual VSA environments.</p>
<ul>
<li>
<xref type="section" href="#topic8339/fails-retrieve-netmask">Failure to retrieve netmask from vsa-bridge</xref>
</li>
<li>
<xref type="section" href="#topic8339/install-script-detect">Installation script detects more than 7 available drive</xref>
</li>
<li>
<xref type="section" href="#topic8339/failure-script">Failure of script due to less than two drives</xref>
</li>
<li>
<xref type="section" href="#topic8339/cannot-enable-ao">Cannot enable AO as only one disk is available</xref>
</li>
<li>
<xref type="section" href="#topic8339/unable-update-json">Unable to update the default input json file </xref>
</li>
<li>
<xref type="section" href="#topic8339/storage-pool-fail">Creation of storage pool failed</xref>
</li>
<li>
<xref type="section" href="#topic8339/post-vsa-fail">Failed during post VSA deployment</xref>
</li>
<li>
<xref type="section" href="#topic8339/vsa-network">vsa_network cannot be destroyed</xref>
</li>
<li>
<xref type="section" href="#topic8339/vsa-pool-cannot-destroy">vsa_storage_pool pool cannot be destroyed</xref>
</li>
<li>
<xref type="section" href="#topic8339/virshfail">Overcloud updates fail because VSA VMs not responding to virsh stop</xref>
</li>
<li>
<xref type="section" href="#topic8339/publicinterfaceset">Public interface not set and is ignored during overcloud update</xref>
</li>
</ul>
<section id="fails-retrieve-netmask"> <title>Failure to retrieve netmask from vsa-bridge</title>
<p>
  <b>System Behavior/Message</b>
</p>
<p>Cannot retrieve netmask from interface vsa-bridge</p>
<p>
  <b>Probable Cause</b>
</p>
<p>VSA deployment script determines the net-mask and gateway details from the provided interface. When there is no IP address assigned to the VSA bridge, this error may occur.</p>
<p>
  <b>Resolution</b>
</p>
<p>To resolve this issue, perform the following steps:</p>
<ul>
<li>
<p>Check whether the IP address is allocated for the VSA bridge</p>
</li>
<li>
<p>Verify the VSA IP address by using the following command:</p>

<codeblock>
<codeph>ifconfig vsa-bridge
</codeph>
</codeblock>
</li>
</ul>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="install-script-detect"> <title>Installation script detects more than 7 available drive</title>
<p>
  <b>System Behavior/Message</b>
</p>
<p>Maximum supported devices 7.</p>
<p>
  <b>Probable Cause</b>
</p>
<p>This issue occurs when there are more than 7 available drives detected by the installation script to deploy StoreVirtual.</p>
<p>
  <b>Resolution</b>
</p>
<p>Perform the following steps:</p>
<ul>
<li>
<p>HPE StoreVirtual VSA supports up to 7 disks</p>
</li>
<li>
<p>Execute <codeph>fdisk &amp;#45;l</codeph> and check for number of available drives in the machine other than <codeph>/dev/sda</codeph>
</p>
</li>
</ul>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="failure-script"> <title>Failure of script due to less than two drives</title>
<p>
  <b>System Behavior/Message</b>
</p>
<p>Minimum number of disks must be 2. No disks are available.</p>
<p>
<b>Probable Cause</b>
When there are less than two drives in the machine, the script will fail to execute.</p>
<p>
  <b>Resolution</b>
</p>
<p>To resolve, perform the following steps:</p>
<ul>
<li>
<p>Execute <codeph>fdisk &amp;#45;l</codeph>
</p>
</li>
<li>
<p>Minimum two drives and maximum of 7 drives should be available for the StoreVirtual deployment other than boot disk(<codeph>/dev/sda</codeph>)</p>
</li>
<li>
<p>At least three drives required for enabling AO
</p>
</li>
</ul>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="cannot-enable-ao"> <title>Cannot enable AO as only one disk is available</title>
<p>
  <b>Probable Cause</b>
</p>
<p>For Adaptive Optimization to be enabled, at least three drives must be available. <codeph>/dev/sdb</codeph> must be SSD drive(Tier 0) and the remaining will be Tier 1.</p>
<p>
  <b>Resolution</b>
</p>
<p>To resolve the issue, do the following:</p>
<ul>
<li>
<p>Use RAID controllers to create RAID groups.</p>
</li>
<li>
<p>Ensure that you create the RAID group for SSD drives immediately after creating the RAID group for boot volume. For example: If three RAID groups are to be created. The following is recommended :</p>

<ul>
<li>
<p>
<b>Step 1</b> : Create the first RAID group for HDD drives and mark this as boot volume(/dev/sda)</p>
</li>
<li>
<p>
<b>Step 2</b>: Create the second RAID group for SSD drives which should be used as Tier 0 for AO (/dev/sdb)</p>
</li>
<li>
<p>
<b>Step 3</b>: Create the third RAID group for HDD drives which will be used as Tier 1(/dev/sdc)</p>
</li>
</ul>
</li>
</ul>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="unable-update-json"> <title>Unable to update the default input json file</title>
<p>
  <b>System Behavior/Message</b>
</p>
<p>Parsing the default JSON file failed. Unable to update the default input json file.</p>
<p>
  <b>Probable Cause</b>
</p>
<p>The script will parse the configuration file and update the values based on the network and configuration files.</p>
<p>
  <b>Resolution</b>
</p>
<p>Perform the following steps:</p>
<ul>
<li>
<p>Verify whether the JSON content is valid in the following files:</p>

<ul>
<li>
<p>
<codeph>/home/vsa-installer/pyVins/etc/vsa/vsa_config.json</codeph>
</p>
</li>
<li>
<p>
<codeph>/etc/vsa/vsa_network_config.json</codeph>
</p>
</li>
</ul>
</li>
</ul>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="storage-pool-fail"> <title>Creation of storage pool failed</title>
<p>
  <b>Probable Cause</b>
</p>
<p>Virtual storage pool will be created for placing the extracted VSA VM image. The storage pool will be created based on local directory  on <codeph>/mnt/state/vsa-kvm-storage</codeph>
</p>
<p>
  <b>Resolution</b>
</p>
<p>Perform the following steps:</p>
<ul>
<li>
<p>Check whether <codeph>/mnt/state/vsa-kvm-storage</codeph> directory is available.</p>
</li>
<li>
<p>Verify for available space to create storage pool in the system.</p>
</li>
<li>
<p>Check the libvirt logs for more errors</p>
</li>
</ul>
<p>Refer <codeph>/var/log/libvirt/libvirt.log</codeph> on VSA system.</p>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="post-vsa-fail"> <title>Failed during post VSA deployment</title>
<p>
  <b>Probable Cause</b>
</p>
<p>The script will persist required files in <codeph>/mnt/state/vsa</codeph> which will be used for recreating the VSA VM during re-imaging scenario</p>
<p>
  <b>Resolution</b>
</p>
<p>This error will occur if the script fails to find <codeph>network_vsa.xml</codeph>, <codeph>storagepool_vsa.xml</codeph> and other configuration files which has to be preserved.</p>
<ul>
<li>
<p>Check for the configuration files on ”/‘ path.</p>
</li>
<li>
<p>On success, the script updates the <codeph>/mnt/state/vsa/vsa_config.json</codeph> file with the updated and created time.</p>
</li>
</ul>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="vsa-install-fail"> <title>VSA installation failed</title>
<p>
  <b>Probable Cause</b>
</p>
<p>When VSA installation fails for any of the above reasons, the script will rollback the network and storage pool.</p>
<p>
  <b>Resolution</b>
</p>
<p>Verify the <codeph>/installer.log</codeph>
</p>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="vsa-network"> <title>vsa_network cannot be destroyed</title>
<p>
  <b>Probable Cause</b>
</p>
<p>VSA network will be destroyed when the VSA installation fails.</p>
<p>
  <b>Resolution</b>
</p>
<p>Perform the following steps:</p>
<ul>
<li>
<p>Check whether the network is already undefined</p>
</li>
<li>
<p>Check whether the network name in <codeph>&lt;PYVINS_DIRS&gt;/etc/vsa/vsa_config.json</codeph> is the same as in the output of <codeph>virsh net-list -all</codeph> command</p>
</li>
</ul>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="vsa-pool-cannot-destroy"> <title>vsa_storage_pool pool cannot be destroyed</title>
<p>
  <b>Probable Cause</b>
</p>
<p>The storage pool will be destroyed when VSA installation fails</p>
<p>
  <b>Resolution</b>
</p>
<p>Perform the following:</p>
<ul>
<li>
<p>Verify whether the storage pool is already undefined</p>
</li>
<li>
<p>Verify whether the pool name is same as in <codeph>&lt;PYVINS_DIRS&gt;/etc/vsa/vsa_config.json</codeph>
</p>
</li>
<li>
<p>Virsh command to list the pools</p>

<codeblock>
<codeph>Virsh pool-list --all
</codeph>
</codeblock>
</li>
</ul>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="failnew"> <title>Failure of newly added compute or VSA node during Scale-out</title>
<p>
  <b>System Behavior/Message</b>
</p>
<p>The newly added compute node or VSA node fails during scale-out.</p>
<p>
  <b>Resolution</b>
</p>
<p>You must remove a failed compute or VSA node before adding a new compute node.</p>
<p>Perform the following steps to remove a failed compute node:</p>
<ol>
<li>
<p>Run <codeph>heat stacklist</codeph>on the undercloud node and search for the failed stack.</p>
</li>
<li>
<p>Delete the failed stack using the following command:</p>

<codeblock>
<codeph># heat stackdelete &lt;stackname or uuid&gt;
</codeph>
</codeblock>
</li>
<li>
<p>List the newly added nova node which is created during scale-out.</p>

<codeblock>
<codeph># novalist
</codeph>
</codeblock>
</li>
<li>
<p>Execute the following command to delete nova node. Node name and the Node ID can be obtained from the above steps.</p>

<codeblock>
<codeph># nova delete &lt;node name or node id&gt;
</codeph>
</codeblock>
</li>
<li>
<p>View a newly added node using the following command:</p>

<codeblock>
<codeph># ironic nodelist
</codeph>
</codeblock>
</li>
<li>
<p>If newly added node is in ERROR state or if the maintenance mode is True then remove those node(s) using the following command.</p>

<codeblock>
<codeph># ironic nodedelete &lt;uuid&gt;
</codeph>
</codeblock>

<p>where uuid is the ID of the node</p>
</li>
</ol>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="virshfail"> <title>Overcloud updates fail because VSA VMs not responding to virsh stop</title>
<!-- DOCS-1067 and DOCS-1272 -->
<p>
  <b>System Behavior/Message</b>
</p>
<p>Overcloud updates require that all VMs be stopped before an update can proceed. During an overcloud update, you may find that you are not able to stop a VSA VM (by issuing a <codeph>virsh stop</codeph> command). This causes the update to stop.</p>
<p>To verify that all VSA VMs are stopped, log onto the overcloud VSA nodes and enter:</p>
<codeblock>
  <codeph>sudo virsh list
</codeph>
</codeblock>
<p>Make sure the list is empty and no VMs are running. If the list is not empty, proceed with the resolution below.</p>
<p>
  <b>Resolution</b>
</p>
<p>To fix this problem, you can use the VSA command-line interface (CLIQ) to shut down VSA nodes. If you do not know the IP address/username/password of the VSA system, look in <codeph>/etc/cinder/cinder.conf</codeph> on controller0 on the overcloud.</p>
<p>Before running the overcloud update, log onto the CMC Cliq CI on the VSA nodes. Then enter:</p>
<codeblock>
  <codeph>    ssh -l &lt;username&gt; &lt;IP&gt; -p 16022
    ClIQ&gt; cliq shutdownNsm action=Shutdown
</codeph>
</codeblock>
<p>Proceed with the update once all VSA VMs are stopped.</p>
<p>
  <!--A BR tag was used here in the original source.-->
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
<section id="publicinterfaceset"> <title>Public interface not set and is ignored during overcloud update</title>
<!--DOCS1240 -->
<p>
  <b>System Behavior/Message</b>
</p>
<p>As of HPE Helion OpenStack 1.1,  when you install Helion OpenStack if you do not specify the public interface for VSA (with the <codeph>VSA_PUBLIC_INTERFACE</codeph> parameter), then updates will not take this parameter into account.</p>
<p>
  <b>Resolution</b>
</p>
<p>To fix this problem, manually update <codeph>VSA_PUBLIC_INTERFACE</codeph> in the <codeph>~/tripleo/overcloud-env.json</codeph> file with the interface name, for example, <codeph>eth1</codeph>.</p>
<p/>
<!-- ===================== horizontal rule ===================== -->
<p>
  <xref href="#topic8339"> Return to Top </xref>
</p>
</section>
</body>
</topic>
