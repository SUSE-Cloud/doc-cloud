<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic4362">
<title>HPE Helion <tm tmtype="reg">OpenStack</tm> 1.1: Metering Service (Ceilometer) Components</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HPE Helion Openstack"/>
<othermeta name="product-version" content="HPE Helion Openstack 1.1"/>
<othermeta name="product-version1" content="HPE Helion Openstack"/>
<othermeta name="product-version2" content="HPE Helion Openstack 1.1"/>
</metadata>
</prolog>
<body>
<p>
<!--PUBLISHED-->
 <!--./commercial/GA1/ceilometer/1.1commerical.services-reporting-components.md-->
 <!--permalink: /helion/openstack/1.1/services/reporting/components/--></p>
<p>The Metering service is included by the TripleO installer as part of the HPE Helion OpenStack installation. During installation, the Metering service is automatically configured to collect data from the Nova, Cinder, Glance and Neutron services.</p>
<p>All the metering processes have a unified configuration file that can be found at <i>/etc/ceilometer/ceilometer.conf</i> on the specific overcloud controller you are logged in to.</p>
<p>The TripleO installation creates several management nodes running different metering components.</p>
<p>
  <image href="../../../media/ceil_overallarchi.png" placement="break"/>
</p>
<section id="components-in-tripleo-overcloud-controller0"> <title>Components in TripleO Overcloud Controller0</title>
<p>This controller node is the first of the High Available (HA) cluster. In this node there is an instance of the Ceilometer API running under the HA Proxy Virtual IP address. The Alarm services run on Overcloud Controller0.</p>
<p>
<b>Note</b>: When a configuration change is made to an API running under the HA Proxy, that change needs to be replicated in <b>all</b> controllers.</p>
<p>The ceilometer-api are now running as part of the Apache2 service together with Horizon and Keystone. To remove them from the active list so that changes can be made and then re-instate them, use the following commands.</p>
<ol>
<li>
<p>Disable the Ceilometer API on the active sites.</p>

<codeblock>
<codeph>sudo a2dissite ceilometer.conf
</codeph>
</codeblock>
</li>
<li>
<p>Perform all necessary changes. The Ceilometer API will not be served until it is re-enabled.</p>
</li>
<li>
<p>Re-enable the Ceilometer API on the active sites.</p>

<codeblock>
<codeph>sudo a2ensite ceilometer.conf
</codeph>
</codeblock>
</li>
<li>
<p>The new changes need to be picked up by Apache2. If possible, force a reload rather than a restart. Unlike a restart, the reload waits for currently active sessions to gracefully terminate or complete.</p>

<codeblock>
<codeph>sudo  /etc/init.d/apache2 force-reload
</codeph>
</codeblock>
</li>
</ol>
</section>
<section id="ceilometer-components-in-tripleo-overcloud-controller1"> <title>Ceilometer Components in TripleO Overcloud Controller1</title>
<p>Just like Controller0, Controller1 has an instance of the Ceilometer API running under the HA Proxy.</p>
</section>
<section id="ceilometer-components-in-tripleo-overcloud-controller2"> <title>Ceilometer Components in TripleO Overcloud Controller2</title>
<p>This node is where all other Ceilometer components are running.</p>
</section>
<section id="ceilometer-sample-polling"> <title>Ceilometer Sample Polling</title>
<p>The Sample Polling is part of the Central Agent. Once sent to the RabbitMQ service, they are consumed by the Collector and stored in the database. The Collector is also responsible for consuming and storing notifications. Here there is a high level picture of the overall polling/collecting cycle.</p>
<p>
  <image href="../../../media/ceil_collectorandagents.png" placement="break"/>
</p>
</section>
<section id="centralagent"> <title>Ceilometer Central Agent</title>
<p>The Central Agent is responsible for coordinating the polling activity. It parses the <i>pipeline.yml</i> configuration file and identifies all the sources that need to be polled from. The sources are then evaluated using a discovery mechanism and all the sources are translated to resources where a dedicated pollster can retrieve and publish data. At each identified interval the discovery mechanism is triggered, the resource list is composed, and the data is polled and sent to the queue.</p>
<p>Metering processes should normally be operating at all times. Upstart will continually attempt to restart stopped processes even if the process was deliberately stopped manually. In order to avoid this conflict, stop or start processes using the following commands.</p>
<ol>
<li>
<p>Determine whether the process is running:</p>

<codeblock>
<codeph>sudo service ceilometer-agent-central status 
ceilometer-agent-central start/running, process 27989
</codeph>
</codeblock>
</li>
<li>
<p>start or stop the process as needed:</p>

<codeblock>
<codeph>sudo service ceilometer-agent-central stop
</codeph>
</codeblock>

<p>or</p>

<codeblock>
<codeph>sudo service ceilometer-agent-central start
</codeph>
</codeblock>
</li>
</ol>
</section>
<section id="collector"> <title>Ceilometer Collector</title>
<p>The collector is responsible for getting the samples/events from the RabbitMQ service and storing it in the main database.</p>
<p>Metering processes should normally be operating at all times. Upstart will continually attempt to restart stopped processes even if the process was deliberately stopped manually. In order to avoid this conflict, stop or start processes using the following commands.</p>
<ol>
<li>
<p>Determine whether the process is running:</p>

<codeblock>
<codeph>sudo service ceilometer-collector status 
ceilometer-collector start/running, process 27455
</codeph>
</codeblock>
</li>
<li>
<p>start or stop the process as needed:</p>

<codeblock>
<codeph>sudo service ceilometer-collector stop
</codeph>
</codeblock>

<p>or</p>

<codeblock>
<codeph>sudo service ceilometer-collector start
</codeph>
</codeblock>
</li>
</ol>
</section>
</body>
</topic>
