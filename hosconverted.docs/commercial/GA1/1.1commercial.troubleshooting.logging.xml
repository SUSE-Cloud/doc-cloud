<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" >
<topic xml:lang="en-us" id="topic2924">
  <title>HPE Helion <tm tmtype="reg">OpenStack</tm> 1.1: Troubleshooting Logging</title>
  <prolog>
    <metadata>
      <othermeta name="layout" content="default"/>
      <othermeta name="product-version" content="HPE Helion Openstack"/>
      <othermeta name="product-version" content="HPE Helion Openstack 1.1"/>
      <othermeta name="role" content="Systems Administrator"/>
      <othermeta name="role" content="Cloud Architect"/>
      <othermeta name="role" content="Storage Administrator"/>
      <othermeta name="role" content="Network Administrator"/>
      <othermeta name="role" content="Service Developer"/>
      <othermeta name="role" content="Cloud Administrator"/>
      <othermeta name="role" content="Application Developer"/>
      <othermeta name="role" content="Network Engineer"/>
      <othermeta name="role" content="Paul F"/>
      <othermeta name="product-version1" content="HPE Helion Openstack"/>
      <othermeta name="product-version2" content="HPE Helion Openstack 1.1"/>
    </metadata>
  </prolog>
  <body>
    <p>
      <!--PUBLISHED-->
      <!--./commercial/GA1/1.1commercial.troubleshooting.logging.md-->
      <!--permalink: /helion/openstack/1.1/services/troubleshooting/logging/--></p>
    <p>HPE Helion OpenStack is an OpenStack technology coupled with a version of <tm tmtype="reg"
        >Linux</tm> provided by HP. This topic describes all the known issues that you might
      encounter. To help you resolve these issues, we have provided possible solutions.</p>
    <section id="logging-best-practices">
      <title>Logging Best Practices</title>
      <p>By default a full backup includes all logs. Logs can be large, which can slow down the
        backup process. During this time, the control plane is offline.</p>
      <p>To balance having useful logs with optimizing system performance, you should routinely
        clean up logs from <codeph>logstash</codeph> to only keep logs of interest. You should only
        do a full backup if you need to preserve logs. In most cases, the exclude option is
        appropriate.</p>
      <!-- Removed per DOCS-851
## Issue in Logging {#issue-in-logging}

The user needs to manually follow the below steps to re-configure Kibana for logging.

1. Log in to the undercloud and start screen session.
2. In the screen, start following command 

    `sudo -u logstash /usr/bin/java -Xmx1g -Djava.io.tmpdir=/var/lib/logstash/ -jar /opt/logstash/logstash.jar agent -f /etc/logstash/conf.d -w 10 -??-log /var/log/logstash/logstash.log`

3. Press Control **&** '**a**', then '**c**' to create another shell.

4. In a new shell execute command 

    `sudo -u logstash /usr/bin/java -Xmx1g -Djava.io.tmpdir=/var/lib/logstash/ -jar /opt/logstash/logstash.jar agent -f /etc/logstash/conf.d -w 10 -??-log /var/log/logstash/logstash.log`

5. Repeat steps from **3-4** two times

6. Press Control **&** '**a**' then '**d**' to detach.
 
**Note**: If node reboots repeat the step from **1-6**.

**EDIT**: Added `sudo -u logstash` at beginning of commands. 
-->
    </section>
    <section id="logs-can-fill-undercloud-node">
      <title>Logs can fill undercloud node</title>
      <p>Logs are stored in one index per day in the Elasticsearch database but are not rotated.</p>
      <p>Because logs are not rotated, the logs can accumulate and consume significant space on the
        undercloud.</p>
      <p>Use the following command to view information on log storage:</p>
      <codeblock>
  <codeph>curl http://localhost:9200/_cat/indices?v
</codeph>
</codeblock>
      <p>The following is an example of output from this command:</p>
      <codeblock>
  <codeph>health index pri rep docs.count docs.deleted store.size pri.store.size
yellow logstash-2015.02.10 5 1 33758082 0 16.5gb 16.5gb
yellow logstash-2015.02.11 5 1 27471823 0 13.6gb 13.6gb
</codeph>
</codeblock>
      <p>You can delete older data using following command:</p>
      <codeblock>
  <codeph>curl -X DELETE http://localhost:9200/[index name]
</codeph>
</codeblock>
    </section>
    <section id="the-number-of-logstash-processes-might-not-be-sufficient">
      <title>The number of logstash processes might not be sufficient</title>
      <p>On larger installations, logstash may not be able to process logs as they are produced. In
        this case unprocessed logs are stored in RabbitMQ queue and this queue is increasing.</p>
      <p>To check size of queue, use the following command:</p>
      <codeblock>
  <codeph>rabbitmqctl list_queues | grep logs
</codeph>
</codeblock>
      <p>The output of the command is similar to the following:</p>
      <codeblock>
  <codeph>logstash-queue 0
</codeph>
</codeblock>
      <p>If the queue is more than zero, wait a few minutes and run command again. If the size has
        increased, logs are not being processed quickly enough and the number of logstash processes
        should be increased.</p>
      <p>To increase logstash processes:</p>
      <ol>
        <li>
          <p>Stop logstash using command</p>
          <p>service logstash stop</p>
        </li>
        <li>
          <p>In the <codeph>/etc/default/logstash</codeph> file, find the
              <codeph>LS_NUM_INSTANCES</codeph> line and change the value to a larger number.</p>
        </li>
        <li>
          <p>Restart logstash using the following command</p>
          <p>service logstash start</p>
        </li>
      </ol>
      <p>In approximately 15 minutes logstash starts processing. Re-check the queue size to make
        sure the queue size is reducing.</p>
    </section>
    <section id="sos">
      <title>Contacting Customer Service</title>
      <p>If you need further assistance, contact <xref href="http://www.hpcloud.com/about/contact"
            format="html">HPE Customer Support</xref>.</p>
      <p>Before contacting HPE Customer Support, <xref
          href="1.1commercial.troubleshooting.xml#topic2105/sos" type="section">run the
            <codeph>run-sosreport</codeph> command</xref> on the affected system.</p>
      <p>
        <xref href="#topic2924"> Return to Top </xref>
      </p>
    </section>
  </body>
</topic>
