<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic5926">
<title>HPE Helion <tm tmtype="reg">OpenStack</tm> 1.1 and 1.1.1: Create the baremetal.csv File for Installation</title>
<titlealts>
<searchtitle>HPE Helion Openstack 1.1: Create the baremetal.csv File for Installation</searchtitle>
</titlealts>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HPE Helion Openstack 1.1"/>
<othermeta name="role" content="Storage Administrator"/>
<othermeta name="role" content="Storage Architect"/>
<othermeta name="role" content="Michael B,"/>
<othermeta name="product-version1" content="HPE Helion Openstack 1.1"/>
</metadata>
</prolog>
<body>
<p>
<!--PUBLISHED-->
 <!--./commercial/GA1/1.1commercial.install-GA-CSV.md-->
 <!--permalink: /helion/openstack/1.1/install/csv/--></p>
<p>
  <b>This document describes the installation process for HPE Helion OpenStack 1.1 and HPE Helion OpenStack 1.1.1.</b>
</p>
<p>(If you already have 1.1 installed, you can update Helion OpenStack from 1.1 to 1.1.1 by following the update procedures described in <xref href="../../commercial/GA1/1.1.1commercial.helion-update.xml" >HPE Helion OpenStack 1.1.1 Update Guide</xref>.)</p>
<p>During the installation process after the seed VM is installed, the installer script looks for information about the baremetal systems. Specifically, it looks for this information in a file called <codeph>baremetal.csv</codeph>. Before you begin the installation process, you must create this file and upload the file to the installer system (called the seed cloud host) at the appropriate installation step.</p>
<p>The baremetal.csv file informs the installer of the size of the Computer that each node will be installed into.</p>
<p>Specify the MAC address, CPU, memory, local disk size, IPMI address, and IPMI password values for each baremetal system you intend to install.</p>
<p>There must be one entry in this file for each baremetal system you intend to install.</p>
<p>Use the following format in the <codeph>baremetal.csv</codeph> file.</p>
<codeblock><codeph>&lt;mac_address&gt;, &lt;user&gt;, &lt;password&gt;, &lt;ip_address&gt;, &lt;no_of_cpus&gt;, &lt;memory_MB&gt;, &lt;diskspace_GiB&gt;, &lt;role&gt;, &lt;power_management&gt;
</codeph></codeblock>
<p>Where <codeph>&lt;mac_address&gt;</codeph> is the MAC address of the network interface from which to boot. <b>Do not use the iLO NIC interface.</b>
</p>
<p>
<b>Important</b> The diskspace size value must be specified in Gibibytes, not Gigabytes.  For example:<!--A BR tag was used here in the original source.-->
 900GB = 838 GiB<!--A BR tag was used here in the original source.-->
 1TB = 1000GB = 931 GiB</p>
<p>
  <b>Example:</b>
</p>
<p>The following is a sample file:</p>
<codeblock><codeph>78:e7:d1:22:5d:58,administrator,password,192.168.11.1,12,32768,2048,Undercloud,IPMI
78:e7:d1:22:5d:10,administrator,password,192.168.11.5,12,32768,2048,OvercloudControl,IPMI
78:e7:d1:22:52:90,administrator,password,192.168.11.3,12,32768,2048,OvercloudControl,IPMI
78:e7:d1:22:5d:c0,administrator,password,192.168.11.2,12,32768,2048,OvercloudControl,IPMI
78:e7:d1:22:5d:a8,administrator,password,192.168.11.4,12,32768,2048,OvercloudSwiftStorage,IPMI
78:e7:d1:22:52:9b,administrator,password,192.168.11.6,12,32768,2048,OvercloudSwiftStorage,IPMI
78:e7:d1:22:52:9e,administrator,password,192.168.11.7,12,32768,2048,OvercloudCompute,IPMI
E4:11:5B:B7:AE:BE,Administrator,gone2far,10.1.192.40,12,73728,70,OvercloudVSAStorage
E8:39:35:21:2B:50,Administrator,gone2far,10.1.192.35,12,73728,70,OvercloudVSAAOStorage
</codeph>
</codeblock>
<p>
<!--1071 added last 2 lines above -->
When creating this file, keep the following in mind :</p>
<ul>
<li>This file must contain from 7 to 100 lines. (100 being the maximum number of nodes supported in an HPE Helion install.)</li>
<li>There must be one entry in this file for each baremetal system you intend to install.</li>
<li>The <codeph>mac_address</codeph> should be the MAC address of the network interface enabled for PXE/network boot on each baremetal system (<i>not</i> the MAC address of the BMC/IPMI controller).</li>
<li>The systems specified in this file must meet the Hardware Requirements detailed above.</li>
<li>The IPMI user and password must have ADMINISTRATOR privilege (it is not sufficient to have OPERATOR privilege).</li>
<li>The <codeph>diskspace_GiB</codeph> specified should never exceed the physical disk size and is in units of GiB (2^30)</li>
<li>The <codeph>role</codeph> can have these values (roles are case-insensitive): <ul>
          <li>Undercloud, </li>
          <li>OvercloudControl, </li>
          <li>OvercloudSwiftStorage, </li>
          <li>OvercloudCompute</li>
          <li>OvercloudVSAStorage, </li>
          <li>OvercloudVSAAOStorage, </li>
          <li>OvercloudSOSwiftProxy,</li>
          <li>OvercloudSOSwiftStorage</li>
        </ul></li>
</ul>
<ul>
<li>
<p>
<b>If role is not specified, then these rules apply, in this priority order:</b>
</p>

<ul>
<li>If no Undercloud node is specified then the first node without a role is assigned as an Undercloud</li>
<li>If there are not enough OvercloudControl nodes, the next nodes without a role are assigned as OvercloudControl until there are enough nodes</li>
<li>If there are not enough OvercloudSwiftStorage nodes the next nodes without a role are assigned as OvercloudSwiftStorage, until there are enough nodes</li>
<li>Similar logic is applied for VSA and Scale-Out Swift node assignments</li>
<li>The remaining nodes without a role will be assigned a role of OvercloudCompute</li>
</ul>
</li>
</ul>
    <note>
      <ul id="ul_s5s_b35_ps">
        <li>The required numbers of OvercloudControl and OvercloudSwiftStorage nodes default to 3
          and 2 respectively.</li>
        <li><codeph>power_management</codeph> can have these values:<ul id="ul_vbl_c35_ps">
            <li>VM</li>
            <li>IPMI </li>
            <li>HP_Moonshot </li>
            <li>HP_iLO4</li>
          </ul><table id="table_bdl_c35_ps">
            <tgroup cols="2">
              <colspec colname="col1"/>
              <colspec colname="col2"/>
              <thead>
                <row>
                  <entry colsep="1" rowsep="1">Value</entry>
                  <entry colsep="1" rowsep="1">Description</entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry colsep="1" rowsep="1">VM</entry>
                  <entry colsep="1" rowsep="1">This is for virtual machines and is set automatically
                    for a virtual install.</entry>
                </row>
                <row>
                  <entry colsep="1" rowsep="1">IPMI</entry>
                  <entry colsep="1" rowsep="1">This is for all systems that can be accessed using
                    IPMI. If no power_management is specified, a default of IPMI is assumed.</entry>
                </row>
                <row>
                  <entry colsep="1" rowsep="1">HP_Moonshot</entry>
                  <entry colsep="1" rowsep="1">This is for HPE Moonshot hardware only. If this is
                    specified it *requires* two colon-separated extra arguments as follows:
                      <b>&lt;transit_address&gt;:&lt;target_address&gt;</b>
                    <!--A BR tag was used here in the original source.-->
                    <!--A BR tag was used here in the original source.--> &lt;transit_address&gt; is
                    also known as 'Cartridge Address' &lt;target_address&gt; is also known as 'Node
                    Address' For example:
                    HP_Moonshot:0x84:0x72<!--A BR tag was used here in the original source.--><!--A BR tag was used here in the original source.-->
                    HPE Moonshot hardware will use ipmitool as its power manager. See the additional
                    notes in the <xref
                      href="../../commercial/GA1/1.1commercial.install-GA-Moonshot.xml">HPE Moonshot
                      document</xref>.</entry>
                </row>
                <row>
                  <entry>HP_iLO4</entry>
                  <entry>Boot HPE iLO4 Gen9 systems in UEFI mode. Specify IPMI to boot such nodes in
                    BIOS mode (you must manually set the pending boot mode to BIOS mode). </entry>
                </row>
              </tbody>
            </tgroup>
          </table></li>
      </ul>
    </note>
<ul>
<li>
<p>power_management maps to OpenStack Ironic power drivers as
follows:</p>

<ul>
<li>VM: pxe_ssh, </li>
<li>(IPMI, HP_Moonshot): pxe_ipmitool, </li>
<li>HP_iLO4: pxe_ilo</li>
</ul>
</li>
</ul>
<p>
<b>Important</b>: Make sure that the information specified is correct. If any node fails to install, you must restart the installation from the beginning.</p>
<p>
    <xref
      href="1.1commercial.install-GA-prereqs.xml#topic9786"> Return to HPE Helion OpenStack Installation Prerequisites.</xref></p>
<!-- ===================== horizontal rule ===================== -->
</body>
</topic>
