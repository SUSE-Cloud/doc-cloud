<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic2919">
<title>HPE Helion <tm tmtype="reg">OpenStack</tm> 1.1: Troubleshooting the Controller Nodes</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HPE Helion Openstack"/>
<othermeta name="product-version" content="HPE Helion Openstack 1.1"/>
<othermeta name="role" content="Systems Administrator"/>
<othermeta name="role" content="Cloud Architect"/>
<othermeta name="role" content="Storage Administrator"/>
<othermeta name="role" content="Network Administrator"/>
<othermeta name="role" content="Service Developer"/>
<othermeta name="role" content="Cloud Administrator"/>
<othermeta name="role" content="Application Developer"/>
<othermeta name="role" content="Network Engineer"/>
<othermeta name="role" content="Paul F"/>
<othermeta name="product-version1" content="HPE Helion Openstack"/>
<othermeta name="product-version2" content="HPE Helion Openstack 1.1"/>
</metadata>
</prolog>
<body>
<p>
<!--PUBLISHED-->
 <!--./commercial/GA1/1.1commercial.troubleshooting.controllers.md-->
 <!--permalink: /helion/openstack/1.1/services/troubleshooting/controllers/--></p>
<p>HPE Helion OpenStack is an OpenStack technology coupled with a version of <tm tmtype="reg">Linux</tm> provided by HP. This topic describes all the known issues that you might encounter. To help you resolve these issues, we have provided possible solutions.</p>
<ul>
<li>
<xref type="section" href="#topic2919/foreverupdate">Heat Stack Updates Take 30+ Minutes</xref>
</li>
<li>
<xref type="section" href="#topic2919/keepalivefail">A keepalived service fails to bring up VIP</xref>
<!-- [After Updating, Cinder Create and Backups Fail](#failcinder)--></li>
</ul>
<!-- ===================== horizontal rule ===================== -->
<section id="foreverupdate"> <title>Heat Stack Updates Take 30+ Minutes</title>
<p>
  <b>System Behavior/Message:</b>
</p>
<p>When <xref href="../../commercial/GA1/1.1commerical.services-remove-replace-failed-overcloud-nodes.dita" >Replacing a Failed Overcloud Controller</xref>, a Heat stack-update appears to be taking a long time (30 minutes or longer).</p>
<p>
  <b>Solution</b>
</p>
<p>Identify which resource is updating: From the seed, run following command to get an indication of which nodes to look at.</p>
<codeblock>
  <codeph>heat resource-list overcloud-ce-controller | grep -v -i complete
</codeph>
</codeblock>
<p>
  <b>View Logs</b>
</p>
<ol>
<li>
<p>On the controller node, look at the <codeph>/var/log/upstart/os-collect-config.log</codeph> for errors. Error messages for <codeph>os-refresh-config</codeph> are the most likely to indicate what the problem is.</p>

<ul>
<li>
<p>If the <codeph>waiting on os-svc-restart -n rabbitmq-server</codeph> message appears in the log then execute the following command.</p>

<codeblock>
<codeph>sudo pkill -u rabbitmq
sudo rm -rf /mnt/state/var/lib/rabbitmq
sudo rm -rf /mnt/state/var/log/rabbitmq
sudo os-refresh-config
ironic port-create --address &lt;MAC&gt; --node_uuid &lt;UUID&gt;
</codeph>
</codeblock>
</li>
</ul>
          <note>If you see the following error after runing<codeph>os-refresh-config</codeph>,
            re-run the command.</note>

<codeblock>
<codeph>        ERROR: os-refresh-config:Could not lock /var/run/os-refresh-config.lock. [Errno 11] Resource temporarily unavailable.
</codeph>
</codeblock>

<ul>
<li>
<p>After adding back controller0, you see that controller1 is the only node in the cluster, and other nodes are taking a long time to join the cluster, run the following command on the controllers to show cluster status:</p>

<codeblock>
<codeph>sudo rabbitmqctl cluster_status
</codeph>
</codeblock>
</li>
</ul>
<p>If the cluster name is not <codeph>controller0</codeph>, run the following command to add the node to the <codeph>controller0</codeph> cluster:</p>

<codeblock>
<codeph>sudo rabbitmqctl stop_app
sudo rabbitmqctl forget_cluster_node &lt;cluster node name&gt;
sudo rabbitmqctl start_app
sudo rabbitmqctl join_cluster_node &lt;controller0 clustername&gt;
sudo os-refresh-config
</codeph>
</codeblock>
</li>
<li>
<p>On the seed node, verify the logs in <codeph>/var/log/</codeph> directories, especially those in the <codeph>heat</codeph>, <codeph>nova</codeph> and <codeph>ironic</codeph> subdirectories respectively.</p>

<codeblock>
<codeph>sudo tail -f /var/log/upstart/os-collect-config.log
</codeph>
</codeblock>
</li>
</ol>
<!-- ## After Updating, Cinder Create and Backups Fail {#failcinder}

After updating to HPE Helion OpenStack 1.1, Cinder [backup](#backupfail) and Cinder [create volume from image](#volumefail) (bootable volume) fail. 

This indicates that ISCSI authentication is failing on controller0. The work-around is to migrate the cinder-volume service to another node and then stop the Cinder Backup service on controller0.

###Fails to Create Volume {#volumefail}

For example, the following command resulted in a volume with the status 'error'

    cinder create -??-image-id eeecc4aa-8a99-447d-848f-c40f4af0d606 -??-availability-zone nova -??-display-name bv_deb_001 -??-display_description bv_deb_001 20
    +=====================+======================================+
    |       Property      |                Value                 |
    +=====================+======================================+
    |     attachments     |                  []                  |
    |  availability_zone  |                 nova                 |
    |       bootable      |                false                 |
    |      created_at     |      2015-02-21T19:44:20.394735      |
    | display_description |              bv_deb_001              |
    |     display_name    |              bv_deb_001              |
    |      encrypted      |                False                 |
    |          id         | 0260a9e1-2e4a-444f-81d7-867f63f23fe9 |
    |       image_id      | eeecc4aa-8a99-447d-848f-c40f4af0d606 |
    |       metadata      |                  {}                  |
    |         size        |                  20                  |
    |     snapshot_id     |                 None                 |
    |     source_volid    |                 None                 |
    |        status       |               creating               |
    |     volume_type     |                 None                 |
    +=====================+======================================+
    
    $ cinder list
    +======================================+========+==============+======+============-+=========-+============-+
    |                  ID                  | Status | Display Name | Size | Volume Type | Bootable | Attached to |
    +======================================+========+==============+======+============-+=========-+============-+
    | 0260a9e1-2e4a-444f-81d7-867f63f23fe9 | error  |  bv_deb_001  |  20  |     None    |  false   |             |
    +======================================+========+==============+======+============-+=========-+============-+

If this error message occurs, **confirm** that the cause is an ISCSI error.

1. Search for the following string in */var/log/cinder/cinder-volume.log* on controller0:

        grep 'Failed to copy image <image-id> to volume: <volume-id>, error: iscsiadm: No session found.' /var/log/cinder/cinder-volume.log
        2015-02-23 13:46:01.415 21650 ERROR cinder.volume.flows.manager.create_volume [req-918f993f-5456-4eba-a266-67a638e9aa99 9f5ec59efa57483aad14b20378091195 c4b1111b613c4454a4cb3101ac420f54 - - -] Failed to copy image eeecc4aa-8a99-447d-848f-c40f4af0d606 to volume: 0260a9e1-2e4a-444f-81d7-867f63f23fe9, error: iscsiadm: No session found.

2. If the string is found, [failover the cinder-volume manager](/helion/openstack/high-availability#cinder-volume) from controller0 to controller1. 
3. Stop the cinder-volume service on controller0.

        sudo service cinder-volume stop
        sudo os-svc-enable-upstart cinder-volume disable


4. Start the cinder-volume service on controller1.
 
        sudo os-svc-enable-upstart cinder-volume enable
        sudo service cinder-volume start

###Backup Fails {#backupfail}

In the case of Cinder volume backups, the following command may result in a volume backup with the status 'error'

    cinder backup-create -??-display-name test10-backup001 dce6491b-87b9-4ccf-89bf-d38540a72
    +===========+======================================+
    |  Property |                Value                 |
    +===========+======================================+
    |     id    | a4ae0286-ba48-4d28-a6b2-4a0022c1f46b |
    |    name   |           test10-backup001           |
    | volume_id | dce6491b-87b9-4ccf-89bf-d38540a72580 |
    +===========+======================================+
    
    cinder backup-list
    +======================================+======================================+===========+==================+======+==============+===============+
    |                  ID                  |              Volume ID               |   Status  |       Name       | Size | Object Count |   Container   |
    +======================================+======================================+===========+==================+======+==============+===============+
    | a4ae0286-ba48-4d28-a6b2-4a0022c1f46b | dce6491b-87b9-4ccf-89bf-d38540a72580 |   error   | test10-backup001 |  10  |     None     |      None     |
    +======================================+======================================+===========+==================+======+==============+===============+
    

If this error occurs, **confirm** that the cause is an ISCSI error.

1. Search the /var/log/cinder/cinder-backup.log on **each** of the controller nodes.

        grep 'Unexpected error while running command' /var/log/cinder/cinder-backup.log | grep <volume-id> | grep 'iscsiadm: No session found'

2. If you find that the error is present on a controller node, stop the cinder-backup service on that node.
    
        sudo service cinder-backup stop

<hr />
-->
</section>
<section id="keepalivefail"> <title>A keepalived service fails to bring up VIP</title>
<p>
  <b>System Behavior/Message:</b>
</p>
<p>Keepalived is not bringing up the Virtual IP (VIP).</p>
<p>
  <b>Solution</b>
</p>
<p>To fix this problem:</p>
<p>Restart keepalived on all three controllers by entering:</p>
<codeblock>
  <codeph>service keepalived restart
</codeph>
</codeblock>
      <note> API requests will fail until the new keepalived cluster restarts.</note>
<p>
  <xref href="#topic2919"> Return to Top </xref>
</p>
</section>
</body>
</topic>
