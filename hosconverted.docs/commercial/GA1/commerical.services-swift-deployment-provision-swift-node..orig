---
layout: default
title: "HP Helion OpenStack&#174; Object Operations Service Overview"
permalink: /helion/openstack/services/swift/provision-nodes-orig/
product: commercial.ga
product-version1: HP Helion OpenStack
product-version2: HP Helion OpenStack 1.0
product-version3: HP Helion OpenStack 1.0.1
product-version4: HP Helion OpenStack 1.1
role1: Storage Administrator
role2: Storage Architect
authors: Keshava HP, Binamra S

---
<!--UNDER REVISION-->

<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>

<!--
<p style="font-size: small;"> <a href="/helion/openstack/services/object/overview/">&#9664; PREV</a> | <a href="/helion/openstack/services/overview/">&#9650; UP</a> | <a href=" /helion/openstack/services/swift/deployment/"> NEXT &#9654</a> </p>-->


# HP Helion OpenStack&#174;: Provisioning Object Storage (Swift) Node(s) 

This page describes the procedure to provision scale-out Swift nodes. 
<!---
**Caution**: Do not provision proxy and scale-out object nodes together as the requirements for each are different. It is recommended that you use HP DL380 or HP SL230 servers for Proxy nodes and SL4540 servers for scale-out object storage nodes. --->

* [Prerequisites](#Preq)
* [Add a new physical server](#adding-physical-server-for-scale-out-Swift) 
* [Verify the node deployment](#verify-swift-node-deployment) 

##Prerequisites {#Preq}

A HP Helion OpenStack&#174; cloud must be deployed. This ensures that the Starter Swift nodes are installed and functional as they are part of the default HP Helion OpenStack cloud deployment.

You can check the health of the starter nodes using the following command. All nodes should be in **ACTIVE** status and the power state should be **Running**.

	# nova list

##Adding physical server to scale-out Object Storage (Swift) {#adding-physical-server-for-scale-out-Swift}

You must add a server to the cloud inventory to handle the increased number of nodes. 

Perform the following steps to add a physical server:

1. Log in to the seed VM:

		ssh root@<Seed IP Address>

2. Make the respective Baremetal entry in `/root/baremetal.csv`.   
	
3. Add the node to `baremetal.csv` at the end.

		<mac_address>,<user>,<password>,<ip_address>,<no_of_cpus>,<memory_MB>,<diskspace_GiB>,<role>,<power_managemenment>

	The following sample displays the output of the above command:

		E8:39:35:2B:FA:30,administrator,password,10.1.192.46,12,73728,70,OvercloudSOSwiftProxy,IPMI
		9C:B6:54:AD:55:A8,administrator,gone2far,10.1.192.50,12,73728,70,overcloudsoswiftstorage,IPMI



  	Ensure that a new node is added at the end of the file. 

3. Edit the scale counts in JSON environment variables file ( for example: `kvm-custom-ips.json`) that was used during the initial installation to define the appropriate scale number:

		"so_swift_storage_scale":<number of object servers>,
		"so_swift_proxy_scale":<number of proxy servers>,

 	**Note**: While deploying a scale-out **proxy** node ensure that the value of `so_swift_storage_scale` is unchanged. While deploying a scale-out **object** node ensure that the value of `so_swift_proxy_scale` is unchanged.

4. Source the environment variables file created during initial installation.

		# source tripleo/tripleo-incubator/scripts/hp_ced_load_config.sh tripleo/configs/<environment variables file name>

	For example:

		# source tripleo/tripleo-incubator/scripts/hp_ced_load_config.sh tripleo/configs/kvm-custom-ips.json


5. Run the installer script:

		bash -x tripleo/tripleo-incubator/scripts/hp_ced_installer.sh --update-overcloud 2>&1 | tee update.log


   This will register a new ironic node and create a new nova instance and a new heat stack.

**Caution**: Do not provision proxy and scale-out object nodes together. The requirements are different for proxy nodes and scale-out object nodes. It is recommended that you use HP DL380 or HP SL230 servers for Proxy nodes and SL4540 servers for scale-out Object storage nodes.

<!---
##Provision Object Storage (Swift) node {#provision-swift-node}

**Caution**: Do not provision proxy and scale-out object nodes together. The requirements are different for proxy nodes and scale-out object nodes. It is recommended that you use HP DL380 or HP SL230 servers for Proxy nodes and SL4540 servers for scale-out Object storage nodes. 

Perform the following steps to provision the Swift node:

1. Log in to the seed cloud.

		# ssh root@<Seed IP address>
		

2. Set the following variables in the environment variables file to configure the following values:

		"so_swift_storage_scale":<number of object servers>,
		"so_swift_proxy_scale":<number of proxy servers>,


	
 **Note**: While deploying a scale-out **proxy** node ensure that the value of `so_swift_storage_scale` is unchanged. While deploying a scale-out **object** node ensure that the value of `so_swift_proxy_scale` is unchanged.

3.Source the environment variables file created during initial installation.

	# source tripleo/tripleo-incubator/scripts/hp_ced_load_config.sh tripleo/configs/<environment variables file name>

For example:

	# source tripleo/tripleo-incubator/scripts/hp_ced_load_config.sh tripleo/configs/kvm-custom-ips.json

4.Run the installer script to update the cloud.

	# bash -x tripleo/tripleo-incubator/scripts/hp_ced_installer.sh --update-overcloud |& tee update_cloud.log
--->

## Verify Object Storage (Swift) node deployment {#verify-swift-node-deployment}

Verify that the new nodes were created and are functioning properly using the following commands:

1. Log in to the undercloud from the seed cloud.

		# ssh heat-admin@<undercloud IP address> 

2. List the available Swift nodes.

		# nova list

	It displays available Swift nodes including the newly added node(s).


<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top &#8593; </a>


----
