<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: ready for edit-->
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="stop_restart">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Bringing Down Your Cloud: Services Down
    Method</title>
  <abstract><shortdesc outputclass="hdphidden">If you have a planned maintenance and need to bring
      down your entire cloud follow the steps below to safely do so. Be mindful that this method
      will bring down all of your services.</shortdesc></abstract>
  <body>
    <!--not tested-->
    <p conkeyref="HOS-conrefs/applies-to"/>
    <section id="about">
      <p>If you have a planned maintenance and need to bring down your entire cloud, follow the
        steps below to safely do so. Be mindful that this method will bring down all of your
        services. If you wish to use a method utilizing rolling reboots where your cloud services
        will continue running then see <xref href="reboot_cloud_rolling.xml"/>.</p>
      <p>If you wish to do any backups prior to these steps, visit the backup and restore pages
        first at <xref href="../../bura/bura_overview.xml"/>.</p>
    </section>
    <section id="steps"><title>Gracefully Bringing Down and Restarting Your Cloud
        Environment</title>
      <p>You will do the following steps from your lifecycle manager.</p>
      <ol>
        <li>Log in to your lifecycle manager.</li>
        <li>Gracefully shut down your cloud by running the <codeph>hlm-stop.yml</codeph> playbook:
          <codeblock>cd ~/scratch/ansible/next/hos/ansible
            ansible-playbook -i hosts/verb_hosts hlm-stop.yml</codeblock></li>
        <li>Shut down your nodes. You should shut down your controller nodes last and bring them up
          first after the maintenance. <p>There are multiple ways you can do this:</p><ol>
            <li>You can SSH to each node and use <codeph>sudo reboot -f</codeph> to reboot the
              node.</li>
            <li>From the lifecycle manager, you can use the <codeph>bm-power-down.yml</codeph> and
                <codeph>bm-power-up.yml</codeph> playbooks.</li>
            <li>You can shutdown the nodes and then physically restart them either via a power
              button or the iLO.</li>
          </ol></li>
        <li>Perform the necessary maintenance.</li>
        <li>After the maintenance is complete, power your lifecycle manager back up and then SSH to
          it.</li>
        <li>Determine the current power status of the nodes in your environment:
          <codeblock>cd ~/scratch/ansible/next/hos/ansible
            ansible-playbook -i hosts/verb_hosts bm-power-status.yml</codeblock></li>
        <li>If necessary, power up any nodes that aren't already powered up, ensuring that you power
          up your controller nodes first. You can target specific nodes with the <codeph>-e
            nodelist=&lt;node_name></codeph>
            switch.<codeblock>cd ~/scratch/ansible/next/hos/ansible
            ansible-playbook -i hosts/verb_hosts bm-power-up.yml [-e nodelist=&lt;node_name>]</codeblock><note>Obtain
            the <codeph>&lt;node_name></codeph> by using the <codeph>sudo cobbler system
              list</codeph> command from the lifecycle manager.</note></li>
        <li>Bring the databases back up:
          <codeblock>cd ~/scratch/ansible/next/hos/ansible
            ansible-playbook -i hosts/verb_hosts percona-bootstrap.yml</codeblock></li>
        <li>Gracefully bring up your cloud services by running the <codeph>hlm-start.yml</codeph>
          playbook:<codeblock>cd ~/scratch/ansible/next/hos/ansible
            ansible-playbook -i hosts/verb_hosts hlm-start.yml</codeblock></li>
        <li>Pause for a few minutes and give the cloud environment time to come up completely and
          then verify the status of the individual services using this
          playbook:<codeblock>cd ~/scratch/ansible/next/hos/ansible
            ansible-playbook -i hosts/verb_hosts hlm-status.yml</codeblock></li>
        <li>If any services did not start properly, you can run playbooks for the specific services
          having issues. <p>For example:</p><p>If RabbitMQ fails,
            run:</p><codeblock>cd ~/scratch/ansible/next/hos/ansible
              ansible-playbook -i hosts/verb_hosts rabbitmq-start.yml</codeblock><p>You
            can check the status of RabbitMQ afterwards with
            this:</p><codeblock>cd ~/scratch/ansible/next/hos/ansible
                  ansible-playbook -i hosts/verb_hosts rabbitmq-status.yml</codeblock><p>If
            the recovery had failed, you can
            run:</p><codeblock>cd ~/scratch/ansible/next/hos/ansible
                      ansible-playbook -i hosts/verb_hosts rabbitmq-disaster-recovery.yml</codeblock><p>Each
            of the other services have playbooks in the
              <codeph>~/scratch/ansible/next/hos/ansible</codeph> directory in the format of
              <codeph>&lt;service>-start.yml</codeph> that you can run. One example, for the compute
            service, is <codeph>nova-start.yml</codeph>.</p></li>
        <li>Continue checking the status of your <keyword keyref="kw-hos-phrase"/> cloud services
          until there are no more failed or unreachable nodes:
          <codeblock>cd ~/scratch/ansible/next/hos/ansible
            ansible-playbook -i hosts/verb_hosts hlm-status.yml</codeblock></li>
      </ol>
    </section>
  </body>
</topic>
