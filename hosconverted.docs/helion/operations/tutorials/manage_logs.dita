<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<!--Edit status: Edited (Michael)-->
<topic id="log_management_integration">
    <title>Log Management and Integration</title>
    <body>
        <section>
            <title>Overview</title>
            <p><keyword keyref="kw-hos"/> uses the ELK (Elasticsearch, Logstash, Kibana) stack for
                log management across the entire cloud infrastructure. This configuration
                facilitates simple administration as well as integration with third-party tools.
                This tutorial covers how to forward your logs to a third-party tool or service, and
                how to access and search the Elasticsearch log stores through API endpoints.</p>
            <p/>
        </section>
        <section id="section_pvm_zkx_1x">
            <title>The ELK stack</title>
            <p/>
            <p>The ELK logging stack is comprised of the Elasticsearch, Logstash, and Kibana
                elements:</p>
            <p/>
            <sectiondiv><b><?oxy_comment_start author="mwelch" timestamp="20160825T231551-0700" comment="Why not put this second in this list, to maintain the &quot;ELK&quot; order?" id="ez5_3q1_cx" mid="1"?><?oxy_comment_start author="jfrench" timestamp="20160826T150212-0700" comment="The pipeline flow of log data is L-E-K. My thinking is to describe the elements in the order that data reaches them." parentID="ez5_3q1_cx"?>Logstash<?oxy_comment_end?><?oxy_comment_end mid="1"?></b><p>Logstash
                    reads the log data from the services running on your servers, and then
                    aggregates and ships that data to a storage location. By default, Logstash sends
                    the data to the Elasticsearch
                    <?oxy_comment_start author="mwelch" timestamp="20160825T233421-0700" comment="The style guide says to use indexes, or does OpenStack use indices?" id="otb_5q1_cx" mid="3"?><?oxy_comment_start author="jfrench" timestamp="20160826T150529-0700" comment="I&apos;m not sure they have a standard. Since the two words mean the same thing, I&apos;m fine with either." parentID="otb_5q1_cx"?>indexes<?oxy_comment_end?><?oxy_comment_end mid="3"?>,
                    but it can also be configured to send data to other storage and indexing tools
                    such as Splunk.</p><p/></sectiondiv>
            <sectiondiv><b>Elasticsearch</b><p>Elasticsearch is the storage and indexing component
                    of the ELK stack. It stores and indexes the data received from Logstash.
                    Indexing makes your log data searchable by tools designed for querying and
                    analyzing massive sets of data. You can query the Elasticsearch datasets from
                    the built-in Kibana console, a third-party data analysis tool, or through the
                    Elasticsearch API (covered later).</p><p/></sectiondiv>
            <sectiondiv><b>Kibana</b><p>Kibana provides a simple and easy-to-use method for
                    searching, analyzing, and visualizing the log data stored in the Elasticsearch
                    <?oxy_delete author="jfrench" timestamp="20160830T142659-0700" content="indix"?><?oxy_insert_start author="jfrench" timestamp="20160830T142659-0700"?>index<?oxy_insert_end?>es.
                    You can customize the Kibana console to provide graphs, charts, and other
                    visualizations of your log data.</p><p/></sectiondiv>
        </section>
        <section id="section_d3k_gnx_1x">
            <title>Using the Elasticsearch API</title>
            <p/>
            <p>You can query the Elasticsearch
                <?oxy_delete author="jfrench" timestamp="20160830T142702-0700" content="indix"?><?oxy_insert_start author="jfrench" timestamp="20160830T142702-0700"?>index<?oxy_insert_end?>es
                through various language-specific APIs, as well as directly over the IP address and
                port that Elasticsearch exposes on your implementation. By default, Elasticsearch
                presents from localhost, port 9200. You can run queries directly from a terminal
                using <codeph>curl</codeph>. For example:</p>
            <p/>
            <p>
                <codeblock>curl -XGET 'http://localhost:9200/_search?q=tag:yourSearchTag'</codeblock>
            </p>
            <p>The preceding command searches all
                <?oxy_delete author="jfrench" timestamp="20160830T142705-0700" content="indix"?><?oxy_insert_start author="jfrench" timestamp="20160830T142705-0700"?>index<?oxy_insert_end?>es
                for all data with the "yourSearchTag" tag.</p>
            <p/>
            <p/>
            <p>You can also use the Elasticsearch API from outside the logging node. This method
                connects over the Kibana VIP address, port 5601, using basic http authentication.
                For example, you can use the following command to perform the same search as the
                preceding search: </p>
            <p/>
            <p>
                <codeblock>curl -u kibana:&lt;password> kibana_vip:5601/_search?q=tag:yourSearchTag</codeblock>
            </p>
            <p/>
            <p/>
            <p>You can further refine your search to a specific index of data, in this case the
                "elasticsearch" index:</p>
            <p/>
            <p>
                <codeblock>curl -XGET 'http://localhost:9200/elasticsearch/_search?q=tag:yourSearchTag'</codeblock>
            </p>
            <p/>
            <p/>
            <p>The search API is RESTful, so responses are provided in JSON format. Here's a sample
                (though empty) response:</p>
            <p/>
            <codeblock>{
    "took":13,
    "timed_out":false,
    "_shards":{
        "total":45,
        "successful":45,
        "failed":0
    },
    "hits":{
        "total":0,
        "max_score":null,
        "hits":[]
    }
}</codeblock>
        </section>
        <p/>
        <p/>
        <p>You can find more detailed Elasticsearch API documentation at <xref
                href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html"
                format="html" scope="external"/>.</p>
        <p/>
        <p>Review Elasticsearch Python API documentation at the following sources:</p>
        <p><xref href="http://elasticsearch-py.readthedocs.io/en/master/api.html" format="html"
                scope="external"/></p>
        <p><xref href="http://elasticsearch-py.readthedocs.io/en/master/api.html" format="html"
                scope="external"/></p>
        <p/>
        <p>Read Elasticsearch Java API documentation at </p>
        <p><xref
                href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/index.html"
                format="html" scope="external"/>.</p>
        <p/>
        <p/>
        <section id="section_knd_hcf_bx"><title>Forwarding your logs</title><p/>You can configure
            Logstash to ship your logs to an outside storage and indexing system, such as Splunk.
            Setting up this configuration is as simple as editing a few configuration files, and
            then running the Ansible playbooks that implement the changes. Here are the steps.<p/><p>
                <ol id="ol_mtz_mnr_bx">
                    <li>Begin by logging in to the Lifecycle Manager.<p/></li>
                    <li>Verify that the logging system is up and
                        running:<codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts logging-status.yml</codeblock><p/><?oxy_delete author="jfrench" timestamp="20160826T151956-0700" content="If"?><?oxy_insert_start author="jfrench" timestamp="20160826T151956-0700"?>When<?oxy_insert_end?>
                        the preceding playbook
                        <?oxy_comment_start author="mwelch" timestamp="20160826T144352-0700" comment="What if it doesn&apos;t?" id="pgv_ps1_cx" mid="5"?><?oxy_comment_start author="jfrench" timestamp="20160826T151929-0700" comment="That&apos;s a really good question. One best posed to the QA or dev team. They&apos;re the ones that provide approved procedures. I can really only include the procedures that they provide." parentID="pgv_ps1_cx"?>completes
                        without error<?oxy_comment_end?><?oxy_comment_end mid="5"?>, proceed to the
                        next step.<p/></li>
                    <li>Edit the Logstash configuration file, found at the following
                            location:<p/><codeblock>~/helion/hos/ansible/roles/logging-server/templates/logstash.conf.j2</codeblock><p/><p/><p>Near
                            the end of the Logstash configuration file, you'll find a section for
                            configuring Logstash output destinations. The following example
                            demonstrates the changes necessary to forward your logs to an outside
                            server (changes in bold). The configuration block sets up a TCP
                            connection to the destination server's IP address over port
                            5514.</p><p/><codeblock># Logstash outputs
                        #----------------------------------------------------------------------------------------
                        output {
                        # Configure Elasticsearch output
                        # http://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html
                        elasticsearch {
                        hosts => ["{{ elasticsearch_http_host }}:{{ elasticsearch_http_port }}"]
                        flush_size => 5000
                        idle_flush_time => 5
                        workers => {{ logstash_num_workers }}
                        }
                        <b>  # Forward Logs to outside source on TCP port 5514
                            tcp { 
                            mode => "client"
                            host => "&lt;Destination listener IP address>"
                            port => 5514</b>
                        }</codeblock><p/><p>Note
                            that Logstash can forward log data to multiple sources, so there's no
                            need to remove or alter the Elasticsearch section in the preceding file.
                            However, if you choose to stop forwarding your log data to
                            Elasticsearch, you can do so by removing the related section in this
                            file, and then continue with the following steps.</p><p/></li>
                    <li>Commit your changes to the local git
                        repository:<codeblock>cd ~/helion/hos/ansible
git add -A
git commit -m "Your commit message"</codeblock><p/><p/></li>
                    <li>Run the configuration
                        processor<?oxy_delete author="mwelch" timestamp="20160826T144548-0700" content=","?>
                        to check the status of all configuration
                        files:<p/><codeblock>ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock><?oxy_insert_start author="jfrench" timestamp="20160826T152601-0700"?><p/><?oxy_insert_end?></li>
                    <li><?oxy_comment_start author="mwelch" timestamp="20160826T144619-0700" comment="Should this be a separately numbered step?" id="fx4_pt1_cx" mid="7"?><?oxy_comment_start author="jfrench" timestamp="20160826T152701-0700" comment="Definitely. Nice catch. I had just reworked this to be a numbered list, looks like I got a bit sloppy." parentID="fx4_pt1_cx"?>Run
                        the ready-deployment
                        playbook:<?oxy_comment_end?><?oxy_comment_end mid="7"?><p/><codeblock>ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock><p/></li>
                    <li>Implement the changes to the Logstash configuration
                        file:<p/><codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts logging-server-configure.yml</codeblock></li>
                </ol>
            </p></section>
        <?oxy_insert_start author="jfrench" timestamp="20160830T142725-0700"?>
        <p>Please note that the configuring the receiving service will vary from product to product.
            Consult the documentation for your particular product for instructions on how to set it
            up to receive log files from logstash.</p>
        <?oxy_insert_end?>
    </body>

</topic>
