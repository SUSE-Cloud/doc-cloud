<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd" >
<topic xml:lang="en-us" id="central_log_troubleshoot">
  <title>Troubleshooting Centralized Logging</title>
  <body><!--not tested-->
<p>This section contains the following scenarios:</p>
    <ul>
      <li><xref href="#central_log_troubleshoot/review_logs">Reviewing Log Files</xref></li>
      <li><xref href="#central_log_troubleshoot/monitoring">Monitoring Centralized Logging</xref></li>
      <li><xref href="#central_log_troubleshoot/log_collection">Situations In Which Logs Might Not Be Collected</xref></li>
      <li><xref href="#central_log_troubleshoot/kibana_visualization">Error When Creating a Kibana Visualization</xref></li> 
      <li><xref href="#central_log_troubleshoot/deployAPI_error">After Deploying Logging-API, Logs Are Not Centrally Stored</xref></li>
      <li><xref href="#central_log_troubleshoot/slow_logging">Re-enable Slow Logging</xref></li>
    </ul>

    <section id="review_logs">
      <title>Reviewing Log Files</title>
      <p>You can troubleshoot service-specific issues by reviewing the logs. After logging into
        Kibana, follow these steps to load the logs for viewing:</p>
      <ol>
        <li>Navigate to the <b>Settings</b> menu to configure an index pattern to search for.</li>
        <li>In the <b>Index name or pattern</b> field, you can enter <codeph>logstash-*</codeph> to
          query all elasticsearch indices.</li>
        <li>Click the green <b>Create</b> button to create and load the index.</li>
        <li>Navigate to the <b>Discover</b> menu to load the index and make it available to
          search.</li>
      </ol>
      <note>If you want to search specific Elasticsearch indices, you can run the following command
        from the control plane to get a full list of available indices:
        <codeblock>curl localhost:9200/_cat/indices?v</codeblock></note>
      <p>Once the logs load you can change the timeframe from the dropdown in the upper-righthand
        corner of the Kibana window. You have the following options to choose from:</p>
      <ul>
        <li><b>Quick</b> - a variety of time frame choices will be available here</li>
        <li><b>Relative</b> - allows you to select a start time relative to the current time to show
          this range</li>
        <li><b>Absolute</b> - allows you to select a date range to query</li>
      </ul>
      <p>When searching there are common fields you will want to use, such as:</p>
      <ul>
        <li><b>type</b> - this will include the service name, such as <codeph>keystone</codeph> or
            <codeph>ceilometer</codeph></li>
        <li><b>host </b>- you can specify a specific host to search for in the logs</li>
        <li><b>file</b> - you can specify a specific log file to search</li>
      </ul>
      <p>For more details on using Kibana and Elasticsearch to query logs, see <xref
          href="https://www.elastic.co/guide/en/kibana/3.0/working-with-queries-and-filters.html"
          scope="external" format="html"
          >https://www.elastic.co/guide/en/kibana/3.0/working-with-queries-and-filters.html</xref></p>
    </section>
    
    
    <section id="monitoring">
      <title>Monitoring Centralized Logging</title>
      <p>To help keep ahead of potential logging issues and resolve issues before they affect
        logging, you may want to monitor the Centralized Logging Alarms.</p>
      <p><b>To monitor logging alarms:</b></p>
      <ol>
        <li>Log in to Operations Console.</li>
        <li>From the menu button in the upper left corner, navigate to the <b>Alarm Definitions</b>
          page.</li>
        <li>Find the alarm definitions that are applied to the various hosts. See the <xref
            href="alarm_resolutions.dita">Logging Alarm Definitions List</xref> for
          the Centralized Logging Alarm Definitions.</li>
        <li>Navigate to the <b>Alarms</b> page</li>
        <li>Find the alarm definitions applied to the various hosts. These should match the alarm
          definitions in the <xref href="alarm_resolutions.dita">Logging Alarm
            Definitions List</xref>.</li>
        <li>See if the alarm is green (good) or is in a bad state. If any are in a bad state, see
          the possible actions to perform in the <xref href="alarm_resolutions.dita"
            >Logging Alarms Definitions List</xref>.</li>
      </ol>
      <p>You can use this filtering technique in the "Alarms" page to look for the following:</p>
      <ol>
        <li>To look for processes that may be down, filter for <b>"Process"</b> then make sure the
          process are up: <ul>
            <li>Elasticsearch</li>
            <li>Logstash</li>
            <li>Beaver</li>
            <li>Apache (Kafka)</li>
            <li>Kibana</li>
            <li>Monasca</li>
          </ul></li>
      
      <li>To look for sufficient disk space, filter for <b>"Disk"</b></li>
      <li>To look for sufficient RAM memory, filter for <b>"Memory"</b></li>
      </ol>
    </section>
    
    <section id="log_collection">
      <title outputclass="headerH">Situations In Which Logs Might Not Be Collected</title>
      <sectiondiv outputclass="insideSection">
        <p>Centralized logging might not collect log data under the following circumstances:</p>
        <ul>
          <li>If the Beaver service is not running on one or more of the nodes (controller or
            compute), logs from these nodes will not be collected.</li>
        </ul>
      </sectiondiv>
    </section>
    
    <section id="kibana_visualization">
      <title outputclass="headerH">Error When Creating a Kibana Visualization</title>
      <sectiondiv outputclass="insideSection">
        <p>When creating a visualization in Kibana you may get an error similiar to this:
          <codeblock>"logstash-*" index pattern does not contain any of the following field types: number</codeblock></p>
        <p>To resolve this issue:</p>
        <ol>
          <li>Log in to Kibana.</li>
          <li>Navigate to the <codeph>Settings</codeph> page.</li>
          <li>In the left panel, select the <codeph>logstash-*</codeph> index.</li>
          <li>Click the <b>Refresh</b> button. You may see a mapping conflict warning after
            refreshing the index.</li>
          <li>Re-create the visualization.</li>
        </ol>
      </sectiondiv>
    </section>

    <section id="deployAPI_error">
      <title outputclass="headerH">After Deploying Logging-API, Logs Are Not Centrally Stored</title>
      <sectiondiv outputclass="insideSection">
        <p>If you are using the Logging-API and logs are not being centrally stored, use the following checklist to troubleshoot Logging-API.</p>
        <table frame="all" rowsep="1" colsep="1" id="deploying_logging_table">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1" colwidth="1*"/>
            <colspec colname="c2" colnum="2" colwidth="19*"/>
            <thead>
              <row>
                <entry>&#9744;</entry>
                <entry>Item</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry/>
                <entry>Ensure Monasca is running.</entry>
              </row>
              <row>
                <entry/>
                <entry>Check any alarms Monasca has triggered.</entry>
              </row>
              <row>
                <entry/>
                <entry>Check to see if the Logging-API (monasca-log-api) process alarm has triggered.</entry>
              </row>
              <row>
                <entry/>
                <entry>Run an Ansible playbook to get status of the Helion Lifecycle Manager:
                  <codeblock>ansible-playbook -i hosts/verb_hosts hlm-status.yml</codeblock></entry>
              </row>
              <row>
                <entry/>
                <entry>Troubleshoot all specific tasks that have failed on the Lifecycle Manager.</entry>
              </row>
              <row>
                <entry/>
                <entry>Ensure that the Logging-API daemon is up.</entry>
              </row>
              <row>
                <entry/>
                <entry>Run an Ansible playbook to try and bring the Logging-API daemon up:
                  <codeblock>ansible-playbook â€“I hosts/verb_hosts logging-start.yml</codeblock></entry>
              </row>
              <row>
                <entry/>
                <entry>If you get errors trying to bring up the daemon, resolve them.</entry>
              </row>
              <row>
                <entry/>
                <entry>Verify the Logging-API configuration settings are correct in the configuration file:
                  <codeblock>roles/kronos-api/templates/kronos-apache2.conf.j2</codeblock></entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <p>The following is a sample Logging-API configuration file:</p>
        <codeblock>{#
# (c) Copyright 2015-2016 Hewlett Packard Enterprise Development LP
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#
#}
Listen {{ kronos_api_host }}:{{ kronos_api_port }}
&lt;VirtualHost *:{{ kronos_api_port }}&gt;
    WSGIDaemonProcess log-api processes=4 threads=4 socket-timeout=300  user={{ kronos_user }} group={{ kronos_group }} python-path=/opt/stack/service/kronos/venv:/opt/stack/service/kronos/venv/bin/../lib/python2.7/site-packages/ display-name=monasca-log-api
    WSGIProcessGroup log-api
    WSGIApplicationGroup log-api
    WSGIScriptAlias / {{ kronos_wsgi_dir }}/app.wsgi
    ErrorLog /var/log/kronos/wsgi.log
    LogLevel info
    CustomLog /var/log/kronos/wsgi-access.log combined

    &lt;Directory /opt/stack/service/kronos/venv/bin/../lib/python2.7/site-packages/monasca_log_api&gt;
      Options Indexes FollowSymLinks MultiViews
      Require all granted
      AllowOverride None
      Order allow,deny
      allow from all
      LimitRequestBody 102400
    &lt;/Directory&gt;

    SetEnv no-gzip 1
&lt;/VirtualHost&gt;
</codeblock>
        
      </sectiondiv>
    </section>

    <section id="slow_logging">
      <title>Re-enabling Slow Logging</title>
      <p>MySQL slow logging was enabled by default in earlier versions. 
        Slow logging logs slow MySQL queries to /var/log/mysql/slow.log on FND-MDB hosts.
      </p>
      <p>As it is possible for temporary tokens to be logged to the slow log we 
        have disabled slow log in this version for security reasons.
      </p>
      <p>
        To re-enable slow logging follow the following procedure:
      </p>
      <p>
        <ol>
          <li>Login to the lifecycle manager and set a mysql service configurable to enable slow
            logging. <codeblock>cd ~/helion/my_cloud</codeblock> 
            <ol>
              <li>Check slow_query_log is currently disabled with a value of 0:
                <codeblock>grep slow ./config/percona/my.cfg.j2
slow_query_log          = 0
slow_query_log_file     = /var/log/mysql/mysql-slow.log</codeblock>
              </li>
              <li>Enable slow logging in the server configurable template file and confirm the new value:
                <codeblock>sed -e 's/slow_query_log = 0/slow_query_log = 1/' -i ./config/percona/my.cfg.j2
grep slow ./config/percona/my.cfg.j2
slow_query_log          = 1
slow_query_log_file     = /var/log/mysql/mysql-slow.log</codeblock>
              </li>
              <li>Commit the changes:
                <codeblock>git add -A
git commit -m "Enable Slow Logging"</codeblock>
              </li>
          
            </ol>
          </li>
          <li>Run the configuration procesor.
            <codeblock>cd ~/helion/hos/ansible/
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock>
          </li>
          <li>You will be prompted for an encryption key, and also asked if you want to change the
            encryption key to a new value, and it must be a different key. You can
            turn off encryption by typing the following:
            <codeblock>ansible-playbook -i hosts/localhost config-processor-run.yml -e encrypt="" -e rekey=""</codeblock>
          </li>
          <li>Create a deployment directory.
            <codeblock>ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock>
          </li>
          <li>Reconfigure Percona (note this will restart your mysqld server on your cluster hosts).
            <codeblock>ansible-playbook -i hosts/verb_hosts percona-reconfigure.yml</codeblock>
          </li>
        
        
        
        
        
        </ol>
      </p>
    </section>

  </body>
</topic>
