<?xml version="1.0"?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [ <!ENTITY % entities SYSTEM "entities.xml"> %entities; ]><!--Edit status: not edited-->
<section id="troubleshooting_ceph">
   <title>
      <phrase/>Ceph Storage Troubleshooting</title>
    
    <para/>
    <para id="idg-operations-troubleshooting-ts_ceph-dita-2">
      
      
    </para>


  <section id="idg-operations-troubleshooting-ts_ceph-dita-3">
      <title>Troubleshooting Ceph deployment issues</title>
      <para>Here is a list of known issues along with resolutions for Ceph deployment issues.</para>

      <formalpara id="issue1">
         <title>Issue: If no Ceph monitor nodes are defined for the cloud, then
          Ceph cloud deployment fails</title>
         <para/>
      </formalpara>
      <formalpara id="issue2">
         <title>Issue: If the disk presented as OSD data and/or a journal disk
          has some pre-existing partitions, then the Ceph cloud deployment fails</title>
         <para/>
      </formalpara>
      <formalpara id="issue3">
         <title>Issue: If on an entry-scale-kvm-ceph cloud, the controller
          nodes are not always a part of the actionable nodes then executing the site.yml playbook
          for a particular node (using --limit &lt;node&gt;) fails</title>
         <para/>
      </formalpara>
      <formalpara id="issue4">
         <title>Issue: If the time required for placement group creation is
          slower than usual (&gt;50 secs for PGs to get created), the ceph-client-prepare.yml playbook
          fails with an error while creating placement groups</title>
         <para/>
      </formalpara>
      <formalpara id="issue5">
         <title>Issue: During configuration of a new OSD disk, there is an
          error similar to "disk does not exist" during the "ceph-disk activate" phase</title>
         <para/>
      </formalpara>
      <formalpara id="issue6">
         <title>Issue: If the volume of requests to Ceph is too high, the logs
          generated by Ceph will fill up the disk quickly.</title>
         <para/>
      </formalpara>
      <formalpara id="issue7">
         <title>Issue: Cinder volume create fails consistently as insufficient
          disk space gets reported when an OSD is down.</title>
         <para/>
      </formalpara>
      <formalpara id="issue8">
         <title>Issue: Retrieving the UUID for your OSD Disks</title>
         <para/>
      </formalpara>


      <formalpara id="issue9">
         <title>Issue: Ceph playbooks fail during disk validation step</title>
         <para/>
      </formalpara>


      <formalpara id="issue10">
         <title>Issue: Nova volume-attach fails after configuring Ceph as the
          backend</title>
         <para/>
      </formalpara>

      <formalpara id="issue11">
         <title>Issue: Upgrade playbook fails if the
          monitor service does not come up on time</title>
         <para/>
      </formalpara>
      
      <formalpara>
         <title>Issue: Multiple OSDS fail to recover</title>
         <para/>
      </formalpara>
      
    </section>
   <section id="rados">
      <title>Troubleshooting RADOS Gateway Issues</title>
      <para>Here is a list of known issues along with resolutions for Ceph RADOS Gateway issues.</para>

      <formalpara>
         <title>Issue: Rados Gateway service does not come up after node
          is rebooted</title>
         <para/>
      </formalpara>


      <formalpara>
         <title>Issue: Rados Gateway service is not responding</title>
         <para/>
      </formalpara>

      <formalpara>
         <title>Issue: HTTP Request errors</title>
         <para/>
      </formalpara>

      <formalpara>
         <title>Issue: Failure of horizon-status.yml</title>
         <para/>
      </formalpara>
      

    </section>
</section>
