<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="compute_alarmdefinitions">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Compute Alarms</title>
  <body>
    <section>
      <p>These alarms show under the Compute section of the HPE Helion Ops Console.</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="compute_alarms">
          <tgroup cols="5">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <colspec colname="c3" colnum="3"/>
            <colspec colname="c4" colnum="4"/>
            <colspec colname="c5" colnum="5"/>
            <thead>
              <row>
                <entry>Service</entry>
                <entry>Alarm Name</entry>
                <entry>Description</entry>
                <entry>Likely Cause</entry>
                <entry>Mitigation Tasks to Perform</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry morerows="5">compute</entry>
                <entry>HTTP Status</entry>
                <entry>This is a <codeph>nova-api</codeph> health check</entry>
                <entry>Process crashed.</entry>
                <entry>Restart the <codeph>nova-api</codeph> process on the affected node. Review
                  the <codeph>nova-api.log</codeph> files. Try to connect locally to the http port
                  that is found in the dimension field of the alarm to see if the connection is
                  accepted.</entry>
              </row>
              <row>
                <entry>Host Status</entry>
                <entry>Alarms when the specified host is down or not reachable.</entry>
                <entry>The host is down, has been rebooted, or has network connectivity
                  issues.</entry>
                <entry>If it is a single host, attempt to restart the system. If it is multiple
                  hosts, investigate networking issues.</entry>
              </row>
              <row>
                <entry>Process Bound Check</entry>
                <entry><codeph>process_name=nova-api</codeph><p>This alarm checks that the number of
                    processes found is in a predefined range</p></entry>
                <entry>Process crashed or too many processes running</entry>
                <entry>Stop all the processes and restart the nova-api process on the affected host.
                  Review the system and nova-api logs.</entry>
              </row>
              <row>
                <entry>Process Check</entry>
                <entry>Separate alarms for each of these Nova services, specified by the
                    <codeph>component</codeph> dimension: <ul id="ul_qwq_1xp_mx">
                    <li>nova-api</li>
                    <li>nova-cert</li>
                    <li>nova-compute</li>
                    <li>nova-consoleauth</li>
                    <li>nova-conductor</li>
                    <li>nova-scheduler</li>
                    <li>nova-novncproxy</li>
                  </ul></entry>
                <entry>Process specified by the <codeph>component</codeph> dimension has crashed on
                  the host specified by the <codeph>hostname</codeph> dimension.</entry>
                <entry>Restart the process on the affected node using these steps: <ol
                    id="ol_rwq_1xp_mx">
                    <li>Log in to the lifecycle manager.</li>
                    <li>Use the Nova start playbook against the affected node:
                      <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts nova-start.yml --limit &lt;hostname></codeblock></li>
                  </ol><p>Review the associated logs. The logs will be in the format of
                      <codeph>&lt;service>.log</codeph>, such as <codeph>nova-compute.log</codeph>
                    or <codeph>nova-scheduler.log</codeph>.</p></entry>
              </row>
              <row>
                <entry>nova.heartbeat</entry>
                <entry>Check that all services are sending heartbeats.</entry>
                <entry>Process for service specified in the alarm has crashed or is hung and not
                  reporting its status to the database. Alternatively it may be the service is fine
                  but an issue with messaging or the database which means the status is not being
                  updated correctly.</entry>
                <entry>Restart the affected service. If the service is reporting OK the issue may be
                  with RabbitMQ or MySQL. In that case, check the alarms for those services.</entry>
              </row>
              <!-- OPSCON-2011
              <row>
                <entry>ESX cluster Memory Usage</entry>
                <entry>Alarms when ESX cluster memory usage is high.</entry>
                <entry/>
                <entry/>
              </row>
              <row>
                <entry>ESX cluster CPU Usage</entry>
                <entry>Alarms when ESX cluster CPU usage is high.</entry>
                <entry/>
                <entry/>
              </row>
              <row>
                <entry>ESX cluster Disk Usage</entry>
                <entry>Alarms when ESX cluster datastore usage is high.</entry>
                <entry/>
                <entry/>
              </row>
              -->
              <row>
                <entry>Service Log Directory Size</entry>
                <entry>Service log directory consuming more disk than its quota.</entry>
                <entry>This could be due to a service set to <codeph>DEBUG</codeph> instead of
                    <codeph>INFO</codeph> level. Another reason could be due to a repeating error
                  message filling up the log files. Finally, it could be due to log rotate not
                  configured properly so old log files are not being deleted properly.</entry>
                <entry>Find the service that is consuming too much disk space. Look at the logs. If
                    <codeph>DEBUG</codeph> log entries exist, set the logging level to
                    <codeph>INFO</codeph>. If the logs are repeatedly logging an error message, do
                  what is needed to resolve the error. If old log files exist, configure log rotate
                  to remove them. You could also choose to remove old log files by hand after
                  backing them up if needed.</entry>
              </row>
              <row>
                <entry morerows="1">image-service</entry>
                <entry>HTTP Status</entry>
                <entry>Separate alarms for each of these Glance services, specified by the
                    <codeph>component</codeph> dimension: <ul id="ul_swq_1xp_mx">
                    <li>glance-api</li>
                    <li>glance-registry</li>
                  </ul></entry>
                <entry>API is unresponsive.</entry>
                <entry>Restart the process on the affected node using these steps: <ol
                    id="ol_twq_1xp_mx">
                    <li>Log in to the lifecycle manager.</li>
                    <li>Use the Glance start playbook against the affected node:
                      <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts glance-start.yml --limit &lt;hostname></codeblock></li>
                  </ol>
                  <p>Review the associated logs.</p></entry>
              </row>
              <row>
                <entry>Service Log Directory Size</entry>
                <entry>Service log directory consuming more disk than its quota.</entry>
                <entry>This could be due to a service set to <codeph>DEBUG</codeph> instead of
                    <codeph>INFO</codeph> level. Another reason could be due to a repeating error
                  message filling up the log files. Finally, it could be due to log rotate not
                  configured properly so old log files are not being deleted properly.</entry>
                <entry>Find the service that is consuming too much disk space. Look at the logs. If
                    <codeph>DEBUG</codeph> log entries exist, set the logging level to
                    <codeph>INFO</codeph>. If the logs are repeatedly logging an error message, do
                  what is needed to resolve the error. If old log files exist, configure log rotate
                  to remove them. You could also choose to remove old log files by hand after
                  backing them up if needed.</entry>
              </row>
              <row>
                <entry morerows="3">baremetal</entry>
                <entry>Process Check</entry>
                <entry>Alarms when the specified process is not running.<p>
                    <codeblock>process_name = ironic-api</codeblock>
                  </p></entry>
                <entry>The Ironic API is unresponsive.</entry>
                <entry>Restart the <codeph>ironic-api</codeph> process with these steps: <ol
                    id="ol_uwq_1xp_mx">
                    <li>Log in to the affected host via SSH.</li>
                    <li>Restart the <codeph>ironic-api</codeph> process with this command:
                      <codeblock>sudo service ironic-api restart</codeblock></li>
                  </ol></entry>
              </row>
              <row>
                <entry>Process Check</entry>
                <entry>Alarms when the specified process is not running.<p>
                    <codeblock>process_name = ironic-conductor</codeblock>
                  </p></entry>
                <entry>The <codeph>ironic-conductor</codeph> process has crashed.</entry>
                <entry>Restart the <codeph>ironic-conductor</codeph> process with these steps: <ol
                    id="ol_vwq_1xp_mx">
                    <li>Log in to the lifecycle manager.</li>
                    <li>Source your <codeph>admin</codeph> user credentials:
                      <codeblock>source ~/service.osrc</codeblock></li>
                    <li>Locate the <codeph>messaging_deployer</codeph> VM:
                      <codeblock>nova list --all-tenants | grep mess</codeblock></li>
                    <li>SSH to the <codeph>messaging_deployer</codeph> VM:
                      <codeblock>sudo -u stack ssh &lt;ip_address_of_messaging_deployer></codeblock></li>
                    <li>Stop the <codeph>ironic-conductor</codeph> process by using this playbook:
                      <codeblock>cd ~/scratch/ansible/next/hos/ansible 
ansible-playbook -i hosts/verb_hosts ironic-stop.yml</codeblock></li>
                    <li>Start the process back up again, effectively restarting it, by using this
                      playbook:
                      <codeblock>cd ~/scratch/ansible/next/hos/ansible 
ansible-playbook -i hosts/verb_hosts ironic-start.yml</codeblock></li>
                  </ol>
                </entry>
              </row>
              <row>
                <entry>HTTP Status</entry>
                <entry>Alarms when the specified HTTP endpoint is down or not reachable.</entry>
                <entry>The API is unresponsive.</entry>
                <entry>
                  <ol id="ol_wwq_1xp_mx">
                    <li>Log in to the lifecycle manager.</li>
                    <li>Source your <codeph>admin</codeph> user credentials:
                      <codeblock>source ~/service.osrc</codeblock></li>
                    <li>Locate the <codeph>messaging_deployer</codeph> VM:
                      <codeblock>nova list --all-tenants | grep mess</codeblock></li>
                    <li>SSH to the <codeph>messaging_deployer</codeph> VM:
                      <codeblock>sudo -u stack ssh &lt;ip_address_of_messaging_deployer></codeblock></li>
                    <li>Stop the <codeph>ironic-api</codeph> process by using this playbook:
                      <codeblock>cd ~/scratch/ansible/next/hos/ansible 
ansible-playbook -i hosts/verb_hosts ironic-stop.yml</codeblock></li>
                    <li>Start the process back up again, effectively restarting it, by using this
                      playbook:
                      <codeblock>cd ~/scratch/ansible/next/hos/ansible 
ansible-playbook -i hosts/verb_hosts ironic-start.yml</codeblock></li>
                  </ol>
                </entry>
              </row>
              <row>
                <entry>Service Log Directory Size</entry>
                <entry>Service log directory consuming more disk than its quota.</entry>
                <entry>This could be due to a service set to <codeph>DEBUG</codeph> instead of
                    <codeph>INFO</codeph> level. Another reason could be due to a repeating error
                  message filling up the log files. Finally, it could be due to log rotate not
                  configured properly so old log files are not being deleted properly.</entry>
                <entry>Find the service that is consuming too much disk space. Look at the logs. If
                    <codeph>DEBUG</codeph> log entries exist, set the logging level to
                    <codeph>INFO</codeph>. If the logs are repeatedly logging an error message, do
                  what is needed to resolve the error. If old log files exist, configure log rotate
                  to remove them. You could also choose to remove old log files by hand after
                  backing them up if needed.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
  </body>
</topic>
