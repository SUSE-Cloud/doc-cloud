<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="crt_adding_transform_spark">
  <title>Adding Monasca Transform and Spark to <keyword keyref="kw-hos-phrase"/> Deployment</title>
  <body>
    <section id="adding_transform_spark">
      <p>Since Monasca Transform and Spark are optional components, the users might 
        elect to not install these two components during their initial 
        <keyword keyref="kw-hos-phrase"/> install. The following instructions 
        provide a way the users can add Monasca Transform and Spark to their 
        existing <keyword keyref="kw-hos-phrase"/> deployment.
      </p>

      <p><b>Steps</b></p>
      <ol>
        <li>Add Monasca Transform and Spark to the input model. Monasca Transform and Spark on a
            entry level cloud would be installed on the common control plane, for mid scale cloud
            which has a MML (Metering, Monitoring and Logging) cluster, Monasca Transform and Spark
            will should be added added to MML cluster.
            <codeblock>cd ~/helion/my_cloud/definition/data/</codeblock> Add spark and
            monasca-transform to input model, control_plane.yml
            <codeblock>clusters
       - name: core
         cluster-prefix: c1
         server-role: CONTROLLER-ROLE
         member-count: 3
         allocation-policy: strict
         service-components:

           [...]

           - zookeeper
           - kafka
           - vertica
           - storm
           - spark
           - monasca-api
           - monasca-persister
           - monasca-notifier
           - monasca-threshold
           - monasca-client 
           - monasca-transform

           [...]
            </codeblock>
          </li>
        <li>Run the Configuration Processor
        <codeblock>cd ~/helion/my_cloud/definition
git add -A
git commit -m "Adding Monasca Transform and Spark"
cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock>
        </li>
        <li>Run Ready Deployment
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml
</codeblock>
        </li>
        <li>Run HLM Deploy
          <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-deploy.yml</codeblock>
        </li>
      </ol>

      
      <p><b>Verify Deployment</b></p>
      <p>Login to each controller node and run <codeblock>sudo service monasca-transform status
sudo service spark-master status
sudo service spark-worker status</codeblock>
        <codeblock>stack@omega-cp1-c1-m1-mgmt:~$ sudo service monasca-transform status
● monasca-transform.service - Monasca Transform Daemon
  Loaded: loaded (/etc/systemd/system/monasca-transform.service; disabled)
  Active: active (running) since Wed 2016-08-24 00:47:56 UTC; 2 days ago
Main PID: 7351 (bash)
  CGroup: /system.slice/monasca-transform.service
          ├─ 7351 bash /etc/monasca/transform/init/start-monasca-transform.sh
          ├─ 7352 /opt/stack/service/monasca-transform/venv//bin/python /opt/monasca/monasca-transform/lib/service_runner.py
          ├─27904 /bin/sh -c export SPARK_HOME=/opt/stack/service/spark/venv/bin/../current &amp;&amp; spark-submit --supervise --master spark://omega-cp1-c1-m1-mgmt:7077,omega-cp1-c1-m2-mgmt:7077,omega-cp1-c1...
          ├─27905 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -cp /opt/stack/service/spark/venv/lib/drizzle-jdbc-1.3.jar:/opt/stack/service/spark/venv/bin/../current/conf/:/opt/stack/service/spark/v...
          └─28355 python /opt/monasca/monasca-transform/lib/driver.py
Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.


stack@omega-cp1-c1-m1-mgmt:~$ sudo service spark-worker status
● spark-worker.service - Spark Worker Daemon
  Loaded: loaded (/etc/systemd/system/spark-worker.service; disabled)
  Active: active (running) since Wed 2016-08-24 00:46:05 UTC; 2 days ago
Main PID: 63513 (bash)
  CGroup: /system.slice/spark-worker.service
          ├─ 7671 python -m pyspark.daemon
          ├─28948 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -cp /opt/stack/service/spark/venv/bin/../current/conf/:/opt/stack/service/spark/venv/bin/../current/lib/spark-assembly-1.6.1-hadoop2.6.0...
          ├─63513 bash /etc/spark/init/start-spark-worker.sh &amp;
          └─63514 /usr/bin/java -cp /opt/stack/service/spark/venv/bin/../current/conf/:/opt/stack/service/spark/venv/bin/../current/lib/spark-assembly-1.6.1-hadoop2.6.0.jar:/opt/stack/service/spark/ven...
Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.



stack@omega-cp1-c1-m1-mgmt:~$ sudo service spark-master status
● spark-master.service - Spark Master Daemon
  Loaded: loaded (/etc/systemd/system/spark-master.service; disabled)
  Active: active (running) since Wed 2016-08-24 00:44:24 UTC; 2 days ago
Main PID: 55572 (bash)
  CGroup: /system.slice/spark-master.service
          ├─55572 bash /etc/spark/init/start-spark-master.sh &amp;
          └─55573 /usr/bin/java -cp /opt/stack/service/spark/venv/bin/../current/conf/:/opt/stack/service/spark/venv/bin/../current/lib/spark-assembly-1.6.1-hadoop2.6.0.jar:/opt/stack/service/spark/ven...
Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.
        </codeblock>
      </p>
    </section>
  </body>
</topic>
