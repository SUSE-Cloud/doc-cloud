<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="OctaviaInstall">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Configuring Load Balancer as a Service</title>
  <abstract><shortdesc outputclass="hdphidden">The <keyword keyref="kw-hos"/> Neutron LBaaS service
      supports several load balancing providers. By default, both Octavia and the namespace haproxy
      driver are configured to be used. We describe this in more detail here.</shortdesc></abstract>
  <body>
    <p conkeyref="HOS-conrefs/applies-to"/>
    <section id="Overview">
      <note type="warning">If you are planning to upgrade from <keyword keyref="kw-hos-phrase-30"/> or <keyword keyref="kw-hos-phrase-40"/>,
        please contact F5 and HPE PointNext to determine which F5 drivers have been certified for
        use with Helion OpenStack. Loading drivers not certified by HPE may result in catastrophic
        failure of your cloud deployment. The last tested versions are 8.0.8 for <keyword keyref="kw-hos"/> 3.x and 9.0.3
        for <keyword keyref="kw-hos"/> 4.x . More information is expected in 4th quarter 2017, including the correct
        drivers for <keyword keyref="kw-hos"/> 5.x.</note>
      
      <p>The <keyword keyref="kw-hos"/> Neutron LBaaS service supports several load balancing
        providers. By default, both Octavia and the namespace haproxy driver are configured to be
        used. A user can specify which provider to use with the <codeph>--provider</codeph> flag
        upon load balancer creation.</p>
      <p>Example:</p>
      <codeblock>neutron lbaas-loadbalancer-create --name &lt;name&gt; --provider [octavia|haproxy] &lt;subnet&gt;</codeblock>
      <p>If you don't specify the <codeph>--provider</codeph> option it will default to Octavia. The
        Octavia driver provides more functionality than the haproxy namespace driver which is
        deprecated. The haproxy namespace driver will be retired in a future version of <keyword
          keyref="kw-hos"/>.</p>
      <p>There are additional drivers for 3rd party hardware load balancers. Please refer to the
        vendor directly. The <codeph>neutron service-provider-list</codeph> command displays not 
        only the currently installed load balancer drivers but also other installed services such as VPN. 
        You can see a list of available services as follows:
        <codeblock>$ neutron service-provider-list
+----------------+----------+---------+
| service_type   | name     | default |
+----------------+----------+---------+
| LOADBALANCERV2 | octavia  | True    |
| VPN            | openswan | True    |
| LOADBALANCERV2 | haproxy  | False   |
| LOADBALANCERV2 | octavia  | True    |
| VPN            | openswan | True    |
| LOADBALANCERV2 | haproxy  | False   |
+----------------+----------+---------+</codeblock></p>
      <note>In the example above, the providers are listed twice. This is a limitation in <keyword
          keyref="kw-hos-phrase-30"/>. Also note that the Octavia load balancer provider is listed
        as the default.</note>
    </section>

    <section id="prerequisites">
      <title>Prerequisites</title>
      <p>You will need to create an external network and create an image to test LBaaS
        functionality. If you have already created an external network and registered an image,
        this step can be skipped.</p>
      <p><b>Creating an external network</b></p>
      <xref href="../operations/create_extnet.dita"/>
      <p><b>Creating and uploading a Glance image</b></p>
      <xref href="../userguide/create_image.dita"/>
    </section>


    <section id="OctaviaProvider">
      <title>Octavia Load Balancing Provider</title>
      <p id="summary_p">The Octavia Load balancing provider bundled with <keyword
          keyref="kw-hos-phrase"/> is an operator grade load balancer for OpenStack. It is based
        on the Mitaka version of Octavia. It differs from the namespace driver by starting a new
        nova virtual machine to house the haproxy load balancer software, called an <i>amphora</i>,
        that provides the load balancer function. A virtual machine for each load balancer requested
        provides a better separation of load balancers between tenants and makes it easier to grow
        load balancing capacity alongside compute node growth. Additionally, if the virtual machine
        fails for any reason Octavia will replace it with a replacement VM from a pool of spare VM's,
        assuming that the feature is configured. 
        <note>The Health Monitor will not create or replace failed amphorae.  If the pool of spare VM's
        is exhausted there will be no additional virtual machines to handle load balancing requests.</note>
      </p>
      <p>Octavia uses two-way SSL encryption to communicate with the amphora. There are demo
        Certificate Authority (CA) certificates included with <keyword keyref="kw-hos-phrase"/>
        in <codeph>/home/stack/scratch/ansible/next/hos/ansible/roles/octavia-common/files</codeph>
        on the lifecycle manager. For additional security in production deployments, all certificate
        authorities should be replaced with ones you generated yourself by running the following
        commands:
        <codeblock>openssl genrsa -passout pass:foobar -des3 -out cakey.pem 2048
openssl req -x509 -passin pass:foobar -new -nodes -key cakey.pem -out ca_01.pem
openssl genrsa -passout pass:foobar -des3 -out servercakey.pem 2048
openssl req -x509 -passin pass:foobar -new -nodes -key cakey.pem -out serverca_01.pem</codeblock>
      </p>
      <p>For more details refer to the <xref
          href="https://www.openssl.org/docs/manmaster/apps/openssl.html" format="html"
          scope="external">openssl man page</xref>. <note> If you change the certificate authority
          and have amphora running with an old CA you wonâ€™t be able to control the amphora. The
          amphora's will need to be failed over so they can utilize the new certificate. If you
          change the CA password for the server certificate you need to change that in the Octavia
          configuration files as well. See the <xref
            href="../networking/octavia_admin.dita#OctaviaAdmin/Tuning"> Octavia
            Administration</xref> guide for more information.</note>
      </p>
      
    </section>
    <section id="Setup">
      <title>Setup of prerequisites</title>
      <p><b>Octavia Network and Management Network Ports</b></p>
      <p>The Octavia management network and Management network must 
        have access to each other.  If you have a configured firewall between 
        the Octavia management network and Management network, you 
        must open up the following ports to allow network traffic between 
        the networks.</p>
      <ul>
        <li>From Management network to Octavia network 
          <ul>
            <li>TCP 9443 (amphora API)</li>
          </ul>
        </li>
        <li>From Octavia network to Management network
          <ul>
            <li>TCP 9876 (Octavia API)</li>
            <li>UDP 5555 (Octavia Health Manager)</li>
          </ul>
        </li>
      </ul>
      
      <p><b>Installing the Amphora Image</b></p>
      <p>Octavia is utilizing Nova VMs for its load balancing function and HPE provides images used
        to boot those VM's called <codeph>octavia-amphora-haproxy</codeph>. <note type="warning"
          >Without these images the Octavia load balancer will not work.</note></p>
 
 
      <p>You can download the <b>Octavia Amphora HA Proxy Guest Image</b> from HPE Software
        Entitlement Portal.
        <ul>
          <li>Sign in and download the product and signature files from the following link: 
            <xref href="http://www.hpe.com/software/entitlements" format="html"
              scope="external">Software Entitlement Portal</xref></li>
          <li>Once the image is downloaded it needs to be placed on the lifecycle manager 
            node and the image registered. </li>
        </ul></p>
      
      <p><b>Register the image.</b></p>
      <ol>
        <li>Switch to the ansible directory and register the image by giving the full path and name
          (e.g. <codeph>/tmp/octavia-amphora-haproxy-guest-image.tgz</codeph>) as argument to
          service_package:
          <codeblock>$ cd ~/scratch/ansible/next/hos/ansible/
$ ansible-playbook -i hosts/verb_hosts -e service_package=&lt;image path/name&gt; service-guest-image.yml</codeblock></li>
        <li>Source the service user (this can be done on a different computer)
          <codeblock>$ source service.osrc</codeblock></li>
        <li>Verify that the image was uploaded and registered (this can be done on a computer with
          access to the glance CLI client)
            <codeblock>$ glance image-list
+--------------------------------------+---------------------------------------+
| ID                                   | Name                                  |
+--------------------------------------+---------------------------------------+
| 01ff1f0d-fc35-4e3e-bae2-e7e2ee1f65b6 | cirros-0.3.3-x86_64                   |
| e64cb914-15d2-4ad8-a63c-b7c60a6c232e | octavia-amphora-x64-haproxy_hos-3.0.0 |
+--------------------------------------+---------------------------------------+
    </codeblock><note>In
            rare circumstances the image won't be registered and you will have to run the whole
            registration again. If you run the registration by accident, the system will only upload
            a new image if the underlying image has been changed.</note></li>
        <li>Check the status of the image by running <codeph>glance image-show
            &lt;image-id&gt;</codeph>. <codeblock>$ glance image-show e64cb914-15d2-4ad8-a63c-b7c60a6c232e
+------------------+---------------------------------------+
| Property         | Value                                 |
+------------------+---------------------------------------+
| checksum         | 094a553d38fb5bfdb43f4a662d84ec2e      |
| container_format | bare                                  |
| created_at       | 2016-04-14T23:05:21Z                  |
| disk_format      | qcow2                                 |
| id               | e64cb914-15d2-4ad8-a63c-b7c60a6c232e  |
| min_disk         | 0                                     |
| min_ram          | 0                                     |
| name             | octavia-amphora-x64-haproxy_hos-3.0.0 |
| owner            | 0671a8d4d71c44ffb210c11cb5d11f7f      |
| protected        | False                                 |
| size             | 434379264                             |
| status           | active                                |
| tags             | []                                    |
| updated_at       | 2016-04-14T23:05:36Z                  |
| virtual_size     | None                                  |
| visibility       | private                               |
+------------------+---------------------------------------+</codeblock>
          <note type="important">In the example above, the status of the image is <i>active</i>
            which means the image was successfully registered. If a status of the images is
              <i>queued</i>, you must run the image registration again.</note>
 
      <p>Please be aware that if you have already created load balancers they won't receive the new
        image. Only load balancers created after the image has been successfully installed will use
        the new image. If existing load balancers need to be switched to the new image please follow
        the instructions in the <xref href="../networking/octavia_admin.dita#OctaviaAdmin/Tuning">
          Octavia Administration</xref> guide.</p>
        </li>
      </ol>
      
      <p><b>Setup network, subnet, router, security and IP's</b></p>
      <p>If you have already created a network, subnet, router, security settings and IP's you can skip the following
      steps and go directly to creating the load balancers.</p>
      <ol>
        <li>Create a network.
          <codeblock>neutron net-create lb_net1
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | True                                 |
| id                        | 71a1ac88-30a3-48a3-a18b-d98509fbef5c |
| mtu                       | 0                                    |
| name                      | lb_net1                              |
| provider:network_type     | vxlan                                |
| provider:physical_network |                                      |
| provider:segmentation_id  | 1061                                 |
| router:external           | False                                |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tenant_id                 | 4b31d0508f83437e83d8f4d520cda22f     |
+---------------------------+--------------------------------------+</codeblock>
        </li>
        <li>Create a subnet.
          <codeblock>neutron subnet-create --name lb_subnet1 lb_net1 10.247.94.128/26 --gateway 10.247.94.129
+-------------------+----------------------------------------------------+
| Field             | Value                                              |
+-------------------+----------------------------------------------------+
| allocation_pools  | {"start": "10.247.94.130", "end": "10.247.94.190"} |
| cidr              | 10.247.94.128/26                                   |
| dns_nameservers   |                                                    |
| enable_dhcp       | True                                               |
| gateway_ip        | 10.247.94.129                                      |
| host_routes       |                                                    |
| id                | 6fc2572c-53b3-41d0-ab63-342d9515f514               |
| ip_version        | 4                                                  |
| ipv6_address_mode |                                                    |
| ipv6_ra_mode      |                                                    |
| name              | lb_subnet1                                         |
| network_id        | 71a1ac88-30a3-48a3-a18b-d98509fbef5c               |
| subnetpool_id     |                                                    |
| tenant_id         | 4b31d0508f83437e83d8f4d520cda22f                   |
+-------------------+----------------------------------------------------+</codeblock>
        </li>
        <li>Create a router.
          <codeblock>neutron router-create --distributed False lb_router1
+-----------------------+--------------------------------------+
| Field                 | Value                                |
+-----------------------+--------------------------------------+
| admin_state_up        | True                                 |
| distributed           | False                                |
| external_gateway_info |                                      |
| ha                    | False                                |
| id                    | 6aafc9a9-93f6-4d7e-94f2-3068b034b823 |
| name                  | lb_router1                           |
| routes                |                                      |
| status                | ACTIVE                               |
| tenant_id             | 4b31d0508f83437e83d8f4d520cda22f     |
+-----------------------+--------------------------------------+</codeblock>
        </li>
        <li>Add interface to router.  In this example, 
          <codeph>neutron router-interface-add lb_router1 lb_subnet1</codeph> will add interface
          426c5898-f851-4f49-b01f-7a6fe490410c to router lb_router1.
          <codeblock>neutron router-interface-add lb_router1 lb_subnet1</codeblock>
        </li>
        <li>Set gateway for router.
          <codeblock>neutron router-gateway-set lb_router1 ext-net</codeblock>
        </li>
        <li>Check networks.
        <codeblock> neutron net-list
+-----------------------------+------------------+-----------------------------+
| id                          | name             | subnets                     |
+-----------------------------+------------------+-----------------------------+
| d3cb12a6-a000-4e3e-         | ext-net          | f4152001-2500-4ebe-ba9d-    |
| 82c4-ee04aa169291           |                  | a8d6149a50df 10.247.96.0/23 |
| 8306282a-3627-445a-a588-c18 | OCTAVIA-MGMT-NET | f00299f8-3403-45ae-ac4b-    |
| 8b6a13163                   |                  | 58af41d57bdc                |
|                             |                  | 10.247.94.128/26            |
| 71a1ac88-30a3-48a3-a18b-    | lb_net1          | 6fc2572c-                   |
| d98509fbef5c                |                  | 53b3-41d0-ab63-342d9515f514 |
|                             |                  | 10.247.94.128/26            |
+-----------------------------+------------------+-----------------------------+</codeblock>          
        </li>
        <li>Create security group.
          <codeblock>neutron security-group-create lb_secgroup1
+----------------------+--------------------------------------------------------------------------------------------------------------------------------+
| Field                | Value                                                                                                                          |
+----------------------+--------------------------------------------------------------------------------------------------------------------------------+
| description          |                                                                                                                                |
| id                   | 75343a54-83c3-464c-8773-802598afaee9                                                                                           |
| name                 | lb_secgroup1                                                                                                                   |
| security_group_rules | {"remote_group_id": null, "direction": "egress", "remote_ip_prefix": null, "protocol": null, "tenant_id":                      |
|                      | "4b31d0508f83437e83d8f4d520cda22f", "port_range_max": null, "security_group_id": "75343a54-83c3-464c-8773-802598afaee9",       |
|                      | "port_range_min": null, "ethertype": "IPv4", "id": "20ae3723-050c-44ed-a8f7-c5da6fa97a7a"}                                     |
|                      | {"remote_group_id": null, "direction": "egress", "remote_ip_prefix": null, "protocol": null, "tenant_id":                      |
|                      | "4b31d0508f83437e83d8f4d520cda22f", "port_range_max": null, "security_group_id": "75343a54-83c3-464c-8773-802598afaee9",       |
|                      | "port_range_min": null, "ethertype": "IPv6", "id": "563c5ca3-3bbd-4c96-9324-1ca9bc3aaef9"}                                     |
| tenant_id            | 4b31d0508f83437e83d8f4d520cda22f                                                                                               |
+----------------------+--------------------------------------------------------------------------------------------------------------------------------+</codeblock>
        </li>
        <li>Create icmp security group rule.
          <codeblock>neutron security-group-rule-create lb_secgroup1 --protocol icmp
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| id                | 16d74150-a5b2-4cf6-82eb-a6c49a972d93 |
| port_range_max    |                                      |
| port_range_min    |                                      |
| protocol          | icmp                                 |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | 75343a54-83c3-464c-8773-802598afaee9 |
| tenant_id         | 4b31d0508f83437e83d8f4d520cda22f     |
+-------------------+--------------------------------------+</codeblock>
        </li>
        <li>Create TCP port 22 rule.
          <codeblock>neutron security-group-rule-create lb_secgroup1 --protocol tcp --port-range-min 22 --port-range-max 22
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| id                | 472d3c8f-c50f-4ad2-97a1-148778e73af5 |
| port_range_max    | 22                                   |
| port_range_min    | 22                                   |
| protocol          | tcp                                  |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | 75343a54-83c3-464c-8773-802598afaee9 |
| tenant_id         | 4b31d0508f83437e83d8f4d520cda22f     |
+-------------------+--------------------------------------+</codeblock>
        </li>
        <li>Create TCP port 80 rule.
          <codeblock>neutron security-group-rule-create lb_secgroup1 --protocol tcp --port-range-min 80 --port-range-max 80
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| id                | 10a76cad-8b1c-46f6-90e8-5dddd279e5f7 |
| port_range_max    | 80                                   |
| port_range_min    | 80                                   |
| protocol          | tcp                                  |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | 75343a54-83c3-464c-8773-802598afaee9 |
| tenant_id         | 4b31d0508f83437e83d8f4d520cda22f     |
+-------------------+--------------------------------------+</codeblock>
        </li>
        <li>If you haven't already created a keypair, create one now with <codeph>nova keypair-add</codeph>.  You'll 
          use the keypair to boot images.
          <codeblock>nova keypair-add lb_kp1 > lb_kp1.pem
            
chmod 400 lb_kp1.pem

cat lb_kp1.pem
-----BEGIN RSA PRIVATE KEY-----
MIIEqAIBAAKCAQEAkbW5W/XWGRGC0LAJI7lttR7EdDfiTDeFJ7A9b9Cff+OMXjhx
WL26eKIr+jp8DR64YjV2mNnQLsDyCxekFpkyjnGRId3KVAeV5sRQqXgtaCXI+Rvd
IyUtd8p1cp3DRgTd1dxO0oL6bBmwrZatNrrRn4HgKc2c7ErekeXrwLHyE0Pia/pz
C6qs0coRdfIeXxsmS3kXExP0YfsswRS/OyDl8QhRAF0ZW/zV+DQIi8+HpLZT+RW1
8sTTYZ6b0kXoH9wLER4IUBj1I1IyrYdxlAhe2VIn+tF0Ec4nDBn1py9iwEfGmn0+
N2jHCJAkrK/QhWdXO4O8zeXfL4mCZ9FybW4nzQIDAQABAoIBACe0PvgB+v8FuIGp
FjR32J8b7ShF+hIOpufzrCoFzRCKLruV4bzuphstBZK/0QG6Nz/7lX99Cq9SwCGp
pXrK7+3EoGl8CB/xmTUylVA4gRb6BNNsdkuXW9ZigrJirs0rkk8uIwRV0GsYbP5A
Kp7ZNTmjqDN75aC1ngRfhGgTlQUOdxBH+4xSb7GukekD13V8V5MF1Qft089asdWp
l/TpvhYeW9O92xEnZ3qXQYpXYQgEFQoM2PKa3VW7FGLgfw9gdS/MSqpHuHGyKmjl
uT6upUX+Lofbe7V+9kfxuV32sLL/S5YFvkBy2q8VpuEV1sXI7O7Sc411WX4cqmlb
YoFwhrkCggCBALkYE7OMTtdCAGcMotJhTiiS5l8d4U/fn1x0zus43XV5Y7wCnMuU
r5vCoK+a+TR9Ekzc/GjccAx7Wz/YYKp6G8FXW114dLcADXZjqjIlX7ifUud4sLCS
y+x3KAJa7LqyzH53I6FOts9RaB5xx4gZ2WjcJquCTbATZWj7j1yGeNgvAoIAgQDJ
h0r0Te5IliYbCRg+ES9YRZzH/PSLuIn00bbLvpOPNEoKe2Pxs+KI8Fqp6ZIDAB3c
4EPOK5QrJvAny9Z58ZArrNZi15t84KEVAkWUATl+c4SmHc8sW/atgmUoqIzgDQXe
AlwadHLY7JCdg7EYDuUxuTKLLOdqfpf6fKkhNxtEwwKCAIAMxi+d5aIPUxvKAOI/
2L1XKYRCrkI9i/ZooBsjusH1+JG8iQWfOzy/aDhExlJKoBMiQOIerpABHIZYqqtJ
OLIvrsK8ebK8aoGDWS+G1HN9v2kuVnMDTK5MPJEDUJkj7XEVjU1lNZSCTGD+MOYP
a5FInmEA1zZbX4tRKoNjZFh0uwKCAIEAiLs7drAdOLBu4C72fL4KIljwu5t7jATD
zRAwduIxmZq/lYcMU2RaEdEJonivsUt193NNbeeRWwnLLSUWupvT1l4pAt0ISNzb
TbbB4F5IVOwpls9ozc8DecubuM9K7YTIc02kkepqNZWjtMsx74HDrU3a5iSsSkvj
73Z/BeMupCMCggCAS48BsrcsDsHSHE3tO4D8pAIr1r+6WPaQn49pT3GIrdQNc7aO
d9PfXmPoe/PxUlqaXoNAvT99+nNEadp+GTId21VM0Y28pn3EkIGE1Cqoeyl3BEO8
f9SUiRNruDnH4F4OclsDBlmqWXImuXRfeiDHxM8X03UDZoqyHmGD3RqA53I=
-----END RSA PRIVATE KEY-----</codeblock>  
        </li>
        <li>Check and boot images.
          <codeblock>nova image-list
+--------------------------------------+---------------------------------------+--------+--------+
| ID                                   | Name                                  | Status | Server |
+--------------------------------------+---------------------------------------+--------+--------+
| 04b1528b-b1e2-45d4-96d1-fbe04c6b2efd | cirros-0.3.3-x86_64                   | ACTIVE |        |
| 8aa51e01-e6f4-480f-b91e-08ea14178f2f | octavia-amphora-x64-haproxy_hos-3.0.0 | ACTIVE |        |
+--------------------------------------+---------------------------------------+--------+--------+</codeblock>
          Boot first VM.
          <codeblock>nova boot --flavor 1 --image 04b1528b-b1e2-45d4-96d1-fbe04c6b2efd --key-name lb_kp1 --security-groups lb_secgroup1 --nic net-id=71a1ac88-30a3-48a3-a18b-d98509fbef5c lb_vm1 --poll
+--------------------------------------+------------------------------------------------------------+
| Property                             | Value                                                      |
+--------------------------------------+------------------------------------------------------------+
| OS-DCF:diskConfig                    | MANUAL                                                     |
| OS-EXT-AZ:availability_zone          |                                                            |
| OS-EXT-SRV-ATTR:host                 | -                                                          |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                                          |
| OS-EXT-SRV-ATTR:instance_name        | instance-00000031                                          |
| OS-EXT-STS:power_state               | 0                                                          |
| OS-EXT-STS:task_state                | scheduling                                                 |
| OS-EXT-STS:vm_state                  | building                                                   |
| OS-SRV-USG:launched_at               | -                                                          |
| OS-SRV-USG:terminated_at             | -                                                          |
| accessIPv4                           |                                                            |
| accessIPv6                           |                                                            |
| adminPass                            | NeVvhP5E8iCy                                               |
| config_drive                         |                                                            |
| created                              | 2016-06-15T16:53:00Z                                       |
| flavor                               | m1.tiny (1)                                                |
| hostId                               |                                                            |
| id                                   | dfdfe15b-ce8d-469c-a9d8-2cea0e7ca287                       |
| image                                | cirros-0.3.3-x86_64 (04b1528b-b1e2-45d4-96d1-fbe04c6b2efd) |
| key_name                             | lb_kp1                                                     |
| metadata                             | {}                                                         |
| name                                 | lb_vm1                                                     |
| os-extended-volumes:volumes_attached | []                                                         |
| progress                             | 0                                                          |
| security_groups                      | lb_secgroup1                                               |
| status                               | BUILD                                                      |
| tenant_id                            | 4b31d0508f83437e83d8f4d520cda22f                           |
| updated                              | 2016-06-15T16:53:00Z                                       |
| user_id                              | fd471475faa84680b97f18e55847ec0a                           |
+--------------------------------------+------------------------------------------------------------+
            
            Server building... 100% complete
            Finished</codeblock>
          Boot second VM.
          <codeblock>nova boot --flavor 1 --image 04b1528b-b1e2-45d4-96d1-fbe04c6b2efd --key-name lb_kp1 --security-groups lb_secgroup1 --nic net-id=71a1ac88-30a3-48a3-a18b-d98509fbef5c lb_vm2 --poll
+--------------------------------------+------------------------------------------------------------+
| Property                             | Value                                                      |
+--------------------------------------+------------------------------------------------------------+
| OS-DCF:diskConfig                    | MANUAL                                                     |
| OS-EXT-AZ:availability_zone          |                                                            |
| OS-EXT-SRV-ATTR:host                 | -                                                          |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                                          |
| OS-EXT-SRV-ATTR:instance_name        | instance-00000034                                          |
| OS-EXT-STS:power_state               | 0                                                          |
| OS-EXT-STS:task_state                | scheduling                                                 |
| OS-EXT-STS:vm_state                  | building                                                   |
| OS-SRV-USG:launched_at               | -                                                          |
| OS-SRV-USG:terminated_at             | -                                                          |
| accessIPv4                           |                                                            |
| accessIPv6                           |                                                            |
| adminPass                            | 3nFXjNrTrmNm                                               |
| config_drive                         |                                                            |
| created                              | 2016-06-15T16:55:10Z                                       |
| flavor                               | m1.tiny (1)                                                |
| hostId                               |                                                            |
| id                                   | 3844bb10-2c61-4327-a0d4-0c043c674344                       |
| image                                | cirros-0.3.3-x86_64 (04b1528b-b1e2-45d4-96d1-fbe04c6b2efd) |
| key_name                             | lb_kp1                                                     |
| metadata                             | {}                                                         |
| name                                 | lb_vm2                                                     |
| os-extended-volumes:volumes_attached | []                                                         |
| progress                             | 0                                                          |
| security_groups                      | lb_secgroup1                                               |
| status                               | BUILD                                                      |
| tenant_id                            | 4b31d0508f83437e83d8f4d520cda22f                           |
| updated                              | 2016-06-15T16:55:09Z                                       |
| user_id                              | fd471475faa84680b97f18e55847ec0a                           |
+--------------------------------------+------------------------------------------------------------+
            
            Server building... 100% complete
            Finished</codeblock>
        </li>
        <li>List the running VM with <codeph>nova list</codeph>
          <codeblock>nova list
+--------------------------------------+--------+--------+------------+-------------+-----------------------+
| ID                                   | Name   | Status | Task State | Power State | Networks              |
+--------------------------------------+--------+--------+------------+-------------+-----------------------+
| dfdfe15b-ce8d-469c-a9d8-2cea0e7ca287 | lb_vm1 | ACTIVE | -          | Running     | lb_net1=10.247.94.132 |
| 3844bb10-2c61-4327-a0d4-0c043c674344 | lb_vm2 | ACTIVE | -          | Running     | lb_net1=10.247.94.133 |
+--------------------------------------+--------+--------+------------+-------------+-----------------------+</codeblock>
        </li>
        <li>Check ports.
          <codeblock>neutron port-list
+--------------------------------------+------+-------------------+--------------------------------------------------------------+
| id                                   | name | mac_address       | fixed_ips                                                    |
+--------------------------------------+------+-------------------+--------------------------------------------------------------+
...
| 7e5e0038-88cf-4f97-a366-b58cd836450e |      | fa:16:3e:66:fd:2e | {"subnet_id": "6fc2572c-53b3-41d0-ab63-342d9515f514",        |
|                                      |      |                   | "ip_address": "10.247.94.132"}                               |
| ca95cc24-4e8f-4415-9156-7b519eb36854 |      | fa:16:3e:e0:37:c4 | {"subnet_id": "6fc2572c-53b3-41d0-ab63-342d9515f514",        |
|                                      |      |                   | "ip_address": "10.247.94.133"}                               |
+--------------------------------------+------+-------------------+--------------------------------------------------------------+</codeblock>
        </li>
        <li>Create the first floating IP.
          <codeblock>neutron floatingip-create ext-net --port-id 7e5e0038-88cf-4f97-a366-b58cd836450e
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    | 10.247.94.132                        |
| floating_ip_address | 10.247.96.26                         |
| floating_network_id | d3cb12a6-a000-4e3e-82c4-ee04aa169291 |
| id                  | 3ce608bf-8835-4638-871d-0efe8ebf55ef |
| port_id             | 7e5e0038-88cf-4f97-a366-b58cd836450e |
| router_id           | 6aafc9a9-93f6-4d7e-94f2-3068b034b823 |
| status              | DOWN                                 |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f     |
+---------------------+--------------------------------------+</codeblock>
        </li>
        <li>Create the second floating IP.
          <codeblock>neutron floatingip-create ext-net --port-id ca95cc24-4e8f-4415-9156-7b519eb36854
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    | 10.247.94.133                        |
| floating_ip_address | 10.247.96.27                         |
| floating_network_id | d3cb12a6-a000-4e3e-82c4-ee04aa169291 |
| id                  | 680c0375-a179-47cb-a8c5-02b836247444 |
| port_id             | ca95cc24-4e8f-4415-9156-7b519eb36854 |
| router_id           | 6aafc9a9-93f6-4d7e-94f2-3068b034b823 |
| status              | DOWN                                 |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f     |
+---------------------+--------------------------------------+</codeblock>
        </li>
        <li>List the floating IP's.
          <codeblock>neutron floatingip-list
+--------------------------------------+------------------+---------------------+--------------------------------------+
| id                                   | fixed_ip_address | floating_ip_address | port_id                              |
+--------------------------------------+------------------+---------------------+--------------------------------------+
| 3ce608bf-8835-4638-871d-0efe8ebf55ef | 10.247.94.132    | 10.247.96.26        | 7e5e0038-88cf-4f97-a366-b58cd836450e |
| 680c0375-a179-47cb-a8c5-02b836247444 | 10.247.94.133    | 10.247.96.27        | ca95cc24-4e8f-4415-9156-7b519eb36854 |
+--------------------------------------+------------------+---------------------+--------------------------------------+</codeblock>          
        </li>
        <li>Show first Floating IP.
          <codeblock>neutron floatingip-show 3ce608bf-8835-4638-871d-0efe8ebf55ef
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    | 10.247.94.132                        |
| floating_ip_address | 10.247.96.26                         |
| floating_network_id | d3cb12a6-a000-4e3e-82c4-ee04aa169291 |
| id                  | 3ce608bf-8835-4638-871d-0efe8ebf55ef |
| port_id             | 7e5e0038-88cf-4f97-a366-b58cd836450e |
| router_id           | 6aafc9a9-93f6-4d7e-94f2-3068b034b823 |
| status              | ACTIVE                               |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f     |
+---------------------+--------------------------------------+</codeblock>
        </li>
        <li>Show second Floating IP.
          <codeblock>neutron floatingip-show 680c0375-a179-47cb-a8c5-02b836247444
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    | 10.247.94.133                        |
| floating_ip_address | 10.247.96.27                         |
| floating_network_id | d3cb12a6-a000-4e3e-82c4-ee04aa169291 |
| id                  | 680c0375-a179-47cb-a8c5-02b836247444 |
| port_id             | ca95cc24-4e8f-4415-9156-7b519eb36854 |
| router_id           | 6aafc9a9-93f6-4d7e-94f2-3068b034b823 |
| status              | ACTIVE                               |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f     |
+---------------------+--------------------------------------+</codeblock>
        </li>
        <li>Ping first Floating IP.
          <codeblock>ping -c 1 10.247.96.26
PING 10.247.96.26 (10.247.96.26) 56(84) bytes of data.
64 bytes from 10.247.96.26: icmp_seq=1 ttl=62 time=3.50 ms
            
--- 10.247.96.26 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 3.505/3.505/3.505/0.000 ms</codeblock>
        </li>
        <li>Ping second Floating IP.
          <codeblock>ping -c 1 10.247.96.27
PING 10.247.96.27 (10.247.96.27) 56(84) bytes of data.
64 bytes from 10.247.96.27: icmp_seq=1 ttl=62 time=3.47 ms
            
--- 10.247.96.27 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 3.473/3.473/3.473/0.000 ms</codeblock>
        </li>
        <li>Listing the VM's will give you both the fixed and floating IP's for each virutal machine.
          <codeblock>nova list
+--------------------------------------+--------+--------+------------+-------------+-------------------------------------+
| ID                                   | Name   | Status | Task State | Power State | Networks                            |
+--------------------------------------+--------+--------+------------+-------------+-------------------------------------+
| dfdfe15b-ce8d-469c-a9d8-2cea0e7ca287 | lb_vm1 | ACTIVE | -          | Running     | lb_net1=10.247.94.132, 10.247.96.26 |
| 3844bb10-2c61-4327-a0d4-0c043c674344 | lb_vm2 | ACTIVE | -          | Running     | lb_net1=10.247.94.133, 10.247.96.27 |
+--------------------------------------+--------+--------+------------+-------------+-------------------------------------+</codeblock>
        </li>
        <li>List Floating IP's.
          <codeblock>neutron floatingip-list
+--------------------------------------+------------------+---------------------+--------------------------------------+
| id                                   | fixed_ip_address | floating_ip_address | port_id                              |
+--------------------------------------+------------------+---------------------+--------------------------------------+
| 3ce608bf-8835-4638-871d-0efe8ebf55ef | 10.247.94.132    | 10.247.96.26        | 7e5e0038-88cf-4f97-a366-b58cd836450e |
| 680c0375-a179-47cb-a8c5-02b836247444 | 10.247.94.133    | 10.247.96.27        | ca95cc24-4e8f-4415-9156-7b519eb36854 |
+--------------------------------------+------------------+---------------------+--------------------------------------+</codeblock>
        </li>
      </ol>
    </section>

    <section id="LoadBalancerCreate">
      <title>Create Load Balancers</title>
      <p>The following steps will setup new Octavia Load Balancers. </p>
      <note>The following examples assume names and values from the previous section.</note>
      <ol>
        <li>Create load balancer for subnet
          <codeblock>neutron lbaas-loadbalancer-create --provider octavia --name lb1 6fc2572c-53b3-41d0-ab63-342d9515f514
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| admin_state_up      | True                                 |
| description         |                                      |
| id                  | 3d9170a1-8605-43e6-9255-e14a8b4aae53 |
| listeners           |                                      |
| name                | lb1                                  |
| operating_status    | OFFLINE                              |
| provider            | octavia                              |
| provisioning_status | PENDING_CREATE                       |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f     |
| vip_address         | 10.247.94.134                        |
| vip_port_id         | da28aed3-0eb4-4139-afcf-2d8fd3fc3c51 |
| vip_subnet_id       | 6fc2572c-53b3-41d0-ab63-342d9515f514 |
+---------------------+--------------------------------------+</codeblock>
        </li>
        <li>List load balancers. You will need to wait until the load balancer
            <codeph>provisioning_status</codeph>is <codeph>ACTIVE</codeph> before proceeding to the
          next
          step.<codeblock>neutron lbaas-loadbalancer-list
+--------------------------------------+------+---------------+---------------------+----------+
| id                                   | name | vip_address   | provisioning_status | provider |
+--------------------------------------+------+---------------+---------------------+----------+
| 3d9170a1-8605-43e6-9255-e14a8b4aae53 | lb1  | 10.247.94.134 | ACTIVE              | octavia  |
+--------------------------------------+------+---------------+---------------------+----------+</codeblock>
        </li>
        <li>Once the load balancer is created, create the listener.  This may take some time.
          <codeblock>neutron lbaas-listener-create --loadbalancer lb1 --protocol HTTP --protocol-port=80 --name lb1_listener
+---------------------------+------------------------------------------------+
| Field                     | Value                                          |
+---------------------------+------------------------------------------------+
| admin_state_up            | True                                           |
| connection_limit          | -1                                             |
| default_pool_id           |                                                |
| default_tls_container_ref |                                                |
| description               |                                                |
| id                        | c723b5c8-e2df-48d5-a54c-fc240ac7b539           |
| loadbalancers             | {"id": "3d9170a1-8605-43e6-9255-e14a8b4aae53"} |
| name                      | lb1_listener                                   |
| protocol                  | HTTP                                           |
| protocol_port             | 80                                             |
| sni_container_refs        |                                                |
| tenant_id                 | 4b31d0508f83437e83d8f4d520cda22f               |
+---------------------------+------------------------------------------------+</codeblock>
        </li>
        <li>Create the load balancing pool.  During the creation of the load balancing pool, the status
          for the load balancer goes to <codeph>PENDING_UPDATE</codeph>.  Use 
          <codeph>neutron lbaas-loadbalancer-list</codeph> to watch for the change to 
          <codeph>ACTIVE</codeph>.  Once the load balancer returns to <codeph>ACTIVE</codeph>,
          proceed with the next step.
          <codeblock>neutron lbaas-pool-create --lb-algorithm ROUND_ROBIN --listener lb1_listener --protocol HTTP --name lb1_pool
+---------------------+------------------------------------------------+
| Field               | Value                                          |
+---------------------+------------------------------------------------+
| admin_state_up      | True                                           |
| description         |                                                |
| healthmonitor_id    |                                                |
| id                  | 0f5951ee-c2a0-4e62-ae44-e1491a8988e1           |
| lb_algorithm        | ROUND_ROBIN                                    |
| listeners           | {"id": "c723b5c8-e2df-48d5-a54c-fc240ac7b539"} |
| members             |                                                |
| name                | lb1_pool                                       |
| protocol            | HTTP                                           |
| session_persistence |                                                |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f               |
+---------------------+------------------------------------------------+</codeblock>
        </li>
        <li>Create first member of the load balancing pool.
          <codeblock>neutron lbaas-member-create --subnet 6fc2572c-53b3-41d0-ab63-342d9515f514 --address 10.247.94.132 --protocol-port 80 lb1_pool
+----------------+--------------------------------------+
| Field          | Value                                |
+----------------+--------------------------------------+
| address        | 10.247.94.132                        |
| admin_state_up | True                                 |
| id             | 61da1e21-e0ae-4158-935a-c909a81470e1 |
| protocol_port  | 80                                   |
| subnet_id      | 6fc2572c-53b3-41d0-ab63-342d9515f514 |
| tenant_id      | 4b31d0508f83437e83d8f4d520cda22f     |
| weight         | 1                                    |
+----------------+--------------------------------------+</codeblock>
        </li>
        <li>Create the second member.
          <codeblock>neutron lbaas-member-create --subnet 6fc2572c-53b3-41d0-ab63-342d9515f514 --address 10.247.94.133 --protocol-port 80 lb1_pool
+----------------+--------------------------------------+
| Field          | Value                                |
+----------------+--------------------------------------+
| address        | 10.247.94.133                        |
| admin_state_up | True                                 |
| id             | 459c7f21-46f7-49e8-9d10-dc7da09f8d5a |
| protocol_port  | 80                                   |
| subnet_id      | 6fc2572c-53b3-41d0-ab63-342d9515f514 |
| tenant_id      | 4b31d0508f83437e83d8f4d520cda22f     |
| weight         | 1                                    |
+----------------+--------------------------------------+</codeblock>
        </li>
        <li>You should check to make sure the load balancer is active and check the pool members.
          <codeblock>neutron lbaas-loadbalancer-list
+--------------------------------------+------+---------------+---------------------+----------+
| id                                   | name | vip_address   | provisioning_status | provider |
+--------------------------------------+------+---------------+---------------------+----------+
| 3d9170a1-8605-43e6-9255-e14a8b4aae53 | lb1  | 10.247.94.134 | ACTIVE              | octavia  |
+--------------------------------------+------+---------------+---------------------+----------+

neutron lbaas-member-list lb1_pool
+--------------------------------------+---------------+---------------+--------+--------------------------------------+----------------+
| id                                   | address       | protocol_port | weight | subnet_id                            | admin_state_up |
+--------------------------------------+---------------+---------------+--------+--------------------------------------+----------------+
| 61da1e21-e0ae-4158-935a-c909a81470e1 | 10.247.94.132 |            80 |      1 | 6fc2572c-53b3-41d0-ab63-342d9515f514 | True           |
| 459c7f21-46f7-49e8-9d10-dc7da09f8d5a | 10.247.94.133 |            80 |      1 | 6fc2572c-53b3-41d0-ab63-342d9515f514 | True           |
+--------------------------------------+---------------+---------------+--------+--------------------------------------+----------------+
          </codeblock>
        </li>
        <li>You can view the details of the load balancer, listener and pool.
          <codeblock>neutron lbaas-loadbalancer-show 3d9170a1-8605-43e6-9255-e14a8b4aae53
+---------------------+------------------------------------------------+
| Field               | Value                                          |
+---------------------+------------------------------------------------+
| admin_state_up      | True                                           |
| description         |                                                |
| id                  | 3d9170a1-8605-43e6-9255-e14a8b4aae53           |
| listeners           | {"id": "c723b5c8-e2df-48d5-a54c-fc240ac7b539"} |
| name                | lb1                                            |
| operating_status    | ONLINE                                         |
| provider            | octavia                                        |
| provisioning_status | ACTIVE                                         |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f               |
| vip_address         | 10.247.94.134                                  |
| vip_port_id         | da28aed3-0eb4-4139-afcf-2d8fd3fc3c51           |
| vip_subnet_id       | 6fc2572c-53b3-41d0-ab63-342d9515f514           |
+---------------------+------------------------------------------------+

neutron lbaas-listener-list
+--------------------------------------+--------------------------------------+--------------+----------+---------------+----------------+
| id                                   | default_pool_id                      | name         | protocol | protocol_port | admin_state_up |
+--------------------------------------+--------------------------------------+--------------+----------+---------------+----------------+
| c723b5c8-e2df-48d5-a54c-fc240ac7b539 | 0f5951ee-c2a0-4e62-ae44-e1491a8988e1 | lb1_listener | HTTP     |            80 | True           |
+--------------------------------------+--------------------------------------+--------------+----------+---------------+----------------+

neutron lbaas-pool-list
+--------------------------------------+----------+----------+----------------+
| id                                   | name     | protocol | admin_state_up |
+--------------------------------------+----------+----------+----------------+
| 0f5951ee-c2a0-4e62-ae44-e1491a8988e1 | lb1_pool | HTTP     | True           |
+--------------------------------------+----------+----------+----------------+</codeblock>
        </li>
      </ol>
    </section>
    
    <section id="FloatingIPs">
      <title>Create Floating IP's for Load Balancer</title>
      <p>To create the floating IP's for the load balancer, you will need to list the current ports to get 
      the load balancer id.  Once you have the id, you can then create the floating IP.</p>
      <ol>
        <li>List the current ports.
          <codeblock>neutron port-list
+--------------------------------------+--------------------------------------------+-------------------+--------------------------------------------+
| id                                   | name                                       | mac_address       | fixed_ips                                  |
+--------------------------------------+--------------------------------------------+-------------------+--------------------------------------------+
...
| 7e5e0038-88cf-4f97-a366-b58cd836450e |                                            | fa:16:3e:66:fd:2e | {"subnet_id": "6fc2572c-                   |
|                                      |                                            |                   | 53b3-41d0-ab63-342d9515f514",              |
|                                      |                                            |                   | "ip_address": "10.247.94.132"}             |
| a3d0b0fe-e7ff-4b00-a033-44e833b55efe |                                            | fa:16:3e:91:a2:5b | {"subnet_id": "f00299f8-3403-45ae-ac4b-    |
|                                      |                                            |                   | 58af41d57bdc", "ip_address":               |
|                                      |                                            |                   | "10.247.94.142"}                           |
| ca95cc24-4e8f-4415-9156-7b519eb36854 |                                            | fa:16:3e:e0:37:c4 | {"subnet_id": "6fc2572c-                   |
|                                      |                                            |                   | 53b3-41d0-ab63-342d9515f514",              |
|                                      |                                            |                   | "ip_address": "10.247.94.133"}             |
| da28aed3-0eb4-4139-afcf-2d8fd3fc3c51 | loadbalancer-                              | fa:16:3e:1d:a2:1c | {"subnet_id": "6fc2572c-                   |
|                                      | 3d9170a1-8605-43e6-9255-e14a8b4aae53       |                   | 53b3-41d0-ab63-342d9515f514",              |
|                                      |                                            |                   | "ip_address": "10.247.94.134"}             |
+--------------------------------------+--------------------------------------------+-------------------+------------</codeblock>
        </li>
        <li>Create the floating IP for the load balancer.
          <codeblock>neutron floatingip-create ext-net --port-id da28aed3-0eb4-4139-afcf-2d8fd3fc3c51
            Created a new floatingip:
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    | 10.247.94.134                        |
| floating_ip_address | 10.247.96.28                         |
| floating_network_id | d3cb12a6-a000-4e3e-82c4-ee04aa169291 |
| id                  | 9a3629bd-b0a6-474c-abe9-89c6ecb2b22c |
| port_id             | da28aed3-0eb4-4139-afcf-2d8fd3fc3c51 |
| router_id           | 6aafc9a9-93f6-4d7e-94f2-3068b034b823 |
| status              | DOWN                                 |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f     |
+---------------------+--------------------------------------+</codeblock>
        </li>
      </ol>
    </section>

    <section id="TestingOctavia">
      <title>Testing the Octavia Load Balancer</title>
      <p>To test the load balancers, create the following web server script so you can run it on
        each virtual machine. You will use <codeph>curl &lt;ip address&gt;</codeph> to test if the
        load balance services are responding properly. </p>
      <p>
        <ol>
          <li>Start running web servers on both of the virtual machines. Create the webserver.sh
            script with below contents. In this example, the port is 80.
            <codeblock>vi webserver.sh
              
#!/bin/bash
              
MYIP=$(/sbin/ifconfig eth0|grep 'inet addr'|awk -F: '{print $2}'| awk '{print $1}');
while true; do
    echo -e "HTTP/1.0 200 OK\r\n\r\nWelcome to $MYIP" | sudo nc -l -p 80
done</codeblock></li>
          <li>Deploy the web server and run it on the first virtual machine.
            <codeblock>ssh-keygen -R 10.247.96.26
/home/stack/.ssh/known_hosts updated.
Original contents retained as /home/stack/.ssh/known_hosts.old

scp -o StrictHostKeyChecking=no -i lb_kp1.pem webserver.sh cirros@10.247.96.26: 
webserver.sh                                      100%  263     0.3KB/s   00:00

ssh -o StrictHostKeyChecking=no -i lb_kp1.pem cirros@10.247.96.26 'chmod +x ./webserver.sh'
ssh -o StrictHostKeyChecking=no -i lb_kp1.pem cirros@10.247.96.26 ./webserver.sh</codeblock>
          </li>
          <li>Test the first web server.
            <codeblock>curl 10.247.96.26
 Welcome to 10.247.94.132</codeblock>
          </li>
          <li>Deploy and start the web server on the second virtual machine like you did in the
            previous steps. Once the second web server is running, list the floating IP's.
            <codeblock>neutron floatingip-list
+--------------------------------------+------------------+---------------------+--------------------------------------+
| id                                   | fixed_ip_address | floating_ip_address | port_id                              |
+--------------------------------------+------------------+---------------------+--------------------------------------+
| 3ce608bf-8835-4638-871d-0efe8ebf55ef | 10.247.94.132    | 10.247.96.26        | 7e5e0038-88cf-4f97-a366-b58cd836450e |
| 680c0375-a179-47cb-a8c5-02b836247444 | 10.247.94.133    | 10.247.96.27        | ca95cc24-4e8f-4415-9156-7b519eb36854 |
| 9a3629bd-b0a6-474c-abe9-89c6ecb2b22c | 10.247.94.134    | 10.247.96.28        | da28aed3-0eb4-4139-afcf-2d8fd3fc3c51 |
+--------------------------------------+------------------+---------------------+--------------------------------------+</codeblock>
          </li>
          <li>Display the floating IP for the load balancer.
            <codeblock>neutron floatingip-show 9a3629bd-b0a6-474c-abe9-89c6ecb2b22c
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    | 10.247.94.134                        |
| floating_ip_address | 10.247.96.28                         |
| floating_network_id | d3cb12a6-a000-4e3e-82c4-ee04aa169291 |
| id                  | 9a3629bd-b0a6-474c-abe9-89c6ecb2b22c |
| port_id             | da28aed3-0eb4-4139-afcf-2d8fd3fc3c51 |
| router_id           | 6aafc9a9-93f6-4d7e-94f2-3068b034b823 |
| status              | ACTIVE                               |
| tenant_id           | 4b31d0508f83437e83d8f4d520cda22f     |
+---------------------+--------------------------------------+</codeblock>
          </li>
          <li>Finally, test the load balancing.
            <codeblock>curl 10.247.96.28
Welcome to 10.247.94.132
              
curl 10.247.96.28
Welcome to 10.247.94.133
              
curl 10.247.96.28
Welcome to 10.247.94.132
              
curl 10.247.96.28
Welcome to 10.247.94.133
              
curl 10.247.96.28
Welcome to 10.247.94.132
              
curl 10.247.96.28
Welcome to 10.247.94.133</codeblock>
          </li>
        </ol>
      </p> 

    </section>
    

  </body>
</topic>
