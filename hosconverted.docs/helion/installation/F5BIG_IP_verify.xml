<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="F5_BIGIP_30_verify">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Verify F5 BIG-IP Integration</title>
  <body><!--not tested-->
    <p conkeyref="HOS-conrefs/applies-to"/>
    <p>To verify that your F5 BIG-IP device runs as a load balancer for Neutron LBaaSv2 in your deployment you will set up a round-robin load balancer on that private network. This is accomplished by creating two instances on their own private network and 
testing critical functionality.</p>
    
    <note type="important">Be aware of the following known issues: <ul>
        <li>For limitations of the F5 Networks driver, review the F5 OpenStack LBaaSv2 driver <xref
            href="http://f5-openstack-lbaasv2-driver.readthedocs.io/en/liberty/release_notes.html"
            scope="external" format="html">Release Notes</xref>.</li>
        <li>The members of a pool should be removed (neutron lbaas-member-delete) before deleting
          the pool (neutron lbaas-pool-delete), or the members may linger in the F5 appliance
          despite being deleted in Neutron.</li>
        <li>The pools of a listener should be removed (neutron lbaas-pool-delete) before deleting
          the listener (neutron lbaas-listener-delete), or the pools may linger in the F5 appliance
          despite being deleted in Neutron.</li>
        <li>If a pool is being monitored, in the BIG-IP control panel, the listener, the pool, and
          the pool members will display a monitoring status, but the nodes will continue to be
          unmonitored. This is because a node is not a service to monitor in LBaaSv2. A pool member
          is a node with a port/service.</li>
      </ul></note>
    
    <p>To very integration, complete all items in the following checklist, in order:</p>
    <table frame="all" rowsep="1" colsep="1" id="table_ckx_F5HOS30_vfy">
      <tgroup cols="2">
        <colspec colname="c1" colnum="1" colwidth="1*"/>
        <colspec colname="c2" colnum="2"  colwidth="19*"/>
        <thead>
          <row>
            <entry>&#9744;</entry>
            <entry>Item</entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify1">Verify or Upload a CirrOS Glance Image</xref> <p>Verify or upload the following CirrOS image in Glance:
              <codeblock>CirrOS-0.3.4-x86_64-disk</codeblock></p></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify2">Verify or Create an
                External Network and Subnet</xref><p>If not already existing, create an external
                network and its associated subnet.</p></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify3">Create a Private Network
                and Subnet for the Instances</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify4">Create a Router</xref>
              <p>Create a router to connect the private network to the external network.</p></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify5">Set up Security
                Groups</xref>
              <p>Set up security groups that allow you to access instances. The following list
                contains the seven commands (in order) that create a security group with all TCP,
                UDP, and ICMP ports opened:</p><ol>
                <li>neutron security-group-create allow_all</li>
                <li>neutron security-group-rule-create allow_all --direction ingress --protocol
                  icmp</li>
                <li>neutron security-group-rule-create allow_all --direction egress --protocol
                  icmp</li>
                <li>neutron security-group-rule-create allow_all --direction ingress --protocol
                  tcp</li>
                <li>neutron security-group-rule-create allow_all --direction egress --protocol
                  tcp</li>
                <li>neutron security-group-rule-create allow_all --direction ingress --protocol
                  udp</li>
                <li>neutron security-group-rule-create allow_all --direction egress --protocol
                  udp</li>
                </ol>These commands open all the ports so that you don't have to troubleshoot security groups if there is a connectivity problem.  These steps are for testing purposes only.</entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify6">Create 2 Virtual Machine
                Instances</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify7">Connect a Floating IP Addresses to Each Instance</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify8">Create a Load
                Balancer</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify9">Create a Listener for the
                Load Balancer</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify10">Create a Round-Robin HTTP Pool</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify11">Create Pool Members</xref>
              <p>Create a pool member for each instance. Make sure that the pool member plugs into the 
                fixed IP address of the instance.</p></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify12">Log in to Each Instance</xref>
              <p>Log in to each instance using their floating IP 
                address and run a web server.</p></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify13">Run a Web Server on Each Instance</xref>
              <p>On another session, connecting to any instance on the same private network, test reaching each 
                instance individually.</p></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify14">Test Connections Individually</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify15">Test the load balancer.</xref></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify16">Set Up a Health Monitor (Optional)</xref>
              <p>Optionally, set up a health monitor for the pool.</p></entry>
          </row>
          <row>
            <entry/>
            <entry><xref type="section" href="#F5_BIGIP_30_verify/verify17">Confirm the F5 BIG-IP Properties</xref>
              Visually confirm that the F5 BIG-IP partition is populated with the correct listener, pool, and members.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
    
    <section id="verify1">
      <title>Verify or Upload a CirrOS Glance Image</title>
      <p>You need a CirrOS image loaded in Glance so that you can create two Nova instances for testing the load balancing.</p>
      <ol>
        <li>Verify that you have the following CirrOS image in Glance 
          <codeblock>CirrOS-0.3.4-x86_64-disk</codeblock></li>
        <li>If you do not have it, to upload a CirrOS image, run:
          <codeblock>cd
#Export a proxy if necessary (e.g. `export http_proxy="http://proxy.atlanta.hp.com:8080"`)
wget 'http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img'
glance image-create --progress --name cirros-0.3.4-x86_64-disk --disk-format qcow2 --container-format bare --visibility public --file ~/cirros-0.3.4-x86_64-disk.img</codeblock></li></ol>
    </section>
    <lines>
    </lines>
    <section id="verify2">
      <title>Verify or Create an External Network and Subnet</title>
      <p>If you do not already have an external network, in this documentation it is called <b>ext-net</b>, then you must create one and its associated subnet.</p>
      <p>Use the following sample to understand how to create the external network:</p>
        <ol>
        <li>To create a new network, run:
          <codeblock>~$ neutron net-create ext-net --router:external True --provider:segmentation_id 812 --provider:network_type vxlan</codeblock>
          Sample
          output:<codeblock>+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | True                                 |
| id                        | a66a65a1-89fe-488b-9149-f7392076e226 |
| mtu                       | 0                                    |
| name                      | ext-net                              |
| provider:network_type     | vxlan                                |
| provider:physical_network |                                      |
| provider:segmentation_id  | 812                                  |
| router:external           | True                                 |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tenant_id                 | aa387f39ed5149149f196e7ab40f7fd3     |
+---------------------------+--------------------------------------+</codeblock></li>
          <li>To create a new subnet:
          <codeblock>~$ neutron subnet-create ext-net 10.246.71.0/24 --name ext-subnet --allocation-pool start=10.246.71.4,end=10.246.71.252 --gateway 10.246.71.1</codeblock>
          Sample
          output:<codeblock>+-------------------+--------------------------------------------------+
| Field             | Value                                            |
+-------------------+--------------------------------------------------+
| allocation_pools  | {"start": "10.246.71.4", "end": "10.246.71.252"} |
| cidr              | 10.246.71.0/24                                   |
| dns_nameservers   |                                                  |
| enable_dhcp       | True                                             |
| gateway_ip        | 10.246.71.1                                      |
| host_routes       |                                                  |
| id                | 072341fc-c085-450c-82d3-cf5100b5bd35             |
| ip_version        | 4                                                |
| ipv6_address_mode |                                                  |
| ipv6_ra_mode      |                                                  |
| name              | ext-subnet                                       |
| network_id        | a66a65a1-89fe-488b-9149-f7392076e226             |
| subnetpool_id     |                                                  |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3                 |
+-------------------+--------------------------------------------------+</codeblock></li>
      </ol>
    </section>
    <lines>
    </lines>
    <section id="verify3">
      <title>Create a Private Network and Subnet for the Instances</title>
      <ol>
        <li>To create a private network for the instances, run:
          <codeblock>~$ neutron net-create f5private</codeblock> Sample
          output:<codeblock>+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | True                                 |
| id                        | c80a0b0f-7f72-4409-9b98-c66bf2aafe04 |
| mtu                       | 0                                    |
| name                      | f5private                            |
| provider:network_type     | vxlan                                |
| provider:physical_network |                                      |
| provider:segmentation_id  | 1005                                 |
| router:external           | False                                |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tenant_id                 | aa387f39ed5149149f196e7ab40f7fd3     |
+---------------------------+--------------------------------------+</codeblock></li>
          <li>To create a subnet under that network, run:
          <codeblock>~$ neutron subnet-create --name f5sub f5private 10.1.0.0/24 --gateway 10.1.0.1</codeblock>
          Sample
          output:<codeblock>+-------------------+--------------------------------------------+
| Field             | Value                                      |
+-------------------+--------------------------------------------+
| allocation_pools  | {"start": "10.1.0.2", "end": "10.1.0.254"} |
| cidr              | 10.1.0.0/24                                |
| dns_nameservers   |                                            |
| enable_dhcp       | True                                       |
| gateway_ip        | 10.1.0.1                                   |
| host_routes       |                                            |
| id                | d1d9675c-43e8-44a0-b3f8-db78761e1d1b       |
| ip_version        | 4                                          |
| ipv6_address_mode |                                            |
| ipv6_ra_mode      |                                            |
| name              | f5sub                                      |
| network_id        | c80a0b0f-7f72-4409-9b98-c66bf2aafe04       |
| subnetpool_id     |                                            |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3           |
+-------------------+--------------------------------------------+</codeblock></li>
      </ol>
    </section>
    <lines>
    </lines>
    <section id="verify4">
      <title>Create a Router</title>
      <p>To connect the private network to the external network:</p>
        <ol>
          <li>To create a new router, run: <codeblock>~$ neutron router-create f5router</codeblock>
          Sample
          output:<codeblock>+-----------------------+--------------------------------------+
| Field                 | Value                                |
+-----------------------+--------------------------------------+
| admin_state_up        | True                                 |
| distributed           | True                                 |
| external_gateway_info |                                      |
| ha                    | False                                |
| id                    | 75a9e224-9e80-4f5a-9fc7-d1cb08513047 |
| name                  | f5router                             |
| routes                |                                      |
| status                | ACTIVE                               |
| tenant_id             | aa387f39ed5149149f196e7ab40f7fd3     |
+-----------------------+--------------------------------------+</codeblock></li>
<li>To add an interface to the router, run:
  <codeblock>~$ neutron router-interface-add f5router f5sub</codeblock>
Sample output:
<codeblock>Added interface 9ff3507a-b466-4de3-a6b0-daa414f7579c to router f5router</codeblock></li>
        <li>To set a gateway for the router, run:
        <codeblock>~$ neutron router-gateway-set f5router ext-net</codeblock>
          Sample output: <codeblock>Set gateway for router f5router</codeblock>
        </li>
        </ol>
    </section>
    <lines>
    </lines>
    <section id="verify5">
      <title>Set Up Security Groups</title>
      <ol>
        <li>To create a new security group, run:
          <codeblock>~$ neutron security-group-create allow_all</codeblock>
          Sample output:
        </li>
          <li>To create a new security group rule, run:
          <codeblock>~$ neutron security-group-rule-create allow_all --direction ingress --protocol icmp</codeblock>
          Sample
          output:<codeblock>+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| id                | fc046657-f3cf-4955-bbbe-cc8ae3ffa782 |
| port_range_max    |                                      |
| port_range_min    |                                      |
| protocol          | icmp                                 |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | fe455a69-9731-481c-b328-bb118aec4204 |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3     |
+-------------------+--------------------------------------+ </codeblock></li>
        <li>To create a new security group rule, run:
          <codeblock>~$ neutron security-group-rule-create allow_all --direction egress --protocol icmp</codeblock>
          Sample
          output:<codeblock>+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | egress                               |
| ethertype         | IPv4                                 |
| id                | 18201397-83c2-4f34-a25e-2c07cafab50e |
| port_range_max    |                                      |
| port_range_min    |                                      |
| protocol          | icmp                                 |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | fe455a69-9731-481c-b328-bb118aec4204 |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3     |
+-------------------+--------------------------------------+</codeblock></li>
        <li>To create a new security group rule, run:
          <codeblock>~$ neutron security-group-rule-create allow_all --direction ingress --protocol tcp
Created a new security_group_rule:
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| id                | ca7fcfa1-9635-45ce-a920-9b7e579876cb |
| port_range_max    |                                      |
| port_range_min    |                                      |
| protocol          | tcp                                  |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | fe455a69-9731-481c-b328-bb118aec4204 |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3     |
+-------------------+--------------------------------------+

~$ neutron security-group-rule-create allow_all --direction egress --protocol tcp
Created a new security_group_rule:
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | egress                               |
| ethertype         | IPv4                                 |
| id                | 04e3b094-4a4f-473b-92a0-3040f44277b9 |
| port_range_max    |                                      |
| port_range_min    |                                      |
| protocol          | tcp                                  |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | fe455a69-9731-481c-b328-bb118aec4204 |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3     |
+-------------------+--------------------------------------+

~$ neutron security-group-rule-create allow_all --direction ingress --protocol udp
Created a new security_group_rule:
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| id                | 793128f7-8229-40f2-a9bc-0ded64f07c01 |
| port_range_max    |                                      |
| port_range_min    |                                      |
| protocol          | udp                                  |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | fe455a69-9731-481c-b328-bb118aec4204 |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3     |
+-------------------+--------------------------------------+

:~$ neutron security-group-rule-create allow_all --direction egress --protocol udp
Created a new security_group_rule:
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| direction         | egress                               |
| ethertype         | IPv4                                 |
| id                | f4bc3c65-b14c-4ab2-8ddf-4d0686ee4180 |
| port_range_max    |                                      |
| port_range_min    |                                      |
| protocol          | udp                                  |
| remote_group_id   |                                      |
| remote_ip_prefix  |                                      |
| security_group_id | fe455a69-9731-481c-b328-bb118aec4204 |
| tenant_id         | aa387f39ed5149149f196e7ab40f7fd3     |
+-------------------+--------------------------------------+</codeblock></li>
      </ol>
    </section>
    <lines>
    </lines>
    <section id="verify6">
      <title>Create 2 Virtual Machine Instances</title>
      <ol>
      <li> To create the first VM, run:
          <codeblock>~$ nova boot --flavor 1 --image "cirros-0.3.4-x86_64-disk" --nic net-id="$(neutron net-list | awk '/f5private/ {print $2}')" --security-groups allow_all f5vm1</codeblock>
          Sample output:
          <codeblock>+--------------------------------------+-----------------------------------------------------------------+
| Property                             | Value                                                           |
+--------------------------------------+-----------------------------------------------------------------+
| OS-DCF:diskConfig                    | MANUAL                                                          |
| OS-EXT-AZ:availability_zone          |                                                                 |
| OS-EXT-SRV-ATTR:host                 | -                                                               |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                                               |
| OS-EXT-SRV-ATTR:instance_name        | instance-00000009                                               |
| OS-EXT-STS:power_state               | 0                                                               |
| OS-EXT-STS:task_state                | scheduling                                                      |
| OS-EXT-STS:vm_state                  | building                                                        |
| OS-SRV-USG:launched_at               | -                                                               |
| OS-SRV-USG:terminated_at             | -                                                               |
| accessIPv4                           |                                                                 |
| accessIPv6                           |                                                                 |
| adminPass                            | ZUnnCFivASV3                                                    |
| config_drive                         |                                                                 |
| created                              | 2016-06-29T19:31:55Z                                            |
| flavor                               | m1.tiny (1)                                                     |
| hostId                               |                                                                 |
| id                                   | a2d196f3-cf11-4dd8-b755-4908f5f0f7d3                            |
| image                                | cirros-0.3.4-x86_64-disk (aa29d1d9-4786-4577-bcaa-1cfaba5d97c4) |
| key_name                             | -                                                               |
| metadata                             | {}                                                              |
| name                                 | f5vm1                                                           |
| os-extended-volumes:volumes_attached | []                                                              |
| progress                             | 0                                                               |
| security_groups                      | allow_all                                                       |
| status                               | BUILD                                                           |
| tenant_id                            | aa387f39ed5149149f196e7ab40f7fd3                                |
| updated                              | 2016-06-29T19:31:55Z                                            |
| user_id                              | bdf0c78bc1b44f009b651a040f1d2773                                |
+--------------------------------------+-----------------------------------------------------------------+</codeblock></li>
        <li> To create the first VM, run:
          <codeblock>~$ nova boot --flavor 1 --image "cirros-0.3.4-x86_64-disk" --nic net-id="$(neutron net-list | awk '/f5private/ {print $2}')" --security-groups allow_all f5vm2</codeblock>
          Sample output:
          <codeblock>+--------------------------------------+-----------------------------------------------------------------+
| Property                             | Value                                                           |
+--------------------------------------+-----------------------------------------------------------------+
| OS-DCF:diskConfig                    | MANUAL                                                          |
| OS-EXT-AZ:availability_zone          |                                                                 |
| OS-EXT-SRV-ATTR:host                 | -                                                               |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                                               |
| OS-EXT-SRV-ATTR:instance_name        | instance-0000000c                                               |
| OS-EXT-STS:power_state               | 0                                                               |
| OS-EXT-STS:task_state                | scheduling                                                      |
| OS-EXT-STS:vm_state                  | building                                                        |
| OS-SRV-USG:launched_at               | -                                                               |
| OS-SRV-USG:terminated_at             | -                                                               |
| accessIPv4                           |                                                                 |
| accessIPv6                           |                                                                 |
| adminPass                            | qsZ8STziYWzD                                                    |
| config_drive                         |                                                                 |
| created                              | 2016-06-29T19:32:02Z                                            |
| flavor                               | m1.tiny (1)                                                     |
| hostId                               |                                                                 |
| id                                   | 5c0f6ac3-a5c5-4474-82f0-d02fb544cf02                            |
| image                                | cirros-0.3.4-x86_64-disk (aa29d1d9-4786-4577-bcaa-1cfaba5d97c4) |
| key_name                             | -                                                               |
| metadata                             | {}                                                              |
| name                                 | f5vm2                                                           |
| os-extended-volumes:volumes_attached | []                                                              |
| progress                             | 0                                                               |
| security_groups                      | allow_all                                                       |
| status                               | BUILD                                                           |
| tenant_id                            | aa387f39ed5149149f196e7ab40f7fd3                                |
| updated                              | 2016-06-29T19:32:02Z                                            |
| user_id                              | bdf0c78bc1b44f009b651a040f1d2773                                |
+--------------------------------------+-----------------------------------------------------------------+</codeblock></li>
      </ol>
    </section>
    <lines>
    </lines>
    <section id="verify7">
      <title>Connect a Floating IP Addresses to Each Instance</title>
      <ol>
        <li> To create a floating IP, run: <codeblock>~$ nova floating-ip-create</codeblock> Sample
          output:
          <codeblock>+--------------------------------------+-------------+-----------+----------+---------+
| Id                                   | IP          | Server Id | Fixed IP | Pool    |
+--------------------------------------+-------------+-----------+----------+---------+
| b7a40218-d304-4113-a701-475338bb6d99 | 10.246.71.7 | -         | -        | ext-net |
+--------------------------------------+-------------+-----------+----------+---------+</codeblock></li>
<li>To create another floating IP, run: <codeblock>~$ nova floating-ip-create</codeblock> Sample
          output:
          <codeblock>+--------------------------------------+-------------+-----------+----------+---------+
| Id                                   | IP          | Server Id | Fixed IP | Pool    |
+--------------------------------------+-------------+-----------+----------+---------+
| fdcb621e-a90e-4fa5-b05a-fdf2fd6a058c | 10.246.71.8 | -         | -        | ext-net |
+--------------------------------------+-------------+-----------+----------+---------+</codeblock></li>
        <li>To associate the new floating IP addresses with an instance, run:
<codeblock>~$ nova floating-ip-associate a2d196f3-cf11-4dd8-b755-4908f5f0f7d3 10.246.71.7
~$ nova floating-ip-associate 5c0f6ac3-a5c5-4474-82f0-d02fb544cf02 10.246.71.8</codeblock></li>
      </ol>
    </section>
    <lines>
    </lines>
    <section id="verify8">
      <title>Create a Load Balancer</title>
      <p>The following command sets up the load balancer on the private IP address 10.1.0.5. Remember to replace this value with the private IP address created on your network.</p>
      <ol>
        <li>To create a new load balancer, run:
          <codeblock>~$ neutron lbaas-loadbalancer-create --name f5lb --vip-address 10.1.0.5 --provider f5networks f5sub</codeblock>
          Sample
          output:<codeblock>+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| admin_state_up      | True                                 |
| description         |                                      |
| id                  | 920378e1-78c6-495a-93a1-4b97fd8560be |
| listeners           |                                      |
| name                | f5lb                                 |
| operating_status    | OFFLINE                              |
| provider            | f5networks                           |
| provisioning_status | PENDING_CREATE                       |
| tenant_id           | aa387f39ed5149149f196e7ab40f7fd3     |
| vip_address         | 10.1.0.5                             |
| vip_port_id         | 69aa3350-b804-40a7-8fd8-a407de3ee8a5 |
| vip_subnet_id       | d1d9675c-43e8-44a0-b3f8-db78761e1d1b |
+---------------------+--------------------------------------+</codeblock></li>
        <li>To show the properties of the newly created load balancer, run:
      <codeblock>~$ neutron lbaas-loadbalancer-show &lt;name of load balancer&gt;</codeblock>
        Sample output:
        <codeblock>~$ neutron lbaas-loadbalancer-show 920378e1-78c6-495a-93a1-4b97fd8560be
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| admin_state_up      | True                                 |
| description         |                                      |
| id                  | 920378e1-78c6-495a-93a1-4b97fd8560be |
| listeners           |                                      |
| name                | f5lb                                 |
| operating_status    | ONLINE                               |
| provider            | f5networks                           |
| provisioning_status | ACTIVE                               |
| tenant_id           | aa387f39ed5149149f196e7ab40f7fd3     |
| vip_address         | 10.1.0.5                             |
| vip_port_id         | 69aa3350-b804-40a7-8fd8-a407de3ee8a5 |
| vip_subnet_id       | d1d9675c-43e8-44a0-b3f8-db78761e1d1b |
+---------------------+--------------------------------------+</codeblock></li>
      </ol>
    </section>
    
    <section id="verify9">
      <title>Create a Listener for the Load Balancer</title>
      <ol>
        <li>To create a new listener, run:
          <codeblock>~$ neutron lbaas-listener-create --loadbalancer f5lb --protocol HTTP --protocol-port 80 --name f5listener</codeblock>
          Sample
          output:<codeblock>+---------------------------+------------------------------------------------+
| Field                     | Value                                          |
+---------------------------+------------------------------------------------+
| admin_state_up            | True                                           |
| connection_limit          | -1                                             |
| default_pool_id           |                                                |
| default_tls_container_ref |                                                |
| description               |                                                |
| id                        | 3969e5b2-4b0a-44ca-9810-731afaf0e19e           |
| loadbalancers             | {"id": "920378e1-78c6-495a-93a1-4b97fd8560be"} |
| name                      | f5listener                                     |
| protocol                  | HTTP                                           |
| protocol_port             | 80                                             |
| sni_container_refs        |                                                |
| tenant_id                 | aa387f39ed5149149f196e7ab40f7fd3               |
+---------------------------+------------------------------------------------+</codeblock>
        </li>
      </ol>
    </section>
    
    <section id="verify10">
      <title>Create a Round-Robin HTTP Pool</title>
      <ol>
        <li>To create a new pool, run:
          <codeblock>~$ neutron lbaas-pool-create --lb-algorithm ROUND_ROBIN --listener f5listener --protocol HTTP --name f5pool</codeblock>
          Sample
          output:<codeblock>+---------------------+------------------------------------------------+
| Field               | Value                                          |
+---------------------+------------------------------------------------+
| admin_state_up      | True                                           |
| description         |                                                |
| healthmonitor_id    |                                                |
| id                  | bfae1a16-2e06-47c3-9cea-fcc56b8e8bae           |
| lb_algorithm        | ROUND_ROBIN                                    |
| listeners           | {"id": "3969e5b2-4b0a-44ca-9810-731afaf0e19e"} |
| members             |                                                |
| name                | f5pool                                         |
| protocol            | HTTP                                           |
| session_persistence |                                                |
| tenant_id           | aa387f39ed5149149f196e7ab40f7fd3               |
+---------------------+------------------------------------------------+</codeblock>
        </li>
      </ol>
    </section>
    <lines>
    </lines>
    <section id="verify11">
      <title>Create Pool Members</title>
      <p>The two new pool members you create will plug into the instances' fixed IP addresses.</p>
        <ol>
        <li>To create a new member, run:
          <codeblock>~$ neutron lbaas-member-create --subnet f5sub --address 10.1.0.7 --protocol-port 80 f5pool</codeblock>
          Sample
          output:<codeblock>+----------------+--------------------------------------+
| Field          | Value                                |
+----------------+--------------------------------------+
| address        | 10.1.0.7                             |
| admin_state_up | True                                 |
| id             | b0f8370d-1ee5-46f6-be38-9efb2c5807ec |
| protocol_port  | 80                                   |
| subnet_id      | d1d9675c-43e8-44a0-b3f8-db78761e1d1b |
| tenant_id      | aa387f39ed5149149f196e7ab40f7fd3     |
| weight         | 1                                    |
+----------------+--------------------------------------+</codeblock></li>
       <li>To create a second new member, run:
          <codeblock>~$ neutron lbaas-member-create --subnet f5sub --address 10.1.0.8 --protocol-port 80 f5pool</codeblock>
          Sample
          output:<codeblock>+----------------+--------------------------------------+
| Field          | Value                                |
+----------------+--------------------------------------+
| address        | 10.1.0.8                             |
| admin_state_up | True                                 |
| id             | 457a9a2d-75bc-4f08-b9f8-26e0270e0f51 |
| protocol_port  | 80                                   |
| subnet_id      | d1d9675c-43e8-44a0-b3f8-db78761e1d1b |
| tenant_id      | aa387f39ed5149149f196e7ab40f7fd3     |
| weight         | 1                                    |
+----------------+--------------------------------------+</codeblock></li>
      </ol>
    </section>
    
    <section id="verify12">
      <title>Log in to Each Instance</title>
      <p>Log in to each instance using its floating IP address. On CirrOS, the following settings are used:</p>
      <dl>
        <dlentry>
          <dt>username</dt>
          <dd>cirros</dd>
        </dlentry>
        <dlentry>
          <dt>password</dt>
          <dd>cubswin:)</dd>
        </dlentry>
      </dl>
      <ol>
        <li>To log in to an instance, run:
          <codeblock>&lt;username&gt; [~]$ ssh cirros@&lt;floating_IP_address&gt;</codeblock> Sample
          output:
          <codeblock>user@myHelion [~]$ ssh cirros@10.246.71.7
Warning: Permanently added '10.246.71.7' (RSA) to the list of known hosts.
cirros@10.246.71.7's password: </codeblock>
        </li>
        <li>Repeat these steps for the second instance.</li>
      </ol>
    </section>
    
    <section id="verify13">
      <title>Run a Web Server on Each Instance</title>
      <ol>
        <li>To run a web server on an instance, run:
        <codeblock>while : ; do echo -e "HTTP/1.0 200 OK\r\n\r\nWelcome to $(/sbin/ifconfig eth0|grep 'inet addr'|awk -F: '{print $2}'| awk '{print $1}')" | sudo nc -l -p 80 ; done</codeblock></li>
        <li>Repeat these steps on each instance.</li>
      </ol>
    </section>
    
    <section id="verify14">
      <title>Test Connections Individually</title>
      <p>On another session, connect to any instance on the same private network, and test reaching that instance individually.</p>
        <ol>
          <li>To log in to an instance, run:
            <codeblock>&lt;username&gt; [~]$ ssh cirros@&lt;floating_IP_address&gt;</codeblock>
            Sample output:
            <codeblock>user@myHelion [~]$ ssh cirros@10.246.71.7
        Warning: Permanently added '10.246.71.7' (RSA) to the list of known hosts.
        cirros@10.246.71.7's password: </codeblock></li>
        <li>To test the connection to an instance, run:
          <codeblock>$ curl &lt;IP_address&gt;</codeblock> Sample output:
          <codeblock>$ curl 10.1.0.7
Welcome to 10.1.0.7</codeblock></li>
            <li>Repeat these steps for each connection you want to test.</li>
      </ol>
    </section>
    
    <section id="verify15">
      <title>Test the Load Balancer</title>
      <ol>
        <li>To test the load balancer, run:
          <codeblock>$ ping -c4 &lt;floating_IP_address&gt;</codeblock> Sample output:
          <codeblock>$ ping -c4 10.1.0.5
PING 10.1.0.5 (10.1.0.5): 56 data bytes
64 bytes from 10.1.0.5: seq=0 ttl=255 time=1.363 ms
64 bytes from 10.1.0.5: seq=1 ttl=255 time=0.332 ms
64 bytes from 10.1.0.5: seq=2 ttl=255 time=0.430 ms
64 bytes from 10.1.0.5: seq=3 ttl=255 time=0.397 ms
--- 10.1.0.5 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.332/0.630/1.363 ms
$ curl 10.1.0.5
Welcome to 10.1.0.7
^C
$ curl 10.1.0.5
Welcome to 10.1.0.7
^C
$ curl 10.1.0.5
Welcome to 10.1.0.8
^C
$ curl 10.1.0.5
Welcome to 10.1.0.8
^C</codeblock></li>
      </ol>
    </section>
    
    <section id="verify16">
      <title>Set Up a Health Monitor (Optional)</title>
      <p>Another option to test F5 integration is to set up a health monitor to monitor the pool.</p>
        <ol>
        <li>To create a new healthmonitor, run:
          <codeblock>~$ neutron lbaas-healthmonitor-create --max-retries 3 --timeout 10 --type PING --pool bfae1a16-2e06-47c3-9cea-fcc56b8e8bae --delay 30</codeblock>
          Sample
          output:<codeblock>
+----------------+------------------------------------------------+
| Field          | Value                                          |
+----------------+------------------------------------------------+
| admin_state_up | True                                           |
| delay          | 30                                             |
| expected_codes | 200                                            |
| http_method    | GET                                            |
| id             | bf5bbdba-b5cf-478e-bd52-f86a72d74c74           |
| max_retries    | 3                                              |
| pools          | {"id": "bfae1a16-2e06-47c3-9cea-fcc56b8e8bae"} |
| tenant_id      | aa387f39ed5149149f196e7ab40f7fd3               |
| timeout        | 10                                             |
| type           | PING                                           |
| url_path       | /                                              |
+----------------+------------------------------------------------+</codeblock></li>
      </ol>
    </section>
    
    
    
        <section id="privateHTTP">
      <title>Walkthrough of creation of a private HTTP load balancer using
        port 80</title><p>Here are the instructions to test if Neutron LBaaSv2 with F5 works on your
        installation. These instructions create two instances on their own private network and sets
        up a port 80 HTTP round robin load balancer on that private network. The load balancer will
        only be accessible from the private network.</p>
      <ol>
        <li>Verify that you have the following CirrOS image in Glance
          <codeblock>CirrOS-0.3.4-x86_64-disk</codeblock></li>
        <li>If you do not have it, to upload a CirrOS image, use these commands to do
          so:<codeblock>#Export a proxy if necessary (e.g. `export http_proxy="http://proxy.atlanta.hp.com:8080"`)
wget 'http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img'
glance image-create --progress --name cirros-0.3.4-x86_64-disk --disk-format qcow2 --container-format bare --visibility public --file ~/cirros-0.3.4-x86_64-disk.img</codeblock></li>
        <li>If you do not already have an external network created in your environment, use the
          steps outlined in  <xref href="../operations/create_extnet.dita#create_extnet"/>
           to do so.</li>
        <li>Create a private network for the instances.
          <codeblock>neutron net-create f5private</codeblock></li>
        <li>Create a subnet under that network. We chose the subnet CIDR of
            <codeph>10.1.0.0/24</codeph> in our example but you can choose your preferred
          CIDR.<codeblock>neutron subnet-create --name f5sub f5private 10.1.0.0/24</codeblock></li>
        <li>Create a router to connect the private network to the external network.
          <codeblock>neutron router-create f5router</codeblock></li>
        <li>Add an interface to the router.
          <codeblock>neutron router-interface-add f5router f5sub</codeblock></li>
        <li>Set a gateway for the router.
          <codeblock>neutron router-gateway-set f5router ext-net</codeblock></li>
        <li>Create a security group.
          <codeblock>neutron security-group-create allow_all</codeblock></li>
        <li>Create the following security group
          rules:<codeblock>neutron security-group-rule-create allow_all --direction ingress --protocol icmp
neutron security-group-rule-create allow_all --direction egress --protocol icmp
neutron security-group-rule-create allow_all --direction ingress --protocol tcp
neutron security-group-rule-create allow_all --direction egress --protocol tcp
neutron security-group-rule-create allow_all --direction ingress --protocol udp
neutron security-group-rule-create allow_all --direction egress --protocol udp</codeblock></li>
        <li>Create two compute instances. <p>To create the first virtual machine,
            run:</p><codeblock>nova boot --flavor 1 --image "cirros-0.3.4-x86_64-disk" --nic net-id="$(neutron net-list | awk '/f5private/ {print $2}')" --security-groups allow_all f5vm1</codeblock><p>To
            create the second virtual machine,
          run:</p><codeblock>nova boot --flavor 1 --image "cirros-0.3.4-x86_64-disk" --nic net-id="$(neutron net-list | awk '/f5private/ {print $2}')" --security-groups allow_all f5vm2</codeblock></li>
        <li>Create floating IP addresses for each instance for network connectivity. <p>To create a
            floating IP, run:</p><codeblock>nova floating-ip-create</codeblock><p>To create a second
            floating IP, run:</p><codeblock>nova floating-ip-create</codeblock></li>
        <li>Using the floating IP addresses and the instance IDs from the output of the previous two
          steps, associate the new floating IP addresses with these command:
          <codeblock>nova floating-ip-associate &lt;instance_id> &lt;floating_IP>
nova floating-ip-associate &lt;instance_id> &lt;floating_IP></codeblock></li>
        <li>Create a load balancer. <p>The following command sets up the load balancer on the
            private IP address 10.1.0.5. Remember to replace this value with the private IP address
            created on your network if you chose a different subnet
          CIDR.</p><codeblock>neutron lbaas-loadbalancer-create --name f5lb --vip-address 10.1.0.5 --provider f5networks f5sub</codeblock></li>
        <li>To show the properties of the newly created load balancer, run:
          <codeblock>neutron lbaas-loadbalancer-show &lt;name of load balancer&gt;</codeblock></li>
        <li>Create a listener for the load balancer.
          <codeblock>neutron lbaas-listener-create --loadbalancer f5lb --protocol HTTP --protocol-port 80 --name f5listener</codeblock></li>
        <li>Create a Round-Robin HTTP Pool.
            <codeblock>neutron lbaas-pool-create --lb-algorithm ROUND_ROBIN --listener f5listener --protocol HTTP --name f5pool</codeblock><note>Take
            note of the UUID of the pool that is created as you will use it in step #24.</note></li>
        <li>Create pool members. The two new pool members you create will plug into the instances'
          fixed IP addresses. <p>To create a new member, use this command, ensuring that you use an
            IP address from the subnet CIDR you
            chose:</p><codeblock>neutron lbaas-member-create --subnet f5sub --address 10.1.0.7 --protocol-port 80 f5pool</codeblock><p>To
            create a second new member, use this command, ensuring that you use an IP address from
            the subnet CIDR you
          chose:</p><codeblock>neutron lbaas-member-create --subnet f5sub --address 10.1.0.8 --protocol-port 80 f5pool</codeblock></li>
        <li>Log in to each instance using its floating IP address. On CirrOS, the following settings
          are used: <dl>
            <dlentry>
              <dt>username</dt>
              <dd>cirros</dd>
            </dlentry>
            <dlentry>
              <dt>password</dt>
              <dd>cubswin:)</dd>
            </dlentry>
          </dl><p>To log in to an instance,
          run:</p><codeblock>&lt;username&gt; [~]$ ssh cirros@&lt;floating_IP_address&gt;</codeblock></li>
        <li>Repeat the last step for the second instance.</li>
        <li>Run a web server on each instance. To run a web server on an instance, run:
            <codeblock>while : ; do echo -e "HTTP/1.0 200 OK\r\n\r\nWelcome to $(/sbin/ifconfig eth0|grep 'inet addr'|awk -F: '{print $2}'| awk '{print $1}')" | sudo nc -l -p 80 ; done</codeblock><p>Repeat
            this step on each instance.</p></li>
        <li>Test each connection individually. <p>On another session, connect to any instance on the
            same private network, and test reaching that instance individually.</p><ol>
            <li>To log in to an instance, run:
              <codeblock>&lt;username&gt; [~]$ ssh cirros@&lt;floating_IP_address&gt;</codeblock>
              Sample output:
              <codeblock>user@myHelion [~]$ ssh cirros@10.246.71.7
Warning: Permanently added '10.246.71.7' (RSA) to the list of known hosts.
cirros@10.246.71.7's password: </codeblock></li>
            <li>To test the connection to an instance, run:
              <codeblock>$ curl &lt;IP_address&gt;</codeblock> Sample output:
              <codeblock>$ curl 10.1.0.7
Welcome to 10.1.0.7</codeblock></li>
            <li>Repeat these steps for each connection you want to test.</li>
          </ol></li>
        <li>Test the Load Balancer. <codeblock>$ ping -c4 &lt;floating_IP_address&gt;</codeblock>
          Sample output:
          <codeblock>$ ping -c4 10.1.0.5
PING 10.1.0.5 (10.1.0.5): 56 data bytes
64 bytes from 10.1.0.5: seq=0 ttl=255 time=1.363 ms
64 bytes from 10.1.0.5: seq=1 ttl=255 time=0.332 ms
64 bytes from 10.1.0.5: seq=2 ttl=255 time=0.430 ms
64 bytes from 10.1.0.5: seq=3 ttl=255 time=0.397 ms
--- 10.1.0.5 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.332/0.630/1.363 ms

$ curl 10.1.0.5
Welcome to 10.1.0.7
^C

$ curl 10.1.0.5
Welcome to 10.1.0.7
^C

$ curl 10.1.0.5
Welcome to 10.1.0.8
^C

$ curl 10.1.0.5
Welcome to 10.1.0.8
^C</codeblock></li>
        <li>Set Up a Health Monitor (Optional). <p>Another option to test F5 integration is to set
            up a health monitor to monitor the pool.</p><ol>
            <li>To create a new healthmonitor, use this command using the pool UUID that was given
              in the output of step #17
              earlier:<codeblock>neutron lbaas-healthmonitor-create --max-retries 3 --timeout 10 --type PING --pool &lt;pool_UUID> --delay 30</codeblock>
              Sample
              output:<codeblock>+----------------+------------------------------------------------+
| Field          | Value                                          |
+----------------+------------------------------------------------+
| admin_state_up | True                                           |
| delay          | 30                                             |
| expected_codes | 200                                            |
| http_method    | GET                                            |
| id             | bf5bbdba-b5cf-478e-bd52-f86a72d74c74           |
| max_retries    | 3                                              |
| pools          | {"id": "bfae1a16-2e06-47c3-9cea-fcc56b8e8bae"} |
| tenant_id      | aa387f39ed5149149f196e7ab40f7fd3               |
| timeout        | 10                                             |
| type           | PING                                           |
| url_path       | /                                              |
+----------------+------------------------------------------------+</codeblock></li>
          </ol></li>
        <li>Confirm the F5 BIG-IP Properties. <p>A final test of integration is to use the F5
            Networks graphical user interface to confirm that the F5 BIG-IP partition is populated
            with the correct listener, pool, and members.</p><p>To open the F5 dashboard:</p><ol>
            <li>Open a browser.</li>
            <li>Navigate to the following URL: <codeblock>https://&lt;iControl_IP&gt;/</codeblock>
              where: <dl>
                <dlentry>
                  <dt>&lt;iControl_IP&gt;</dt>
                  <dd>IP address or hostname of the BIG-IP appliance</dd>
                </dlentry>
              </dl><p>Sample output:</p><image href="../../media/F5BIGIP_verify.png"
                id="f5bigip_verify"/></li>
          </ol>
        </li>
      </ol>
    </section>

    <section id="privateHTTPS">
      <title>Walkthrough of creation of a private HTTPS load balancer using port 443 with instances
        using port 80</title>
      <p>Here are the instructions to test if Neutron LBaaSv2 with F5 and Barbican TLS containers
        works on your installation. These instructions create two instances on their own private
        network and sets up a port 443 TERMINATED_HTTPS round robin load balancer on that private
        network. The load balancer virtual IP address (VIP) exchanges HTTPS traffic with connecting
        clients, but the traffic between the load balancer listener and the instances is HTTP. The
        load balancer will only be accessible from the private network.</p>
      <ol>
        <li>Generate your site certificate chain and key. These sample commands are taken from the
            <xref
            href="https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Create_certificate_chain_and_key"
            scope="external" format="html">OpenStack wiki</xref>.
            <codeblock>openssl genrsa -des3 -out ca.key 1024
openssl req -new-x509 -days 3650-key ca.key -out ca.crt  
openssl x509  -in  ca.crt -out ca.pem 
openssl genrsa -des3 -out ca-int_encrypted.key 1024
openssl rsa -in ca-int_encrypted.key -out ca-int.key 
openssl req -new-key ca-int.key -out ca-int.csr -subj "/CN=ca-int@acme.com"
openssl x509 -req -days 3650-in ca-int.csr -CA ca.crt -CAkey ca.key -set_serial 01-out ca-int.crt 
openssl genrsa -des3 -out server_encrypted.key 1024
openssl rsa -in server_encrypted.key -out server.key 
openssl req -new-key server.key -out server.csr -subj "/CN=server@acme.com"
openssl x509 -req -days 3650-in server.csr -CA ca-int.crt -CAkey ca-int.key -set_serial 01-out server.crt</codeblock><p>Sample
            output:<codeblock>stack@helion-cp1-c0-m1-mgmt:~$ mkdir tmp
stack@helion-cp1-c0-m1-mgmt:~$ cd tmp
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl genrsa -des3 -out ca.key 1024
Generating RSA private key, 1024 bit long modulus
........................................++++++
...........................++++++
e is 65537 (0x10001)
Enter pass phrase for ca.key:
Verifying - Enter pass phrase for ca.key:
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl req -new -x509 -days 3650 -key ca.key -out ca.crt
Enter pass phrase for ca.key:
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [AU]:US
State or Province Name (full name) [Some-State]:Texas
Locality Name (eg, city) []:Austin
Organization Name (eg, company) [Internet Widgits Pty Ltd]:Hewlett Packard Enterprise
Organizational Unit Name (eg, section) []:Independent Hardware Vendor Certification
Common Name (e.g. server FQDN or YOUR name) []:IHV
Email Address []:helion.ihvteam@hpe.com
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl x509  -in  ca.crt -out ca.pem
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl genrsa -des3 -out ca-int_encrypted.key 1024
Generating RSA private key, 1024 bit long modulus
.....++++++
....++++++
e is 65537 (0x10001)
Enter pass phrase for ca-int_encrypted.key:
Verifying - Enter pass phrase for ca-int_encrypted.key:
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl rsa -in ca-int_encrypted.key -out ca-int.key
Enter pass phrase for ca-int_encrypted.key:
writing RSA key
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl req -new -key ca-int.key -out ca-int.csr -subj "/CN=helion.ihvteam@hpe.com"
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl x509 -req -days 3650 -in ca-int.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out ca-int.crt
Signature ok
subject=/CN=helion.ihvteam@hpe.com
Getting CA Private Key
Enter pass phrase for ca.key:
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl genrsa -des3 -out server_encrypted.key 1024
Generating RSA private key, 1024 bit long modulus
.............++++++
.............................................................................................................................++++++
e is 65537 (0x10001)
Enter pass phrase for server_encrypted.key:
Verifying - Enter pass phrase for server_encrypted.key:
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl rsa -in server_encrypted.key -out server.key
Enter pass phrase for server_encrypted.key:
writing RSA key
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl req -new -key server.key -out server.csr -subj "/CN=helion.ihvteam@hpe.com"
stack@helion-cp1-c0-m1-mgmt:~/tmp$ openssl x509 -req -days 3650 -in server.csr -CA ca-int.crt -CAkey ca-int.key -set_serial 01 -out server.crt
Signature ok
subject=/CN=helion.ihvteam@hpe.com
Getting CA Private Key
stack@helion-cp1-c0-m1-mgmt:~/tmp$ ls
ca-int.crt  ca-int.csr  ca-int.key  ca-int_encrypted.key  ca.crt  ca.key  ca.pem  server.crt  server.csr  server.key  server_encrypted.key</codeblock></p></li>
        <li>In Barbican, import the certificate as <codeph>certificate</codeph> and the private key
          as <codeph>private_key</codeph> and create a container called
            <codeph>tls_container</codeph> for TLS using this series of commands. These commands
          assume that the site certificate is stored in the file <codeph>server.crt</codeph> and
          that the private key is stored in <codeph>server.key</codeph> before
          running.<codeblock>source ~/barbican.osrc
barbican secret store --payload-content-type='text/plain' --name='certificate' --payload="$(cat server.crt)"
barbican secret store --payload-content-type='text/plain' --name='private_key' --payload="$(cat server.key)"
barbican secret container create --name='tls_container' --type='certificate' --secret="certificate=$(barbican secret list | awk '/ certificate / {print $2}')" --secret="private_key=$(barbican secret list | awk '/ private_key / {print $2}')"</codeblock></li>
        <li>If you do not already have a CirrOS image in Glance called
            <codeph>cirros-0.3.4-x86_64-disk</codeph> then use these commands to achieve
          this:<codeblock># Export a proxy if necessary (e.g. `export http_proxy="http://proxy.atlanta.hp.com:8080"`)
wget 'http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img'
glance image-create --progress --name cirros-0.3.4-x86_64-disk --disk-format qcow2 --container-format bare --visibility public --file ~/cirros-0.3.4-x86_64-disk.img</codeblock></li>
        <li>Verify that you have the following CirrOS image in Glance
          <codeblock>CirrOS-0.3.4-x86_64-disk</codeblock></li>
        <li>If you do not have it, to upload a CirrOS image, use these commands to do
          so:<codeblock>#Export a proxy if necessary (e.g. `export http_proxy="http://proxy.atlanta.hp.com:8080"`)
wget 'http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img'
glance image-create --progress --name cirros-0.3.4-x86_64-disk --disk-format qcow2 --container-format bare --visibility public --file ~/cirros-0.3.4-x86_64-disk.img</codeblock></li>
        <li>If you do not already have an external network created in your environment, use the
          steps outlined in <xref href="../operations/create_extnet.dita#create_extnet"/> to do so.</li>
        <li>Create a private network for the instances.
          <codeblock>neutron net-create f5private</codeblock></li>
        <li>Create a subnet under that network. We chose the subnet CIDR of
            <codeph>10.1.0.0/24</codeph> in our example but you can choose your preferred
          CIDR.<codeblock>neutron subnet-create --name f5sub f5private 10.1.0.0/24</codeblock></li>
        <li>Create a router to connect the private network to the external network.
          <codeblock>neutron router-create f5router</codeblock></li>
        <li>Add an interface to the router.
          <codeblock>neutron router-interface-add f5router f5sub</codeblock></li>
        <li>Set a gateway for the router.
          <codeblock>neutron router-gateway-set f5router ext-net</codeblock></li>
        <li>Create a security group.
          <codeblock>neutron security-group-create allow_all</codeblock></li>
        <li>Create the following security group
          rules:<codeblock>neutron security-group-rule-create allow_all --direction ingress --protocol icmp
neutron security-group-rule-create allow_all --direction egress --protocol icmp
neutron security-group-rule-create allow_all --direction ingress --protocol tcp
neutron security-group-rule-create allow_all --direction egress --protocol tcp
neutron security-group-rule-create allow_all --direction ingress --protocol udp
neutron security-group-rule-create allow_all --direction egress --protocol udp</codeblock></li>
        <li>Create two compute instances. <p>To create the first virtual machine,
          run:</p><codeblock>nova boot --flavor 1 --image "cirros-0.3.4-x86_64-disk" --nic net-id="$(neutron net-list | awk '/f5private/ {print $2}')" --security-groups allow_all f5vm1</codeblock>
          To create the second virtual machine, run:
          <codeblock>nova boot --flavor 1 --image "cirros-0.3.4-x86_64-disk" --nic net-id="$(neutron net-list | awk '/f5private/ {print $2}')" --security-groups allow_all f5vm2</codeblock></li>
        <li>Create floating IP addresses for each instance for network connectivity.
            <codeblock>nova floating-ip-create</codeblock><p>To create a second floating IP,
            run:</p><codeblock>nova floating-ip-create</codeblock></li>
        <li>Using the floating IP addresses and the instance IDs from the output of the previous two
          steps, associate the new floating IP addresses with these command:
          <codeblock>nova floating-ip-associate &lt;instance_id> &lt;floating_IP>
nova floating-ip-associate &lt;instance_id> &lt;floating_IP></codeblock></li>
        <li>Create a load balancer. <p>The following command sets up the load balancer on the
            private IP address 10.1.0.5. Remember to replace this value with the private IP address
            created on your
          network.</p><codeblock>neutron lbaas-loadbalancer-create --name f5lb --vip-address 10.1.0.5 --provider f5networks f5sub</codeblock></li>
        <li>Create a TERMINATED_HTTPS listener for the load balancer using the TLS container
            <codeph>tls_container</codeph>:
            <codeblock>neutron lbaas-listener-create --loadbalancer f5lb2 --protocol TERMINATED_HTTPS --protocol-port 443 --name f5listener_tls --default-tls-container=$(barbican secret container list | awk '/ tls_container / {print $2}')</codeblock><p>Sample
            output:</p><codeblock>Starting new HTTPS connection (1): helion-cp1-vip-KEY-API-mgmt
Starting new HTTPS connection (1): 10.246.68.2
Created a new listener:
+---------------------------+-----------------------------------------------------------------------------+
| Field                     | Value                                                                       |
+---------------------------+-----------------------------------------------------------------------------+
| admin_state_up            | True                                                                        |
| connection_limit          | -1                                                                          |
| default_pool_id           |                                                                             |
| default_tls_container_ref | https://10.246.68.2:9311/v1/containers/8bb3110f-9599-4377-a546-c02bdaa52978 |
| description               |                                                                             |
| id                        | 728b381a-edf8-4461-b920-1277e65f018f                                        |
| loadbalancers             | {"id": "30b7627b-237d-48f9-bb01-e75f1f04c8c0"}                              |
| name                      | f5listener_tls                                                              |
| protocol                  | TERMINATED_HTTPS                                                            |
| protocol_port             | 443                                                                         |
| sni_container_refs        |                                                                             |
| tenant_id                 | d59003927b7441c588e29f6f590f225d                                            |
+---------------------------+-----------------------------------------------------------------------------+</codeblock></li>
        <li>Create a round robin HTTP pool:<codeblock>neutron lbaas-pool-create --lb-algorithm ROUND_ROBIN --listener f5listener_tls --protocol HTTP --name f5pool_tlsflex</codeblock>
          <note>Take note of the UUID of the pool that is created as you will use it in step
            #27.</note></li>
        <li>Create pool members. The two new pool members you create will plug into the instances'
          fixed IP addresses. <p>To create a new member, use this command, ensuring that you use an
            IP address from the subnet CIDR you
            chose:</p><codeblock>neutron lbaas-member-create --subnet f5sub --address 10.1.0.7 --protocol-port 80 f5pool</codeblock><p>To
            create a second new member, use this command, ensuring that you use an IP address from
            the subnet CIDR you
          chose:</p><codeblock>neutron lbaas-member-create --subnet f5sub --address 10.1.0.8 --protocol-port 80 f5pool</codeblock></li>
        <li>Log in to each instance using its floating IP address. On CirrOS, the following settings
          are used: <dl>
            <dlentry>
              <dt>username</dt>
              <dd>cirros</dd>
            </dlentry>
            <dlentry>
              <dt>password</dt>
              <dd>cubswin:)</dd>
            </dlentry>
          </dl><p>To log in to an instance,
          run:</p><codeblock>&lt;username&gt; [~]$ ssh cirros@&lt;floating_IP_address&gt;</codeblock></li>
        <li>Repeat the last step for the second instance.</li>
        <li>Run a web server on each instance. To run a web server on an instance, run:
            <codeblock>while : ; do echo -e "HTTP/1.0 200 OK\r\n\r\nWelcome to $(/sbin/ifconfig eth0|grep 'inet addr'|awk -F: '{print $2}'| awk '{print $1}')" | sudo nc -l -p 80 ; done</codeblock><p>Repeat
            this step on each instance.</p></li>
        <li>Test each connection individually. <p>On another session, connect to any instance on the
            same private network, and test reaching that instance individually.</p><ol>
            <li>To log in to an instance, run:
              <codeblock>&lt;username&gt; [~]$ ssh cirros@&lt;floating_IP_address&gt;</codeblock>
              Sample output:
              <codeblock>user@myHelion [~]$ ssh cirros@10.246.71.7
Warning: Permanently added '10.246.71.7' (RSA) to the list of known hosts.
cirros@10.246.71.7's password: </codeblock></li>
            <li>To test the connection to an instance, run:
              <codeblock>$ curl &lt;IP_address&gt;</codeblock> Sample output:
              <codeblock>$ curl 10.1.0.7
Welcome to 10.1.0.7</codeblock></li>
            <li>Repeat these steps for each connection you want to test.</li>
          </ol></li>
        <li>Test the Load Balancer. <codeblock>$ ping -c4 &lt;floating_IP_address&gt;</codeblock>
          Sample output:
          <codeblock>$ ping -c4 10.1.0.5
PING 10.1.0.5 (10.1.0.5): 56 data bytes
64 bytes from 10.1.0.5: seq=0 ttl=255 time=1.363 ms
64 bytes from 10.1.0.5: seq=1 ttl=255 time=0.332 ms
64 bytes from 10.1.0.5: seq=2 ttl=255 time=0.430 ms
64 bytes from 10.1.0.5: seq=3 ttl=255 time=0.397 ms
--- 10.1.0.5 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.332/0.630/1.363 ms

$ curl 10.1.0.5
Welcome to 10.1.0.7
^C

$ curl 10.1.0.5
Welcome to 10.1.0.7
^C

$ curl 10.1.0.5
Welcome to 10.1.0.8
^C

$ curl 10.1.0.5
Welcome to 10.1.0.8
^C</codeblock></li>
        <li>If you have an instance with the OpenSSL binary package installed (CirrOS does not have
          the <codeph>openssl</codeph> command), you can check that the certificate being returned
          is the right one using this
          command:<codeblock>openssl s_client -connect 10.1.0.11:443</codeblock></li>
        <li>Set Up a Health Monitor (Optional). <p>Another option to test F5 integration is to set
            up a health monitor to monitor the pool.</p><ol>
            <li>To create a new healthmonitor, use this command using the pool UUID that was given
              in the output of step #19
              earlier:<codeblock>neutron lbaas-healthmonitor-create --max-retries 3 --timeout 10--type HTTP --pool &lt;pool_UUID> --delay 30</codeblock>
              Sample
              output:<codeblock>Created a new healthmonitor:
+----------------+------------------------------------------------+
| Field          | Value                                          |
+----------------+------------------------------------------------+
| admin_state_up | True                                           |
| delay          | 30                                             |
| expected_codes | 200                                            |
| http_method    | GET                                            |
| id             | 88d18085-8e83-4413-b8e8-419a8fc8dc39           |
| max_retries    | 3                                              |
| pools          | {"id": "c9e4712a-57a6-4bda-b7b2-1d24647c9cd0"} |
| tenant_id      | d59003927b7441c588e29f6f590f225d               |
| timeout        | 10                                             |
| type           | HTTP                                           |
| url_path       | /                                              |
+----------------+------------------------------------------------+</codeblock></li>
          </ol></li>
        <li>Confirm the F5 BIG-IP Properties. <p>A final test of integration is to use the F5
            Networks graphical user interface to confirm that the F5 BIG-IP partition is populated
            with the correct listener, pool, and members.</p><p>To open the F5 dashboard:</p><ol>
            <li>Open a browser.</li>
            <li>Navigate to the following URL: <codeblock>https://&lt;iControl_IP&gt;/</codeblock>
              where: <dl>
                <dlentry>
                  <dt>&lt;iControl_IP&gt;</dt>
                  <dd>IP address or hostname of the BIG-IP appliance</dd>
                </dlentry>
              </dl><p>Sample output:</p>
              <image href="../../media/f5-bigip-console-showing-working-lbaas-tls.png"/></li>
          </ol>
        </li>
      </ol>
    </section>
    
    
    
    
    
    
    
    <section id="verify17">
      <title>Confirm the F5 BIG-IP Properties</title>
      <p>A final test of integration is to use the F5 Networks graphical user interface to confirm that the F5 BIG-IP partition is populated with the correct listener, pool, and members.</p>
      <p>To open the F5 dashboard:</p>
      <ol>
        <li>Open a browser.</li>
        <li>Navigate to the following URL: <codeblock>https://&lt;iControl_IP&gt;/</codeblock>
          where: <dl>
            <dlentry>
              <dt>&lt;iControl_IP&gt;</dt>
              <dd>IP address or hostname of the BIG-IP appliance</dd>
            </dlentry>
          </dl> Sample output: <image href="../../media/F5BIGIP_verify.png"/></li>
      </ol>
    </section>
    
  </body>
</topic>
