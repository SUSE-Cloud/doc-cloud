<?xml version="1.0"?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [ <!ENTITY % entities SYSTEM "entities.xml"> %entities; ]><!--Edit status: not edited-->
<section id="idg-installation-esx-procedure_to_deploy_esx_cloud-dita-1">
   <title>
      <phrase/>Procedure to Deploy ESX Cloud with
    OVSvApp</title>
    
    
      <bridgehead renderas="sect4">Set up the Lifecycle Manager</bridgehead>
      <para><emphasis role="bold">Installing the Lifecycle Manager</emphasis></para>

      <para>The lifecycle manager will contain the installation scripts and configuration files to
        deploy your cloud. You can set up the lifecycle manager on a dedicated node or you do so on
        your first controller node. The default choice is to use the first controller node as the
        lifecycle manager.</para>

      <orderedlist>
        <listitem>
            <para>Sign in and download the product and signature files at the link below: </para>

            <orderedlist>
               <listitem>
                  <para><ulink url="http://www.hpe.com/software/entitlements">Software Entitlement Portal</ulink></para>

               </listitem>
            </orderedlist>
         </listitem>
        <listitem>
            <para>You can verify the download was complete via the signature verification process outlined
            <ulink url="https://h20392.www2.hpe.com/portal/swdepot/displayProductInfo.do?productNumber=HPLinuxCodeSigning">here</ulink>.</para>

         </listitem>
        <listitem>
            <para>Boot your lifecycle manager from the ISO contained in the download.</para>

         </listitem>
        <listitem>
            <para>Enter "install" to start installation. </para>

            <note>
               <para>"install" is all lower case</para>

            </note>
         </listitem>
        <listitem>
            <para>Select the language. Note that only the English language selection is currently
          supported.</para>

         </listitem>
        <listitem>
            <para>Select the location.</para>

         </listitem>
        <listitem>
            <para>Select the keyboard layout.</para>

         </listitem>
        <listitem>
            <para>Select the primary network interface, if prompted:</para>

            <orderedlist>
               <listitem>
                  <para>Assign IP address, subnet mask, and default gateway</para>

               </listitem>
            </orderedlist>
         </listitem>
        <listitem>
            <para>Create new account:</para>

            <orderedlist>
               <listitem>
                  <para>Enter a username.</para>

               </listitem>
               <listitem>
                  <para>Enter a password.</para>

               </listitem>
               <listitem>
                  <para>Enter time zone.</para>

               </listitem>
            </orderedlist>
         </listitem>
      </orderedlist>
      <para>Once the initial installation is finished, complete the lifecycle manager setup with these
        steps:</para>

      <orderedlist>
        <listitem>
            <para>Ensure your lifecycle manager has a valid DNS nameserver specified in
            <literal>/etc/resolv.conf</literal>.</para>

         </listitem>
        <listitem>
            <para>Set the environment variable LC_ALL: </para>

            <screen>export LC_ALL=C</screen>
            <note>
               <para>This
            can be added to <literal>~stack/.bashrc</literal> or
            <literal>/etc/bash.bashrc</literal>.</para>

            </note>
         </listitem>
      </orderedlist>
      <para>At the end of this section you should have a node set up with Linux for HPE Helion on
        it.</para>

      <para><emphasis role="bold">Configure and Run the Lifecycle Manager</emphasis></para>

      <important>
         <para>It is critical that you don't run any of the commands below as the
          <literal>root</literal> user or use <literal>sudo</literal>, unless it is stated explicitly in
        the steps. Run then as the user you just created (or <literal>stack</literal> if you left the
        default of "stack").</para>

      </important>
      <orderedlist>
        <listitem>
            <para>Log into your lifecycle manager as the user you created and mount the install media at
            <literal>/media/cdrom</literal>. It may be necessary to use <literal>wget</literal> or
          another file transfer method to transfer the install media to the lifecycle manager before
          completing this step. Here is the command to mount the media: </para>

            <para>Example for <phrase/><phrase/></para>

            <screen>sudo mount HelionOpenStack-5.0.iso /media/cdrom</screen>
         </listitem>


        <listitem>
            <para>Unpack the tarball that is in the <literal>/media/cdrom/hos/</literal> directory:
            </para>

            <para>Example for <phrase/></para>

            <screen>tar xvf /media/cdrom/hos/hos-5.0.0-&lt;timestamp&gt;.tar</screen>
         </listitem>
        <listitem>
            <para>Run the hos-init.bash script which is included in the build: </para>

            <para>Example for <phrase/><phrase/></para>

            <screen>~/hos-5.0.0/hos-init.bash</screen>
            <para>You will be prompted to enter
            an optional SSH passphrase when running <literal>hos-init.bash</literal>. This passphrase
            is used to protect the key used by Ansible when connecting to its client nodes. If you
            do not want to use a passphrase then just press return at the prompt.</para>

            <para>For
            automated installation (e.g. CI) it is possible to disable SSH passphrase prompting by
            setting the <literal>HOS_INIT_AUTO</literal> environment variable before running
              <literal>hos-init.bash</literal>, like
          this:</para>

            <screen>export HOS_INIT_AUTO=y</screen>
         </listitem>
      </orderedlist>
      <para>If you have protected the SSH key with a passphrase then execute the following commands to
        avoid having to enter the passphrase on every attempt by Ansible to connect to its client
        nodes:</para>

      <screen>eval $(ssh-agent)
ssh-add ~/.ssh/id_rsa</screen>
      <para>At the end of this section you should have a local directory structure, as described
        below:</para>

      <screen>~/helion/                        Top level directory
~/helion/examples/               Directory contains the config input files of the example clouds
~/helion/my_cloud/definition/    Directory contains the config input files
~/helion/my_cloud/config/        Directory contains .j2 files which are symlinks to the ~/helion/hos/ansible directory
~/helion/hos/                    Directory contains files used by the installer</screen>
      <note/>
      <para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>

   
    
      <bridgehead renderas="sect4">Prepare and Deploy Cloud Controllers</bridgehead>
      <orderedlist id="ol_c1w_pfl_ft">
        <listitem>
            <para>Setup your configuration files, as follows: </para>

            <orderedlist id="ol_sgn_tqy_2x">
               <listitem>
                  <para>Copy the example configuration files into the required setup directory and edit them
              as required:
                </para>

                  <screen>cp -r ~/helion/examples/entry-scale-esx-kvm-vsa/* ~/helion/my_cloud/definition/</screen>
                  <para>See
                a sample set of configuration files in the
                  <literal>~/helion/examples/entry-scale-esx-kvm-vsa</literal> directory. The
                accompanying README.md file explains the contents of each of the configuration
                files.
              </para>

               </listitem>
               <listitem>
                  <para>Begin inputting your environment information into the configuration files in the
                <literal> ~/helion/my_cloud/definition</literal> directory. </para>

                  <note>
                        <para>If you want to use a dedicated deployer node in your ESX deployment, add
                    <emphasis role="bold">eon-client</emphasis> service-component, to manage vCenter via EON operation from
                  the deployer node, in the <literal>control_plane.yml</literal> file as shown in the
                  following example. </para>
                     </note>
<screen> clusters:
        - name: cluster0
          cluster-prefix: c0
          server-role: HLM-ROLE
          service-components:
            - lifecycle-manager
            - <emphasis role="bold">eon-client</emphasis> 
            ...</screen>

               </listitem>
            </orderedlist>
         </listitem>
        <listitem>
            <para>Commit your cloud deploy configuration to the <xref linkend="using_git"/>, as follows: </para>

            <screen>cd ~/helion/hos/ansible
git add -A
git commit -m "My config or other commit message"</screen>
            <note>
               <para>This step needs to be repeated any time you make changes to your configuration files
            before you move onto the following steps. See <xref linkend="using_git"/> for more information.</para>

            </note>
         </listitem>
      </orderedlist>
   
    
      <bridgehead renderas="sect4">Provision Your Baremetal Nodes</bridgehead>
      <para>To provision the baremetal nodes in your cloud deployment you can either use the automated
        operating system installation process provided by <phrase/> or you can use
        the 3rd party installation tooling of your choice. We will outline both methods below:</para>

      <para><emphasis role="bold">Using 3rd Party Baremetal Installers</emphasis></para>

      <para>If you do not wish to use the automated operating system installation tooling included with
          <phrase/> then the requirements that have to be met using the
        installation tooling of your choice are:</para>

      <itemizedlist>
        <listitem>
            <para>The operating system must be installed via the HPE Linux for <phrase/>
          ISO provided on the <ulink url="http://www.hpe.com/software/entitlements">Software Entitlement Portal</ulink>.</para>

         </listitem>
        <listitem>
            <para>Each node must have SSH keys in place that allows the same user from the lifecycle
          manager node who will be doing the deployment to SSH to each node without a password.</para>

         </listitem>
        <listitem>
            <para>Passwordless sudo needs to be enabled for the user.</para>

         </listitem>
        <listitem>
            <para>There should be a LVM logical volume as <literal>/root</literal> on each node.</para>

         </listitem>
        <listitem>
            <para>If the LVM volume group name for the volume group holding the "root" LVM logical volume
          is hlm-vg then it will align with the disk input models in the examples.</para>

         </listitem>
        <listitem>
            <para><phrase>Ensure that <literal>openssh-server</literal>,
              <literal>python</literal>, <literal>python-apt</literal>, and <literal>rsync</literal> are
            installed.</phrase></para>

         </listitem>
      </itemizedlist>
      <para>If you chose this method for installing your baremetal hardware, skip forward to the <xref linkend="install_kvm"/> step.</para>

      <para>If you would like to use the automated operating system installation tools provided by
          <phrase/> then complete all of the steps below.</para>

      <para><emphasis role="bold">Using the Automated Operating System Installation Provided by <phrase/>
         </emphasis></para>

      <para><emphasis role="bold">Part One: Deploy Cobbler</emphasis></para>

      <para>This phase of the install process takes the baremetal information that was provided in
          <literal>servers.yml</literal> and installs the Cobbler provisioning tool and loads this
        information into Cobbler. This sets each node to <literal>netboot-enabled: true</literal> in
        Cobbler. Each node will be automatically marked as <literal>netboot-enabled: false</literal>
        when it completes its operating system install successfully. Even if the node tries to PXE
        boot subsequently, Cobbler will not serve it. This is deliberate so that you can't reimage a
        live node by accident.</para>

      <para>The <literal>cobbler-deploy.yml</literal> playbook prompts for a password - this is the
        password that will be encrypted and stored in Cobbler, which is associated with the user
        running the command on the lifecycle manager, that you will use to log in to the nodes via
        their consoles after install. The username is the same as the user set up in the initial
        dialogue when installing the lifecycle manager from the iso, and is the same user that is
        running the cobbler-deploy play.</para>

      <orderedlist>
        <listitem>
            <para>Run the following playbook which confirms that there is iLo connectivity for each of
          your nodes so that they are accessible to be re-imaged in a later step:
          </para>

            <screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-power-status.yml</screen>
         </listitem>
        <listitem>
            <para>Run the following playbook to deploy Cobbler:
          </para>

            <screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</screen>
         </listitem>
      </orderedlist>
      <para><emphasis role="bold">Part Two: Image the Nodes</emphasis></para>

      <para>This phase of the install process goes through a number of distinct steps: </para>
<orderedlist>
            <listitem>
               <para>Powers down the nodes to be installed</para>
            </listitem>
            <listitem>
               <para>Sets the nodes hardware boot order so that the first option is a network boot.</para>
            </listitem>
            <listitem>
               <para>Powers on the nodes. (The nodes will then boot from the network and be installed using
            infrastructure set up in the previous phase)</para>
            </listitem>
            <listitem>
               <para>Waits for the nodes to power themselves down (this indicates a success install). This
            can take some time.</para>
            </listitem>
            <listitem>
               <para>Sets the boot order to hard disk and powers on the nodes.</para>
            </listitem>
            <listitem>
               <para>Waits for the nodes to be ssh-able and verifies that they have the signature
            expected.</para>
            </listitem>
        </orderedlist>

      <para>The reimage command is:</para>

      <screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml [-e nodelist=node1,node2,node3]</screen>
      <para>If a nodelist is not specified then the set of nodes in cobbler with
          <literal>netboot-enabled: True</literal> is selected. The playbook pauses at the start to
        give you a chance to review the set of nodes that it is targeting and to confirm that it's
        correct.</para>

      <para>You can use the command below which will list all of your nodes with the
          <literal>netboot-enabled: True</literal> flag set:</para>

      <screen>sudo cobbler system find --netboot-enabled=1</screen>
      <para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>

   
    
      <bridgehead renderas="sect4">Run the Configuration Processor</bridgehead>
      <para>Once you have your configuration files setup you need to run the configuration processor to
        complete your configuration.</para>

      <para>When you run the configuration processor you will be prompted for two
        passwords. Enter the first password to make the configuration processor encrypt its
        sensitive data, which is comprised of the random inter-service passwords that it generates
        and the ansible <literal>group_vars</literal> and <literal>host_vars</literal> that it produces
        for subsequent deploy runs. You will need this password for subsequent ansible deploy and
        configuration processor runs. If you wish to change an encryption password that you have
        already used when running the configuration processor then enter the new password at the
        second prompt, otherwise just press carriage return to bypass this.</para>

      <para>Run the configuration processor with this command:</para>

      <screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
      <para>For automated installation (e.g. CI) you can specify the required passwords on the ansible
        command line. For example, the command below will disable encryption by the configuration
        processor
        </para>
<screen>ansible-playbook -i hosts/localhost config-processor-run.yml -e encrypt="" -e rekey=""</screen>

      <para>If you receive an error during this step then there is probably an issue with one or more
        of your configuration files. We recommend that you verify that all of the information in
        each of your configuration files is correct for your environment and then commit those
        changes to git using the instructions in the previous section before re-running the
        configuration processor again.</para>

      <para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>

   
    
      <bridgehead renderas="sect4">Deploy the Cloud</bridgehead>
      <orderedlist>
        <listitem>
            <para>Use the playbook below to create a deployment directory:
          </para>

            <screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
         </listitem>
        <listitem>
            <para>[OPTIONAL] - Run the <literal>wipe_disks.yml</literal> playbook to ensure all of your
          partitions on your nodes are completely wiped before continuing with the installation. If
          you are using fresh machines this step may not be necessary.
            </para>

            <screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts wipe_disks.yml</screen>
            <para>If
            you have used an encryption password when running the configuration processor use the
            command below and enter the encryption password when prompted:
            </para>
<screen>ansible-playbook -i hosts/verb_hosts wipe_disks.yml --ask-vault-pass</screen>

         </listitem>
        <listitem>
            <para>Run the <literal>site.yml</literal> playbook below:
            </para>

            <screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts site.yml</screen>
            <para>If
            you have used an encryption password when running the configuration processor use the
            command below and enter the encryption password when prompted:
            </para>
<screen>ansible-playbook -i hosts/verb_hosts site.yml --ask-vault-pass </screen>

            <note>
               <para>The
            step above runs <literal>osconfig</literal> to configure the cloud and
              <literal>hlm-deploy</literal> to deploy the cloud. Therefore, this step may run for a
            while, perhaps 45 minutes or more, depending on the number of nodes in your
            environment.</para>

            </note>
         </listitem>
        <listitem>
            <para>Verify that the network is working correctly. Ping each IP in the
            <literal>/etc/hosts</literal> file from one of the controller nodes.</para>

         </listitem>
      </orderedlist>
      <para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>

   
  </section>
