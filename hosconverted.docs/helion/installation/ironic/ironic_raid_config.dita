<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="ironic_raid_config">
    <title><ph conkeyref="HOS-conrefs/product-title"/>Raid Configuration for Ironic</title>
    <body>
        <!--not tested-->
        <p conkeyref="HOS-conrefs/applies-to"/>
      
      

        <ol>
          <li>Node Creation:
            
          <p>Check the raid capabilities of the driver:</p>
<codeblock>
ironic --ironic-api-version 1.15 driver-raid-logical-disk-properties pxe_ilo
</codeblock>            
            
           This will generate output similar to the following:
           
<codeblock>

+--------------------------+--------------------------------------------------------------------------------------------------------------+ 
| Property                    | Description                                                                                               | 
+--------------------------+--------------------------------------------------------------------------------------------------------------+ 
| controller               | Controller to use for this logical disk. If not specified, the driver will choose a suitable RAID controller | 
|                          | on the bare metal node. Optional.                                                                            | 
| disk_type                | The type of disk preferred. Valid values are 'hdd' and 'ssd'. If this is not specified, disk type will not   | 
|                          | be a selection criterion for choosing backing physical disks. Optional.                                      | 
| interface_type           | The interface type of disk. Valid values are 'sata', 'scsi' and 'sas'. If this is not specified, interface   | 
|                          | type will not be a selection criterion for choosing backing physical disks. Optional.                        | 
| is_root_volume           | Specifies whether this disk is a root volume. By default, this is False. Optional.                           | 
| number_of_physical_disks | Number of physical disks to use for this logical disk. By default, the driver uses the minimum number of     | 
|                          | disks required for that RAID level. Optional.                                                                | 
| physical_disks           | The physical disks to use for this logical disk. If not specified, the driver will choose suitable physical  | 
|                          | disks to use. Optional.                                                                                      | 
| <b>raid_level               | RAID level for the logical disk. Valid values are '0', '1', '2', '5', '6', '1+0', '5+0' and '6+0'. Required.</b> | 
| share_physical_disks     | Specifies whether other logical disks can share physical disks with this logical disk.                       | 
|                          | By default, this is False. Optional.                                                                         | 
| <b>size_gb                  | Size in GiB (Integer) for the logical disk. Use 'MAX' as size_gb if this logical disk is supposed to  </b>       | 
|                          | <b>use the rest of the space available. Required.</b>                                                               | 
| volume_name              | Name of the volume to be created. If this is not specified, it will be auto-generated. Optional.             | 
+--------------------------+--------------------------------------------------------------------------------------------------------------+ 
</codeblock>           
            
<p>
Node State will be <b>Available</b></p>            
 
<codeblock>
ironic node-create -d pxe_ilo -i ilo_address=&lt;ip_address> -i ilo_username=&lt;username> -i ilo_password=&lt;password> -i ilo_deploy_iso=&lt;iso_id> -i deploy_kernel=&lt;kernel_id> -i deploy_ramdisk=&lt;ramdisk_id> -p cpus=2 -p memory_mb=4096 -p local_gb=80  -p cpu_arch=amd64 -p capabilities="boot_option:local,boot_mode:bios"
</codeblock>
            
<codeblock>
ironic port-create -a &lt;port> -n &lt;node-uuid>
</codeblock>
            
<note type="note">Ensure that the node created supports raid configuration:
<codeblock>
ironic node-validate &lt;node-uuid>
</codeblock>
</note>
            
            
            
            
          </li>

          
          <li>
          Apply the target raid configuration on the node:
          
          <p>See the OpenStack documentation for RAID configuration at 
            <xref href="http://docs.openstack.org/developer/ironic/deploy/raid.html" format="html" scope="external"/>.</p>
            
           <p>Set the target RAID configuration by editing the file <codeph>raid_conf.json</codeph> and setting the approprate values, for example:
           
<codeblock>
{ "logical_disks": [ {"size_gb": 5, "raid_level": "0", "is_root_volume": true} ] }
</codeblock>       
             
             
            and then run the following command:
            
<codeblock>
ironic --ironic-api-version 1.15 node-set-target-raid-config &lt;node-uuid> raid_conf.json
</codeblock>            
             
             The output produced should be similar to the following:
             
<codeblock>
+------------------------+---------------------------------------------------------------------------+
| Property               | Value                                                                    | 
|+------------------------+--------------------------------------------------------------------------+
| chassis_uuid           |                                                                          | 
| clean_step             | {}                                                                       | 
| console_enabled        | False                                                                    | 
| created_at             | 2016-06-14T14:58:07+00:00                                                | 
| driver                 | pxe_ilo                                                                  | 
| driver_info            | {u'ilo_deploy_iso': u'd43e589a-07db-4fce-a06e-98e2f38340b4',             | 
|                        | u'deploy_kernel': u'915c5c74-1ceb-4f78-bdb4-8547a90ac9c0',               | 
|                        | u'ilo_address': u'10.1.196.116', u'deploy_ramdisk':                      | 
|                        | u'154e7024-bf18-4ad2-95b0-726c09ce417a', u'ilo_password': u'******',     | 
|                        | u'ilo_username': u'Administrator'}                                       | 
| driver_internal_info   | {u'agent_cached_clean_steps_refreshed': u'2016-06-15 07:16:08.264091',   | 
|                        | u'agent_cached_clean_steps': {u'raid': [{u'interface': u'raid',          | 
|                        | u'priority': 0, u'step': u'delete_configuration'}, {u'interface':        | 
|                        | u'raid', u'priority': 0, u'step': u'create_configuration'}], u'deploy':  | 
|                        | [{u'priority': 10, u'interface': u'deploy', u'reboot_requested': False,  | 
|                        | u'abortable': True, u'step': u'erase_devices'}]}, u'clean_steps': None,  | 
|                        | u'hardware_manager_version': {u'generic_hardware_manager': u'3'},        | 
|                        | u'agent_erase_devices_iterations': 1, u'agent_url':                      | 
|                        | u'http://192.168.245.143:9999', u'agent_last_heartbeat': 1465974974}     | 
| extra                  | {}                                                                       | 
| inspection_finished_at | None                                                                     | 
| inspection_started_at  | None                                                                     | 
| instance_info          | {u'deploy_key': u'XXN2ON0V9ER429MECETJMUG5YHTKOQOZ'}                     | 
| instance_uuid          | None                                                                     | 
| last_error             | None                                                                     | 
| maintenance            | False                                                                    | 
| maintenance_reason     | None                                                                     | 
| name                   | None                                                                     | 
| power_state            | power off                                                                | 
| properties             | {u'cpu_arch': u'amd64', u'root_device': {u'wwn': u'0x600508b1001ce286'}, | 
|                        | u'cpus': 2, u'capabilities':                                             | 
|                        | u'boot_mode:bios,raid_level:6,boot_option:local', u'memory_mb': 4096,    | 
|                        | u'local_gb': 4}                                                          | 
| provision_state        | available                                                                | 
| provision_updated_at   | 2016-06-15T07:16:27+00:00                                                | 
| reservation            | padawan-ironic-cp1-c1-m2-mgmt                                            | 
| target_power_state     | power off                                                                | 
| target_provision_state | None                                                                     | 
| <b>target_raid_config</b>     | {u'logical_disks': [{u'size_gb': 5, <b>u'raid_level': u'6',</b>                 | 
|                        | u'is_root_volume': True}]}                                               | 
| updated_at             | 2016-06-15T07:44:22+00:00                                                | 
| uuid                   | 22ab9f85-71a1-4748-8d6b-f6411558127e                                     | 
+------------------------+--------------------------------------------------------------------------+ 

</codeblock>   
             <note type="note">Ensure that the <b>target_raid_config</b>  option has the updated raid information</note>
             
           </p> 
          
          <p>
            Now set the state of the node to <b>manageable</b>:
            
<codeblock>
 ironic --ironic-api-version latest node-set-provision-state &lt;node-uuid> manage
</codeblock>            
            
          </p>
            
            
          </li>
          
          <li>
             Manual cleaning steps:
             
             <p>Manual cleaning is enabled by default in production - the following are the steps to enable cleaning if the manual cleaning has been disabled.</p>
            
             <ul>
               <li>Provide <codeph>cleaning_network_uuid</codeph>  in <codeph>ironic-conductor.conf</codeph></li>
               <li>Edit <codeph>~/helion/my_cloud/definition/data/ironic/ironic_config.yml</codeph> file and set <codeph>enable_node_cleaning</codeph> to <codeph>true</codeph></li>
               <li>Then run the following set of commands:
<codeblock>
cd ~/helion/hos/ansible
git add -A 
git commit -m "enabling node cleaning" 
cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml 
ansible-playbook -i hosts/localhost ready-deployment.yml 
cd ~/scratch/ansible/next/hos/ansible 
ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml
</codeblock>             
                 
                 <p>After performing these steps, the state of the node will become <b>Cleaning</b>.</p>
               </li>
             </ul>
            
            
            
            <p>Run the following command:
<codeblock>
ironic --ironic-api-version latest node-set-provision-state 2123254e-8b31-4259-b632-fb232f5aa6fd clean --clean-steps '[{ "interface": "raid","step": "delete_configuration"},{  "interface": "raid" ,"step": "create_configuration"}]'
</codeblock>     
              
            <note type="note">The state of the node will change to <b>clean wait</b> and then to <b>manageable</b> if the manual cleaning returns without any error.
             If the manual cleaning fails, the state of the node will change to <b>clean failed</b>.
            </note>
              
            </p>
            
            <p> Node-information after a Manual cleaning:</p>
            
<codeblock>
 


+------------------------+---------------------------------------------------------------------------+
| Property               | Value                                                                    | 
|+------------------------+--------------------------------------------------------------------------+
| chassis_uuid           |                                                                          | 
| clean_step             | {}                                                                       | 
| console_enabled        | False                                                                    | 
| created_at             | 2016-06-14T14:58:07+00:00                                                | 
| driver                 | pxe_ilo                                                                  | 
| driver_info            | {u'ilo_deploy_iso': u'd43e589a-07db-4fce-a06e-98e2f38340b4',             | 
|                        | u'deploy_kernel': u'915c5c74-1ceb-4f78-bdb4-8547a90ac9c0',               | 
|                        | u'ilo_address': u'10.1.196.116', u'deploy_ramdisk':                      | 
|                        | u'154e7024-bf18-4ad2-95b0-726c09ce417a', u'ilo_password': u'******',     | 
|                        | u'ilo_username': u'Administrator'}                                       | 
| driver_internal_info   | {u'agent_cached_clean_steps_refreshed': u'2016-06-15 07:16:08.264091',   | 
|                        | u'agent_cached_clean_steps': {u'raid': [{u'interface': u'raid',          | 
|                        | u'priority': 0, u'step': u'delete_configuration'}, {u'interface':        | 
|                        | u'raid', u'priority': 0, u'step': u'create_configuration'}], u'deploy':  | 
|                        | [{u'priority': 10, u'interface': u'deploy', u'reboot_requested': False,  | 
|                        | u'abortable': True, u'step': u'erase_devices'}]}, u'clean_steps': None,  | 
|                        | u'hardware_manager_version': {u'generic_hardware_manager': u'3'},        | 
|                        | u'agent_erase_devices_iterations': 1, u'agent_url':                      | 
|                        | u'http://192.168.245.143:9999', u'agent_last_heartbeat': 1465974974}     | 
| extra                  | {}                                                                       | 
| inspection_finished_at | None                                                                     | 
| inspection_started_at  | None                                                                     | 
| instance_info          | {u'deploy_key': u'XXN2ON0V9ER429MECETJMUG5YHTKOQOZ'}                     | 
| instance_uuid          | None                                                                     | 
| last_error             | None                                                                     | 
| maintenance            | False                                                                    | 
| maintenance_reason     | None                                                                     | 
| name                   | None                                                                     | 
| power_state            | power off                                                                | 
| properties             | {u'cpu_arch': u'amd64', u'root_device': {u'wwn': u'0x600508b1001ce286'}, | 
|                        | u'cpus': 2, u'capabilities':                                             | 
|                        | u'boot_mode:bios,raid_level:6,boot_option:local', u'memory_mb': 4096,    | 
|                        | u'local_gb': 4}                                                          | 
| provision_state        | manageable                                                               | 
| provision_updated_at   | 2016-06-15T07:16:27+00:00                                                | 
| raid_config            | {u'last_updated': u'2016-06-15 07:16:14.584014', u'physical_disks':      | 
|                        | [{u'status': u'ready', u'size_gb': 1024, u'interface_type': u'sata',     | 
|                        | u'firmware': u'HPGC', u'controller': u'Smart Array P440ar in Slot 0      | 
|                        | (Embedded)', u'model': u'ATA     MM1000GBKAL', u'disk_type': u'hdd',     | 
|                        | u'id': u'1I:3:3'}, {u'status': u'ready', u'size_gb': 1024,               | 
|                        | u'interface_type': u'sata', u'firmware': u'HPGC', u'controller': u'Smart | 
|                        | Array P440ar in Slot 0 (Embedded)', u'model': u'ATA     MM1000GBKAL',    | 
|                        | u'disk_type': u'hdd', u'id': u'1I:3:1'}, {u'status': u'active',          | 
|                        | u'size_gb': 1024, u'interface_type': u'sata', u'firmware': u'HPGC',      | 
|                        | u'controller': u'Smart Array P440ar in Slot 0 (Embedded)', u'model':     | 
|                        | u'ATA     MM1000GBKAL', u'disk_type': u'hdd', u'id': u'1I:3:2'},         | 
|                        | {u'status': u'active', u'size_gb': 1024, u'interface_type': u'sata',     | 
|                        | u'firmware': u'HPGC', u'controller': u'Smart Array P440ar in Slot 0      | 
|                        | (Embedded)', u'model': u'ATA     MM1000GBKAL', u'disk_type': u'hdd',     | 
|                        | u'id': u'2I:3:6'}, {u'status': u'active', u'size_gb': 1024,              | 
|                        | u'interface_type': u'sata', u'firmware': u'HPGC', u'controller': u'Smart | 
|                        | Array P440ar in Slot 0 (Embedded)', u'model': u'ATA     MM1000GBKAL',    | 
|                        | u'disk_type': u'hdd', u'id': u'2I:3:5'}, {u'status': u'active',          | 
|                        | u'size_gb': 1024, u'interface_type': u'sata', u'firmware': u'HPGC',      | 
|                        | u'controller': u'Smart Array P440ar in Slot 0 (Embedded)', u'model':     | 
|                        | u'ATA     MM1000GBKAL', u'disk_type': u'hdd', u'id': u'1I:3:4'}],        | 
|                        | u'logical_disks': [{u'size_gb': 4, u'physical_disks': [u'1I:3:2',        | 
|                        | u'2I:3:6', u'2I:3:5', u'1I:3:4'], u'raid_level': u'6',                   | 
|                        | u'is_root_volume': True, u'root_device_hint': {u'wwn':                   | 
|                        | u'0x600508b1001ce286'}, u'controller': u'Smart Array P440ar in Slot 0    | 
|                        | (Embedded)', u'volume_name': u'015E795CPDNLH0BRH8N406AAB7'}]}            | 
| reservation            | padawan-ironic-cp1-c1-m2-mgmt                                            | 
| target_power_state     | power off                                                                | 
| target_provision_state | None                                                                     | 
| target_raid_config     | {u'logical_disks': [{u'size_gb': 5, u'raid_level': u'6',                 | 
|                        | u'is_root_volume': True}]}                                               | 
| updated_at             | 2016-06-15T07:44:22+00:00                                                | 
| uuid                   | 22ab9f85-71a1-4748-8d6b-f6411558127e                                     | 
+------------------------+--------------------------------------------------------------------------+ 
</codeblock>            
            
            <p>After the manual cleaning, run the following command to change the state of a node to <b>available</b>:
            
<codeblock>
ironic --ironic-api-version latest node-set-provision-state &lt;node-uuid> provide 
</codeblock>            
            
            </p>
            
          </li>
          
          
        </ol>
      
      
      
  </body>
</topic>
