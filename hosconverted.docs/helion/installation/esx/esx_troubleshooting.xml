<?xml version="1.0" encoding="UTF-8"?>
<!--Edit status: not edited-->
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="esx_troubleshooting_installation">
    <title><ph conkeyref="HOS-conrefs/product-title"/>Troubleshooting the ESX</title>
    <abstract>
        <shortdesc outputclass="hdphidden">We have gathered some of the common issues that occur
            during installation and organized them by when they occur during the
            installation.</shortdesc>
    </abstract>
    <body>
        <!--not tested-->
        <p conkeyref="HOS-conrefs/applies-to"/>
        <section id="about">
            <p>This section contains troubleshooting tasks for your <keyword keyref="kw-hos-tm"/>
                <keyword keyref="kw-hos-version"/> for ESX.</p>
        </section>
        <section id="deployer_setup">
            <title>Issue: If hlm-ux-services.service is not running, the EON resource-activate and
                resource-deactivate commands fails</title>
            <p>If you perform any maintenance work or reboot the lifecycle manager/deployer node,
                make sure to restart the HLM UX service for standalone deployer node and shared
                HLM/controller node based on your environment.</p>
            <p>For standalone deployer node, execute <codeph>hlm-start.yml</codeph> playbook to
                restart the HLM UX services on the deployer node after a reboot.</p>
            <p>For shared deployer/controller node, execute <codeph>hlm-start.yml</codeph> playbook
                on all the controllers to restart HLM UX services. </p>
            <p>For
                example:<codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit &lt;host name of the HLM node or HLM Node/Shared Controller></codeblock></p>
        </section>
        <section>
            <title>Issue: ESX onboard Compute </title>
            <p>
                <ol id="ol_t5l_2bd_px">
                    <li>If there is a failure in provisioning phase<ol id="ol_jjg_kbd_px">
                            <li>The spawned applicances will be deleted.</li>
                            <li>Check for <codeph>/var/log/eon/eon-conductor.log</codeph> for
                                specific errors to troubleshoot the error.</li>
                        </ol></li>
                    <li>If there is a failures in activating phase <ol id="ol_q2z_nbd_px">
                            <li>The spawned appliances will be left intact, and you can try
                                executing activate command again. <p> b. Check the
                                        <codeph>~/.ansible/ansible.log</codeph> or
                                        <codeph>/var/log/hlm-ux-service/service.log</codeph> in the
                                        <codeph>hlm-deployer</codeph>. </p><p>In case of SSH
                                    failure, check the background connectivity and try to ping
                                    again.</p></li>
                        </ol></li>
                    <li>Failures leading to inconsistent Database (DB) state, execute the following
                        command:<codeblock>eon resource-deactivate &lt;id&gt; --forced True </codeblock></li>
                </ol>
            </p>
        </section>
        <section><title>Issue: Migrate eon-conductor </title><p>Currently eon-conductor service is
                running in the first node of the control plane.</p><b>Procedure to migrate
                eon-conductor</b><p>Perform the following steps to migrate eon-conductor service to
                any other node in the control plane.<ol id="ol_o1z_zh4_px">
                    <li>SSH to lifecycle manager. </li>
                    <li>Change the
                        directory.<codeblock>cd /home/user/scratch/ansible/next/hos/ansible</codeblock></li>
                    <li>Search where the eon conductor is running currently. In the following
                        example, eon-conductor is running in <codeph>helion-cp1-c1-m1-mgmt</codeph>.
                        <codeblock>(helion-cp1-c1-m1-mgmt)
stack@helion-cp1-c1-m1-mgmt:~$ ps aux | grep eon
eon      11236  5.5  0.0 142104 52088 ?        Ss   18:53   0:01 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon      11281 23.2  0.1 401964 238080 ?       Ss   18:53   0:06 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-conductor/venv/bin/eon-conductor --config-file=/opt/stack/service/eon-conductor-20160503T082438Z/etc/eon/eon-conductor.conf
eon      11590  1.5  0.0 144420 49084 ?        S    18:53   0:00 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon      11591  1.4  0.0 144416 49056 ?        S    18:53   0:00 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon      11592  1.1  0.0 144420 48828 ?        S    18:53   0:00 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
stack    12086  0.0  0.0  12736  2064 pts/9    S+   18:54   0:00 grep eon
</codeblock><codeblock>(helion-cp1-c1-m2-mgmt)
stack@helion-cp1-c1-m2-mgmt:~$ ps aux | grep eon
eon       7050  1.9  0.0 142100 52052 ?        Ss   18:53   0:03 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon       7677  1.1  0.0 144552 49156 ?        S    18:53   0:02 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon       7678  1.2  0.0 144544 49256 ?        S    18:53   0:02 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon       7679  1.2  0.0 144548 49136 ?        S    18:53   0:02 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
stack    13523  0.0  0.0  12732  2076 pts/0    S+   18:56   0:00 grep eon</codeblock></li>
                    <li>Stop the eon
                            service.<codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts eon-stop.yml </codeblock><p>Example:</p><codeblock>stack@helion-cp1-c1-m1-mgmt:~/scratch/ansible/next/hos/ansible$ ansible-playbook -i hosts/verb_hosts eon-stop.yml

PLAY [EON-API] ****************************************************************

TASK: [eon-common | stop | stop eon-api service] ******************************
changed: [helion-cp1-c1-m3-mgmt]
changed: [helion-cp1-c1-m1-mgmt]
changed: [helion-cp1-c1-m2-mgmt]

PLAY [EON-CND--first-member] **************************************************

TASK: [eon-common | stop | stop eon-conductor service] ************************
changed: [helion-cp1-c1-m1-mgmt]

PLAY [EON-ONEVIEW--first-member] **********************************************
skipping: no hosts matched

PLAY RECAP ********************************************************************
eon-common | stop | stop eon-conductor service -------------------------- 8.39s
eon-common | stop | stop eon-api service -------------------------------- 0.42s
-------------------------------------------------------------------------------
Total: ------------------------------------------------------------------ 8.99s
helion-cp1-c1-m1-mgmt        : ok=2    changed=2    unreachable=0    failed=0
helion-cp1-c1-m2-mgmt        : ok=1    changed=1    unreachable=0    failed=0
helion-cp1-c1-m3-mgmt        : ok=1    changed=1    unreachable=0    failed=0</codeblock></li>
                    <li>Edit the
                            <codeph>/home/user/scratch/ansible/next/hos/ansible/hosts/verb_hosts</codeph>.
                        In the following example, we change the node name from
                            <codeph>helion-cp1-c1-m1-mgmt</codeph> to
                            <codeph>helion-cp1-c1-m2-mgmt</codeph> in the
                        [EON-CND--first-member:children] group to move the eon-conductor service to
                        node
                        <codeph>helion-cp1-c1-m2-mgmt</codeph>.<codeblock>[EON-CND--first-member:children]   (ORIGINAL)
helion-cp1-c1-m1-mgmt  &lt;- original node that eon-conductor is setup on.

[EON-CND--first-member:children]   (MODIFIED)
helion-cp1-c1-m2-mgmt &lt;- new node that eon-conductor is setup on.
</codeblock></li>
                    <li> Execute the following playbook in
                            sequence.<codeblock>ansible-playbook -i hosts/verb_hosts eon-deploy.yml
ansible-playbook -i hosts/verb_hosts eon-start.yml</codeblock><p>Example:
                            <codeblock>TASK: [eon-conductor | start | start eon-conductor service] *******************
changed: [helion-cp1-c1-m2-mgmt]

PLAY RECAP ********************************************************************
eon-api | start | start eon-api service --------------------------------- 0.26s
eon-conductor | start | start eon-conductor service --------------------- 0.23s
eon-api | start | activate the latest installed version ----------------- 0.07s
eon-api | start | restart eon-api service ------------------------------- 0.07s
eon-conductor | start | restart eon-conductor service ------------------- 0.02s
eon-conductor | start | activate the latest installed version ----------- 0.02s
-------------------------------------------------------------------------------
Total: ------------------------------------------------------------------ 1.09s
helion-cp1-c1-m1-mgmt      : ok=1    changed=0    unreachable=0    failed=0
helion-cp1-c1-m2-mgmt      : ok=2    changed=0    unreachable=0    failed=0 &lt;- Service is moved and started
helion-cp1-c1-m3-mgmt      : ok=1    changed=0    unreachable=0    failed=0</codeblock></p></li>
                    <li>Ensure that the conductor is running on the node that you have migrated. In
                        the following example observe that the eon-conductor have migrated to node
                            <codeph>helion-cp1-c1-m2-mgmt</codeph>.
                        <codeblock>(helion-cp1-c1-m1-mgmt)
stack@helion-cp1-c1-m1-mgmt:~$ ps aux | grep eon
stack     2624  0.0  0.0  12732  2132 pts/9    S+   18:46   0:00 grep eon
eon      27786  1.3  0.0 142112 52064 ?        Ss   16:21   1:55 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon      27816  1.2  0.0 149712 55060 ?        S    16:21   1:50 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon      27817  1.2  0.0 150380 55724 ?        S    16:21   1:49 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon      27818  1.2  0.0 148516 53844 ?        S    16:21   1:49 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf

(helion-cp1-c1-m2-mgmt)
stack@helion-cp1-c1-m2-mgmt:~$ ps aux | grep eon
eon       1567  1.3  0.0 142108 52076 ?        Ss   16:21   1:56 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon       1606  1.2  0.0 144816 49888 ?        S    16:21   1:51 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon       1607  1.2  0.0 145068 49888 ?        S    16:21   1:50 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon       1608  1.2  0.0 145064 49888 ?        S    16:21   1:49 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-api/venv/bin/eon-api --config-file=/opt/stack/service/eon-api-20160503T082438Z/etc/eon/eon-api.conf
eon      22720  0.0  0.1 404872 241220 ?       Ss   16:15   0:08 /opt/stack/venv/eon-20160503T082438Z/bin/python2 /opt/stack/service/eon-conductor/venv/bin/eon-conductor --config-file=/opt/stack/service/eon-conductor-20160503T082438Z/etc/eon/eon-conductor.conf
stack    31965  0.0  0.0  12732  2308 pts/0    S+   18:50   0:00 grep eon
</codeblock></li>
                </ol></p></section>
        <section>
            <title>Issue: ESX Cluster shows UNKNOWN in OpsConsole</title>
            <p>In the OpsConsole Alarms dashboard, if all the alarms for ESX cluster are showing
                UNKNOWN then restart the <codeph>monasca-agent</codeph> running in ESX compute
                proxy. <ol id="ol_hr3_fbf_tx">
                    <li>SSH to the respective compute proxy. You can find the hostname of the proxy
                        from the dimensions list shown against the respective alarm.</li>
                    <li>Restart the <codeph>monasca-agent</codeph>
                        service.<codeblock>sudo systemctl restart monasca-agent</codeblock></li>
                </ol></p>
        </section>
        <section><title>Issue: Unable to view the VM console in Horizon UI</title><p>By default the
                gdbserver firewall is disabled in ESXi host which results in a Handshake error when
                accessing the VM instance console in the Horizon UI.</p><p><image
                    href="../../../media/esx/gdbserver.png" id="image_ijr_j3c_xx"/></p><b>Procedure
                to enable gdbserver</b><p>
                <ol id="ol_nzh_hzn_wx">
                    <li>Login to vSphere Client.</li>
                    <li>Select the ESXi Host and click <b>Configuration</b> tab in the menu bar. You
                        must perform the following actions on all the ESXi hosts in the compute
                                clusters.<p><image href="../../../media/esx/1.PNG"
                                id="image_mlh_j2p_wx"/></p></li>
                    <li>On the left hand side select <b>Security Profile</b> from the list of
                            <b>Software</b>. Click <b>Properties</b> on the right hand side.
                                <p><image href="../../../media/esx/2.PNG" id="image_kpz_r2p_wx"
                            /></p><p>Firewall Properties box displays.</p></li>
                    <li>Select <b>gdbserver</b> checkbox and click <b>OK</b>.<p><image
                                href="../../../media/esx/3.PNG" id="image_ntp_s2p_wx"/></p></li>
                </ol>
            </p></section>
        <!--<section><title>Issue: Cinder volumne attach to the VM on the ESXi does not reflect a new disk automaitcally</title><p>When you attach a Cnder volume to the VM running on the ESX host, the volume will not get detected automatically</p><p><b>Procedure</b></p>Login to the VM and run a SCSI bus rescan to detect the newly presented volumes or restart the VM to  reflect the disks attached as volumes<p>After volumes are attached to ESXi based instances the rescan of scsi bus or reboot of instance should be done to reflect the disks attached as volumes</p></section>-->
    </body>
</topic>

