<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.1">
  <title>Install and configure a storage node</title>
  <section>
    <title>Prerequisites</title>
    <para>Before you install and configure the Block Storage service on the
                storage node, you must prepare the storage device.</para>
    <note>
      <para>Perform these steps on the storage node.</para>
    </note>
    <procedure>
      <step>
        <para>Install the supporting utility packages.</para>
      </step>
      <step>
        <para>Install the LVM packages:</para>
        <screen language="console"># zypper install lvm2</screen>
      </step>
      <step>
        <para>(Optional) If you intend to use non-raw image types such as QCOW2
                        and VMDK, install the QEMU package:</para>
        <screen language="console"># zypper install qemu</screen>
        <note>
          <para>Some distributions include LVM by default.</para>
        </note>
      </step>
      <step>
        <para>Create the LVM physical volume <literal>/dev/sdb</literal>:</para>
        <screen language="console"># pvcreate /dev/sdb

Physical volume "/dev/sdb" successfully created</screen>
      </step>
      <step>
        <para>Create the LVM volume group <literal>cinder-volumes</literal>:</para>
        <screen language="console"># vgcreate cinder-volumes /dev/sdb

Volume group "cinder-volumes" successfully created</screen>
        <para>The Block Storage service creates logical volumes in this volume group.</para>
      </step>
      <step>
        <para>Only instances can access Block Storage volumes. However, the
                        underlying operating system manages the devices associated with
                        the volumes. By default, the LVM volume scanning tool scans the
                        <literal>/dev</literal> directory for block storage devices that
                        contain volumes. If projects use LVM on their volumes, the scanning
                        tool detects these volumes and attempts to cache them which can cause
                        a variety of problems with both the underlying operating system
                        and project volumes. You must reconfigure LVM to scan only the devices
                        that contain the <literal>cinder-volumes</literal> volume group. Edit the
                        <literal>/etc/lvm/lvm.conf</literal> file and complete the following actions:</para>
        <itemizedlist>
          <listitem>
            <para>In the <literal>devices</literal> section, add a filter that accepts the
                                <literal>/dev/sdb</literal> device and rejects all other devices:</para>
            <screen language="bash">devices {
...
filter = [ "a/sdb/", "r/.*/"]</screen>
            <para>Each item in the filter array begins with <literal>a</literal> for <emphasis role="bold">accept</emphasis> or
                                <literal>r</literal> for <emphasis role="bold">reject</emphasis> and includes a regular expression for the
                                device name. The array must end with <literal>r/.*/</literal> to reject any
                                remaining devices. You can use the <command>vgs -vvvv</command> command
                                to test filters.</para>
            <warning>
              <para>If your storage nodes use LVM on the operating system disk, you
                                    must also add the associated device to the filter. For example,
                                    if the <literal>/dev/sda</literal> device contains the operating system:</para>
              <screen language="ini">filter = [ "a/sda/", "a/sdb/", "r/.*/"]</screen>
              <para>Similarly, if your compute nodes use LVM on the operating
                                    system disk, you must also modify the filter in the
                                    <literal>/etc/lvm/lvm.conf</literal> file on those nodes to include only
                                    the operating system disk. For example, if the <literal>/dev/sda</literal>
                                    device contains the operating system:</para>
              <screen language="ini">filter = [ "a/sda/", "r/.*/"]</screen>
            </warning>
          </listitem>
        </itemizedlist>
      </step>
    </procedure>
  </section>
  <section>
    <title>Install and configure components</title>
    <procedure>
      <step>
        <para>Install the packages:</para>
        <screen language="console"># zypper install openstack-cinder-volume tgt</screen>
      </step>
      <step>
        <para>Edit the <literal>/etc/cinder/cinder.conf</literal> file
                        and complete the following actions:</para>
        <itemizedlist>
          <listitem>
            <para>In the <literal>[database]</literal> section, configure database access:</para>
            <screen language="ini">[database]
# ...
connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder</screen>
            <para>Replace <literal>CINDER_DBPASS</literal> with the password you chose for
                                the Block Storage database.</para>
          </listitem>
          <listitem>
            <para>In the <literal>[DEFAULT]</literal> section, configure <literal>RabbitMQ</literal>
                                message queue access:</para>
            <screen language="ini">[DEFAULT]
# ...
transport_url = rabbit://openstack:RABBIT_PASS@controller</screen>
            <para>Replace <literal>RABBIT_PASS</literal> with the password you chose for
                                the <literal>openstack</literal> account in <literal>RabbitMQ</literal>.</para>
          </listitem>
          <listitem>
            <para>In the <literal>[DEFAULT]</literal> and <literal>[keystone_authtoken]</literal> sections,
                                configure Identity service access:</para>
            <screen language="ini">[DEFAULT]
# ...
auth_strategy = keystone

[keystone_authtoken]
# ...
auth_uri = http://controller:5000
auth_url = http://controller:35357
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = cinder
password = CINDER_PASS</screen>
            <para>Replace <literal>CINDER_PASS</literal> with the password you chose for the
                                <literal>cinder</literal> user in the Identity service.</para>
            <note>
              <para>Comment out or remove any other options in the
                                    <literal>[keystone_authtoken]</literal> section.</para>
            </note>
          </listitem>
          <listitem>
            <para>In the <literal>[DEFAULT]</literal> section, configure the <literal>my_ip</literal> option:</para>
            <screen language="ini">[DEFAULT]
# ...
my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS</screen>
            <para>Replace <literal>MANAGEMENT_INTERFACE_IP_ADDRESS</literal> with the IP address
                                of the management network interface on your storage node,
                                typically 10.0.0.41 for the first node in the
                                <xref linkend="overview-example-architectures"/>.</para>
          </listitem>
          <listitem>
            <para>In the <literal>[lvm]</literal> section, configure the LVM back end with the
                                LVM driver, <literal>cinder-volumes</literal> volume group, iSCSI protocol,
                                and appropriate iSCSI service:</para>
            <screen language="ini">[lvm]
# ...
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_group = cinder-volumes
iscsi_protocol = iscsi
iscsi_helper = tgtadm</screen>
          </listitem>
          <listitem>
            <para>In the <literal>[DEFAULT]</literal> section, enable the LVM back end:</para>
            <screen language="ini">[DEFAULT]
# ...
enabled_backends = lvm</screen>
            <note>
              <para>Back-end names are arbitrary. As an example, this guide
                                    uses the name of the driver as the name of the back end.</para>
            </note>
          </listitem>
          <listitem>
            <para>In the <literal>[DEFAULT]</literal> section, configure the location of the
                                Image service API:</para>
            <screen language="ini">[DEFAULT]
# ...
glance_api_servers = http://controller:9292</screen>
          </listitem>
          <listitem>
            <para>In the <literal>[oslo_concurrency]</literal> section, configure the lock path:</para>
            <screen language="ini">[oslo_concurrency]
# ...
lock_path = /var/lib/cinder/tmp</screen>
          </listitem>
        </itemizedlist>
      </step>
      <step>
        <para>Create the <literal>/etc/tgt/conf.d/cinder.conf</literal> file
                        with the following data:</para>
        <screen language="shell">include /var/lib/cinder/volumes/*</screen>
      </step>
    </procedure>
  </section>
  <section>
    <title>Finalize installation</title>
    <procedure>
      <step>
        <para>Start the Block Storage volume service including its dependencies
                        and configure them to start when the system boots:</para>
        <screen language="console"># systemctl enable openstack-cinder-volume.service tgtd.service
# systemctl start openstack-cinder-volume.service tgtd.service</screen>
      </step>
    </procedure>
  </section>
</section>
