<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.1">
  <title>Modifying Ring Partition Power</title>
  <para>The ring partition power determines the on-disk location of data files and is
            selected when creating a new ring. In normal operation, it is a fixed value.
            This is because a different partition power results in a different on-disk
            location for all data files.</para>
  <para>However, increasing the partition power by 1 can be done by choosing locations
            that are on the same disk. As a result, we can create hard-links for both the
            new and old locations, avoiding data movement without impacting availability.</para>
  <para>To enable a partition power change without interrupting user access, object
            servers need to be aware of it in advance. Therefore a partition power change
            needs to be done in multiple steps.</para>
  <note>
    <para>Do not increase the partition power on account and container rings.
                Increasing the partition power is <emphasis>only</emphasis> supported for object rings.
                Trying to increase the part_power for account and container rings <emphasis>will</emphasis>
                result in unavailability, maybe even data loss.</para>
  </note>
  <section>
    <title>Caveats</title>
    <para>Before increasing the partition power, consider the possible drawbacks.
                There are a few caveats when increasing the partition power:</para>
    <itemizedlist>
      <listitem>
        <para>All hashes.pkl files will become invalid once hard links are created, and the
                        replicators will need significantly more time on the first run after finishing
                        the partition power increase.</para>
      </listitem>
      <listitem>
        <para>Object replicators will skip partitions during the partition power increase.
                        Replicators are not aware of hard-links, and would simply copy the content;
                        this would result in heavy data movement and the worst case would be that all
                        data is stored twice.</para>
      </listitem>
      <listitem>
        <para>Due to the fact that each object will now be hard linked from two locations,
                        many more inodes will be used - expect around twice the amount. You need to
                        check the free inode count <emphasis>before</emphasis> increasing the partition power.</para>
      </listitem>
      <listitem>
        <para>Also, object auditors might read each object twice before cleanup removes the
                        second hard link.</para>
      </listitem>
      <listitem>
        <para>Due to the new inodes more memory is needed to cache them, and your
                        object servers should have plenty of available memory to avoid running out of
                        inode cache. Setting <literal>vfs_cache_pressure</literal> to 1 might help with that.</para>
      </listitem>
      <listitem>
        <para>All nodes in the cluster <emphasis>must</emphasis> run at least Swift version 2.13.0 or later.</para>
      </listitem>
    </itemizedlist>
    <para>Due to these caveats you should only increase the partition power if really
                needed, i.e. if the number of partitions per disk is extremely low and the data
                is distributed unevenly across disks.</para>
  </section>
  <section>
    <title>1. Prepare partition power increase</title>
    <para>The swift-ring-builder is used to prepare the ring for an upcoming partition
                power increase. It will store a new variable <literal>next_part_power</literal> with the current
                partition power + 1. Object servers recognize this, and hard links to the new
                location will be created (or deleted) on every PUT or DELETE.  This will make
                it possible to access newly written objects using the future partition power:</para>
    <screen>swift-ring-builder &lt;builder-file&gt; prepare_increase_partition_power
swift-ring-builder &lt;builder-file&gt; write_ring</screen>
    <para>Now you need to copy the updated .ring.gz to all nodes. Already existing data
                needs to be relinked too; therefore an operator has to run a relinker command
                on all object servers in this phase:</para>
    <screen>swift-object-relinker relink</screen>
    <note>
      <para>Start relinking after <emphasis>all</emphasis> the servers re-read the modified ring files,
                    which normally happens within 15 seconds after writing a modified ring.
                    Also, make sure the modified rings are pushed to all nodes running object
                    services (replicators, reconstructors and reconcilers)- they have to skip
                    partitions during relinking.</para>
    </note>
    <para>Relinking might take some time; while there is no data copied or actually
                moved, the tool still needs to walk the whole file system and create new hard
                links as required.</para>
  </section>
  <section>
    <title>2. Increase partition power</title>
    <para>Now that all existing data can be found using the new location, it’s time to
                actually increase the partition power itself:</para>
    <screen>swift-ring-builder &lt;builder-file&gt; increase_partition_power
swift-ring-builder &lt;builder-file&gt; write_ring</screen>
    <para>Now you need to copy the updated .ring.gz again to all nodes. Object servers
                are now using the new, increased partition power and no longer create
                additional hard links.</para>
    <note>
      <para>The object servers will create additional hard links for each modified or
                    new object, and this requires more inodes.</para>
    </note>
    <note>
      <para>If you decide you don’t want to increase the partition power, you should
                    instead cancel the increase. It is not possible to revert this operation
                    once started. To abort the partition power increase, execute the following
                    commands, copy the updated .ring.gz files to all nodes and continue with
                    <xref linkend="cleanup"/> afterwards:</para>
      <screen>swift-ring-builder &lt;builder-file&gt; cancel_increase_partition_power
swift-ring-builder &lt;builder-file&gt; write_ring</screen>
    </note>
  </section>
  <section xml:id="cleanup">
    <title>3. Cleanup</title>
    <para>Existing hard links in the old locations need to be removed, and a cleanup tool
                is provided to do this. Run the following command on each storage node:</para>
    <screen>swift-object-relinker cleanup</screen>
    <note>
      <para>The cleanup must be finished within your object servers reclaim_age period
                    (which is by default 1 week). Otherwise objects that have been overwritten
                    between step #1 and step #2 and deleted afterwards can’t be cleaned up
                    anymore.</para>
    </note>
    <para>Afterwards it is required to update the rings one last
                time to inform servers that all steps to increase the partition power are done,
                and replicators should resume their job:</para>
    <screen>swift-ring-builder &lt;builder-file&gt; finish_increase_partition_power
swift-ring-builder &lt;builder-file&gt; write_ring</screen>
    <para>Now you need to copy the updated .ring.gz again to all nodes.</para>
  </section>
  <section>
    <title>Background</title>
    <para>An existing object that is currently located on partition X will be placed
                either on partition 2*X or 2*X+1 after the partition power is increased. The
                reason for this is the Ring.get_part() method, that does a bitwise shift to the
                right.</para>
    <para>To avoid actual data movement to different disks or even nodes, the allocation
                of partitions to nodes needs to be changed. The allocation is pairwise due to
                the above mentioned new partition scheme. Therefore devices are allocated like
                this, with the partition being the index and the value being the device id:</para>
    <screen>    old        new
part  dev   part  dev
----  ---   ----  ---
0     0     0     0
            1     0
1     3     2     3
            3     3
2     7     4     7
            5     7
3     5     6     5
            7     5
4     2     8     2
            9     2
5     1     10    1
            11    1</screen>
    <para>There is a helper method to compute the new path, and the following example
                shows the mapping between old and new location:</para>
    <screen>&gt;&gt;&gt; from swift.common.utils import replace_partition_in_path
&gt;&gt;&gt; old='objects/16003/a38/fa0fcec07328d068e24ccbf2a62f2a38/1467658208.57179.data'
&gt;&gt;&gt; replace_partition_in_path(old, 14)
'objects/16003/a38/fa0fcec07328d068e24ccbf2a62f2a38/1467658208.57179.data'
&gt;&gt;&gt; replace_partition_in_path(old, 15)
'objects/32007/a38/fa0fcec07328d068e24ccbf2a62f2a38/1467658208.57179.data'</screen>
    <para>Using the original partition power (14) it returned the same path; however
                after an increase to 15 it returns the new path, and the new partition is 2*X+1
                in this case.</para>
  </section>
</section>
