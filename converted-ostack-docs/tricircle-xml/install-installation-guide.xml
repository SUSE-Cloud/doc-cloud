<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.1">
  <title>Installation Guide</title>
  <para>Now the Tricircle can be played with Devstack for all-in-one single pod and
            multi-pod. You can build different Tricircle environments with Devstack
            according to your needs. In the near future there will be a manual installation
            guide in this installation guide that discussing how to install the Tricircle
            step by step without DevStack for users who install OpenStack manually.</para>
  <section>
    <title>Single pod installation with DevStack</title>
    <para>Now the Tricircle can be played with all-in-one single pod DevStack. For
                the resource requirement to setup single pod DevStack, please refer
                to <link xlink:href="https://docs.openstack.org/devstack/latest/guides.html#all-in-one-single-machine">All-In-One Single Machine</link> for
                installing DevStack in bare metal server
                or <link xlink:href="https://docs.openstack.org/devstack/latest/guides.html#all-in-one-single-vm">All-In-One Single VM</link> for
                installing DevStack in virtual machine.</para>
    <itemizedlist>
      <listitem>
        <para>1 Install DevStack. Please refer to <link xlink:href="https://docs.openstack.org/devstack/latest/">DevStack document</link>
                        on how to install DevStack into single VM or bare metal server.</para>
      </listitem>
      <listitem>
        <para>2 In DevStack folder, create a file local.conf, and copy the content of
                        <link xlink:href="https://github.com/openstack/tricircle/blob/master/devstack/local.conf.sample"/>
                        to local.conf, change password in the file if needed.</para>
      </listitem>
      <listitem>
        <para>3 Run DevStack. In DevStack folder, run</para>
        <screen>./stack.sh</screen>
      </listitem>
      <listitem>
        <para>4 After DevStack successfully starts, we need to create environment variables for
                        the user (admin user as example in this document). In DevStack folder</para>
        <screen>source openrc admin demo</screen>
      </listitem>
      <listitem>
        <para>5 Unset the region name environment variable, so that the command can be issued to
                        specified region in following commands as needed</para>
        <screen>unset OS_REGION_NAME</screen>
      </listitem>
      <listitem>
        <para>6 Check if services have been correctly registered. Run</para>
        <screen>openstack --os-region-name=RegionOne endpoint list</screen>
        <para>you should get output looks like as following</para>
        <screen><?dbsuse-fo font-size="8pt"?>+----------------------------------+---------------+--------------+----------------+
| ID                               | Region        | Service Name | Service Type   |
+----------------------------------+---------------+--------------+----------------+
| 3944592550764e349d0e82dba19a8e64 | RegionOne     | cinder       | volume         |
| 2ce48c73cca44e66a558ad69f1aa4436 | CentralRegion | tricircle    | Tricircle      |
| d214b688923a4348b908525266db66ed | RegionOne     | nova_legacy  | compute_legacy |
| c5dd60f23f2e4442865f601758a73982 | RegionOne     | keystone     | identity       |
| a99d5742c76a4069bb8621e0303c6004 | RegionOne     | cinderv3     | volumev3       |
| 8a3c711a24b2443a9a4420bcc302ed2c | RegionOne     | glance       | image          |
| e136af00d64a4cdf8b6b367210476f49 | RegionOne     | nova         | compute        |
| 4c3e5d52a90e493ab720213199ab22cd | RegionOne     | neutron      | network        |
| 8a1312afb6944492b47c5a35f1e5caeb | RegionOne     | cinderv2     | volumev2       |
| e0a5530abff749e1853a342b5747492e | CentralRegion | neutron      | network        |
+----------------------------------+---------------+--------------+----------------+</screen>
        <para>“CentralRegion” is the region you set in local.conf via CENTRAL_REGION_NAME,
                        whose default value is “CentralRegion”, we use it as the region for the
                        central Neutron server and Tricircle Admin API(ID is
                        2ce48c73cca44e66a558ad69f1aa4436 in the above list).
                        “RegionOne” is the normal OpenStack region which includes Nova, Cinder,
                        Neutron.</para>
      </listitem>
      <listitem>
        <para>7 Create pod instances for the Tricircle to manage the mapping between
                        availability zone and OpenStack instances</para>
        <screen><?dbsuse-fo font-size="8pt"?>openstack multiregion networking pod create --region-name CentralRegion

openstack multiregion networking pod create --region-name RegionOne --availability-zone az1</screen>
        <para>Pay attention to “region_name” parameter we specify when creating pod. Pod name
                        should exactly match the region name registered in Keystone. In the above
                        commands, we create pods named “CentralRegion” and “RegionOne”.</para>
      </listitem>
      <listitem>
        <para>8 Create necessary resources in central Neutron server</para>
        <screen><?dbsuse-fo font-size="8pt"?>neutron --os-region-name=CentralRegion net-create --availability-zone-hint RegionOne net1
neutron --os-region-name=CentralRegion subnet-create net1 10.0.0.0/24</screen>
        <para>Please note that the net1 ID will be used in later step to boot VM.</para>
      </listitem>
      <listitem>
        <para>9 Get image ID and flavor ID which will be used in VM booting</para>
        <screen>glance --os-region-name=RegionOne image-list
nova --os-region-name=RegionOne flavor-list</screen>
      </listitem>
      <listitem>
        <para>10 Boot a virtual machine</para>
        <screen><?dbsuse-fo font-size="8pt"?>nova --os-region-name=RegionOne boot --flavor 1 --image $image_id --nic net-id=$net_id vm1</screen>
      </listitem>
      <listitem>
        <para>11 Verify the VM is connected to the net1</para>
        <screen>neutron --os-region-name=CentralRegion port-list
neutron --os-region-name=RegionOne port-list
nova --os-region-name=RegionOne list</screen>
        <para>The IP address of the VM could be found in local Neutron server and central
                        Neutron server. The port has same uuid in local Neutron server and central
                        Neutron Server.</para>
      </listitem>
    </itemizedlist>
  </section>
  <section>
    <title>Multi-pod Installation with DevStack</title>
    <section>
      <title>Introduction</title>
      <para>In the single pod installation guide, we discuss how to deploy the Tricircle in
                    one single pod with DevStack. Besides the Tricircle API and the central Neutron
                    server, only one pod(one pod means one OpenStack instance) is running. Network
                    is created with the default network type: local. Local type network will be only
                    presented in one pod. If a local type network is already hosting virtual machines
                    in one pod, you can not use it to boot virtual machine in another pod. That is
                    to say, local type network doesn’t support cross-Neutron l2 networking.</para>
      <para>With multi-pod installation of the Tricircle, you can try out cross-Neutron l2
                    networking and cross-Neutron l3 networking features.</para>
      <para>To support cross-Neutron l2 networking, we have added both VLAN and VxLAN
                    network type to the Tricircle. When a VLAN type network created via the
                    central Neutron server is used to boot virtual machines in different pods, local
                    Neutron server in each pod will create a VLAN type network with the same VLAN
                    ID and physical network as the central network, so each pod should be configured
                    with the same VLAN allocation pool and physical network. Then virtual machines
                    in different pods can communicate with each other in the same physical network
                    with the same VLAN tag. Similarly, for VxLAN network type, each pod should be
                    configured with the same VxLAN allocation pool, so local Neutron server in each
                    pod can create a VxLAN type network with the same VxLAN ID as is allocated by
                    the central Neutron server.</para>
      <para>Cross-Neutron l3 networking is supported in two ways in the Tricircle. If two
                    networks connected to the router are of local type, we utilize a shared
                    VLAN or VxLAN network to achieve cross-Neutron l3 networking. When a subnet is
                    attached to a router via the central Neutron server, the Tricircle not only
                    creates corresponding subnet and router in the pod, but also creates a “bridge”
                    network. Both tenant network and “bridge” network are attached to the router.
                    Each tenant will have one allocated VLAN or VxLAN ID, which is shared by the
                    tenant’s “bridge” networks across Neutron servers. The CIDRs of “bridge” networks for one
                    tenant are also the same, so the router interfaces in “bridge” networks across
                    different Neutron servers can communicate with each other. By adding an extra route as
                    following:</para>
      <screen>destination: CIDR of tenant network in another pod
nexthop: "bridge" network interface ip in another pod</screen>
      <para>When a virtual machine sends a packet whose receiver is in another network and
                    in another pod, the packet first goes to router, then is forwarded to the router
                    in another pod according to the extra route, at last the packet is sent to the
                    target virtual machine. This route configuration job is triggered when user
                    attaches a subnet to a router via the central Neutron server and the job is
                    finished asynchronously.</para>
      <para>If one of the network connected to the router is not local type, meaning that
                    cross-Neutron l2 networking is supported in this network(like VLAN type), and
                    the l2 network can be stretched into current pod, packets sent to the virtual
                    machine in this network will not pass through the “bridge” network. Instead,
                    packets first go to router, then are directly forwarded to the target virtual
                    machine via the l2 network. A l2 network’s presence scope is determined by the
                    network’s availability zone hint. If the l2 network is not able to be stretched
                    into the current pod, the packets will still pass through the “bridge network”.
                    For example, let’s say we have two pods, pod1 and pod2, and two availability
                    zones, az1 and az2. Pod1 belongs to az1 and pod2 belongs to az2. If the
                    availability zone hint of one VLAN type network is set to az1, this
                    network can not be stretched to pod2. So packets sent from pod2 to virtual
                    machines in this network still need to pass through the “bridge network”.</para>
    </section>
    <section>
      <title>Prerequisite</title>
      <para>In this guide we take two nodes deployment as an example. One node to run the
                    Tricircle API, the central Neutron server and one pod, the other one node to run
                    another pod. For VLAN network, both nodes should have two network interfaces,
                    which are connected to the management network and provider VLAN network. The
                    physical network infrastructure should support VLAN tagging. For VxLAN network,
                    you can combine the management plane and data plane, in this case, only one
                    network interface is needed. If you would like to try north-south networking,
                    too, you should prepare one more network interface in the second node for the
                    external network. In this guide, the external network is also VLAN type, so the
                    local.conf sample is based on VLAN type external network setup. For the resource
                    requirements to setup each node, please refer to
                    <link xlink:href="https://docs.openstack.org/devstack/latest/guides.html#all-in-one-single-machine">All-In-One Single Machine</link>
                    for installing DevStack in bare metal server and
                    <link xlink:href="https://docs.openstack.org/devstack/latest/guides.html#all-in-one-single-vm">All-In-One Single VM</link>
                    for installing DevStack in virtual machine.</para>
      <para>If you want to experience cross Neutron VxLAN network, please make sure
                    compute nodes are routable to each other on data plane, and enable L2
                    population mechanism driver in OpenStack RegionOne and OpenStack RegionTwo.</para>
    </section>
    <section>
      <title>Setup</title>
      <para>In pod1 in node1 for Tricircle service, central Neutron and OpenStack
                    RegionOne,</para>
      <itemizedlist>
        <listitem>
          <para>1 Install DevStack. Please refer to
                            <link xlink:href="https://docs.openstack.org/devstack/latest/">DevStack document</link>
                            on how to install DevStack into single VM or bare metal server.</para>
        </listitem>
        <listitem>
          <para>2 In DevStack folder, create a file local.conf, and copy the content of
                            <link xlink:href="https://github.com/openstack/tricircle/blob/master/devstack/local.conf.node_1.sample">local.conf node1 sample</link>
                            to local.conf, change password in the file if needed.</para>
        </listitem>
        <listitem>
          <para>3 Change the following options according to your environment</para>
          <itemizedlist>
            <listitem>
              <para>change HOST_IP to your management interface ip:</para>
              <screen>HOST_IP=10.250.201.24</screen>
            </listitem>
            <listitem>
              <para>the format of Q_ML2_PLUGIN_VLAN_TYPE_OPTIONS is
                                    (network_vlan_ranges=&lt;physical network name&gt;:&lt;min vlan&gt;:&lt;max vlan&gt;),
                                    you can change physical network name, but remember to adapt your change
                                    to the commands showed in this guide; also, change min VLAN and max vlan
                                    to adapt the VLAN range your physical network supports. You need to
                                    additionally specify the physical network “extern” to ensure the
                                    central neutron can create “extern” physical network which located in
                                    other pods:</para>
              <screen><?dbsuse-fo font-size="8pt"?>Q_ML2_PLUGIN_VLAN_TYPE_OPTIONS=(network_vlan_ranges=bridge:2001:3000,extern:3001:4000)</screen>
            </listitem>
            <listitem>
              <para>if you would like to also configure vxlan network, you can set
                                    Q_ML2_PLUGIN_VXLAN_TYPE_OPTIONS. the format of it is
                                    (vni_ranges=&lt;min vxlan&gt;:&lt;max vxlan&gt;):</para>
              <screen>Q_ML2_PLUGIN_VXLAN_TYPE_OPTIONS=(vni_ranges=1001:2000)</screen>
            </listitem>
            <listitem>
              <para>the format of OVS_BRIDGE_MAPPINGS is &lt;physical network name&gt;:&lt;ovs bridge name&gt;,
                                    you can change these names, but remember to adapt your change to the
                                    commands showed in this guide. You do not need specify the bridge mapping
                                    for “extern”, because this physical network is located in other pods:</para>
              <screen>OVS_BRIDGE_MAPPINGS=bridge:br-vlan</screen>
              <para>this option can be omitted if only VxLAN networks are needed</para>
            </listitem>
            <listitem>
              <para>if you would like to also configure flat network, you can set
                                    Q_ML2_PLUGIN_FLAT_TYPE_OPTIONS, the format of it is
                                    (flat_networks=phy_net1,phy_net2,…). Besides specifying a list of
                                    physical network names, you can also use ‘*’ to allow flat networks with
                                    arbitrary physical network names; or use an empty list to disable flat
                                    networks. For simplicity, we use the same physical networks and bridge
                                    mappings for vlan and flat network configuration. Similar to vlan network,
                                    You need to additionally specify the physical network “extern” to ensure
                                    the central neutron can create “extern” physical network which located in
                                    other pods:</para>
              <screen>Q_ML2_PLUGIN_FLAT_TYPE_OPTIONS=(flat_networks=bridge,extern)</screen>
            </listitem>
            <listitem>
              <para>set TRICIRCLE_START_SERVICES to True to install the Tricircle service and
                                    central Neutron in node1:</para>
              <screen>TRICIRCLE_START_SERVICES=True</screen>
            </listitem>
          </itemizedlist>
        </listitem>
        <listitem>
          <para>4 Create OVS bridge and attach the VLAN network interface to it</para>
          <screen>sudo ovs-vsctl add-br br-vlan
sudo ovs-vsctl add-port br-vlan eth1</screen>
          <para>br-vlan is the OVS bridge name you configure on OVS_PHYSICAL_BRIDGE, eth1 is
                            the device name of your VLAN network interface, this step can be omitted if
                            only VxLAN networks are provided to tenants.</para>
        </listitem>
        <listitem>
          <para>5 Run DevStack. In DevStack folder, run</para>
          <screen>./stack.sh</screen>
        </listitem>
        <listitem>
          <para>6 After DevStack successfully starts, begin to setup node2.</para>
        </listitem>
      </itemizedlist>
      <para>In pod2 in node2 for OpenStack RegionTwo,</para>
      <itemizedlist>
        <listitem>
          <para>1 Install DevStack. Please refer to
                            <link xlink:href="https://docs.openstack.org/devstack/latest/">DevStack document</link>
                            on how to install DevStack into single VM or bare metal server.</para>
        </listitem>
        <listitem>
          <para>2 In DevStack folder, create a file local.conf, and copy the content of
                            <link xlink:href="https://github.com/openstack/tricircle/blob/master/devstack/local.conf.node_2.sample">local.conf node2 sample</link>
                            to local.conf, change password in the file if needed.</para>
        </listitem>
        <listitem>
          <para>3 Change the following options according to your environment</para>
          <itemizedlist>
            <listitem>
              <para>change HOST_IP to your management interface ip:</para>
              <screen>HOST_IP=10.250.201.25</screen>
            </listitem>
            <listitem>
              <para>change KEYSTONE_SERVICE_HOST to management interface ip of node1:</para>
              <screen>KEYSTONE_SERVICE_HOST=10.250.201.24</screen>
            </listitem>
            <listitem>
              <para>change KEYSTONE_AUTH_HOST to management interface ip of node1:</para>
              <screen>KEYSTONE_AUTH_HOST=10.250.201.24</screen>
            </listitem>
            <listitem>
              <para>the format of Q_ML2_PLUGIN_VLAN_TYPE_OPTIONS is
                                    (network_vlan_ranges=&lt;physical network name&gt;:&lt;min vlan&gt;:&lt;max vlan&gt;),
                                    you can change physical network name, but remember to adapt your change
                                    to the commands showed in this guide; also, change min vlan and max vlan
                                    to adapt the vlan range your physical network supports:</para>
              <screen><?dbsuse-fo font-size="8pt"?>Q_ML2_PLUGIN_VLAN_TYPE_OPTIONS=(network_vlan_ranges=bridge:2001:3000,extern:3001:4000)</screen>
            </listitem>
            <listitem>
              <para>if you would like to also configure vxlan network, you can set
                                    Q_ML2_PLUGIN_VXLAN_TYPE_OPTIONS. the format of it is
                                    (vni_ranges=&lt;min vxlan&gt;:&lt;max vxlan&gt;):</para>
              <screen>Q_ML2_PLUGIN_VXLAN_TYPE_OPTIONS=(vni_ranges=1001:2000)</screen>
            </listitem>
            <listitem>
              <para>the format of OVS_BRIDGE_MAPPINGS is &lt;physical network name&gt;:&lt;ovs bridge name&gt;,
                                    you can change these names, but remember to adapt your change to the commands
                                    showed in this guide:</para>
              <screen>OVS_BRIDGE_MAPPINGS=bridge:br-vlan,extern:br-ext</screen>
              <para>if you only use vlan network for external network, it can be configured like:</para>
              <screen>OVS_BRIDGE_MAPPINGS=extern:br-ext</screen>
            </listitem>
            <listitem>
              <para>if you would like to also configure flat network, you can set
                                    Q_ML2_PLUGIN_FLAT_TYPE_OPTIONS, the format of it is
                                    (flat_networks=phy_net1,phy_net2,…). Besides specifying a list of
                                    physical network names, you can also use ‘*’ to allow flat networks with
                                    arbitrary physical network names; or use an empty list to disable flat
                                    networks. For simplicity, we use the same physical networks and bridge
                                    mappings for vlan and flat network configuration:</para>
              <screen>Q_ML2_PLUGIN_FLAT_TYPE_OPTIONS=(flat_networks=bridge,extern)</screen>
            </listitem>
            <listitem>
              <para>set TRICIRCLE_START_SERVICES to False(it’s True by default) so Tricircle
                                    services and central Neutron will not be started in node2:</para>
              <screen>TRICIRCLE_START_SERVICES=False</screen>
            </listitem>
          </itemizedlist>
          <para>In this guide, we define two physical networks in node2, one is “bridge” for
                            bridge network, the other one is “extern” for external network. If you do not
                            want to try l3 north-south networking, you can simply remove the “extern”
                            part. The external network type we use in the guide is VLAN, if you want to
                            use other network type like flat, please refer to
                            <link xlink:href="https://docs.openstack.org/devstack/latest/">DevStack document</link>.</para>
        </listitem>
        <listitem>
          <para>4 Create OVS bridge and attach the VLAN network interface to it</para>
          <screen>sudo ovs-vsctl add-br br-vlan
sudo ovs-vsctl add-port br-vlan eth1
sudo ovs-vsctl add-br br-ext
sudo ovs-vsctl add-port br-ext eth2</screen>
          <para>br-vlan and br-ext are the OVS bridge names you configure on
                            OVS_PHYSICAL_BRIDGE, eth1 and eth2 are the device names of your VLAN network
                            interfaces, for the “bridge” network and the external network. Omit br-vlan
                            if you only use vxlan network as tenant network.</para>
        </listitem>
        <listitem>
          <para>5 Run DevStack. In DevStack folder, run</para>
          <screen>./stack.sh</screen>
        </listitem>
        <listitem>
          <para>6 After DevStack successfully starts, the setup is finished.</para>
        </listitem>
      </itemizedlist>
      <note>
        <para>In the newest version of codes, we may fail to boot an instance in
                        node2. The reason is that Apache configuration file of Nova placement API
                        doesn’t grant access right to the placement API bin folder. You can use
                        “screen -r” to check placement API is working well or not. If placement API
                        is in stuck status, manually update “/etc/apache2/sites-enabled/placement-api.conf”
                        placement API configuration file in node2 to add the following section:</para>
        <screen>&lt;Directory /usr/local/bin&gt;
    Require all granted
&lt;/Directory&gt;</screen>
        <para>After update, restart Apache service first, and then placement API.</para>
        <para>
          <emphasis role="bold">This problem no longer exists after this patch:</emphasis>
        </para>
        <para>
          <link xlink:href="https://github.com/openstack-dev/devstack/commit/6ed53156b6198e69d59d1cf3a3497e96f5b7a870"/>
        </para>
      </note>
    </section>
    <section>
      <title>How to play</title>
      <itemizedlist>
        <listitem>
          <para>1 After DevStack successfully starts, we need to create environment variables
                            for the user (admin user as example in this guide). In DevStack folder</para>
          <screen>source openrc admin demo</screen>
        </listitem>
        <listitem>
          <para>2 Unset the region name environment variable, so that the command can be
                            issued to specified region in following commands as needed</para>
          <screen>unset OS_REGION_NAME</screen>
        </listitem>
        <listitem>
          <para>3 Check if services have been correctly registered. Run</para>
          <screen>openstack --os-region-name=RegionOne endpoint list</screen>
          <para>you should get output looks like as following</para>
          <screen><?dbsuse-fo font-size="8pt"?>+----------------------------------+---------------+--------------+----------------+
| ID                               | Region        | Service Name | Service Type   |
+----------------------------------+---------------+--------------+----------------+
| 4adaab1426d94959be46314b4bd277c2 | RegionOne     | glance       | image          |
| 5314a11d168042ed85a1f32d40030b31 | RegionTwo     | nova_legacy  | compute_legacy |
| ea43c53a8ab7493dacc4db079525c9b1 | RegionOne     | keystone     | identity       |
| a1f263473edf4749853150178be1328d | RegionOne     | neutron      | network        |
| ebea16ec07d94ed2b5356fb0a2a3223d | RegionTwo     | neutron      | network        |
| 8d374672c09845f297755117ec868e11 | CentralRegion | tricircle    | Tricircle      |
| e62e543bb9cf45f593641b2d00d72700 | RegionOne     | nova_legacy  | compute_legacy |
| 540bdedfc449403b9befef3c2bfe3510 | RegionOne     | nova         | compute        |
| d533429712954b29b9f37debb4f07605 | RegionTwo     | glance       | image          |
| c8bdae9506cd443995ee3c89e811fb45 | CentralRegion | neutron      | network        |
| 991d304dfcc14ccf8de4f00271fbfa22 | RegionTwo     | nova         | compute        |
+----------------------------------+---------------+--------------+----------------+</screen>
          <para>“CentralRegion” is the region you set in local.conf via CENTRAL_REGION_NAME,
                            whose default value is “CentralRegion”, we use it as the region for the
                            Tricircle API and central Neutron server. “RegionOne” and “RegionTwo” are the
                            normal OpenStack regions which includes Nova, Neutron and Glance. Shared
                            Keystone service is registered in “RegionOne”.</para>
        </listitem>
        <listitem>
          <para>4 Create pod instances for the Tricircle to manage the mapping between
                            availability zones and OpenStack instances</para>
          <screen><?dbsuse-fo font-size="8pt"?>openstack multiregion networking pod create --region-name CentralRegion

openstack multiregion networking pod create --region-name RegionOne --availability-zone az1

openstack multiregion networking pod create --region-name RegionTwo --availability-zone az2</screen>
          <para>Pay attention to “region_name” parameter we specify when creating pod. Pod name
                            should exactly match the region name registered in Keystone. In the above
                            commands, we create pods named “CentralRegion”, “RegionOne” and “RegionTwo”.</para>
        </listitem>
        <listitem>
          <para>5 Create necessary resources in central Neutron server</para>
          <screen><?dbsuse-fo font-size="8pt"?>neutron --os-region-name=CentralRegion net-create --availability-zone-hint RegionOne net1
neutron --os-region-name=CentralRegion subnet-create net1 10.0.1.0/24
neutron --os-region-name=CentralRegion net-create --availability-zone-hint RegionTwo net2
neutron --os-region-name=CentralRegion subnet-create net2 10.0.2.0/24</screen>
          <para>Please note that the net1 and net2 ID will be used in later step to boot VM.</para>
        </listitem>
        <listitem>
          <para>6 Get image ID and flavor ID which will be used in VM booting</para>
          <screen>glance --os-region-name=RegionOne image-list
nova --os-region-name=RegionOne flavor-list
glance --os-region-name=RegionTwo image-list
nova --os-region-name=RegionTwo flavor-list</screen>
        </listitem>
        <listitem>
          <para>7 Boot virtual machines</para>
          <screen><?dbsuse-fo font-size="8pt"?>nova --os-region-name=RegionOne boot --flavor 1 --image $image1_id --nic net-id=$net1_id vm1
nova --os-region-name=RegionTwo boot --flavor 1 --image $image2_id --nic net-id=$net2_id vm2</screen>
        </listitem>
        <listitem>
          <para>8 Verify the VMs are connected to the networks</para>
          <screen>neutron --os-region-name=CentralRegion port-list
neutron --os-region-name=RegionOne port-list
nova --os-region-name=RegionOne list
neutron --os-region-name=RegionTwo port-list
nova --os-region-name=RegionTwo list</screen>
          <para>The ip address of each VM could be found in local Neutron server and central
                            Neutron server. The port has same uuid in local Neutron server and central
                            Neutron Server.</para>
        </listitem>
        <listitem>
          <para>9 Create external network and subnet</para>
          <screen><?dbsuse-fo font-size="8pt"?>neutron --os-region-name=CentralRegion net-create --router:external --provider:network_type vlan --provider:physical_network extern --availability-zone-hint RegionTwo ext-net
neutron --os-region-name=CentralRegion subnet-create --name ext-subnet --disable-dhcp ext-net 163.3.124.0/24</screen>
          <para>Pay attention that when creating external network, we need to pass
                            “availability_zone_hints” parameter, which is the name of the pod that will
                            host external network.</para>
          <para>
            <emphasis>Currently external network needs to be created before attaching subnet to the
                                router, because plugin needs to utilize external network information to setup
                                bridge network when handling interface adding operation. This limitation will
                                be removed later.</emphasis>
          </para>
        </listitem>
        <listitem>
          <para>10 Create router and attach subnets in central Neutron server</para>
          <screen>neutron --os-region-name=CentralRegion router-create router
neutron --os-region-name=CentralRegion router-interface-add router $subnet1_id
neutron --os-region-name=CentralRegion router-interface-add router $subnet2_id</screen>
        </listitem>
        <listitem>
          <para>11 Set router external gateway in central Neutron server</para>
          <screen>neutron --os-region-name=CentralRegion router-gateway-set router ext-net</screen>
          <para>Now virtual machine in the subnet attached to the router should be able to
                            ping machines in the external network. In our test, we use hypervisor tool
                            to directly start a virtual machine in the external network to check the
                            network connectivity.</para>
        </listitem>
        <listitem>
          <para>12 Launch VNC console and test connection</para>
          <screen>nova --os-region-name=RegionOne get-vnc-console vm1 novnc
nova --os-region-name=RegionTwo get-vnc-console vm2 novnc</screen>
          <para>You should be able to ping vm1 from vm2 and vice versa.</para>
        </listitem>
        <listitem>
          <para>13 Create floating ip in central Neutron server</para>
          <screen>neutron --os-region-name=CentralRegion floatingip-create ext-net</screen>
        </listitem>
        <listitem>
          <para>14 Associate floating ip</para>
          <screen>neutron --os-region-name=CentralRegion floatingip-list
neutron --os-region-name=CentralRegion port-list
neutron --os-region-name=CentralRegion floatingip-associate $floatingip_id $port_id</screen>
          <para>Now you should be able to access virtual machine with floating ip bound from
                            the external network.</para>
        </listitem>
      </itemizedlist>
    </section>
  </section>
  <section>
    <title>Manual Installation</title>
    <para>The Tricircle works with Neutron to provide networking automation functionality
                across Neutron in multi-region OpenStack deployment. In this guide we discuss
                how to manually install the Tricircle with local and central Neutron server.</para>
    <para>Local Neutron server, running with the Tricircle local plugin, is responsible
                for triggering cross-Neutron networking automation. Every OpenStack instance
                has one local Neutron service, registered in the same region with other core
                services like Nova, Cinder, Glance, etc. Central Neutron server, running with
                the Tricircle central plugin, is responsible for unified resource allocation
                and cross-Neutron networking building. Besides regions for each OpenStack
                instance, we also need one specific region for central Neutron service. Only
                the Tricircle administrator service needs to be registered in this region along
                with central Neutron service while other core services are not mandatory.</para>
    <section>
      <title>Installation with Central Neutron Server</title>
      <itemizedlist>
        <listitem>
          <para>1 Install the Tricircle package:</para>
          <screen>git clone https://github.com/openstack/tricircle.git
cd tricircle
pip install -e .</screen>
        </listitem>
        <listitem>
          <para>2 Register the Tricircle administrator API to Keystone:</para>
          <screen><?dbsuse-fo font-size="8pt"?>openstack user create tricircle --password password
openstack role add --project service --user tricircle service
openstack service create tricircle --name tricircle --description "Cross Neutron Networking Automation Service"
service_id=$(openstack service show tricircle -f value -c id)
service_host=162.3.124.201
service_port=19999
service_region=CentralRegion
service_url=http://$service_host:$service_port/v1.0
openstack endpoint create $service_id --publicurl $service_url --adminurl $service_url --internalurl $service_url --region $service_region</screen>
          <para>change password, service_host, service_port and service_region in the above
                            commands to adapt your deployment. OpenStack CLI tool will automatically find
                            the endpoints to send to registration requests. If you would like to specify
                            the region for endpoints, use:</para>
          <screen>openstack --os-region-name &lt;region_name&gt; &lt;command&gt;</screen>
        </listitem>
        <listitem>
          <para>3 Generate the Tricircle configuration sample:</para>
          <screen>cd tricircle
oslo-config-generator --config-file=etc/api-cfg-gen.conf
oslo-config-generator --config-file=etc/xjob-cfg-gen.conf</screen>
          <para>The generated sample files are located in tricircle/etc</para>
        </listitem>
        <listitem>
          <para>4 Configure the Tricircle administrator API:</para>
          <screen>cd tricircle/etc
cp api.conf.sample api.conf</screen>
          <para>Edit etc/api.conf, for detail configuration information, please refer to the
                            configuration guide. Below only options necessary to be changed are listed.</para>
        </listitem>
      </itemizedlist>
      <informaltable>
        <tgroup cols="3">
          <colspec colname="c1" colwidth="33.3*"/>
          <colspec colname="c2" colwidth="33.3*"/>
          <colspec colname="c3" colwidth="33.3*"/>
          <thead>
            <row>
              <entry>
                <para>Option</para>
              </entry>
              <entry>
                <para>Description</para>
              </entry>
              <entry>
                <para>Example</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>[DEFAULT] tricircle_db_connection</para>
              </entry>
              <entry>
                <para>database connection string for tricircle</para>
              </entry>
              <entry>
                <para>mysql+pymysql://root:password@ 127.0.0.1/tricircle?charset=utf8</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[DEFAULT] transport_url</para>
              </entry>
              <entry>
                <para>a URL representing the used messaging driver and its full configuration</para>
              </entry>
              <entry>
                <para>rabbit://user:password@ 127.0.0.1:5672</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] auth_type</para>
              </entry>
              <entry>
                <para>authentication method</para>
              </entry>
              <entry>
                <para>password</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] auth_url</para>
              </entry>
              <entry>
                <para>keystone authorization url</para>
              </entry>
              <entry>
                <para>
                  <link xlink:href="http://$keystone_service_host/identity"/>
                </para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] username</para>
              </entry>
              <entry>
                <para>username of service account, needed for password authentication</para>
              </entry>
              <entry>
                <para>tricircle</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] password</para>
              </entry>
              <entry>
                <para>password of service account, needed for password authentication</para>
              </entry>
              <entry>
                <para>password</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] user_domain_name</para>
              </entry>
              <entry>
                <para>user domain name of service account, needed for password authentication</para>
              </entry>
              <entry>
                <para>Default</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] project_name</para>
              </entry>
              <entry>
                <para>project name of service account, needed for password authentication</para>
              </entry>
              <entry>
                <para>service</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] project_domain_name</para>
              </entry>
              <entry>
                <para>project domain name of service account, needed for password authentication</para>
              </entry>
              <entry>
                <para>Default</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] auth_uri</para>
              </entry>
              <entry>
                <para>complete public Identity API endpoint</para>
              </entry>
              <entry>
                <para>
                  <link xlink:href="http://$keystone_service_host/identity"/>
                </para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] cafile</para>
              </entry>
              <entry>
                <para>A PEM encoded Certificate Authority to use when verifying HTTPs</para>
              </entry>
              <entry>
                <para>/opt/stack/data/ca-bundle.pem</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] signing_dir</para>
              </entry>
              <entry>
                <para>Directory used to cache files related to PKI tokens</para>
              </entry>
              <entry>
                <para>/var/cache/tricircle</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[keystone_authtoken] memcached_servers</para>
              </entry>
              <entry>
                <para>Optionally specify a list of memcached server(s) to use for caching</para>
              </entry>
              <entry>
                <para>$keystone_service_host:11211</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] auth_url</para>
              </entry>
              <entry>
                <para>keystone authorization url</para>
              </entry>
              <entry>
                <para>
                  <link xlink:href="http://$keystone_service_host/identity"/>
                </para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] identity_url</para>
              </entry>
              <entry>
                <para>keystone service url</para>
              </entry>
              <entry>
                <para>
                  <link xlink:href="http://$keystone_service_host/identity/v3"/>
                </para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] auto_refresh_endpoint</para>
              </entry>
              <entry>
                <para>if set to True, endpoint will be automatically refreshed if timeout accessing</para>
              </entry>
              <entry>
                <para>True</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] top_region_name</para>
              </entry>
              <entry>
                <para>name of central region which client needs to access</para>
              </entry>
              <entry>
                <para>CentralRegion</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_username</para>
              </entry>
              <entry>
                <para>username of admin account</para>
              </entry>
              <entry>
                <para>admin</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_password</para>
              </entry>
              <entry>
                <para>password of admin account</para>
              </entry>
              <entry>
                <para>password</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_tenant</para>
              </entry>
              <entry>
                <para>project name of admin account</para>
              </entry>
              <entry>
                <para>demo</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_user_domain_name</para>
              </entry>
              <entry>
                <para>user domain name of admin account</para>
              </entry>
              <entry>
                <para>Default</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_tenant_domain_name</para>
              </entry>
              <entry>
                <para>project name of admin account</para>
              </entry>
              <entry>
                <para>Default</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
      <note>
        <para>The Tricircle utilizes the Oslo library to setup service, database,
                        log and RPC, please refer to the configuration guide of the corresponding
                        Oslo library if you need further configuration of these modules. Change
                        keystone_service_host to the address of Keystone service.</para>
      </note>
      <itemizedlist>
        <listitem>
          <para>5 Create the Tricircle database(take mysql as an example):</para>
          <screen>mysql -uroot -p -e "create database tricircle character set utf8;"
cd tricircle
tricircle-db-manage --config-file etc/api.conf db_sync</screen>
        </listitem>
        <listitem>
          <para>6 Start the Tricircle administrator API:</para>
          <screen>sudo mkdir /var/cache/tricircle
sudo chown $(whoami) /var/cache/tricircle/
cd tricircle
tricircle-api --config-file etc/api.conf</screen>
        </listitem>
        <listitem>
          <para>7 Configure the Tricircle Xjob daemon:</para>
          <screen>cd tricircle/etc
cp xjob.conf.sample xjob.conf</screen>
          <para>Edit etc/xjob.conf, for detail configuration information, please refer to the
                            configuration guide. Below only options necessary to be changed are listed.</para>
        </listitem>
      </itemizedlist>
      <informaltable>
        <tgroup cols="3">
          <colspec colname="c1" colwidth="33.3*"/>
          <colspec colname="c2" colwidth="33.3*"/>
          <colspec colname="c3" colwidth="33.3*"/>
          <thead>
            <row>
              <entry>
                <para>Option</para>
              </entry>
              <entry>
                <para>Description</para>
              </entry>
              <entry>
                <para>Example</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>[DEFAULT] tricircle_db_connection</para>
              </entry>
              <entry>
                <para>database connection string for tricircle</para>
              </entry>
              <entry>
                <para>mysql+pymysql://root:password@ 127.0.0.1/tricircle?charset=utf8</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[DEFAULT] transport_url</para>
              </entry>
              <entry>
                <para>a URL representing the used messaging driver and its full configuration</para>
              </entry>
              <entry>
                <para>rabbit://user:password@ 127.0.0.1:5672</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] auth_url</para>
              </entry>
              <entry>
                <para>keystone authorization url</para>
              </entry>
              <entry>
                <para>
                  <link xlink:href="http://$keystone_service_host/identity"/>
                </para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] identity_url</para>
              </entry>
              <entry>
                <para>keystone service url</para>
              </entry>
              <entry>
                <para>
                  <link xlink:href="http://$keystone_service_host/identity/v3"/>
                </para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] auto_refresh_endpoint</para>
              </entry>
              <entry>
                <para>if set to True, endpoint will be automatically refreshed if timeout accessing</para>
              </entry>
              <entry>
                <para>True</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] top_region_name</para>
              </entry>
              <entry>
                <para>name of central region which client needs to access</para>
              </entry>
              <entry>
                <para>CentralRegion</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_username</para>
              </entry>
              <entry>
                <para>username of admin account</para>
              </entry>
              <entry>
                <para>admin</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_password</para>
              </entry>
              <entry>
                <para>password of admin account</para>
              </entry>
              <entry>
                <para>password</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_tenant</para>
              </entry>
              <entry>
                <para>project name of admin account</para>
              </entry>
              <entry>
                <para>demo</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_user_domain_name</para>
              </entry>
              <entry>
                <para>user domain name of admin account</para>
              </entry>
              <entry>
                <para>Default</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>[client] admin_tenant_domain_name</para>
              </entry>
              <entry>
                <para>project name of admin account</para>
              </entry>
              <entry>
                <para>Default</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
      <note>
        <para>The Tricircle utilizes the Oslo library to setup service, database,
                        log and RPC, please refer to the configuration guide of the corresponding
                        Oslo library if you need further configuration of these modules. Change
                        keystone_service_host to the address of Keystone service.</para>
      </note>
      <itemizedlist>
        <listitem>
          <para>8 Start the Tricircle Xjob daemon:</para>
          <screen>cd tricircle
tricircle-xjob --config-file etc/xjob.conf</screen>
        </listitem>
        <listitem>
          <para>9 Setup central Neutron server</para>
          <para>In this guide we assume readers are familiar with how to install Neutron
                            server, so we just briefly discuss the steps and extra configuration needed
                            by central Neutron server. For detail information about the configuration
                            options in “client” and “tricircle” groups, please refer to the configuration
                            guide. Neutron server can be installed alone, or you can install a full
                            OpenStack instance then remove or stop other services.</para>
          <itemizedlist>
            <listitem>
              <para>install Neutron package</para>
            </listitem>
            <listitem>
              <para>configure central Neutron server</para>
              <para>edit neutron.conf</para>
            </listitem>
          </itemizedlist>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="33.3*"/>
              <colspec colname="c2" colwidth="33.3*"/>
              <colspec colname="c3" colwidth="33.3*"/>
              <thead>
                <row>
                  <entry>
                    <para>Option</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                  <entry>
                    <para>Example</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>[database] connection</para>
                  </entry>
                  <entry>
                    <para>database connection string for central Neutron server</para>
                  </entry>
                  <entry>
                    <para>mysql+pymysql://root:password@ 127.0.0.1/neutron?charset=utf8</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[DEFAULT] bind_port</para>
                  </entry>
                  <entry>
                    <para>Port central Neutron server binds to</para>
                  </entry>
                  <entry>
                    <para>change to a different value rather than 9696 if you run central and local Neutron server in the same host</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[DEFAULT] core_plugin</para>
                  </entry>
                  <entry>
                    <para>core plugin central Neutron server uses</para>
                  </entry>
                  <entry>
                    <para>tricircle.network.central_plugin. TricirclePlugin</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[DEFAULT] service_plugins</para>
                  </entry>
                  <entry>
                    <para>service plugin central Neutron server uses</para>
                  </entry>
                  <entry>
                    <para>(leave empty)</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[DEFAULT] tricircle_db_connection</para>
                  </entry>
                  <entry>
                    <para>database connection string for tricircle</para>
                  </entry>
                  <entry>
                    <para>mysql+pymysql://root:password@ 127.0.0.1/tricircle?charset=utf8</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] auth_url</para>
                  </entry>
                  <entry>
                    <para>keystone authorization url</para>
                  </entry>
                  <entry>
                    <para>
                      <link xlink:href="http://$keystone_service_host/identity"/>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] identity_url</para>
                  </entry>
                  <entry>
                    <para>keystone service url</para>
                  </entry>
                  <entry>
                    <para>
                      <link xlink:href="http://$keystone_service_host/identity/v3"/>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] auto_refresh_endpoint</para>
                  </entry>
                  <entry>
                    <para>if set to True, endpoint will be automatically refreshed if timeout accessing</para>
                  </entry>
                  <entry>
                    <para>True</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] top_region_name</para>
                  </entry>
                  <entry>
                    <para>name of central region which client needs to access</para>
                  </entry>
                  <entry>
                    <para>CentralRegion</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_username</para>
                  </entry>
                  <entry>
                    <para>username of admin account</para>
                  </entry>
                  <entry>
                    <para>admin</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_password</para>
                  </entry>
                  <entry>
                    <para>password of admin account</para>
                  </entry>
                  <entry>
                    <para>password</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_tenant</para>
                  </entry>
                  <entry>
                    <para>project name of admin account</para>
                  </entry>
                  <entry>
                    <para>demo</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_user_domain_name</para>
                  </entry>
                  <entry>
                    <para>user domain name of admin account</para>
                  </entry>
                  <entry>
                    <para>Default</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_tenant_domain_name</para>
                  </entry>
                  <entry>
                    <para>project name of admin account</para>
                  </entry>
                  <entry>
                    <para>Default</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] type_drivers</para>
                  </entry>
                  <entry>
                    <para>list of network type driver entry points to be loaded</para>
                  </entry>
                  <entry>
                    <para>vxlan,vlan,flat,local</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] tenant_network_types</para>
                  </entry>
                  <entry>
                    <para>ordered list of network_types to allocate as tenant networks</para>
                  </entry>
                  <entry>
                    <para>vxlan,vlan,flat,local</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] network_vlan_ranges</para>
                  </entry>
                  <entry>
                    <para>physical network names and VLAN tags range usable of VLAN provider</para>
                  </entry>
                  <entry>
                    <para>bridge:2001:3000</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] vni_ranges</para>
                  </entry>
                  <entry>
                    <para>VxLAN VNI range</para>
                  </entry>
                  <entry>
                    <para>1001:2000</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] flat_networks</para>
                  </entry>
                  <entry>
                    <para>physical network names with which flat networks can be created</para>
                  </entry>
                  <entry>
                    <para>bridge</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] bridge_network_type</para>
                  </entry>
                  <entry>
                    <para>l3 bridge network type which is enabled in tenant_network_types and is not local type</para>
                  </entry>
                  <entry>
                    <para>vxlan</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] default_region_for_external_network</para>
                  </entry>
                  <entry>
                    <para>Default Region where the external network belongs to</para>
                  </entry>
                  <entry>
                    <para>RegionOne</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] enable_api_gateway</para>
                  </entry>
                  <entry>
                    <para>whether the API gateway is enabled</para>
                  </entry>
                  <entry>
                    <para>False</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <note>
            <para>Change keystone_service_host to the address of Keystone service.</para>
          </note>
          <itemizedlist>
            <listitem>
              <para>create database for central Neutron server</para>
            </listitem>
            <listitem>
              <para>register central Neutron server endpoint in Keystone, central Neutron
                                    should be registered in the same region with the Tricircle</para>
            </listitem>
            <listitem>
              <para>start central Neutron server</para>
            </listitem>
          </itemizedlist>
        </listitem>
      </itemizedlist>
    </section>
    <section>
      <title>Installation with Local Neutron Server</title>
      <itemizedlist>
        <listitem>
          <para>1 Install the Tricircle package:</para>
          <screen>git clone https://github.com/openstack/tricircle.git
cd tricircle
pip install -e .</screen>
        </listitem>
        <listitem>
          <para>2 Setup local Neutron server</para>
          <para>In this guide we assume readers have already installed a complete OpenStack
                            instance running services like Nova, Cinder, Neutron, etc, so we just discuss
                            how to configure Neutron server to work with the Tricircle. For detail
                            information about the configuration options in “client” and “tricircle”
                            groups, please refer to the configuration guide. After the change, you just
                            restart the Neutron server.</para>
          <para>edit neutron.conf.</para>
          <note>
            <para>Pay attention to the service_plugins configuration item, make sure
                                the plugin which is configured can support the association of floating IP
                                to a port whose network is not directly attached to the router. To support
                                it, TricircleL3Plugin is inherited from Neutron original L3RouterPlugin
                                and overrides the original “get_router_for_floatingip” implementation.
                                In order to configure local Neutron to use original L3RouterPlugin, you
                                will need to patch the function “get_router_for_floatingip” in the same
                                way that has been done for TricircleL3Plugin.</para>
            <para>It’s not necessary to configure the service plugins if cross Neutron L2
                                networking is the only need in the deployment.</para>
          </note>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="33.3*"/>
              <colspec colname="c2" colwidth="33.3*"/>
              <colspec colname="c3" colwidth="33.3*"/>
              <thead>
                <row>
                  <entry>
                    <para>Option</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                  <entry>
                    <para>Example</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>[DEFAULT] core_plugin</para>
                  </entry>
                  <entry>
                    <para>core plugin local Neutron server uses</para>
                  </entry>
                  <entry>
                    <para>tricircle.network.local_plugin. TricirclePlugin</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[DEFAULT] service_plugins</para>
                  </entry>
                  <entry>
                    <para>service plugins local Neutron server uses</para>
                  </entry>
                  <entry>
                    <para>tricircle.network.local_l3_plugin. TricircleL3Plugin</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] auth_url</para>
                  </entry>
                  <entry>
                    <para>keystone authorization url</para>
                  </entry>
                  <entry>
                    <para>
                      <link xlink:href="http://$keystone_service_host/identity"/>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] identity_url</para>
                  </entry>
                  <entry>
                    <para>keystone service url</para>
                  </entry>
                  <entry>
                    <para>
                      <link xlink:href="http://$keystone_service_host/identity/v3"/>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] auto_refresh_endpoint</para>
                  </entry>
                  <entry>
                    <para>if set to True, endpoint will be automatically refreshed if timeout accessing</para>
                  </entry>
                  <entry>
                    <para>True</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] top_region_name</para>
                  </entry>
                  <entry>
                    <para>name of central region which client needs to access</para>
                  </entry>
                  <entry>
                    <para>CentralRegion</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_username</para>
                  </entry>
                  <entry>
                    <para>username of admin account</para>
                  </entry>
                  <entry>
                    <para>admin</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_password</para>
                  </entry>
                  <entry>
                    <para>password of admin account</para>
                  </entry>
                  <entry>
                    <para>password</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_tenant</para>
                  </entry>
                  <entry>
                    <para>project name of admin account</para>
                  </entry>
                  <entry>
                    <para>demo</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_user_domain_name</para>
                  </entry>
                  <entry>
                    <para>user domain name of admin account</para>
                  </entry>
                  <entry>
                    <para>Default</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[client] admin_tenant_domain_name</para>
                  </entry>
                  <entry>
                    <para>project name of admin account</para>
                  </entry>
                  <entry>
                    <para>Default</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] real_core_plugin</para>
                  </entry>
                  <entry>
                    <para>the core plugin the Tricircle local plugin invokes</para>
                  </entry>
                  <entry>
                    <para>neutron.plugins.ml2.plugin. Ml2Plugin</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[tricircle] central_neutron_url</para>
                  </entry>
                  <entry>
                    <para>central Neutron server url</para>
                  </entry>
                  <entry>
                    <para><link xlink:href="http://$neutron_service_host"/> :9696</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <note>
            <para>Change keystone_service_host to the address of Keystone service,
                                and neutron_service_host to the address of central Neutron service.</para>
          </note>
          <para>edit ml2_conf.ini</para>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="33.3*"/>
              <colspec colname="c2" colwidth="33.3*"/>
              <colspec colname="c3" colwidth="33.3*"/>
              <thead>
                <row>
                  <entry>
                    <para>Option</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                  <entry>
                    <para>Example</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>[ml2] mechanism_drivers</para>
                  </entry>
                  <entry>
                    <para>add l2population if vxlan network is used</para>
                  </entry>
                  <entry>
                    <para>openvswitch,l2population</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[agent] l2_population</para>
                  </entry>
                  <entry>
                    <para>set to True if vxlan network is used</para>
                  </entry>
                  <entry>
                    <para>True</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[agent] tunnel_types</para>
                  </entry>
                  <entry>
                    <para>set to vxlan if vxlan network is used</para>
                  </entry>
                  <entry>
                    <para>vxlan</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[ml2_type_vlan] network_vlan_ranges</para>
                  </entry>
                  <entry>
                    <para>for a specific physical network, the vlan range should be the same with
                                                tricircle.network_vlan_ranges option for central Neutron, configure this
                                                option if vlan network is used</para>
                  </entry>
                  <entry>
                    <para>bridge:2001:3000</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[ml2_type_vxlan] vni_ranges</para>
                  </entry>
                  <entry>
                    <para>should be the same with tricircle.vni_ranges option for central Neutron,
                                                configure this option if vxlan network is used</para>
                  </entry>
                  <entry>
                    <para>1001:2000</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[ml2_type_flat] flat_networks</para>
                  </entry>
                  <entry>
                    <para>should be part of the tricircle.network_vlan_ranges option for central
                                                Neutron, configure this option if flat network is used</para>
                  </entry>
                  <entry>
                    <para>bridge</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[ovs] bridge_mappings</para>
                  </entry>
                  <entry>
                    <para>map the physical network to an ovs bridge</para>
                  </entry>
                  <entry>
                    <para>bridge:br-bridge</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <note>
            <para>In tricircle.network_vlan_ranges option for central Neutron, all
                                the available physical networks in all pods and their vlan ranges should
                                be configured without duplication. It’s possible that one local Neutron
                                doesn’t contain some of the physical networks configured in
                                tricircle.network_vlan_ranges, in this case, users need to specify
                                availability zone hints when creating network or booting instances in the
                                correct pod, to ensure that the required physical network is available in
                                the target pod.</para>
          </note>
        </listitem>
      </itemizedlist>
    </section>
  </section>
  <section>
    <title>Work with Nova cell v2(experiment)</title>
    <note>
      <para>Multi-cell support of Nova cell v2 is under development. DevStack
                    doesn’t support multi-cell deployment currently, so the steps discussed in
                    this document may seem not that elegant. We will keep updating this document
                    according to the progress of multi-cell development by Nova team.</para>
    </note>
    <section>
      <title>Setup</title>
      <itemizedlist>
        <listitem>
          <para>1 Follow “Multi-pod Installation with DevStack” document to prepare your
                            local.conf for both nodes, and set TRICIRCLE_DEPLOY_WITH_CELL to True for
                            both nodes. Start DevStack in node1, then node2.</para>
        </listitem>
      </itemizedlist>
      <note>
        <para>After running DevStack in both nodes, a multi-cell environment will
                        be prepared: there is one CentralRegion, where Nova API and central Neutron
                        will be registered. Nova has two cells, node1 belongs to cell1, node2 belongs
                        to cell2, and each cell will be configured to use a dedicated local Neutron.
                        For cell1, it’s RegionOne Neutron in node1; for cell2, it’s RegionTwo Neutron
                        in node2(you can set the region name in local.conf to make the name more
                        friendly). End user can access CentralRegion endpoint of Nova and Neutron to
                        experience the integration of Nova cell v2 and Tricircle.</para>
      </note>
      <itemizedlist>
        <listitem>
          <para>2 Enter the screen section in node2, stop n-api and n-sch.</para>
        </listitem>
      </itemizedlist>
      <note>
        <para>Actually for cell v2, only one Nova API is required. We enable n-api
                        in node2 because we need DevStack to help us create the necessary cell
                        database. If n-api is disabled, neither API database nor cell database will
                        be created.</para>
      </note>
      <itemizedlist>
        <listitem>
          <para>3 In node2, run the following command:</para>
          <screen>mysql -u$user -p$password -Dnova -e 'select host, mapped from compute_nodes</screen>
          <para>you can see that this command returns you one row showing the host of node2
                            is already mapped:</para>
          <screen>+-----------+--------+
| host      | mapped |
+-----------+--------+
| zhiyuan-2 |      1 |
+-----------+--------+</screen>
          <para>This host is registered to Nova API in node2, which is already stopped by us,
                            We need to update this row to set “mapped” to 0:</para>
          <screen><?dbsuse-fo font-size="8pt"?>mysql -u$user -p$password -Dnova -e 'update compute_nodes set mapped = 0 where host = "zhiyuan-2"'</screen>
          <para>then we can register this host again in step4.</para>
        </listitem>
        <listitem>
          <para>4 In node1, run the following commands to register the new cell:</para>
          <screen><?dbsuse-fo font-size="8pt"?>nova-manage cell_v2 create_cell --name cell2 \
  --transport-url rabbit://$rabbit_user:$rabbit_passwd@$node2_ip:5672/ \
  --database_connection mysql+pymysql://$db_user:$db_passwd@$node2_ip/nova?charset=utf8

nova-manage cell_v2 discover_hosts</screen>
          <para>then you can see the new cell and host are added in the database:</para>
          <screen>mysql -u$user -p$password -Dnova -e 'select cell_id, host from host_mappings'

+---------+-----------+
| cell_id | host      |
+---------+-----------+
|       2 | zhiyuan-1 |
|       3 | zhiyuan-2 |
+---------+-----------+

mysql -u$user -p$password -Dnova -e 'select id, name from cell_mappings'

+----+-------+
| id | name  |
+----+-------+
|  1 | cell0 |
|  2 | cell1 |
|  3 | cell2 |
+----+-------+</screen>
        </listitem>
        <listitem>
          <para>5 In node1, check if compute services in both hosts are registered:</para>
          <screen><?dbsuse-fo font-size="8pt"?>openstack --os-region-name CentralRegion compute service list

+----+------------------+-----------+----------+---------+-------+----------------------------+
| ID | Binary           | Host      | Zone     | Status  | State | Updated At                 |
+----+------------------+-----------+----------+---------+-------+----------------------------+
|  5 | nova-conductor   | zhiyuan-1 | internal | enabled | up    | 2017-05-27T06:04:37.000000 |
|  7 | nova-scheduler   | zhiyuan-1 | internal | enabled | up    | 2017-05-27T06:04:36.000000 |
|  8 | nova-consoleauth | zhiyuan-1 | internal | enabled | up    | 2017-05-27T06:04:39.000000 |
|  9 | nova-compute     | zhiyuan-1 | nova     | enabled | up    | 2017-05-27T06:04:42.000000 |
|  4 | nova-conductor   | zhiyuan-2 | internal | enabled | up    | 2017-05-27T06:04:40.000000 |
|  6 | nova-scheduler   | zhiyuan-2 | internal | enabled | down  | 2017-05-27T02:56:50.000000 |
|  7 | nova-consoleauth | zhiyuan-2 | internal | enabled | up    | 2017-05-27T06:04:36.000000 |
|  8 | nova-compute     | zhiyuan-2 | nova     | enabled | up    | 2017-05-27T06:04:38.000000 |
+----+------------------+-----------+----------+---------+-------+----------------------------+</screen>
          <para>Nova scheduler in host zhiyuan-2 is down because we stop it in step2.</para>
        </listitem>
        <listitem>
          <para>6 Create two aggregates and put the two hosts in each aggregate:</para>
          <screen>nova --os-region-name CentralRegion aggregate-create ag1 az1
nova --os-region-name CentralRegion aggregate-create ag2 az2
nova --os-region-name CentralRegion aggregate-add-host ag1 zhiyuan-1
nova --os-region-name CentralRegion aggregate-add-host ag2 zhiyuan-2</screen>
        </listitem>
        <listitem>
          <para>7 Create pods, tricircle client is used:</para>
          <screen><?dbsuse-fo font-size="8pt"?>openstack --os-region-name CentralRegion multiregion networking pod create --region-name CentralRegion
openstack --os-region-name CentralRegion multiregion networking pod create --region-name RegionOne --availability-zone az1
openstack --os-region-name CentralRegion multiregion networking pod create --region-name RegionTwo --availability-zone az2</screen>
        </listitem>
        <listitem>
          <para>8 Create network and boot virtual machines:</para>
          <screen><?dbsuse-fo font-size="8pt"?>net_id=$(openstack --os-region-name CentralRegion network create --provider-network-type vxlan net1 -c id -f value)
openstack --os-region-name CentralRegion subnet create --subnet-range 10.0.1.0/24 --network net1 subnet1
image_id=$(openstack --os-region-name CentralRegion image list -c ID -f value)

openstack --os-region-name CentralRegion server create --flavor 1 --image $image_id --nic net-id=$net_id --availability-zone az1 vm1
openstack --os-region-name CentralRegion server create --flavor 1 --image $image_id --nic net-id=$net_id --availability-zone az2 vm2</screen>
        </listitem>
      </itemizedlist>
    </section>
    <section>
      <title>Trouble Shooting</title>
      <itemizedlist>
        <listitem>
          <para>1 After you run “compute service list” in step5, you only see services in node1, like:</para>
          <screen><?dbsuse-fo font-size="8pt"?>+----+------------------+-----------+----------+---------+-------+----------------------------+
| ID | Binary           | Host      | Zone     | Status  | State | Updated At                 |
+----+------------------+-----------+----------+---------+-------+----------------------------+
|  5 | nova-conductor   | zhiyuan-1 | internal | enabled | up    | 2017-05-27T06:04:37.000000 |
|  7 | nova-scheduler   | zhiyuan-1 | internal | enabled | up    | 2017-05-27T06:04:36.000000 |
|  8 | nova-consoleauth | zhiyuan-1 | internal | enabled | up    | 2017-05-27T06:04:39.000000 |
|  9 | nova-compute     | zhiyuan-1 | nova     | enabled | up    | 2017-05-27T06:04:42.000000 |
+----+------------------+-----------+----------+---------+-------+----------------------------+</screen>
          <para>Though new cell has been registered in the database, the running n-api process
                            in node1 may not recognize it. We find that restarting n-api can solve this
                            problem.</para>
        </listitem>
        <listitem>
          <para>2 After you create a server, the server turns into Error status with error
                            “No valid host was found”</para>
          <para>We check the log of n-sch process in node1 and find it says: “Found 2 cells”,
                            this is incorrect since we have three cells including cell0. After restarting
                            n-sch, the log says “Found 3 cells”. Try creating server again after that.</para>
          <para>Another reason for this problem we have found is that n-cpu doesn’t sync
                            available resource with n-sch, restarting n-cpu can slove this problem.</para>
        </listitem>
      </itemizedlist>
    </section>
  </section>
</section>
