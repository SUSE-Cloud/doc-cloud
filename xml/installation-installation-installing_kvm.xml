<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<!--Edit status: not edited-->
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="install_kvm"><title>Installing Mid-scale and Entry-scale KVM</title>
    
    
    <itemizedlist>
        <listitem/>
        <listitem/>
        <listitem/>
        <listitem/>
        <listitem/>
        <listitem/>
        <listitem/>
        <listitem/>
      </itemizedlist>

    <bridgehead  renderas="sect4">Important Notes</bridgehead><itemizedlist>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-8"><para>If you are looking for information about when to use the GUI installer
          and when to use the CLI, see the <xref linkend="install_overview"/>.</para>
</listitem>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-9"><para>Review the <citetitle>FIXME: broken external xref</citetitle> that we have listed.</para>
</listitem>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-10"><para>Review the <citetitle>FIXME: broken external xref</citetitle>
          to make yourself aware of any known issues and limitations.</para>
</listitem>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-11"><para>The installation process can occur in different phases. For example,
          you can install the control plane only and then add Compute nodes afterwards if you would
          like.</para>
</listitem>
        <!-- consider including steps to achieve this -->
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-12"><para>If you run into issues during installation, we have put together a
          list of <xref linkend="troubleshooting_installation"/> you can reference.</para>
</listitem>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-13"><para>Make sure all disks on the system(s) are wiped before you begin the
          install. (For Swift, refer to <citetitle>FIXME: broken external xref</citetitle>)</para>
</listitem>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-14"><para>There is no requirement to have a dedicated network for OS-install
          and system deployment, this can be shared with the management network. More information
          can be found on the 
          page.</para>
</listitem>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-15"><para>You may see the terms deployer and lifecycle manager used
          interchangeably. These are referring to the same nodes in your environment.</para>
</listitem>
        <listitem xml:id="idg-installation-installation-installing_kvm-xml-16"><para>When running the Ansible playbook in this installation guide, if a
          runbook fails you will see in the error response to use the <literal>--limit</literal>
          switch when retrying a playbook. This should be avoided. You can simply re-run any
          playbook without this switch.</para>
</listitem>
        <listitem><para>DVR is not supported with ESX compute.</para>
</listitem>
        <listitem><para>When you attach a Cinder volume to the VM running on the ESXi host, the volume will not
          get detected automatically.
          
          Make sure to set the image metadata <emphasis role="bold">vmware_adaptertype=lsiLogicsas</emphasis> for image before
          launching the instance. This will help to discover the volume change appropriately. </para>
</listitem>
      </itemizedlist>
    <bridgehead  renderas="sect4">Before You Start</bridgehead><para>We have put together a <xref linkend="preinstall_checklist"/> that should help with the recommended pre-installation tasks.</para>

    <bridgehead  renderas="sect4">Set up the Lifecycle Manager</bridgehead><para><emphasis role="bold">Installing the Lifecycle Manager</emphasis></para>
<para>The lifecycle manager will contain the installation scripts and configuration files to
        deploy your cloud. You can set up the lifecycle manager on a dedicated node or you do so on
        your first controller node. The default choice is to use the first controller node as the
        lifecycle manager.</para>
<orderedlist>
        <listitem><para>Sign in and download the product and signature files at the link below: </para>
<orderedlist>
            <listitem><para><link xlink:href="http://www.hpe.com/software/entitlements">Software Entitlement Portal</link></para>
</listitem>
          </orderedlist></listitem>
        <listitem><para>You can verify the download was complete via the signature verification process outlined
            <link xlink:href="https://h20392.www2.hpe.com/portal/swdepot/displayProductInfo.do?productNumber=HPLinuxCodeSigning">here</link>.</para>
</listitem>
        <listitem><para>Boot your lifecycle manager from the ISO contained in the download.</para>
</listitem>
        <listitem><para>Enter "install" to start installation. </para>
<note><para>"install" is all lower case</para>
</note></listitem>
        <listitem><para>Select the language. Note that only the English language selection is currently
          supported.</para>
</listitem>
        <listitem><para>Select the location.</para>
</listitem>
        <listitem><para>Select the keyboard layout.</para>
</listitem>
        <listitem><para>Select the primary network interface, if prompted:</para>
<orderedlist>
            <listitem><para>Assign IP address, subnet mask, and default gateway</para>
</listitem>
          </orderedlist></listitem>
        <listitem><para>Create new account:</para>
<orderedlist>
            <listitem><para>Enter a username.</para>
</listitem>
            <listitem><para>Enter a password.</para>
</listitem>
            <listitem><para>Enter time zone.</para>
</listitem>
          </orderedlist></listitem>
      </orderedlist><para>Once the initial installation is finished, complete the lifecycle manager setup with these
        steps:</para>
<orderedlist>
        <listitem><para>Ensure your lifecycle manager has a valid DNS nameserver specified in
            <literal>/etc/resolv.conf</literal>.</para>
</listitem>
        <listitem><para>Set the environment variable LC_ALL: </para>
<screen>export LC_ALL=C</screen><note><para>This
            can be added to <literal>~stack/.bashrc</literal> or
            <literal>/etc/bash.bashrc</literal>.</para>
</note></listitem>
      </orderedlist><para>At the end of this section you should have a node set up with Linux for HPE Helion on
        it.</para>
<para><emphasis role="bold">Configure and Run the Lifecycle Manager</emphasis></para>
<important><para>It is critical that you don't run any of the commands below as the
          <literal>root</literal> user or use <literal>sudo</literal>, unless it is stated explicitly in
        the steps. Run then as the user you just created (or <literal>stack</literal> if you left the
        default of "stack").</para>
</important><orderedlist>
        <listitem><para>Log into your lifecycle manager as the user you created and mount the install media at
            <literal>/media/cdrom</literal>. It may be necessary to use <literal>wget</literal> or
          another file transfer method to transfer the install media to the lifecycle manager before
          completing this step. Here is the command to mount the media: </para>
<para>Example for &kw-hos-tm;
            &kw-hos-version;</para>
<screen>sudo mount HelionOpenStack-5.0.iso /media/cdrom</screen></listitem>


        <listitem><para>Unpack the tarball that is in the <literal>/media/cdrom/hos/</literal> directory:
            </para>
<para>Example for &kw-hos-phrase;
          </para>
<screen>tar xvf /media/cdrom/hos/hos-5.0.0-&lt;timestamp&gt;.tar</screen></listitem>
        <listitem><para>Run the hos-init.bash script which is included in the build: </para>
<para>Example for &kw-hos-tm;
            &kw-hos-version;</para>
<screen>~/hos-5.0.0/hos-init.bash</screen><para>You will be prompted to enter
            an optional SSH passphrase when running <literal>hos-init.bash</literal>. This passphrase
            is used to protect the key used by Ansible when connecting to its client nodes. If you
            do not want to use a passphrase then just press return at the prompt.</para>
<para>For
            automated installation (e.g. CI) it is possible to disable SSH passphrase prompting by
            setting the <literal>HOS_INIT_AUTO</literal> environment variable before running
              <literal>hos-init.bash</literal>, like
          this:</para>
<screen>export HOS_INIT_AUTO=y</screen></listitem>
      </orderedlist><para>If you have protected the SSH key with a passphrase then execute the following commands to
        avoid having to enter the passphrase on every attempt by Ansible to connect to its client
        nodes:</para>
<screen >eval $(ssh-agent)
ssh-add ~/.ssh/id_rsa</screen><para>At the end of this section you should have a local directory structure, as described
        below:</para>
<screen >~/helion/                        Top level directory
~/helion/examples/               Directory contains the config input files of the example clouds
~/helion/my_cloud/definition/    Directory contains the config input files
~/helion/my_cloud/config/        Directory contains .j2 files which are symlinks to the ~/helion/hos/ansible directory
~/helion/hos/                    Directory contains files used by the installer</screen><note /><para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>



    <bridgehead  renderas="sect4">Configure Your Environment</bridgehead><para>During the configuration phase of the installation you will be making modifications to the
        example configuration input files to match your cloud environment. You should use the  documentation for detailed
        information on how to do this. There is also a README.md file included in each of the
        example directories on the lifecycle manager that has useful information about the
        models.</para>
<para>In the steps below we show how to set up the directory structure with the example input
        files as well as use the optional encryption methods for your sensitive data.</para>
<orderedlist>
        <listitem><para>Setup your configuration files, as follows: </para>
<orderedlist>
            <listitem><para>Copy the example configuration files into the required setup directory and edit them
              to contain the details of your environment. </para>
<para>For example, if you want to use the
                Helion Mid-scale KVM with VSA model, you can use this command to copy the files to
                your cloud definition
                directory:</para>
<screen>cp -r ~/helion/examples/mid-scale-kvm-vsa/* ~/helion/my_cloud/definition/</screen><para>If
                you want to use the Helion Entry-scale KVM with VSA model, you can use this command
                to copy the files to your cloud definition
              directory:</para>
<screen>cp -r ~/helion/examples/entry-scale-kvm-vsa/* ~/helion/my_cloud/definition/</screen></listitem>
            <listitem><para>Begin inputting your environment information into the configuration files in the
                <literal>~/helion/my_cloud/definition</literal> directory. </para>
<para>If you are using the
                Mid-scale or Entry-scale KVM with VSA model, see  for details.</para>
<para>If you are using the Entry-scale
                KVM with Ceph model, see <xref linkend="ceph_overview"/>
                for details.</para>
</listitem>
          </orderedlist></listitem>


        <listitem xml:id="hosencrypt"><para>[OPTIONAL] - You can use the <literal>hosencrypt.py</literal> script to
          encrypt your iLo passwords. This script uses OpenSSL. </para>
<orderedlist>
            <listitem><para>Change to the Ansible directory: </para>
<screen>cd ~/helion/hos/ansible</screen></listitem>
            <listitem><para>Put the encryption key into the following environment variable:
              </para>
<screen>export HOS_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</screen></listitem>
            <listitem><para>Run the python script below and follow the instructions. Enter a password that you
              want to encrypt. </para>
<screen>./hosencrypt.py</screen></listitem>
            <listitem><para>Take the string generated and place it in the <literal>"ilo-password"</literal> field
              in your <literal>~/helion/my_cloud/definition/data/servers.yml</literal> file,
              remembering to enclose it in quotes.</para>
</listitem>
            <listitem><para>Repeat the above for each server. </para>
<note><para>Before you run any playbooks, remember that
                you need to export the encryption key in the following environment variable:
                  <literal>export HOS_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption
              key&gt;</literal></para>
</note></listitem>
          </orderedlist></listitem>

        <listitem xml:id="commit"><para>Commit your configuration to the <xref linkend="using_git"/>, as follows:</para>
<screen>cd ~/helion/hos/ansible
git add -A
git commit -m "My config or other commit message"</screen><important><para>This step needs to be repeated any time you make changes to your
              configuration files before you move onto the following steps. See <xref linkend="using_git"/> for more
              information.</para>
</important>
</listitem>
      </orderedlist>


    <bridgehead  renderas="sect4">Provision Your Baremetal Nodes</bridgehead><para>To provision the baremetal nodes in your cloud deployment you can either use the automated
        operating system installation process provided by &kw-hos; or you can use
        the 3rd party installation tooling of your choice. We will outline both methods below:</para>
<para><emphasis role="bold">Using 3rd Party Baremetal Installers</emphasis></para>
<para>If you do not wish to use the automated operating system installation tooling included with
          &kw-hos-version; then the requirements that have to be met using the
        installation tooling of your choice are:</para>
<itemizedlist>
        <listitem><para>The operating system must be installed via the HPE Linux for &kw-hos;
          ISO provided on the <link xlink:href="http://www.hpe.com/software/entitlements">Software Entitlement Portal</link>.</para>
</listitem>
        <listitem><para>Each node must have SSH keys in place that allows the same user from the lifecycle
          manager node who will be doing the deployment to SSH to each node without a password.</para>
</listitem>
        <listitem><para>Passwordless sudo needs to be enabled for the user.</para>
</listitem>
        <listitem><para>There should be a LVM logical volume as <literal>/root</literal> on each node.</para>
</listitem>
        <listitem><para>If the LVM volume group name for the volume group holding the "root" LVM logical volume
          is hlm-vg then it will align with the disk input models in the examples.</para>
</listitem>
        <listitem><para><phrase>Ensure that <literal>openssh-server</literal>,
              <literal>python</literal>, <literal>python-apt</literal>, and <literal>rsync</literal> are
            installed.</phrase></para>
</listitem>
      </itemizedlist><para>If you chose this method for installing your baremetal hardware, skip forward to the <xref linkend="install_kvm"/> step.</para>
<para>If you would like to use the automated operating system installation tools provided by
          &kw-hos-version; then complete all of the steps below.</para>
<para><emphasis role="bold">Using the Automated Operating System Installation Provided by &kw-hos;</emphasis></para>
<para><emphasis role="bold">Part One: Deploy Cobbler</emphasis></para>
<para>This phase of the install process takes the baremetal information that was provided in
          <literal>servers.yml</literal> and installs the Cobbler provisioning tool and loads this
        information into Cobbler. This sets each node to <literal>netboot-enabled: true</literal> in
        Cobbler. Each node will be automatically marked as <literal>netboot-enabled: false</literal>
        when it completes its operating system install successfully. Even if the node tries to PXE
        boot subsequently, Cobbler will not serve it. This is deliberate so that you can't reimage a
        live node by accident.</para>
<para>The <literal>cobbler-deploy.yml</literal> playbook prompts for a password - this is the
        password that will be encrypted and stored in Cobbler, which is associated with the user
        running the command on the lifecycle manager, that you will use to log in to the nodes via
        their consoles after install. The username is the same as the user set up in the initial
        dialogue when installing the lifecycle manager from the iso, and is the same user that is
        running the cobbler-deploy play.</para>
<orderedlist>
        <listitem><para>Run the following playbook which confirms that there is iLo connectivity for each of
          your nodes so that they are accessible to be re-imaged in a later step:
          </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-power-status.yml</screen></listitem>
        <listitem><para>Run the following playbook to deploy Cobbler:
          </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</screen></listitem>
      </orderedlist><para><emphasis role="bold">Part Two: Image the Nodes</emphasis></para>
<para>This phase of the install process goes through a number of distinct steps: </para>
<orderedlist>
          <listitem><para>Powers down the nodes to be installed</para>
</listitem>
          <listitem><para>Sets the nodes hardware boot order so that the first option is a network boot.</para>
</listitem>
          <listitem><para>Powers on the nodes. (The nodes will then boot from the network and be installed using
            infrastructure set up in the previous phase)</para>
</listitem>
          <listitem><para>Waits for the nodes to power themselves down (this indicates a success install). This
            can take some time.</para>
</listitem>
          <listitem><para>Sets the boot order to hard disk and powers on the nodes.</para>
</listitem>
          <listitem><para>Waits for the nodes to be ssh-able and verifies that they have the signature
            expected.</para>
</listitem>
        </orderedlist>
<para>The reimage command is:</para>
<screen >cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml [-e nodelist=node1,node2,node3]</screen><para>If a nodelist is not specified then the set of nodes in cobbler with
          <literal>netboot-enabled: True</literal> is selected. The playbook pauses at the start to
        give you a chance to review the set of nodes that it is targeting and to confirm that it's
        correct.</para>
<para>You can use the command below which will list all of your nodes with the
          <literal>netboot-enabled: True</literal> flag set:</para>
<screen >sudo cobbler system find --netboot-enabled=1</screen><para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>


    <bridgehead  renderas="sect4">Run the Configuration Processor</bridgehead><para>Once you have your configuration files setup you need to run the configuration processor to
        complete your configuration.</para>
<para>When you run the configuration processor you will be prompted for two
        passwords. Enter the first password to make the configuration processor encrypt its
        sensitive data, which is comprised of the random inter-service passwords that it generates
        and the ansible <literal>group_vars</literal> and <literal>host_vars</literal> that it produces
        for subsequent deploy runs. You will need this password for subsequent ansible deploy and
        configuration processor runs. If you wish to change an encryption password that you have
        already used when running the configuration processor then enter the new password at the
        second prompt, otherwise just press carriage return to bypass this.</para>
<para>Run the configuration processor with this command:</para>
<screen >cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</screen><para>For automated installation (e.g. CI) you can specify the required passwords on the ansible
        command line. For example, the command below will disable encryption by the configuration
        processor
        </para>
<screen >ansible-playbook -i hosts/localhost config-processor-run.yml -e encrypt="" -e rekey=""</screen>
<para>If you receive an error during this step then there is probably an issue with one or more
        of your configuration files. We recommend that you verify that all of the information in
        each of your configuration files is correct for your environment and then commit those
        changes to git using the instructions in the previous section before re-running the
        configuration processor again.</para>
<para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>


    <bridgehead  renderas="sect4">Configuring TLS</bridgehead><important><para>This section is optional, but recommended, for a &kw-hos; installation.</para>
</important><para>After you run the configuration processor the first time, the IP addresses for your
        environment will be generated and populated in the
          <literal>~/helion/my_cloud/info/address_info.yml</literal> file. It's at this point that you
        will want to take into consideration whether or not you want to configure TLS and setup a
        SSL certificate for your environment. Please read <xref linkend="tls30"/> before proceeding for how to
        achieve this.</para>


    <bridgehead  renderas="sect4">Deploy the Cloud</bridgehead><orderedlist>
        <listitem><para>Use the playbook below to create a deployment directory:
          </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</screen></listitem>
        <listitem><para>[OPTIONAL] - Run the <literal>wipe_disks.yml</literal> playbook to ensure all of your
          partitions on your nodes are completely wiped before continuing with the installation. If
          you are using fresh machines this step may not be necessary.
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts wipe_disks.yml</screen><para>If
            you have used an encryption password when running the configuration processor use the
            command below and enter the encryption password when prompted:
            </para>
<screen>ansible-playbook -i hosts/verb_hosts wipe_disks.yml --ask-vault-pass</screen>
</listitem>
        <listitem><para>Run the <literal>site.yml</literal> playbook below:
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts site.yml</screen><para>If
            you have used an encryption password when running the configuration processor use the
            command below and enter the encryption password when prompted:
            </para>
<screen>ansible-playbook -i hosts/verb_hosts site.yml --ask-vault-pass </screen>
<note><para>The
            step above runs <literal>osconfig</literal> to configure the cloud and
              <literal>hlm-deploy</literal> to deploy the cloud. Therefore, this step may run for a
            while, perhaps 45 minutes or more, depending on the number of nodes in your
            environment.</para>
</note></listitem>
        <listitem><para>Verify that the network is working correctly. Ping each IP in the
            <literal>/etc/hosts</literal> file from one of the controller nodes.</para>
</listitem>
      </orderedlist><para>For any troubleshooting information regarding these steps, see <xref linkend="troubleshooting_installation"/></para>


    <bridgehead  renderas="sect4">Configure a Block Storage Backend (Optional)</bridgehead><para>&kw-hos; supports VSA, 3PAR, and Ceph as block storage backend options.
        You can utilize one or more of these as setting up multiple block storage backends and
        multiple volume types is supported.</para>
<para>Regardless of whether you have a single or multiple block storage backends defined in your
          <literal>cinder.conf.j2</literal> file then you can create one or more volume types using
        the specific attributes associated with the backend. You can find details on how to do that
        for each of the supported backend types here:</para>
<itemizedlist>
        <listitem/>
        <listitem/>
        <listitem/>
      </itemizedlist>

    <bridgehead  renderas="sect4">Post-Installation Verification and Administration</bridgehead><para>We recommend verifying the installation using the <xref linkend="cloud_verification"/> page.</para>
<para>There are also a list of other common post-installation administrative tasks listed in the
          <xref linkend="postinstall_checklist"/> list.</para>

  </section>
