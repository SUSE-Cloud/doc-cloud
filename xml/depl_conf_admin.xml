<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet
href="urn:x-daps:xslt:profiling:novdoc-profile.xsl"
type="text/xml"
title="Profiling step"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
<!ENTITY % NOVDOC.DEACTIVATE.IDREF "IGNORE">
<!ENTITY % entities SYSTEM "entity-decl.ent">
%entities;
]>
<chapter id="cha.depl.adm_conf">
  <title>Configuring the &admserv;</title>
  <abstract>
   <para>
    After the installation of the operating system and the add-on products on
    the &admserv; has finished, you need to set up product and update
    repositories and, optionally, configure a custom network setup. After the
    &admserv; host is fully configured, start the cloud installation script.
   </para>
  </abstract>

  <sect1 id="sec.depl.adm_conf.repos">
   <title>Setting up the Repositories</title>
   <para>
    Nodes in &cloud; are automatically installed from the &admserv;. To do so,
    software repositories containing products, extensions and the respective
    updates for all software need to be available on or accessible from the
    &admserv;. Two types of repositories can be distinguished:
   </para>
   <variablelist>
    <varlistentry>
     <term>Product Media Repositories</term>
     <listitem>
      <para>
       Product media repositories are copies of the installation media. They
       need to be directly copied to the &admserv;,
       <quote>loop-mounted</quote> from an iso image or mounted from a remote
       server via NFS. Affected are &slsa; 11 SP3 (DVD #1), &productname;
       &productnumber; (DVD #1), and, optionally, &slsa; 12 (DVD #1). The
       first two are mandatory, the latter is only needed when wanting to set
       up &compnode;s running &slsa; 12 or &ceph; &stornode;s. The content of
       these repositories is static.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Update and Pool Repositories</term>
     <listitem>
      <para>
       Update and Pool repositories are provided by the &scc;. They provide
       all updates and patches for the products and extensions. To make them
       available for &cloud; they need to be mirrored from the &scc;. Since
       their content is regularly updated, they need to be kept in
       synchronization with &scc;. For these purposes, &suse; provides either
       the &smtool; (&smt;) or the &susemgr;.
      </para>
      <para>
       The repositories can be made available on the &admserv; using one of
       the following methods (or a mix of them): 
      </para>
      <itemizedlist>
       <listitem>
	<para>
	 <xref linkend="sec.depl.adm_conf.repos.scc.local_smt"/>
	</para>
       </listitem>
       <listitem>
	<para>
	 <xref linkend="sec.depl.adm_conf.repos.scc.remote_smt"/>
	</para>
       </listitem>
       <listitem>
	<para>
	 <xref linkend="sec.depl.adm_conf.repos.scc.remote_susemgr"/>
	</para>
       </listitem>
       <listitem>
	<para>
	 <xref linkend="sec.depl.adm_conf.repos.scc.remote"/>
	</para>
       </listitem>
       <listitem>
	<para>
	 <xref linkend="sec.depl.adm_conf.repos.scc.sneaker"/>
	</para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
   </variablelist>

   <sect2 id="sec.depl.adm_conf.repos.product">
    <title>Copying the Product Media Repositories</title>
    <para>
     The files in the product repositories for &sls; and &cloud; do not
     change, therefore they do not need to be synchronized with a remote
     source.  It is sufficient to either copy the data (from a remote host or
     the installation media) or mount the product repository from a remote
     server via <literal>NFS</literal>. Alternatively you may copy the iso
     images of DVD #1 from the products to the &admserv; and <quote>loop
     mount</quote> them. Refer to <xref
     linkend="sec.depl.adm_conf.repos.product"/> for instructions.
    </para>

    <important>
     <title>No Symbolic Links for the &sls; Repository</title>
     <para>
      Note that the &sls; product repository <emphasis>must</emphasis> be
      directly available from the local directory listed below. It is not
      possible to use a symbolic link to a directory located elsewhere, since
      this will cause booting using PXE to fail.
     </para>
    </important>
    
    <tip>
     <title>Providing the &productname; Repository via HTTP</title>
     <para>
      While the &sls; product repositories needs to be made available locally
      to enable PXE boot for node deployment, the &productname; repository may
      also be served via <literal>http</literal> from a remote host. In this
      case, enter the URL to the <literal>Cloud</literal> repository as
      described in <xref linkend="sec.depl.adm_inst.crowbar.repos"/>.
     </para>
     <para>
      However, copying the data to the &admserv;
      as described here, is recommended. It does not require
      much hard disk space ((approximately &mediaspace;) nor does it require
      the &admserv; to be able to access a remote host from a different
      network.
     </para>
    </tip>
    <para>
     The following product media needs to be copied to the specified
     directories:
    </para>
    <table>
     <title>Local Product Repositories for &cloud;</title>
     <tgroup cols="2">
      <colspec colnum="1" colname="1" colwidth="40*"/>
      <colspec colnum="2" colname="2" colwidth="60*"/>
      <thead>
       <row>
        <entry>
         <para>
          Repository
         </para>
        </entry>
        <entry>
         <para>
          Directory
         </para>
        </entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>
         <para>
          &slsa; 11 SP3 DVD #1
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/install/</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          &productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/repos/Cloud/</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          &slsa; 12 DVD #1 (optional)
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/install/</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          &productname; &productnumber; DVD #4 (optional, Cloud for &slsa; 12)
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/repos/Cloud/</filename>
         </para>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </table>
    <para>
     The data can be copied by a variety of methods:
    </para>
    <sect3 id="sec.depl.adm_conf.repos.product.media">
     <title>Copying from the Installation Media</title>
     <para>
      If copying, it is recommended to use <command>rsync</command>. If the
      installation data is located on a removable device, make sure to mount
      it first (for example, after inserting the DVD1 in the &admserv; and
      waiting for the device to become ready):
     </para>
     <variablelist>
      <varlistentry>
       <term>&slsa; 11 SP3 DVD #1</term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-11.3/install/
umount /mnt</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-11.3/repos/Cloud/
umount /mnt</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>&slsa; 12 DVD #1</term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-12.0/install/
umount /mnt</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
umount /mnt</screen>
       </listitem>
      </varlistentry>
     </variablelist>
    </sect3>
    <sect3 id="sec.depl.adm_conf.repos.product.remote">
     <title>Copying from a Remote Host</title>
     <para>
      If the data is provided by a remote machine, log in to that machine and
      push the data to the &admserv; (which has the IP address <systemitem
      class="etheraddress">192.168.124.10</systemitem> in the following
      example):
     </para>
     <variablelist>
      <varlistentry>
       <term>&slsa; 11 SP3 DVD #1</term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
rsync -avPz <replaceable>/data/SLES-11-SP3/DVD1/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-11.3/install/</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
rsync -avPz <replaceable>/data/SUSE-CLOUD//DVD1/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-11.3/repos/Cloud/</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>&slsa; 12 DVD #1</term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
rsync -avPz <replaceable>/data/SLES-12//DVD1/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-12.0/install/</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
rsync -avPz <replaceable>/data/SUSE-CLOUD//DVD4/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute</screen>
       </listitem>
      </varlistentry>
     </variablelist>
    </sect3>
    <sect3 id="sec.depl.adm_conf.repos.product.nfs">
     <title>Mounting from an NFS Server</title>
     <para>
      If the installation data is provided via NFS by a remote machine, mount
      the respective shares as follows. To automatically mount these
      directories either create entries in <filename>/etc/fstab</filename> or
      set up the automounter.
     </para>
     <variablelist>
      <varlistentry>
       <term>&slsa; 11 SP3 DVD #1</term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SLES-11-SP3/x86_64/DVD1/</replaceable> /srv/tftpboot/suse-11.3/install</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SUSE-CLOUD/DVD1/</replaceable> /srv/tftpboot/suse-11.3/repos/Cloud</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>&slsa; 12 DVD #1</term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SLES-12/x86_64/DVD1/</replaceable> /srv/tftpboot/suse-12.0/install</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SUSE-CLOUD/DVD4/</replaceable> /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute
umount /mnt</screen>
       </listitem>
      </varlistentry>
     </variablelist>
    </sect3>
    <sect3 id="sec.depl.adm_conf.repos.product.loop">
     <title>Mounting ISO Images</title>
     <para>
      he product repositories can also be made available by copying the
      respective iso images to the &admserv; and mounting them. To
      automatically mount these directories either create entries in
      <filename>/etc/fstab</filename> or set up the automounter.
     </para>
     <variablelist>
      <varlistentry>
       <term>&slsa; 11 SP3 DVD #1</term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
mount -o loop <replaceable>/local/SLES-11-SP3-x86_64-DVD1.iso</replaceable> /srv/tftpboot/suse-11.3/install/</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
       <listitem>
	<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
mount -o loop <replaceable>/local/SUSE-CLOUD-&productnumber;-DVD1.iso</replaceable> /srv/tftpboot/suse-11.3/repos/Cloud</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>&slsa; 12 DVD #1</term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
mount -o loop <replaceable>/local/SLES-12-x86_64-DVD1.iso</replaceable> /srv/tftpboot/suse-12.0/install</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
       <listitem>
	<para>
	 Note that this repository only needs to be copied in case you want
	 to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
	</para>
	<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SUSE-CLOUD/DVD4/</replaceable> /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute</screen>
       </listitem>
      </varlistentry>
     </variablelist>
    </sect3>
   </sect2>
   <sect2 id="sec.depl.adm_conf.repos.scc">
    <title>Update and Pool Repositories</title>
    <para>
     Update repositories are already used when deploying the nodes that will
     build &cloud; to ensure they are initially equipped with the
     latest software versions available. If you have installed an &smt; server
     on the &admserv;, no further action is required, all repositories will
     automatically be detected. If you are using a remote &smt; or SUSE
     Manager server, the update repositories from the remote server are used
     directly. In this case the repository URLs need to be added via the
     &yast; Crowbar module as explained in <xref
     linkend="sec.depl.adm_inst.crowbar.repos"/>. If using repositories
     locally available, the &admserv; itself acts as the repository provider
     for all nodes. This requires to make them available in
     <filename>/srv/tftpboot/suse-11.3/repos</filename>.
    </para>
    <sect3 id="sec.depl.adm_conf.repos.scc.local_smt">
     <title>Repositories Hosted on an &smt; Server Installed on the &admserv;</title>
     <para>
      When all update and pool repositories are managed by an &smt; server
      installed on the &admserv; (see <xref linkend="app.deploy.smt"/>) no
      further action is required. The &cloud; installation script
      automatically detects all required repositories and creates links to
      them in <filename>/srv/tftpboot/suse-11.3/repos</filename> and
      <filename>/srv/tftpboot/suse-12.0/repos</filename>.
     </para>
    </sect3>
    <sect3 id="sec.depl.adm_conf.repos.scc.remote_smt">
     <title>Repositories Hosted on a Remote &smt; Server</title>
     <para> 
      To use repositories from a remote &smt; server you first need
      to make sure all required repositories are mirrored on the server. Refer
      to <xref linkend="app.deploy.smt.repos"/> for more information. Now you
      need to enter the repository URLs on the <guimenu>Repositories</guimenu>
      tab in the &yast; &crow; module as described in <xref
      linkend="sec.depl.adm_inst.crowbar.repos"/>. A complete set of
      repository URLs is listed at <xref linkend="tab.smt.repos"/>. Note that
      you need to replace <replaceable>smt.&exampledomain;</replaceable> with
      the fully qualified host name of your &smt; server.
     </para>
     <note>
      <title>Accessing an External &smt; Server</title>
      <para>
       In &cloud;, only the &admserv; needs to be able to access the external
       &smt; server. A network connection can either be established via a
       bastion network (see <xref
       linkend="sec.depl.adm_inst.crowbar.mode.bastion"/> or an external
       gateway.
      </para>
     </note>
    </sect3>
    <sect3 id="sec.depl.adm_conf.repos.scc.remote_susemgr">
     <title>Repositories Hosted on a &susemgr; Server</title>
     <para>
      To use repositories from &susemgr; you first need to make sure
      all required products and extensions are registered and the
      corresponding channels are mirrored in &susemgr; (refer to <xref
      linkend="tab.depl.adm_conf.susemgr-repos"/> for a list of channels).
     </para>
     <important>
      <title>Accessing a &susemgr; Server</title>
      <para>
       An external &susemgr; server needs to be accessed from
       <emphasis>all</emphasis> nodes in &cloud;. To be able to access it, the
       network hosting the &susemgr; server needs to be added to the network
       definitions as described in <xref
       linkend="sec.depl.inst.admserv.post.network.external"/>.
      </para>
     </important>
     <para>
      By default &susemgr; does not expose repositories for direct access. To
      be able to access them via <literal>https</literal>, you need to create
      a <guimenu>Distribution</guimenu> for auto-installation for the &sls; 11
      SP3 (x86_64) product on &susemgr;. If you plan to also deploy &slsa; 12
      &compnode;s or &ceph; &stornode;s, you also need to do this for the
      &sls; 12 (x86_64) Product.  Instructions can be found at
      <ulink
	url="https://www.suse.com/documentation/suse_manager/book_susemanager_ref/data/book_susemanager_ref.html"/>
      under the heading <guimenu>Creating Distribution for
      Autoinstallation</guimenu>.
     </para>
     <para>
      During the distribution setup you need to provide a
      <guimenu>Label</guimenu> for the distribution. This label will be part
      of the URL under which the repositories are available. It is recommended
      to choose a name consisting of characters that do not need to be
      URL-encoded, for example <literal>sles11-sp3-x86_64</literal> and
      <literal>sles12-x86_64</literal>.
     </para>
     <para>
      Creating a distribution for &slsa; not only makes the update
      repositories for this product available, but also for all registered
      add-on products, including &productname; &productnumber; and other
      extensions.
     </para>
     <para>
      To make the repositories available for node deployment, you need to
      enter the repository URLs on the <guimenu>Repositories</guimenu> tab in
      the &yast; &crow; module as described in <xref
      linkend="sec.depl.adm_inst.crowbar.repos"/>.
     </para>
     <para>
      The repositories are available under the URLs listed below.
      <literal>manager.&exampledomain;</literal> needs to be replaced by the
      fully qualified host name of your &susemgr; server.
      <literal>sles11-sp3-x86_64</literal> and
      <literal>sles12-x86_64</literal> need to be replaced by the distribution
      labels you specified when setting up the distribution for
      auto-installation. Note that the URLs are not browseable.
     </para>
   <table id="tab.depl.adm_conf.susemgr-repos">
    <title>&susemgr; Channels and URLs</title>
    <tgroup cols="2">
     <colspec colnum="1" colname="1" colwidth="25*"/>
     <colspec colnum="2" colname="2" colwidth="75*"/>
     <thead>
      <row>
       <entry>
	<para>
	 Channel
	</para>
       </entry>
       <entry>
	<para>
	 URL
	</para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry namest="1" nameend="2">
	<para>Mandatory Repositories</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLES11-SP3-Updates
	</para>
       </entry>
       <entry>
	<para>
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/sles11-sp3-updates-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Cloud-5-Pool
	</para>
       </entry>
       <entry>
	<para>
	 http://manager.&exampledomain;/ks/dist/child/suse-cloud-5-pool-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Cloud-5-Updates
	</para>
       </entry>
       <entry>
	<para>
	 http://manager.&exampledomain;/ks/dist/child/suse-cloud-5-updates-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
	</para>
       </entry>
      </row>
      <row>
       <entry namest="1" nameend="2">
	<para>Optional Repositories</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLES12-Updates
	</para>
       </entry>
       <entry>
	<para>
	 http://<replaceable>manager.&exampledomain;</replaceable>ks/dist/child/sles12-updates-x86_64/<replaceable>sles12-x86_64</replaceable>/
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE-12-Cloud-Compute5-Pool
	</para>
       </entry>
       <entry>
	<para>
	 to be announced
<!--
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE-12-Cloud-Compute5-Updates
	</para>
       </entry>
       <entry>
	<para>
	 to be announced
<!--
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE11-HAE-SP3-Pool
	</para>
       </entry>
       <entry>
	<para>
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/sle11-hae-sp3-pool-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE11-HAE-SP3-Updates
	</para>
       </entry>
       <entry>
	<para>
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/sle11-hae-sp3-updates-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Enterprise-Storage-1.0-Pool
	</para>
       </entry>
       <entry>
	<para>
	 to be announced
<!--
	  http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Enterprise-Storage-1.0-Updates
	</para>
       </entry>
       <entry>
	<para>
	 to be announced
<!--
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
	</para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <para>
    The autoinstallation tree provided by &susemgr; does not provide the
    &slsa; Pool repositories. Although these repositories are not used for
    node installation, &ay;, which is used for the automatic installation,
    requires them to be present. To work around this issue, it is sufficient
    to create an empty Pool repository for &slsa; 11 SP3:
   </para>
   <screen>mkdir /srv/tftpboot/suse-11.3/repos/SLES11-SP3-Pool/
createrepo /srv/tftpboot/suse-11.3/repos/SLES11-SP3-Pool/</screen>
   <para>
    In case you plan deploy optional &slsa; 12 nodes, you also need to create
    the respective &slsa; 12 repository: 
   </para>
   <screen>mkdir /srv/tftpboot/suse-12.0/repos/SLES12-Pool/
createrepo /srv/tftpboot/suse-12.0/repos/SLES12-Pool/</screen>
    </sect3>
    <sect3 id="sec.depl.adm_conf.repos.scc.remote">
     <title>Repositories Hosted on a Remote Host</title>
     <para>
      If the update repositories are hosted on a remote host that can be
      accessed from the &admserv; you can either mount them, for example via
      <literal>NFS</literal>, or regularly <command>rsync</command> them.
     </para>
     <para>
      To <literal>NFS</literal>-mount the repositories from a remote host,
      either use the &yast; <guimenu>NFS Client</guimenu> module or edit
      <filename>/etc/fstab</filename>. See <xref
      linkend="tab.depl.adm_conf.local-repos"/> for a table of repositories
      and their local mount points.
     </para>
     <para>
      To <command>rsync</command> the repositories from a remote host, create
      a daily cron job for mirroring. The following example pulls the
      mandatory repositories from a host named host.&exampledomain;. The
      optional repositories can be mirrored the same way. Refer to <xref
      linkend="tab.depl.adm_conf.local-repos"/> for a table of repositories
      and their local target directories.
     </para>
     <screen><?dbsuse-fo font-size="0.63em"?>for REPO in SLES11-SP3-{Pool,Updates} SUSE-Cloud-5-{Pool,Updates}; do
  rsync -avPz host.&exampledomain;:/srv/www/htdocs/repo/\\\$RCE/$REPO/sle-11-x86_64/ \
  /srv/tftpboot/suse-11.3/repos/${REPO}/
done</screen>
     <para>
      Alternatively you may set up the cron job on the remote host and
      <emphasis>push</emphasis> the files to the &admserv; (which has the IP
      address <systemitem class="etheraddress">192.168.124.10</systemitem>
      in the following example):
     </para>
     <screen><?dbsuse-fo font-size="0.63em"?>for REPO in SLES11-SP3-{Pool,Updates} SUSE-Cloud-5-{Pool,Updates}; do
  rsync -avPz /srv/www/htdocs/repo/\\\$RCE/$REPO/sle-11-x86_64/ \
  <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-11.3/repos/${REPO}/
done</screen>
     <note>
      <title>Mind the Trailing Slash</title>
      <para>
       The <command>rsync</command> command must be used with trailing slashes
       in the directory names as shown above. Otherwise rsync would copy the
       repositories into the wrong directory.
      </para>
     </note>
     <note>
      <title>Accessing a remote Host</title>
      <para>
       A remote machine hosting the update repositories needs to be accessed
       from the &admserv; only. A network connection can either be established
       via a bastion network (see <xref
       linkend="sec.depl.adm_inst.crowbar.mode.bastion"/> or an
       external gateway.
      </para>
     </note>
   <table id="tab.depl.adm_conf.local-repos">
    <title>Repository Locations on the &admserv;</title>
    <tgroup cols="2">
     <colspec colnum="1" colname="1" colwidth="25*"/>
     <colspec colnum="2" colname="2" colwidth="75*"/>
     <thead>
      <row>
       <entry>
	<para>
	 Channel
	</para>
       </entry>
       <entry>
	<para>
	 Directory on the &admserv;
	</para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry namest="1" nameend="2">
	<para>Mandatory Repositories</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLES11-SP3-Pool
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-11.3/repos/SLES11-SP3-Pool/</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLES11-SP3-Updates
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-11.3/repos/SLES11-SP3-Updates/</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Cloud-5-Pool
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-11.3/repos/SUSE-Cloud-5-Pool/</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Cloud-5-Updates
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-11.3/repos/SUSE-Cloud-5-Updates</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry namest="1" nameend="2">
	<para>Optional Repositories</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLES12-Pool
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-12.0/repos/SLES12-Pool</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLES12-Updates
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-12.0/repos/SLES12-Updates</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE-12-Cloud-Compute5-Pool
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-12.0/repos/SLE-12-Cloud-Compute5-Pool</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE-12-Cloud-Compute5-Updates
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-12.0/repos/SLE-12-Cloud-Compute5-Updates</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE11-HAE-SP3-Pool
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-11.3/repos/SLE11-HAE-SP3-Pool</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SLE11-HAE-SP3-Updates
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-11.3/repos/SLE11-HAE-SP3-Updates</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Enterprise-Storage-1.0-Pool
	</para>
       </entry>
       <entry>
	<para>
	  <filename>/srv/tftpboot/suse-12.0/repos/SUSE-Enterprise-Storage-1.0-Pool</filename>
	</para>
       </entry>
      </row>
      <row>
       <entry>
	<para>
	 SUSE-Enterprise-Storage-1.0-Updates
	</para>
       </entry>
       <entry>
	<para>
	 <filename>/srv/tftpboot/suse-12.0/repos/SUSE-Enterprise-Storage-1.0-Updates</filename>
	</para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>

    </sect3>
    <sect3 id="sec.depl.adm_conf.repos.scc.sneaker">
     <title>
      Repositories Hosted on Removable Media
      (<quote>Sneakernet</quote>)
     </title>
     <para>
      If your admin network is isolated from other networks, you need to
      manually synchronize the update repositories from removable media. To do
      so you can either use <command>rsync</command> (see above for an
      example) or <command>cp <option>-axu</option></command>. If copying from
      an &smt; server, see <xref linkend="tab.depl.adm_conf.local-repos"/> for
      a list of directories to copy to.
     </para>
    </sect3>
   </sect2>
  </sect1>

  <sect1 id="sec.depl.inst.admserv.post.adm_repos">
   <title>Default Software Repository Sources on the &admserv;</title>
   <para>
    Update repositories are not only required to deploy &cloud;. The
    &admserv; itself also needs to be kept up-to-date and therefore needs to
    have a proper repository setup. In case you have registered &sls; and
    &productname; during the installation process, the &admserv; already has
    all required update repositories.
   </para>
   <para>
    These repositories are served directly from &ncc;. To avoid downloading
    the same patches twice or in case you want to cut off the &admserv; from
    the Internet, it makes sense to change this setup in a way that the
    repositories set up for &cloud; deployment are also used on the
    &admserv;. To do so, you need to disable or delete all services.  In a
    second step all &sls; and &cloud; repositories need to be edited to point
    to the alternative sources. Editing the repository setup can either be
    done with Zypper or &yast;. Note that changing the repository setup on the
    &admserv; is optional.
   </para>
  </sect1>

  <sect1 id="sec.depl.inst.admserv.post.network">
   <title>Custom Network Configuration</title>
   <para>
    In case you need to adjust the pre-defined network setup of &cloud;
    beyond the scope of changing IP address assignments (as described in
    <xref linkend="sec.depl.adm_inst.crowbar"/>), you need to
    manually modify the network &barcl; template. Refer to
    <xref linkend="app.deploy.network_json"/> for details.
   </para>
   <sect2 id="sec.depl.inst.admserv.post.network.external">
    <title>Providing Access to External Networks</title>
    <para>
     By default, external networks cannot be reached from nodes in the
     &cloud;. To be able to access external services such as a
     &susemgr; server an &smt; server, or a SAN, you need to make the external
     network(s) known to &cloud;. This is achieved by adding a network
     definition for each external network to
     <filename>/etc/crowbar/network.json</filename>. Refer to <xref
     linkend="app.deploy.network_json"/> for setup instructions.
    </para>
    <example>
     <title>
      Example Network Definition for the External Network 192.168.150.0/16
     </title>
     <screen>            "external" : {
               "add_bridge" : false,
               "vlan" : <replaceable>XXX</replaceable>,
               "ranges" : {
                  "host" : {
                     "start" : "192.168.150.1",
                     "end" : "192.168.150.254"
                  }
               },
               "broadcast" : "192.168.150.255",
               "netmask" : "255.255.255.0",
               "conduit" : "intf1",
               "subnet" : "192.168.150.0",
               "use_vlan" : true
            }</screen>
    </example>
    <para>
     The value <replaceable>XXX</replaceable> for the VLAN needs to be
     replaced by a value not used within the &cloud; network and not used by
     &o_netw;. By default, the following VLANs are already used:
    </para>
    <table>
     <title>VLANs used by the &cloud; Default Network Setup</title>
     <tgroup cols="2">
      <colspec colnum="1" colname="1" colwidth="20*"/>
      <colspec colnum="2" colname="2" colwidth="80*"/>
      <thead>
       <row>
	<entry><para>VLAN ID</para></entry>
	<entry><para>Used by</para></entry>
       </row>
      </thead>
      <tbody>
       <row>
	<entry><para>100</para></entry>
	<entry><para>BMC VLAN (bmc_vlan)</para></entry>
       </row>
       <row>
	<entry><para>200</para></entry>
	<entry><para>Storage Network</para></entry>
       </row>
       <row>
	<entry><para>300</para></entry>
	<entry><para>Public Network (nova-floating, public)</para></entry>
       </row>
       <row>
	<entry><para>400</para></entry>
	<entry><para>Software-defined network (os_sdn)</para></entry>
       </row>
       <row>
	<entry><para>500</para></entry>
	<entry><para>Private Network (nova-fixed)</para></entry>
       </row>
       <row>
	<entry><para>501 - 2500</para></entry>
	<entry><para>&o_netw; (value of nova-fixed plus 2000)</para></entry>
       </row>
      </tbody>
     </tgroup>
    </table>
    
   </sect2>
  </sect1>

  <sect1 id="sec.depl.inst.admserv.post.cloud_installation">
   <title>Running the Cloud Installation Script</title>
   <para>
    Before running the cloud installation script to finish the configuration
    of the &admserv; make sure to double-check the following items.
   </para>
   <itemizedlist>
    <title>Final Check Points</title>
    <listitem>
     <para>
      Make sure the network configuration is correct. Run <menuchoice>
      <guimenu>&yast;</guimenu> <guimenu>&crow;</guimenu> </menuchoice> to
      review/change the configuration. See
      <xref
	linkend="sec.depl.adm_inst.crowbar"/> for further
      instructions.
     </para>

     <important>
      <title>An &haSetup; Requires Teaming Network Mode</title>
      <para>
       In case you are planning to make &cloud; highly available upon the
       initial setup or at a later point in time, make sure to set up the
       network in teaming mode. Such a setup requires at least two network
       cards for each node. 
      </para>
     </important>
     
    </listitem>
    <listitem>
     <para>
      Make sure <command>hostname <option>-f</option></command> returns a
      fully qualified host name. See
      <xref
	linkend="sec.depl.adm_inst.network"/> for further
      instructions.
     </para>
    </listitem>
    <listitem>
     <para>
      Make sure all update and product repositories are available.
      See <xref linkend="sec.depl.adm_conf.repos"/> for
      further instructions.
     </para>
    </listitem>
    <listitem>
     <para>
      Make sure the operating system and &productname; are up-to-date and
      have the latest patches installed. Run <command>zypper patch</command>
      to install them.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Now everything is in place to finally configure the &admserv;. This is
    done by running the script <filename>install-suse-cloud</filename>. This
    command will install and configure &chef;, and use it to complete the
    installation of &crow; and all required &barcl;s. It will take several
    minutes to complete. If you are <emphasis>not</emphasis> using &susemgr;
    to provide update repositories, run the following command:
   </para>
   <screen>screen install-suse-cloud</screen>
   <para>
    In case you are using &susemgr; (as described in <xref
    linkend="sec.depl.adm_conf.repos.scc.remote_susemgr"/>), you need to run
    the following command:
   </para>
   <screen>screen env REPOS_SKIP_CHECKS+=" SLES11-SP3-Pool SLES12-Pool" install-suse-cloud</screen>
   <important>
    <title>Use a Terminal Multiplexer to run the Cloud Installation Script</title>
    <para>
     Run the installation script <filename>install-suse-cloud</filename>
     inside of a terminal multiplexer like GNU Screen (provided by the
     <systemitem class="resource">screen</systemitem> package).
    </para>
    <para>
     During the run of this script the network will be reconfigured. This
     may result in interrupting the script when being run from a network
     connection (like SSH). Using <command>screen</command> will continue
     running the script in a session to which you can reconnect via
     <command>screen -r</command> if you lose the connection.
    </para>
   </important>
   <para>
    <command>install-suse-cloud</command> will produce a lot of output that
    gets written to a log file located at
    <filename>/var/log/crowbar/install.log</filename>. Check this log file
    in case something goes wrong. You can run
    <command>install-suse-cloud</command> multiple times as long as you have
    not started to deploy the &ostack; services. It is also possible to run
    <command>install-suse-cloud</command> in verbose mode with the
    <option>-v</option> switch. It will show the same output that goes to
    the log file on STDOUT, too.
   </para>
   <para>
    If the script has successfully finished, you will see a message telling
    you how to log in to the &crow; Web interface.
   </para>
   &no_network_changes;
   <figure>
    <title>&crow; Web Interface: Initial State</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="depl_node_dashboard_initial.png" width="100%"
		 format="png"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="depl_node_dashboard_initial.png" width="75%"
		 format="png"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect1>
 </chapter>


