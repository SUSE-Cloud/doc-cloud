<?xml version="1.0"?>
<!DOCTYPE chapter [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<chapter xml:id="install_rhel_compute_node"
 xmlns="http://docbook.org/ns/docbook" version="5.1"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>Using &rhla; as a &compnode;</title>
 <para>
  This section outlines how to install a &rhla; &compnode; as a member of a
  a new or existing cloud created with &productname;.
 </para>
 <section xml:id="sec.install_rhel_compute_node.provision-deployer">
  <title>Setting Up a Deployer for &rhla;</title>
  <para>
   Ensure that your environment includes a Subscription Management Tool (SMT)
   server. Run the following steps on that server to configure an RPM
   repository for use by &rhla; clients.
  </para>
  <procedure>
   <step>
    <para>
     Enable SMT mirroring of the external CentOS 7.5 repository to distribute
     RHEL-compatible packages to nodes in the cloud.
    </para>
<screen>&prompt.sudo;smt-setup-custom-repos --name CentOS --description "CentOS 7.5" --productid 100682 \
  https://download.opensuse.org/repositories/systemsmanagement:/Ardana:/8:/CentOS:/7.5/CentOS_7.5/
&prompt.sudo;smt-repos -e CentOS
&prompt.sudo;smt-sync
&prompt.sudo;smt-mirror</screen>
   </step>
   <step>
    <para>
     CentOS RPM packages will now be stored on the SMT server in
     <filename>/srv/www/htdocs/repo/RPMMD/CentOS</filename>. If your deployer
     node also operates as your SMT server, publish this content to other nodes
     with the following command:
    </para>
<screen>&prompt.sudo;ln -s /srv/www/htdocs/repo/RPMMD/CentOS /opt/ardana_packager/ardana/rhel7/yum/centos</screen>
    <para>
     Or, if your SMT server is hosted separately from your deployer, follow the
     same steps for this repository as you are doing to mirror other repos, ensuring
     that it results in hosting the repo on the deployer at
     <filename>/opt/ardana_packager/ardana/rhel7/yum/centos</filename>.
    </para>
   </step>
   <step>
    <para>
     Add this new repo as a Yum package source to cloud nodes by populating
     <filename>/etc/yum.repos.d/ardana-centos.repo</filename> in each
     &rhla; system with the following contents:
    </para>
<screen>[ardana-centos]
name=Ardana CentOS Repository
baseurl=http://<replaceable>DEPLOYER-IP</replaceable>:79/ardana/rhel7/yum/centos
enabled=1
gpgcheck=0</screen>
   </step>
   <step>
    <para>
     Add the new repository to the deployer node as well (and accept its
     certificate), but with lower priority than other repositories. This
     ensures that packages present in both repos are preferably installed
     from the &sles; repositories.
    </para>
<screen>&prompt.sudo;zypper ar -p 100 file:/opt/ardana_packager/ardana/rhel7/yum/centos centos
&prompt.sudo;zypper ref</screen>
   </step>
  </procedure>
  <para>
   &ostack; components are installed on &rhel; &compnode;s
   via virtualenv (venv). To facilitate this, certain packages
   must be installed from the <systemitem>centos</systemitem> repository
   on the deployer node:
  </para>
<screen>for i in nova neutron monasca_agent
  do sudo zypper in -y venv-openstack-$i-rhel-x86_64
done</screen>
  <para>
   Once these packages are installed, they will populate a new package
   directory which must be prepared to serve as a &rhla; Yum repository:
  </para>
<screen>&prompt.sudo;create_index --dir=/opt/ardana_packager/ardana-8/rhel_venv/x86_64</screen>
 </section>
 <section xml:id="sec.install_rhel_compute_node.yum-ardana">
  <title>Package Dependencies for &rhla; &compnode;s</title>
  <para>
   To use the &ostack-current; version of
   <literal>nova-compute</literal>, a <literal>qemu-kvm</literal> version
   greater than 2.10.0 must be installed on &rhla; nodes.
  </para>
  <para>
   The RPM packages needed for <literal>nova-compute</literal> must be
   provided before executing <filename>site.yml</filename>. It is expected
   that a &rhla; subscription will be used to provide these RPM packages so
   that they get continuous updates.
  </para>
  <para>
   The RPM package for libcacard-ev is required and should be automatically
   pulled in when you use the Yum repo as described above <emphasis
   role="bold">and</emphasis> you install with the <command>Yum</command>
   command. If this dependency is not found, you will receive an error message
   reporting a failed dependency. In this case, the RPM package must be
   installed manually with the qemu-kvm packages.
  </para>
  <para>
   The <literal>qemu-kvm</literal> packages can also be can be downloaded from
   <link
   xlink:href="http://ftp.halifax.rwth-aachen.de/centos/7.5.1804/virt/x86_64/kvm-common/"/>.
   The following RPM packages from that location have been tested successfully:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     <filename>qemu-img-ev-2.10.0-21.el7_5.4.1.x86_64.rpm</filename>
    </para>
   </listitem>
   <listitem>
    <para>
     <filename>qemu-kvm-common-ev-2.10.0-21.el7_5.4.1.x86_64.rpm</filename>
    </para>
   </listitem>
   <listitem>
    <para>
     <filename>qemu-kvm-ev-2.10.0-21.el7_5.4.1.x86_64.rpm</filename>
    </para>
   </listitem>
   <listitem>
    <para>
     <filename>qemu-kvm-tools-ev-2.10.0-21.el7_5.4.1.x86_64.rpm</filename>
    </para>
   </listitem>
  </itemizedlist>
  <note>
   <para>
    When migrating from a previous version of these packages, they should be
    installed using <command>rpm -U
    <replaceable>FILENAME</replaceable></command> rather than <command>rpm -i
    <replaceable>FILENAME</replaceable></command>.
   </para>
  </note>
  <para>
   All of the RPM packages should be installed together and not individually, as
   shown below:
  </para>
  <screen>&prompt.sudo;rpm -Uvh qemu-img-ev-2.6.0-28.el7.10.1.x86_64.rpm \
qemu-kvm-common-ev-2.6.0-28.el7.10.1.x86_64.rpm \
qemu-kvm-ev-2.6.0-28.el7.10.1.x86_64.rpm \
qemu-kvm-tools-ev-2.6.0-28.el7.10.1.x86_64.rpm \
libcacard-ev-2.3.0-31.el7_2.21.1.x86_64.rpm</screen>
 </section>
 <section xml:id="sec.install_rhel_compute_node.deploying">
  <title>Deploying &rhla; &compnode;s</title>
  <para>
   SELinux policy updates are needed for
   <literal>nova-compute</literal> to work properly. SELinux policy updates can be
   enabled by changing a flag in default configuration. This needs to be
   done on the &lcm; <emphasis>before</emphasis> <literal>nova-compute</literal>
   is installed on &rhla; nodes.
  </para>
  <procedure>
   <step>
    <para>
     On the &lcm; node, edit the following file:
    </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;vi roles/NOV-CMP-KVM/defaults/main.yml</screen>
   </step>
   <step>
    <para>
     Set the SELinux flag to <literal>true</literal>:
    </para>
<screen>nova_rhel_compute_apply_selinux_policy_updates: true</screen>
   </step>
   <step>
    <para>
     Save and close the file.
    </para>
   </step>
   <step>
    <para>
     Commit the change to Git:
    </para>
<screen>&prompt.ardana;git commit -a --allow-empty -m "Enable SELinux policy updates for compute nodes"</screen>
   </step>
   <step>
    <para>
     Publish the changes so that they are included in playbook runs:
    </para>
<screen>&prompt.ardana;ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
   </step>
  </procedure>
  <para>
   Continue to deploy &ostack; services on &rhla; nodes by providing the
   names of each &rhla; node (as defined in <filename>hosts/verb_hosts</filename>)
   in the following command:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts site.yml -l "<replaceable>NODE1_NAME</replaceable>,<replaceable>NODE2_NAME</replaceable>"</screen>
  <para>
   If you have used an encryption password when running the configuration
   processor, include the additional parameter <command>--ask-vault-pass</command>
   to the end of the above command.
  </para>
 </section>
</chapter>
