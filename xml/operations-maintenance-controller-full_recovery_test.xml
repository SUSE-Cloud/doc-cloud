<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="full_recovery_test">
 <title>Full Disaster Recovery Test</title>
 <para>
  Full Disaster Recovery Test
 </para>
 <section>
   <title>Prerequisites</title>
   <para>&productname; platform</para>
   <para>An external server to store backups using SSH</para>
 </section>
 <section>
   <title>Goals</title>
   <para>Here is a high level view of how we expect to test the disaster recovery of the platform.</para>
   <orderedlist>
     <listitem>
       <para>Backup the Cassandra Database</para>
     </listitem>
     <listitem>
       <para>Re-install Controller 1 with the &productname; ISO</para>
     </listitem>
     <listitem>
       <para>Re-install &productname; on Controller 1, 2, 3</para>
     </listitem>
     <listitem>
       <para>Recover the backup of the &mariadb; database</para>
     </listitem>
     <listitem>
       <para>Recover the Cassandra Database</para>
     </listitem>
   </orderedlist>
 </section>
 <section>
  <title>Description of the testing environment</title>
  <para>
   The testing environment is very similar to the Entry Scale model.
  </para>
  <para>
   It used 5 servers: 3 Controllers and 2 computes.
  </para>
  <para>
   The controller node have three disks. The first one is reserved for the
   system, while others are used for &o_objstore;.
  </para>
  <note>
   <para>
    During this Disaster Recovery exercise, we have saved the data on disk 2
    and 3 of the &o_objstore; controllers.
   </para>
   <para>
    This allow to restore the &o_objstore; objects after the recovery.
   </para>
   <para>
    If these disks were to be wiped as well, &o_objstore; data would be lost
    but the procedure would not change.
   </para>
   <para>
    The only difference is that Glance images would be lost and they will have
    to be re-uploaded.
   </para>
  </note>
 </section>
 <section>
  <title>Disaster recovery test note</title>
  <para>
   If it is not specified otherwise, all the commands should be executed on
   controller 1, which is also the deployer node.
  </para>
 </section>
 <section>
  <title>Pre-Disaster testing</title>
  <para>
   In order to validate the procedure after recovery, we need to create some
   workloads.
  </para>
  <orderedlist>
   <listitem>
    <para>
     Source the service credential file
    </para>
<screen>&prompt.ardana;source ~/service.osrc</screen>
   </listitem>
   <listitem>
    <para>
     Copy an image to the platform and create a Glance image with it. In this
     example, Cirros is used
    </para>
<screen>&prompt.ardana;openstack image create --disk-format raw --container-format bare --public --file ~/cirros-0.3.5-x86_64-disk.img cirros</screen>
   </listitem>
   <listitem>
    <para>
     Create a network
    </para>
<screen>&prompt.ardana;openstack network create test_net</screen>
   </listitem>
   <listitem>
    <para>
     Create a subnet
    </para>
<screen>&prompt.ardana;neutron subnet-create 07c35d11-13f9-41d4-8289-fa92147b1d44 192.168.42.0/24 --name test_subnet</screen>
   </listitem>
   <listitem>
    <para>
     Create some instances
    </para>
<screen>&prompt.ardana;openstack server create server_1 --image 411a0363-7f4b-4bbc-889c-b9614e2da52e --flavor m1.small --nic net-id=07c35d11-13f9-41d4-8289-fa92147b1d44
&prompt.ardana;openstack server create server_2 --image 411a0363-7f4b-4bbc-889c-b9614e2da52e --flavor m1.small --nic net-id=07c35d11-13f9-41d4-8289-fa92147b1d44
&prompt.ardana;openstack server create server_3 --image 411a0363-7f4b-4bbc-889c-b9614e2da52e --flavor m1.small --nic net-id=07c35d11-13f9-41d4-8289-fa92147b1d44
&prompt.ardana;openstack server create server_4 --image 411a0363-7f4b-4bbc-889c-b9614e2da52e --flavor m1.small --nic net-id=07c35d11-13f9-41d4-8289-fa92147b1d44
&prompt.ardana;openstack server create server_5 --image 411a0363-7f4b-4bbc-889c-b9614e2da52e --flavor m1.small --nic net-id=07c35d11-13f9-41d4-8289-fa92147b1d44
&prompt.ardana;openstack server list</screen>
   </listitem>
   <listitem>
    <para>
     Create containers and objects
    </para>
<screen>&prompt.ardana;openstack object create container_1 ~/service.osrc
var/lib/ardana/service.osrc

&prompt.ardana;openstack object create container_1 ~/backup.osrc
openstack object create container_1 ~/backup.osrc

&prompt.ardana;openstack container list container_1
var/lib/ardana/backup.osrc
var/lib/ardana/service.osrc</screen>
   </listitem>
  </orderedlist>
 </section>
 <section>
   <title>Preparation of the backup server</title>
   <para>Preparation of the backup server</para>
   <section>
     <title>Preparation to store Cassandra backups</title>
     <para>In this example, we want to store the backups on the server 192.168.69.132. We will store the backups in the <filename>/mnt/backups/cassandra_backups/</filename> directory.</para>
     <orderedlist>
       <listitem>
         <para>Create a directory on the backup server to store cassandra backups</para>
<screen><prompt>backupuser &gt; </prompt>mkdir /mnt/backups/cassandra_backups</screen>
    </listitem>
    <listitem>
     <para>
      Copy private ssh key from backupserver to all controller nodes
     </para>
<screen><prompt>backupuser &gt; </prompt>scp /mnt/backups/.ssh/id_rsa ardana@<replaceable>CONTROLLER</replaceable>:~/.ssh/id_rsa_backup
         Password:
         id_rsa     100% 1675     1.6KB/s   00:00</screen>
     <para>
      <replaceable>Replace CONTROLLER with each control node e.g.
      doc-cp1-c1-m1-mgmt, doc-cp1-c1-m2-mgmt etc</replaceable>
     </para>
    </listitem>
    <listitem>
     <para>
      Login to each controller node and copy private ssh key to the root user's
      .ssh directory
     </para>
<screen>&prompt.sudo;cp /var/lib/ardana/.ssh/id_rsa_backup /root/.ssh/</screen>
    </listitem>
    <listitem>
     <para>
      Verify that you can ssh to backup server as backup user using the private
      key
     </para>
<screen>&prompt.root;ssh -i ~/.ssh/id_rsa_backup backupuser@doc-cp1-comp0001-mgmt</screen>
    </listitem>
   </orderedlist>
  </section>
 </section>
 <section>
  <title>Perform Backups for disaster recovery test</title>
  <para>
   Perform Backups for disaster recovery
  </para>
  <section>
   <title>Execute backup of Cassandra</title>
   <para>
    Execute backup of Cassandra
   </para>
   <para>
    Create cassandra-backup-extserver.sh script on all controller nodes
   </para>
<screen>&prompt.root;cat &gt; ~/cassandra-backup-extserver.sh &lt;&lt; EOF
#!/bin/sh

# backup user
BACKUP_USER=backupuser
# backup server
BACKUP_SERVER=192.168.69.132
# backup directory
BACKUP_DIR=/mnt/backups/cassandra_backups/

# Setup variables
DATA_DIR=/var/cassandra/data/data
NODETOOL=/usr/bin/nodetool

# e.g. cassandra-snp-2018-06-26-1003
SNAPSHOT_NAME=cassandra-snp-\$(date +%F-%H%M)
HOST_NAME=\$(/bin/hostname)_

# Take a snapshot of cassandra database
\$NODETOOL snapshot -t \$SNAPSHOT_NAME monasca

# Collect a list of directories that make up the snapshot
SNAPSHOT_DIR_LIST=\$(find \$DATA_DIR -type d -name \$SNAPSHOT_NAME)
for d in \$SNAPSHOT_DIR_LIST
  do
    # copy snapshot directories to external server
    rsync -avR -e "ssh -i /root/.ssh/id_rsa_backup" \$d \$BACKUP_USER@\$BACKUP_SERVER:\$BACKUP_DIR/\$HOST_NAME\$SNAPSHOT_NAME
  done

\$NODETOOL clearsnapshot monasca
EOF</screen>
<screen>&prompt.root;chmod +x ~/cassandra-backup-extserver.sh</screen>
   <para>
    Execute following steps on all the controller nodes
   </para>
   <note>
    <para>
     /usr/local/sbin/cassandra-backup-extserver.sh should be executed on all
     the three controller nodes at the same time (within seconds of each other)
     for a successful backup
    </para>
   </note>
   <orderedlist>
    <listitem>
     <para>
      Edit /usr/local/sbin/cassandra-backup-extserver.sh script
     </para>
     <para>
      Set <literal>BACKUP_USER</literal> and <literal>BACKUP_SERVER</literal>
      to the desired backup user (for example,
      <systemitem class="username">backupuser</systemitem>) and desired backup
      server (for example, <literal>192.168.68.132</literal>), respectively.
     </para>
<screen>
BACKUP_USER=backupuser
BACKUP_SERVER=192.168.69.132
BACKUP_DIR=/mnt/backups/cassandra_backups/
</screen>
    </listitem>
    <listitem>
     <para>
      Execute ~/cassandra-backup-extserver.sh
     </para>
<screen>&prompt.root;~/cassandra-backup-extserver.sh (on all controller nodes which are also cassandra nodes)

Requested creating snapshot(s) for [monasca] with snapshot name [cassandra-snp-2018-06-28-0251] and options {skipFlush=false}
Snapshot directory: cassandra-snp-2018-06-28-0251
sending incremental file list
created directory /mnt/backups/cassandra_backups//doc-cp1-c1-m1-mgmt_cassandra-snp-2018-06-28-0251
/var/
/var/cassandra/
/var/cassandra/data/
/var/cassandra/data/data/
/var/cassandra/data/data/monasca/

...
...
...

/var/cassandra/data/data/monasca/measurements-e29033d0488d11e8bdabc32666406af1/snapshots/cassandra-snp-2018-06-28-0306/mc-72-big-Summary.db
/var/cassandra/data/data/monasca/measurements-e29033d0488d11e8bdabc32666406af1/snapshots/cassandra-snp-2018-06-28-0306/mc-72-big-TOC.txt
/var/cassandra/data/data/monasca/measurements-e29033d0488d11e8bdabc32666406af1/snapshots/cassandra-snp-2018-06-28-0306/schema.cql
sent 173,691 bytes  received 531 bytes  116,148.00 bytes/sec
total size is 171,378  speedup is 0.98
Requested clearing snapshot(s) for [monasca]
</screen>
    </listitem>
    <listitem>
     <para>
      Verify cassandra backup directory on backup server
     </para>
<screen><prompt>backupuser &gt; </prompt>ls -alt /mnt/backups/cassandra_backups
total 16
drwxr-xr-x 4 backupuser users 4096 Jun 28 03:06 .
drwxr-xr-x 3 backupuser users 4096 Jun 28 03:06 doc-cp1-c1-m2-mgmt_cassandra-snp-2018-06-28-0306
drwxr-xr-x 3 backupuser users 4096 Jun 28 02:51 doc-cp1-c1-m1-mgmt_cassandra-snp-2018-06-28-0251
drwxr-xr-x 8 backupuser users 4096 Jun 27 20:56 ..

$backupuser@backupserver> du -shx /mnt/backups/cassandra_backups/*
6.2G    /mnt/backups/cassandra_backups/doc-cp1-c1-m1-mgmt_cassandra-snp-2018-06-28-0251
6.3G    /mnt/backups/cassandra_backups/doc-cp1-c1-m2-mgmt_cassandra-snp-2018-06-28-0306</screen>
       </listitem>
     </orderedlist>
   </section>
     <section>
       <title>Cassandra database restore</title>
       <para>Cassandra database restore</para>
       <para>Create a script cassandra-restore-extserver.sh on all
       controller nodes</para>
<screen>&prompt.root;cat &gt; ~/cassandra-restore-extserver.sh &lt;&lt; EOF
#!/bin/sh

# backup user
BACKUP_USER=backupuser
# backup server
BACKUP_SERVER=192.168.69.132
# backup directory
BACKUP_DIR=/mnt/backups/cassandra_backups/

# Setup variables
DATA_DIR=/var/cassandra/data/data
NODETOOL=/usr/bin/nodetool

HOST_NAME=\$(/bin/hostname)_

#Get snapshot name from command line.
if [ -z "\$*"  ]
then
  echo "usage \$0 &lt;snapshot to restore&gt;"
  exit 1
fi
SNAPSHOT_NAME=\$1

# restore
rsync -av -e "ssh -i /root/.ssh/id_rsa_backup" \$BACKUP_USER@\$BACKUP_SERVER:\$BACKUP_DIR/\$HOST_NAME\$SNAPSHOT_NAME/ /

# set ownership of newley restored files
chown -R cassandra:cassandra \$DATA_DIR/monasca/*

# Get a list of snapshot directories that have files to be restored.
RESTORE_LIST=\$(find \$DATA_DIR -type d -name \$SNAPSHOT_NAME)

# use RESTORE_LIST to move snapshot files back into place of database.
for d in \$RESTORE_LIST
do
  cd \$d
  mv * ../..
  KEYSPACE=\$(pwd | rev | cut -d '/' -f4 | rev)
  TABLE_NAME=\$(pwd | rev | cut -d '/' -f3 |rev | cut -d '-' -f1)
  \$NODETOOL refresh \$KEYSPACE \$TABLE_NAME
done
cd
# Cleanup snapshot directories
\$NODETOOL clearsnapshot \$KEYSPACE
EOF</screen>
<screen>&prompt.root;chmod +x ~/cassandra-restore-extserver.sh</screen>
   <para>
    Execute following steps on all the controller nodes
   </para>
   <orderedlist>
    <listitem>
     <para>
      Edit ~/cassandra-restore-extserver.sh script
     </para>
     <para>
      Set
      <replaceable>BACKUP_USER</replaceable>,<replaceable>BACKUP_SERVER</replaceable>
      to the desired backup user (for example,
      <systemitem class="username">backupuser</systemitem>) and the desired
      backup server (for example, <literal>192.168.68.132</literal>),
      respectively.
     </para>
<screen>
BACKUP_USER=backupuser
BACKUP_SERVER=192.168.69.132
BACKUP_DIR=/mnt/backups/cassandra_backups/</screen>
    </listitem>
    <listitem>
     <para>
      Execute ~/cassandra-restore-extserver.sh
      <replaceable>SNAPSHOT_NAME</replaceable>
     </para>
     <para>
      You will have to find out <replaceable>SNAPSHOT_NAME</replaceable> from
      listing of /mnt/backups/cassandra_backups. All the directories are of
      format
      <replaceable>HOST</replaceable>_<replaceable>SNAPSHOT_NAME</replaceable>
     </para>
<screen>ls -alt /mnt/backups/cassandra_backups
total 16
drwxr-xr-x 4 backupuser users 4096 Jun 28 03:06 .
drwxr-xr-x 3 backupuser users 4096 Jun 28 03:06 doc-cp1-c1-m2-mgmt_cassandra-snp-2018-06-28-0306</screen>
<screen>&prompt.root;~/cassandra-restore-extserver.sh cassandra-snp-2018-06-28-0306

receiving incremental file list
./
var/
var/cassandra/
var/cassandra/data/
var/cassandra/data/data/
var/cassandra/data/data/monasca/
var/cassandra/data/data/monasca/alarm_state_history-e6bbdc20488d11e8bdabc32666406af1/
var/cassandra/data/data/monasca/alarm_state_history-e6bbdc20488d11e8bdabc32666406af1/snapshots/
var/cassandra/data/data/monasca/alarm_state_history-e6bbdc20488d11e8bdabc32666406af1/snapshots/cassandra-snp-2018-06-28-0306/
var/cassandra/data/data/monasca/alarm_state_history-e6bbdc20488d11e8bdabc32666406af1/snapshots/cassandra-snp-2018-06-28-0306/manifest.json
var/cassandra/data/data/monasca/alarm_state_history-e6bbdc20488d11e8bdabc32666406af1/snapshots/cassandra-snp-2018-06-28-0306/mc-37-big-CompressionInfo.db
var/cassandra/data/data/monasca/alarm_state_history-e6bbdc20488d11e8bdabc32666406af1/snapshots/cassandra-snp-2018-06-28-0306/mc-37-big-Data.db
...
...
...
/usr/bin/nodetool clearsnapshot monasca</screen>
    </listitem>
   </orderedlist>
  </section>
  <section>
   <title>Restart &productname; services</title>
   <para>
    Restart &productname; services
   </para>
   <orderedlist>
    <listitem>
     <para>
      Restart the &mariadb; Database
     </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts galera-bootstrap.yml</screen>
     <para>
      On the deployer node, execute the
      <filename>galera-bootstrap.yml</filename> playbook which will
      automatically determine the log sequence number, bootstrap the main node,
      and start the database cluster.
     </para>
     <para>
      If this process fails to recover the database cluster, please refer to
      <xref linkend="mysql"/>. There Scenario 3 covers the process of manually
      starting the database.
     </para>
    </listitem>
    <listitem>
     <para>
      Restart &productname; services limited to the three controllers (replace
      the the hostnames of the controllers in the command).
     </para>
<screen>ansible-playbook -i hosts/verb_hosts ardana-start.yml \
 --limit doc-cp1-c1-m1-mgmt,doc-cp1-c1-m2-mgmt,doc-cp1-c1-m3-mgmt,localhost</screen>
    </listitem>
    <listitem>
     <para>
      Re-configure &productname;
     </para>
<screen>ansible-playbook -i hosts/verb_hosts ardana-reconfigure.yml</screen>
         </listitem>
       </orderedlist>
    </section>
 <section>
  <title>Post restore testing</title>
  <para>
   Post restore testing
  </para>
  <orderedlist>
   <listitem>
    <para>
     Source the service credential file
    </para>
<screen>&prompt.ardana;source ~/service.osrc</screen>
   </listitem>
   <listitem>
    <para>
     &o_objstore;
    </para>
<screen>&prompt.ardana;openstack container list
container_1
volumebackups

&prompt.ardana;openstack container list container_1
var/lib/ardana/backup.osrc
var/lib/ardana/service.osrc

&prompt.ardana;openstack container save container_1 /tmp/backup.osrc</screen>
   </listitem>
   <listitem>
    <para>
     Neutron
    </para>
<screen>&prompt.ardana;openstack network list
+--------------------------------------+---------------------+--------------------------------------+
| ID                                   | Name                | Subnets                              |
+--------------------------------------+---------------------+--------------------------------------+
| 07c35d11-13f9-41d4-8289-fa92147b1d44 | test-net             | 02d5ca3b-1133-4a74-a9ab-1f1dc2853ec8|
+--------------------------------------+---------------------+--------------------------------------+</screen>
   </listitem>
   <listitem>
    <para>
     Glance
    </para>
<screen>&prompt.ardana;openstack image list
+--------------------------------------+----------------------+--------+
| ID                                   | Name                 | Status |
+--------------------------------------+----------------------+--------+
| 411a0363-7f4b-4bbc-889c-b9614e2da52e | cirros-0.4.0-x86_64  | active |
+--------------------------------------+----------------------+--------+
&prompt.ardana;openstack image save --file /tmp/cirros f751c39b-f1e3-4f02-8332-3886826889ba
&prompt.ardana;ls -lah /tmp/cirros
-rw-r--r-- 1 ardana ardana 12716032 Jul  2 20:52 /tmp/cirros</screen>
   </listitem>
   <listitem>
    <para>
     Nova
    </para>
<screen>&prompt.ardana;openstack server list

&prompt.ardana;openstack server list

&prompt.ardana;openstack server create server_6 --image 411a0363-7f4b-4bbc-889c-b9614e2da52e  --flavor m1.small --nic net-id=07c35d11-13f9-41d4-8289-fa92147b1d44
+-------------------------------------+------------------------------------------------------------+
| Field                               | Value                                                      |
+-------------------------------------+------------------------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                                                     |
| OS-EXT-AZ:availability_zone         |                                                            |
| OS-EXT-SRV-ATTR:host                | None                                                       |
| OS-EXT-SRV-ATTR:hypervisor_hostname | None                                                       |
| OS-EXT-SRV-ATTR:instance_name       |                                                            |
| OS-EXT-STS:power_state              | NOSTATE                                                    |
| OS-EXT-STS:task_state               | scheduling                                                 |
| OS-EXT-STS:vm_state                 | building                                                   |
| OS-SRV-USG:launched_at              | None                                                       |
| OS-SRV-USG:terminated_at            | None                                                       |
| accessIPv4                          |                                                            |
| accessIPv6                          |                                                            |
| addresses                           |                                                            |
| adminPass                           | iJBoBaj53oUd                                               |
| config_drive                        |                                                            |
| created                             | 2018-07-02T21:02:01Z                                       |
| flavor                              | m1.small (2)                                               |
| hostId                              |                                                            |
| id                                  | ce7689ff-23bf-4fe9-b2a9-922d4aa9412c                       |
| image                               | cirros-0.4.0-x86_64 (f751c39b-f1e3-4f02-8332-3886826889ba) |
| key_name                            | None                                                       |
| name                                | server_6                                                   |
| progress                            | 0                                                          |
| project_id                          | cca416004124432592b2949a5c5d9949                           |
| properties                          |                                                            |
| security_groups                     | name='default'                                             |
| status                              | BUILD                                                      |
| updated                             | 2018-07-02T21:02:01Z                                       |
| user_id                             | 8cb1168776d24390b44c3aaa0720b532                           |
| volumes_attached                    |                                                            |
+-------------------------------------+------------------------------------------------------------+

&prompt.ardana;openstack server list
+--------------------------------------+----------+--------+---------------------------------+---------------------+-----------+
| ID                                   | Name     | Status | Networks                        | Image               | Flavor    |
+--------------------------------------+----------+--------+---------------------------------+---------------------+-----------+
| ce7689ff-23bf-4fe9-b2a9-922d4aa9412c | server_6 | ACTIVE | n1=1.1.1.8                      | cirros-0.4.0-x86_64 | m1.small  |

&prompt.ardana;openstack server delete ce7689ff-23bf-4fe9-b2a9-922d4aa9412c</screen>
   </listitem>
  </orderedlist>
 </section>
</section>
</section>
