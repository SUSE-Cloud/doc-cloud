<?xml version="1.0"?>
<!DOCTYPE section [
<!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="troubleshooting_blockstorage">
 <title>块存储故障排除</title>
 <para>
  块存储服务使用 &ostack; &o_blockstore;，可以与包括 3Par 在内的多个后端集成。&o_blockstore; API 级别可能存在故障，操作可能会失败，或者您可能会在监视服务中看到警报被触发。这些可能是由配置问题，网络问题或服务器或存储后端问题引起的。本页面和章节的目的是描述服务的工作原理，在何处查找更多信息，出现的一些常见问题以及解决方法。
 </para>
 <section xml:id="logs">
  <title>在哪里寻找信息</title>
  <para>
   调试块存储问题时，了解部署拓扑并知道在何处查找包含更多信息的日志会很有帮助。
  </para>
  <para>
   &o_blockstore; 服务包括：
  </para>
  <itemizedlist>
   <listitem>
    <para>
     API 服务，通常在控制器节点上部署和激活。
    </para>
   </listitem>
   <listitem>
    <para>
     调度程序服务，通常也在控制器节点上部署和激活。
    </para>
   </listitem>
   <listitem>
    <para>
     卷服务，部署在所有控制器节点上，但仅在其中一个节点上处于活动状态。
    </para>
   </listitem>
   <listitem>
    <para>
     备份服务，与卷服务部署在同一控制器节点上。
    </para>
   </listitem>
  </itemizedlist>
  <informalfigure>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="media-hos.docs-troubleshooting-cinder_topology.png" width="75%"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="media-hos.docs-troubleshooting-cinder_topology.png"/>
    </imageobject>
   </mediaobject>
  </informalfigure>
  <para>
   您可以参考配置文件（通常位于 &lcm; 上的 <literal>~/openstack/my_cloud/definition/</literal> 中），以获取有关服务所在位置的详细信息。它们通常位于控制器节点上。
  </para>
  <para>
   &o_blockstore; 使用 &mariadb; 数据库，并通过来自 RabbitMQ 消息服务的消息在组件之间进行通信。
  </para>
  <para>
   &o_blockstore; API 服务在 HAProxy 服务的下层，并使用 keepalived 维护的虚拟 IP 地址进行访问。
  </para>
  <para>
   如果任何 &o_blockstore; 组件未在其预期主机上运行，则会发出警报。有关如何解决这些警报的详细信息，请参见  <xref linkend="alarmdefinitions"/>  页面。您应该在适当的节点上检查服务的日志。所有 &o_blockstore; 日志都存储在 <literal>/var/log/cinder/</literal> 中，并且 <literal>INFO</literal> 级别以上的所有日志条目也会发送到集中式日志记录服务。有关如何更改 &o_blockstore; 服务的日志记录级别的详细信息，请参见 <xref linkend="central_log_configure_services"/>。
  </para>
  <para>
   为了获得错误的完整情况，您可能需要检查各个节点上的完整日志文件。请注意，如果组件在多个节点上运行，则需要查看组件运行的每个节点上的日志。还要记住，当日志轮替时，您感兴趣的时间段可能位于较旧的日志文件中。
  </para>
  <para>
   <emphasis role="bold">日志位置：</emphasis>
  </para>
  <para>
   <literal>/var/log/cinder/cinder-api.log</literal> - 如果您遇到端点或连接问题，请检查此日志
  </para>
  <para>
   <literal>/var/log/cinder/cinder-scheduler.log</literal> - 如果系统无法将卷分配给后端，请检查此日志
  </para>
  <para>
   <literal>/var/log/cinder/cinder-backup.log</literal> - 如果您有备份或还原问题，请检查此日志
  </para>
  <para>
   <literal>/var/log/cinder-cinder-volume.log</literal> - 在此处检查创建卷时的故障
  </para>
  <para>
   <literal>/var/log/nova/nova-compute.log</literal> - 在此处检查将卷附加到计算实例的故障
  </para>
  <para>
   如果您的云出现数据库或消息传递错误，您还可以检查数据库和/或 RabbitMQ 服务的日志。
  </para>
  <para>
   如果 API 服务器已启动并正在运行但 API 无法访问，应查看活动的 keepalived 节点上的 HAProxy 日志。
  </para>
  <para>
   如果使用 Nova API 将卷附加到计算实例时出错，其日志将位于与实例关联的计算节点上。您可以使用以下命令确定托管实例的节点：
  </para>
  <screen>nova show &lt;instance_uuid&gt;</screen>
  <para>
   然后，您可以检查该计算节点上位于 <literal>/var/log/nova/nova-compute.log</literal> 的日志。
  </para>
 </section>
 <section xml:id="volume_states">
  <title>了解 &o_blockstore; 卷状态</title>
  <para>
   理解拓扑后，如果 &o_blockstore; 服务的问题与特定卷有关，那么您应该很好地了解卷的各种状态。状态包括：
  </para>
  <itemizedlist>
   <listitem>
    <para>
     attaching
    </para>
   </listitem>
   <listitem>
    <para>
     available
    </para>
   </listitem>
   <listitem>
    <para>
     backing-up
    </para>
   </listitem>
   <listitem>
    <para>
     creating
    </para>
   </listitem>
   <listitem>
    <para>
     deleting
    </para>
   </listitem>
   <listitem>
    <para>
     downloading
    </para>
   </listitem>
   <listitem>
    <para>
     error
    </para>
   </listitem>
   <listitem>
    <para>
     error attaching
    </para>
   </listitem>
   <listitem>
    <para>
     error deleting
    </para>
   </listitem>
   <listitem>
    <para>
     error detaching
    </para>
   </listitem>
   <listitem>
    <para>
     error extending
    </para>
   </listitem>
   <listitem>
    <para>
     error restoring
    </para>
   </listitem>
   <listitem>
    <para>
     in-use
    </para>
   </listitem>
   <listitem>
    <para>
     extending
    </para>
   </listitem>
   <listitem>
    <para>
     restoring
    </para>
   </listitem>
   <listitem>
    <para>
     restoring backup
    </para>
   </listitem>
   <listitem>
    <para>
     retyping
    </para>
   </listitem>
   <listitem>
    <para>
     uploading
    </para>
   </listitem>
  </itemizedlist>
  <para>
   通常状态是 <literal>in-use</literal>，表示卷当前附加到计算实例，<literal>available</literal> 表示卷在后端创建，可以自由附加到实例。所有 <literal>-ing</literal> 状态都是暂时的，代表着过渡状态。如果卷停留在其中一个状态中的时间太长，表明它已卡住，或者如果它出现故障并进入错误状态，您应该在日志中检查故障。
  </para>
 </section>
 <section xml:id="idg-all-operations-troubleshooting-ts_blockstorage-xml-7">
  <title>初步故障排除步骤</title>
  <para>
   这些应该是您使用的初始故障排除步骤。
  </para>
  <procedure>
   <step>
    <para>
     如果您注意到服务存在问题，则应检查监控系统是否有触发的警报。有关这些警报的解决步骤，请参见 <xref linkend="alarmdefinitions"/>。
    </para>
   </step>
   <step>
    <para>
     通过列出 &lcm; 中的可用卷来检查 &o_blockstore; API 服务是否处于活动状态：
    </para>
    <screen>source ~/service.osrc
     openstack volume list</screen>
   </step>
   <step>
    <para>
     从 &lcm; 运行基本诊断：
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
     ansible-playbook -i hosts/verb_hosts _cinder_post_check.yml</screen>
    <para>
     此 ansible 脚本将列出所有卷，创建 1 GB 卷，然后使用 v1 和 v2 API 删除它，这将运用基本的 &o_blockstore; 功能。
    </para>
   </step>
  </procedure>
 </section>
 <section xml:id="common_issues">
  <title>常见故障</title>
  <para>
   <emphasis role="bold">&o_blockstore; 服务的警报</emphasis>
  </para>
  <para>
   检查与块存储服务关联的警报，注意这些警报可能包括与服务器节点关闭相关的警报，与消息传递和数据库服务相关的警报，或 HAProxy 和 keepalived 服务，以及直接源于块存储服务的警报。
  </para>
  <para>
    &opscon; 提供用于检查警报的 Web UI。有关如何连接到 &opscon; 的详细信息，请参见 <xref linkend="opsconsole"/>。
  </para>
  <para>
   <emphasis role="bold">&o_blockstore; 卷服务已关闭</emphasis>
  </para>
  <para>
   如果托管卷服务的服务器出现故障，&o_blockstore; 卷服务可能会关闭。在这种情况下，您应该按照下面链接的文档过程在另一个控制器节点上启动卷服务。有关详细信息，请参见 <xref linkend="sec.operation.manage-block-storage"/>。
  </para>
  <para>
   <emphasis role="bold">创建 &o_blockstore; 可引导卷失败</emphasis>
  </para>
  <para>
   从镜像创建可引导卷时，&o_blockstore; 卷必须大于镜像的虚拟大小（原始大小），否则创建将失败并显示错误。
  </para>
  <para>
   类似于以下的错误会出现在 <literal>cinder-volume.log</literal> 文件中：
  </para>
<screen>'2016-06-14 07:44:00.954 25834 ERROR oslo_messaging.rpc.dispatcher ImageCopyFailure: Failed to copy image to volume: qemu-img: /dev/disk/by-path/ip-192.168.92.5:3260-iscsi-iqn.2003-10.com.lefthandnetworks:mg-ses:146:volume-c0e75c66-a20a-4368-b797-d70afedb45cc-lun-0: error while converting raw: Device is too small
   2016-06-14 07:44:00.954 25834 ERROR oslo_messaging.rpc.dispatcher'</screen>
  <para>
   示例中创建 1GB 可引导卷失败，您的映像可能类似于以下情况：
  </para>
  <screen>$ qemu-img info /tmp/image.qcow2
   image: /tmp/image.qcow2
   file format: qcow2
   virtual size: 1.5G (1563295744 bytes)
   disk size: 354M
   cluster_size: 65536
   ...</screen>
  <para>
   在这个例子中，请注意映像格式为 qcow2，而虚拟大小为 1.5GB，大于可引导卷的大小。即使压缩的映像大小小于 1GB，此可引导卷创建也将失败。
  </para>
  <para>
   为具有 cinder 卷角色的节点创建硬盘模型时，如果要创建可引导卷，请确保为临时空间分配足够的硬盘空间以进行映像转换。您应该为文件系统分配足够的空间，以满足可用于可引导卷的映像的原始大小 - 例如，Windows 映像的原始格式可能非常大。
  </para>
  <para>
   默认情况下，&o_blockstore; 使用 <literal>/var/lib/cinder</literal> 进行镜像转换，除非明确分隔，否则它将位于根文件系统上。您可以通过确保根文件系统足够大来确保有足够的空间，或者在安装系统时在硬盘模型中创建挂载在 <literal>/var/lib/cinder</literal> 上的逻辑卷。
  </para>
  <para>
   如果您的系统已安装，请使用以下步骤更新：
  </para>
  <orderedlist>
   <listitem>
    <para>
     编辑 <literal>cinder.conf.j2</literal> 中的配置项 <literal>image_conversion_dir</literal> 以指向具有更多硬盘空间的另一个位置。确保新目录位置与 <literal>/var/lib/cinder</literal> 具有相同的所有权和权限（所有者：cinder 组：cinder。模式 0750）。
    </para>
   </listitem>
   <listitem>
    <para>
     然后运行此脚本：
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
     ansible-playbook -i hosts/verb_hosts cinder-reconfigure.yml</screen>
   </listitem>
  </orderedlist>
  <para>
   <emphasis role="bold">API 级故障</emphasis>
  </para>
  <para>
   如果 API 不可访问，请确定 API 服务是否正在目标节点上运行。如果没有，请在日志文件中检查 API 服务未运行的原因。如果运行正常，请检查 HAProxy 服务是否正常运行。
  </para>
  <note>
   <para>
    重新启动控制器节点后，必须确保运行 <literal>ardana-start.yml</literal> 脚本以确保所有服务都已启动并正在运行。有关更多信息，请参见 <xref linkend="recover_downed_cluster"/>。
   </para>
  </note>
  <para>
   如果 API 服务返回错误代码，请在所有 API 节点上的 API 日志中查找错误消息。成功完成的服务记录类似与以下：
  </para>
  <screen>2016-04-25 10:09:51.107 30743 INFO eventlet.wsgi.server [<emphasis role="bold">req-a14cd6f3-6c7c-4076-adc3-48f8c91448f6</emphasis>
   dfb484eb00f94fb39b5d8f5a894cd163 7b61149483ba4eeb8a05efa92ef5b197 - - -] 192.168.186.105 - - [25/Apr/2016
   10:09:51] "GET /v2/7b61149483ba4eeb8a05efa92ef5b197/volumes/detail HTTP/1.1" <emphasis role="bold">200</emphasis> 13915 0.235921</screen>
  <para>
   其中 <literal>200</literal> 表示成功完成的 HTTP 状态 200。查找包含您的状态码的行，然后检查与请求 ID 关联的所有条目。成功完成的请求 ID 在上面以粗体突出显示。
  </para>
  <para>
   请求可能在调度程序、卷或备份服务上失败，您还应该在这些日志中检查感兴趣的时间段；注意，感兴趣的日志文件可能位于不同的节点上。
  </para>
  <para>
   <emphasis role="bold">不会完成的操作</emphasis>
  </para>
  <para>
   如果您已启动操作（如创建或删除卷）但不会完成， &o_blockstore; 卷可能会卡在某种状态。您应该按照处理卡住卷的步骤进行操作。
<!-- ERROR -->
  </para>
  <para>
   卷可能卡在六种过渡状态：
  </para>
  <informaltable colsep="1" rowsep="1">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1"/>
    <colspec colname="c2" colnum="2"/>
    <thead>
     <row>
      <entry>状态</entry>
      <entry>描述</entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry>creating</entry>
      <entry>&o_blockstore; 卷管理器已向后端驱动程序发送请求以创建卷，但尚未收到卷可用的确认。</entry>
     </row>
     <row>
      <entry>attaching</entry>
      <entry>&o_blockstore; 已收到 Nova 要求提供一个卷关联到实例的请求，但尚未收到 Nova 关联已完成的确认。</entry>
     </row>
     <row>
      <entry>detaching</entry>
      <entry>&o_blockstore; 已收到 Nova 将从一个实例中分离一个卷的通知，但尚未收到该分离已完成的通知。</entry>
     </row>
     <row>
      <entry>deleting</entry>
      <entry>&o_blockstore; 已收到删除卷的请求但尚未完成操作。</entry>
     </row>
     <row>
      <entry>backing-up</entry>
      <entry>&o_blockstore; 备份管理器已经开始将卷备份到 Swift 或其他一些备份目标，但尚未完成操作。</entry>
     </row>
     <row>
      <entry>restoring</entry>
      <entry>&o_blockstore; 备份管理器已经开始从 Swift 或其他一些备份目标恢复卷，但尚未完成操作。</entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
  <para>
   在高级别上，解决任何这些状态的步骤都很类似：
  </para>
  <orderedlist>
   <listitem>
    <para>
     确认卷确实卡住，而不是暂时被阻塞。
    </para>
   </listitem>
   <listitem>
    <para>
     尽可能删除卷所持有的任何资源。例如，如果卷被卡住，要移除它则可能需要删除计算节点上的关联的 iSCSI 或 DM 设备。
    </para>
   </listitem>
   <listitem>
    <para>
     将卷的状态重置为适当的状态，例如 <literal>available</literal> 或 <literal>error</literal>。
    </para>
   </listitem>
   <listitem>
    <para>
     做最后的清理工作。例如，如果将状态重置为 <literal>error</literal>，则可以删除该卷。
    </para>
   </listitem>
  </orderedlist>
  <para>
   接下来的部分将描述您可以对卡在过渡状态中的卷执行的具体步骤。
  </para>
  <para>
   <emphasis role="bold">卷卡在 Creating</emphasis>
  </para>
  <para>
   总的来讲，有两种情况可能导致卷在 <literal>creating</literal> 时卡住。在尝试创建卷时，<literal>cinder-volume</literal> 服务可能抛出异常，并且无法正确处理异常。或者，在收到 &o_blockstore; 创建卷的请求后，卷后端可能已失败或下线。
  </para>
  <para>
   这两种情况的不同之处在于，对于第二种情况，您需要确定后端下线的原因并重新启动它。通常，当后端重新启动时，卷将从 <literal>creating</literal> 变成 <literal>available</literal>，问题解决。
  </para>
  <para>
   如果您可以在卡在 <literal>creating</literal> 的卷相同的后端上成功创建卷，则后端没有下线。因此，您需要重置卷的状态，然后将其删除。
  </para>
  <para>
   要重置卷的状态，可以使用 <literal>cinder reset-state</literal> 命令。您可以使用 UUID 或卡住卷的卷名。
  </para>
  <para>
   例如，这是一个卷列表，其中我们有一个卡住的卷：
  </para>
  <screen>$ cinder list
   +--------------------------------------+-----------+------+------+-------------+------------+
   |                  ID                  |   Status  | Name | Size | Volume Type |Attached to |
   +--------------------------------------+-----------+------+------+-------------+------------+
   | 14b76133-e076-4bd3-b335-fa67e09e51f6 | creating  | vol1 |  1   |      -      |            |
   +--------------------------------------+-----------+------+------+-------------+------------+</screen>
  <para>
   您可以使用 <literal>cinder reset-state</literal> 命令重置状态，如下所示：
  </para>
  <screen>cinder reset-state --state error 14b76133-e076-4bd3-b335-fa67e09e51f6</screen>
  <para>
   再次列出列表确认：
  </para>
  <screen>$ cinder list
   +--------------------------------------+-----------+------+------+-------------+------------+
   |                  ID                  |   Status  | Name | Size | Volume Type |Attached to |
   +--------------------------------------+-----------+------+------+-------------+------------+
   | 14b76133-e076-4bd3-b335-fa67e09e51f6 | error     | vol1 |  1   |      -      |            |
   +--------------------------------------+-----------+------+------+-------------+------------+</screen>
  <para>
   然后，您可以删除该卷：
  </para>
  <screen>$ cinder delete 14b76133-e076-4bd3-b335-fa67e09e51f6
   Request to delete volume 14b76133-e076-4bd3-b335-fa67e09e51f6 has been accepted.</screen>
  <para>
   <emphasis role="bold">卷卡在 Deleting</emphasis>
  </para>
  <para>
   如果卷卡在删除状态，则删除卷的请求可能已经或可能未被发送到后端并由其执行。如果您可以识别后端的卷，则可以检查后端以确定卷是否仍然存在。然后，您可以决定可以采用以下哪种途径。通过检查最近的卷创建尝试或创建和删除测试卷来确定后端是否响应也可能很有用。
  </para>
  <para>
   第一个选项是将卷的状态重置为 <literal>available</literal>，然后再次尝试删除卷。
  </para>
  <para>
   第二个选项是将卷的状态重置为<literal>error</literal>，然后删除卷。
  </para>
  <para>
   如果您已将卷状态重置为 <literal>error</literal>，卷可能仍在消耗后端存储。如果是这样，那么您需要使用后端的特定工具从后端删除它。
  </para>
  <para>
   <emphasis role="bold">卷卡在 Attaching</emphasis>
  </para>
  <para>
   处理卷关联或分离的情况最复杂，因为除了处理 &o_blockstore; 和后端的卷状态，您还要处理来自后端的导出， 计算节点的导入，以及计算实例的附件。
  </para>
  <para>
   您拥有的两个选项是确保删除所有导出和导入，并将卷的状态重置为 <literal>available</literal>，或确保所有导出和导入都正确，并将卷的状态重置为 <literal>in-use</literal>。
  </para>
  <para>
   处于关联状态的卷应该从没有对计算实例可用过，因此其应该没有被写入任何数据，也不应该有数据在计算实例和卷后端之间的任何缓冲区中。在这种情况下，通常可以安全地手动拆除在后端导出并在计算主机上导入的设备，然后将卷状态重置为 <literal>available</literal>。
  </para>
  <para>
   您可以使用您使用的后端的管理功能来查找要导出卷的计算主机。
  </para>
  <para>
   <emphasis role="bold">卷卡在 Detaching</emphasis>
  </para>
  <para>
   处理处于 <literal>detaching</literal> 状态的卷的步骤非常类似于 <literal>attaching</literal> 的卷。但是，还有一个额外要考虑的因素，该卷连接到计算实例并可能在进行 I/O 服务。因此，您必须注意确保在分离卷之前正确清空所有缓冲区。
  </para>
  <para>
   当卷卡在 <literal>detaching</literal> 时，<literal>cinder list</literal> 命令的输出将包括卷关联的实例的 UUID。用它可以使用 <literal>nova show</literal> 命令识别正在运行实例的计算主机。
  </para>
  <para>
   例如，以下是一些片段：
  </para>
  <screen>$ cinder list
   +--------------------------------------+-----------+-----------------------+-----------------+
   |                  ID                  |   Status  |       Name            |   Attached to   |
   +--------------------------------------+-----------+-----------------------+-----------------+
   | 85384325-5505-419a-81bb-546c69064ec2 | detaching |        vol1           | 4bedaa76-78ca-… |
   +--------------------------------------+-----------+-----------------------+-----------------+</screen>
  <screen>$ nova show 4bedaa76-78ca-4fe3-806a-3ba57a9af361|grep host
   | OS-EXT-SRV-ATTR:host                 | mycloud-cp1-comp0005-mgmt
   | OS-EXT-SRV-ATTR:hypervisor_hostname  | mycloud-cp1-comp0005-mgmt
   | hostId                               | 61369a349bd6e17611a47adba60da317bd575be9a900ea590c1be816</screen>
  <para>
   在这种情况下要检查的第一件事是实例是否仍在导入卷。使用 <literal>virsh list</literal> 和 <literal>virsh dumpxml</literal>，如上一节中所述。如果实例的 XML 中有对设备的引用，则应将卷状态重置为 <literal>in-use</literal> 并再次尝试 <literal>cinder detach</literal> 操作。
  </para>
  <screen>$ cinder reset-state --state in-use --attach-status attached 85384325-5505-419a-81bb-546c69064ec2</screen>
  <para>
   如果卷分离再次卡住，可能存在更底层的问题，这超出了本文档的范围，您应该联系支持团队。
  </para>
  <para>
   如果实例的 XML 中未引用该卷，则应删除计算节点和后端上的所有设备，然后将卷的状态重置为 <literal>available</literal>。
  </para>
  <screen>$ cinder reset-state --state available --attach-status detached 85384325-5505-419a-81bb-546c69064ec2</screen>
  <para>
   您可以使用您使用的后端的管理功能来查找要导出卷的计算主机。
  </para>
  <para>
   <emphasis role="bold">卷卡在 restoring</emphasis>
  </para>
  <para>
   从备份恢复 &o_blockstore; 卷将与备份一样慢。因此，您必须通过检查 <literal>cinder-backup.log</literal> 确认卷实际上已卡住。例如：
  </para>
  <screen># tail -f cinder-backup.log |grep 162de6d5-ba92-4e36-aba4-e37cac41081b
   2016-04-27 12:39:14.612 6689 DEBUG swiftclient [req-0c65ec42-8f9d-430a-b0d5-05446bf17e34 - -
   2016-04-27 12:39:15.533 6689 DEBUG cinder.backup.chunkeddriver [req-0c65ec42-8f9d-430a-b0d5-
   2016-04-27 12:39:15.566 6689 DEBUG requests.packages.urllib3.connectionpool [req-0c65ec42-
   2016-04-27 12:39:15.567 6689 DEBUG swiftclient [req-0c65ec42-8f9d-430a-b0d5-05446bf17e34 - - -</screen>
  <para>
   如果确定卷在 <literal>detaching</literal> 时确实卡住了，则必须按照上面分离部分中描述的过程删除仍然从后端导出并导入控制器节点的所有卷。请记住，在这种情况下，卷将导入并安装在运行 <literal>cinder-backup</literal> 的控制器节点上。因此，您不必搜索正确的计算主机。还要记住，不涉及任何实例，因此您无需确认该卷未导入任何实例。
  </para>
 </section>
 <section xml:id="debugging_attachment">
  <title>调试卷附件</title>
  <para>
   在错误情况下，&o_blockstore; 卷可能无法完成操作并恢复到其初始状态。例如，将 &o_blockstore; 卷关联到 Nova 实例，因此您将按照上述步骤检查关联请求的 Nova 计算日志。
  </para>
 </section>
 <section xml:id="errors_creating">
  <title>创建卷的错误</title>
  <para>
   如果您正在创建卷并且它进入 <literal>ERROR</literal> 状态，一个常见错误是：<literal>No valid host was found</literal>。这意味着调度程序无法将卷调度到后端。您应该检查卷服务是否已启动并正在运行，可以使用此命令：
  </para>
  <screen>$ sudo cinder-manage service list
   Binary           Host                                 Zone             Status     State Updated At
   cinder-scheduler ha-volume-manager                    nova             enabled    :-)   2016-04-25 11:39:30
cinder-volume    ha-volume-manager@ses1               nova             enabled    XXX   2016-04-25 11:27:26
cinder-backup    ha-volume-manager                    nova             enabled    :-)   2016-04-25 11:39:28</screen>
  <para>
   在此示例中，<literal>XXX</literal> 的状态表示服务已关闭。
  </para>
  <para>
   如果服务已启动，请检查后端是否有足够的空间。您可以使用此命令显示每个后端的可用空间和总空间：
  </para>
  <screen>cinder get-pools –detail</screen>
  <para>
   如果部署使用卷类型，请检查 <literal>cinder.conf</literal> 文件中的 <literal>volume_backend_name</literal> 是否与所选卷类型的 <literal>volume_backend_name</literal> 匹配。
  </para>
  <para>
   您可以使用以下命令验证卷类型的后端名称：
  </para>
  <screen>openstack volume type list</screen>
  <para>
   然后列出有关卷类型的详细信息。例如：
  </para>
  <screen>$ openstack volume type show dfa8ecbd-8b95-49eb-bde7-6520aebacde0
   +---------------------------------+--------------------------------------+
   | Field                           | Value                                |
   +---------------------------------+--------------------------------------+
   | description                     | None                                 |
   | id                              | dfa8ecbd-8b95-49eb-bde7-6520aebacde0 |
   | is_public                       | True                                 |
   | name                            | my3par                               |
   | os-volume-type-access:is_public | True                                 |
   | properties                      | volume_backend_name='3par'           |
   +---------------------------------+--------------------------------------+</screen>
 </section>
 <section xml:id="idg-all-operations-troubleshooting-ts_blockstorage-xml-12">
  <title>诊断后端问题</title>
  <para>
   您可以通过访问这些页面找到特定后端类型的进一步故障排除步骤：
<!-- ERROR -->
  </para>
 </section>
</section>
