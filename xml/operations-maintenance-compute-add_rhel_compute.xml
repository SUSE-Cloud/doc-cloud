<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="add_rhel_compute">
 <title>Adding a &rhla; Compute Node</title>
 <para>
  Adding a &rhla; compute node allows you to increase cloud capacity for more
  virtual machines. These steps will help you add new &rhla; compute hosts for
  this purpose.
 </para>
 <section xml:id="idg-all-operations-maintenance-compute-add_rhel_compute-xml-5">
  <title>Prerequisites</title>
  <para>
   You need to ensure your input model files are properly setup for &rhla;
   compute host clusters. This must be done during the installation process of
   your cloud and is discussed further at <xref linkend="rhel_compute_model"/>.
  </para>
 </section>
 <section xml:id="idg-all-operations-maintenance-compute-add_rhel_compute-xml-6">
  <title>Adding a &rhla; compute node</title>
  <para>
   You must have &rhla; 7.5 pre-installed on the baremetal host prior to
   beginning these steps.
  </para>
  <procedure>
   <step>
    <para>
     Ensure you have &rhla; 7.5 pre-installed on your baremetal host.
    </para>
   </step>
   <step>
    <para>
     Log in to the &lcm;.
    </para>
   </step>
   <step>
    <para>
     Edit your <literal>~/openstack/my_cloud/definition/data/servers.yml</literal>
     file to include the details about your new compute host(s).
    </para>
    <para>
     For example, if you already had a cluster of three &rhla; compute hosts
     using the <literal>RHEL-COMPUTE-ROLE</literal> role and needed to add a
     fourth one you would add your details to the bottom of the file in the
     format. Note that we left out the IPMI details because they will not be needed
     since you pre-installed the &rhla; OS on your host(s).
    </para>
<screen>- id: compute4
  ip-addr: 192.168.102.70
  role: RHEL-COMPUTE-ROLE
  server-group: RACK1  </screen>
    <para>
     You can find detailed descriptions of these fields in <xref linkend="configobj_servers"/>. Ensure that you use
     the same role for any new &rhla; hosts you are adding as you specified on
     your existing &rhla; hosts.
    </para>
    <important>
     <para>
      Verify that the <literal>ip-addr</literal> value you
      choose for this host does not conflict with any other IP address in your
      cloud environment. You can confirm this by checking the
      <filename>~/openstack/my_cloud/info/address_info.yml</filename> file on your
      &lcm;.
     </para>
    </important>
   </step>
   <step>
    <para>
     In your
     <literal>~/openstack/my_cloud/definition/data/control_plane.yml</literal>
     file you will need to check the values for
     <literal>member-count</literal>, <literal>min-count</literal>, and
     <literal>max-count</literal>. If you specified them, ensure that they
     match up with your new total node count. For example, if you had
     previously specified <literal>member-count: 3</literal> and are adding a
     fourth compute node, you will need to change that value to
     <literal>member-count: 4</literal>.
    </para>
    <para>
     See <xref linkend="configobj_controlplane"/> for more details.
    </para>
   </step>
   <step>
    <para>
     Commit the changes to git:
    </para>
<screen>git add -A
git commit -a -m "Add node &lt;name&gt;"</screen>
   </step>
   <step>
    <para>
     Run the configuration processor and resolve any errors that are indicated:
    </para>
<screen>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
   </step>
   <step>
    <para>
     Update your deployment directory:
    </para>
<screen>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
    <para>
     Before proceeding, you may want to take a look at
     <emphasis role="bold">info/server_info.yml</emphasis> to see if the
     assignment of the node you have added is what you expect. It may not be,
     as nodes will not be numbered consecutively if any have previously been
     removed. This is to prevent loss of data; the config processor retains
     data about removed nodes and keeps their ID numbers from being
     reallocated. See <xref linkend="persistedserverallocations"/> for
     information on how this works.
    </para>
   </step>
   <step>
    <para>
     Look up the value for the new compute node's <literal>hostname</literal> in
     <filename>~/scratch/ansible/next/ardana/ansible/hosts/verb_hosts</filename>.
    </para>
    <para>
     Then, complete the compute host deployment with this playbook:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible/
ansible-playbook -i hosts/verb_hosts site.yml --tag "generate_hosts_file"
ansible-playbook -i hosts/verb_hosts site.yml --limit &lt;hostname&gt;</screen>
   </step>
  </procedure>
 </section>
 <section xml:id="idg-all-operations-maintenance-compute-add_rhel_compute-xml-8">
  <title>Adding a new &rhla; compute node to monitoring</title>
  <para>
   If you want to add a new Compute node to the monitoring service checks,
   there is an additional playbook that must be run to ensure this happens:
  </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts monasca-deploy.yml --tags "active_ping_checks"</screen>
 </section>
</section>
