<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="crt_increasing_scale">
 <title>Increase Monasca Transform Scale</title>
 <para>
  Monasca Transform in the default configuration can scale up to estimated
  data for 100 node cloud deployment. Estimated maximum rate of metrics from a
  100 node cloud deployment is 120M/hour.
 </para>
 <para>
  You can further increase the processing rate to 180M/hour. Making
  the Spark configuration change will increase the CPU's being used by Spark
  and Monasca Transform from average of around 3.5 to 5.5 CPU's per control
  node over a 10 minute batch processing interval.
 </para>
 <para>
  To increase the processing rate to 180M/hour the customer will have to make
  following spark configuration change.
 </para>
 <para>
  <emphasis role="bold">Steps</emphasis>
 </para>
 <orderedlist>
  <listitem>
   <para>
    Edit /var/lib/ardana/openstack/my_cloud/config/spark/spark-defaults.conf.j2 and
    set spark.cores.max to 6 and spark.executor.cores 2
   </para>
   <para>
    <emphasis role="bold">Set spark.cores.max to 6</emphasis>
   </para>
<screen>spark.cores.max {{ spark_cores_max }}</screen>
   <para>
    to
   </para>
<screen>spark.cores.max 6</screen>
   <para>
    <emphasis role="bold">Set spark.executor.cores to 2</emphasis>
   </para>
<screen>spark.executor.cores {{ spark_executor_cores }}</screen>
   <para>
    to
   </para>
<screen>spark.executor.cores 2</screen>
  </listitem>
  <listitem>
   <para>
    Edit ~/openstack/my_cloud/config/spark/spark-env.sh.j2
   </para>
   <para>
    <emphasis role="bold">Set SPARK_WORKER_CORES to 2</emphasis>
   </para>
<screen>export SPARK_WORKER_CORES={{ spark_worker_cores }}</screen>
   <para>
    to
   </para>
<screen>export SPARK_WORKER_CORES=2</screen>
  </listitem>
  <listitem>
   <para>
    Edit ~/openstack/my_cloud/config/spark/spark-worker-env.sh.j2
   </para>
   <para>
    <emphasis role="bold">Set SPARK_WORKER_CORES to 2</emphasis>
   </para>
<screen>export SPARK_WORKER_CORES={{ spark_worker_cores }}</screen>
   <para>
    to
   </para>
<screen>export SPARK_WORKER_CORES=2</screen>
  </listitem>
  <listitem>
   <para>
    Run Configuration Processor
   </para>
<screen>&prompt.ardana;cd ~/openstack/my_cloud/definition
&prompt.ardana;git add -A
&prompt.ardana;git commit -m "Changing Spark Config increase scale"
&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
  </listitem>
  <listitem>
   <para>
    Run Ready Deployment
   </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
  </listitem>
  <listitem>
   <para>
    Run spark-reconfigure.yml and monasca-transform-reconfigure.yml
   </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts spark-reconfigure.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-transform-reconfigure.yml</screen>
  </listitem>
 </orderedlist>
</section>
