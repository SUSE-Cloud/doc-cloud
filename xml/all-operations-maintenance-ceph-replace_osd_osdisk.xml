<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<!---->
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="replacing_os_disks">
 <title>Replacing the Operating System Disk in a Ceph OSD Node</title>
 <para>
  Maintenance steps for replacing the operating system disk in a Ceph OSD node.
 </para>
 <orderedlist>
  <listitem>
   <para>
    SSH to the Ceph OSD node with the operating system disk you want to
    replace.
   </para>
  </listitem>
  <listitem>
   <para>
    Use this command to avoid the cluster rebalancing itself while you perform
    the replacement:
   </para>
<screen>ceph osd set noout --cluster <replaceable>CEPH_CLUSTER</replaceable></screen>
  </listitem>
  <listitem>
   <para>
    Log in to the lifecycle manager.
   </para>
  </listitem>
  <listitem>
   <para>
    Use this playbook to stop the services on the OSD node:
   </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit <replaceable>OSD_HOSTNAME</replaceable></screen>
  </listitem>
  <listitem>
   <para>
    Run the following command on the OSD node to activate and mount the disk:
   </para>
<screen>sudo ceph-disk -v activate --activate-key /var/lib/ceph/bootstrap-osd/v_ceph.keyring --mark-init=systemd /dev/<replaceable>DISK</replaceable></screen>
  </listitem>
  <listitem>
   <para>
    Reimage the node using this playbook:
   </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml -e nodelist=<replaceable>SERVER_NAME</replaceable></screen>
   <note>
    <para>
     The <replaceable>SERVER_NAME</replaceable> value will be the value
     corresponding to this node in Cobbler. You can run <command>sudo cobbler
     system list</command> to retrieve these names.
    </para>
   </note>
  </listitem>
  <listitem>
   <para>
    Once the reimage completes, use this playbook to reconfigure the operating
    system:
   </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts osconfig-run.yml --limit <replaceable>HOST_NAME</replaceable></screen>
  </listitem>
  <listitem>
   <para>
    Configure services on the node using this playbook:
   </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-deploy.yml --limit <replaceable>HOST_NAME</replaceable></screen>
  </listitem>
  <listitem>
   <para>
    SSH to the Ceph OSD node and unset the cluster from noout:
   </para>
<screen>ceph osd unset noout --cluster <replaceable>CEPH_CLUSTER</replaceable></screen>
  </listitem>
  <listitem>
   <para>
    Use this command to verify the status of the affected OSD node and ensure
    it returns <literal>up 1</literal>:
   </para>
<screen>ceph osd tree --cluster <replaceable>CLUSTER_NAME</replaceable></screen>
  </listitem>
 </orderedlist>
</section>
