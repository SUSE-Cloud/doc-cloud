<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<!---->
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="replacing_os_disks"><title>Replacing the Operating System Disk in a Ceph
    OSD Node</title><abstract><para><para>Maintenance steps for replacing the operating system
      disk in a Ceph OSD node.</para></para>
</abstract>

    <orderedlist>
      <listitem><para>SSH to the Ceph OSD node with the operating system disk you want to replace. </para>
</listitem>
      <listitem><para>Use this command to avoid the cluster rebalancing itself while you perform the
        replacement: </para>
<screen>ceph osd set noout --cluster &lt;ceph-cluster&gt;</screen></listitem>
      <listitem><para>Log in to the lifecycle manager. </para>
</listitem>
      <listitem><para>Use this playbook to stop the services on the OSD node:
        </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit &lt;osd_hostname&gt;</screen></listitem>
      <listitem><para>Run the following command on the OSD node to activate and mount the disk:
        </para>
<screen>sudo ceph-disk -v activate --activate-key /var/lib/ceph/bootstrap-osd/v_ceph.keyring --mark-init=systemd /dev/&lt;disk&gt;</screen></listitem>
      <listitem><para>Reimage the node using this playbook: </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml -e nodelist=&lt;server_name&gt;</screen></listitem>
      <listitem><para>Once the reimage completes, use this playbook to reconfigure the operating system: </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts osconfig-run.yml --limit &lt;hostname&gt;</screen></listitem>
      <listitem><para>Configure services on the node using this playbook:
        </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-deploy.yml --limit &lt;hostname&gt;</screen></listitem>
      <listitem><para>SSH to the Ceph OSD node and unset the cluster from noout:
        </para>
<screen>ceph osd unset noout --cluster &lt;ceph-cluster&gt;</screen></listitem>
      <listitem><para>Use this command to verify the status of the affected OSD node and ensure it returns
          <literal>up 1</literal>: </para>
<screen>ceph osd tree --cluster &lt;cluster-name&gt;</screen></listitem>
    </orderedlist>


  </section>
