<?xml version="1.0"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [ <!ENTITY % entities SYSTEM "entities.ent"> %entities; ]>
<chapter id="nodes-update">
  <title>Keeping the Nodes Up-To-Date</title>
  <para>
   Keeping the nodes in SUSE OpenStack Cloud Crowbar up-to-date requires
   an appropriate setup of the update and pool repositories and the
   deployment of either the Updater barclamp or the SUSE Manager
   barclamp.
  </para>
  <para>
   If one of those barclamps is deployed, patches are installed on the
   nodes. Patches that do not require a reboot will not cause a service
   interruption. If a patch (for example, a kernel
   update) requires a reboot after the installation, services running on the
   machine that is rebooted will not be available within SUSE OpenStack Cloud.
   Therefore it is strongly recommended to install those patches during a
   maintenance window.
  </para>
  <note>
   <para>
    As of SUSE OpenStack Cloud Crowbar 8, it is not possible to put
    SUSE OpenStack Cloud into <quote>Maintenance Mode</quote>.
   </para>
  </note>
  <variablelist>
   <title>Consequences when Rebooting Nodes</title>
   <varlistentry>
    <term>Administration Server</term>
    <listitem>
     <para>
      While the Administration Server is offline, it is not possible to
      deploy new nodes. However, rebooting the Administration Server has
      no effect on starting instances or on instances already running.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Control Nodes</term>
    <listitem>
     <para>
      The consequences a reboot of a Control Node depend on the
      services running on that node:
     </para>
     <formalpara>
      <title>Database, Keystone, RabbitMQ, Glance, Nova:</title>
      <para>
       No new instances can be started.
      </para>
     </formalpara>
     <formalpara>
      <title>Swift:</title>
      <para>
       No object storage data is available. If Glance uses
       Swift, it will not be possible to start new instances.
      </para>
     </formalpara>
     <formalpara>
      <title>Cinder, Ceph:</title>
      <para>
       No block storage data is available.
      </para>
     </formalpara>
     <formalpara>
      <title>Neutron:</title>
      <para>
       No new instances can be started. On running instances the
       network will be unavailable.
      </para>
     </formalpara>
     <formalpara>
      <title>Horizon</title>
      <para>
       Horizon will be unavailable. Starting and managing instances
       can be done with the command line tools.
      </para>
     </formalpara>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Compute Nodess</term>
    <listitem>
     <para>
      Whenever a Compute Nodes is rebooted, all instances running on
      that particular node will be shut down and must be manually restarted.
      Therefore it is recommended to <quote>evacuate</quote> the node by
      migrating instances to another node, before rebooting it.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <section id="service-order-soc">
  <title>Service Order on SUSE OpenStack Cloud Start-up or Shutdown</title>
  <para>
   In case you need to restart your complete SUSE OpenStack Cloud (after a complete shut
   down or a power outage), ensure that the external Ceph cluster is started,
   available and healthy. Start then the nodes and services in the
   following order:
  </para>
  <orderedlist>
   <listitem>
    <para>
     Control Node/Cluster on which the Database is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which RabbitMQ is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which Keystone is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     For Swift:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Storage Node on which the <literal>swift-storage</literal> role is deployed
      </para>
     </listitem>
     <listitem>
      <para>
       Storage Node on which the <literal>swift-proxy</literal> role is deployed
      </para>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Any remaining Control Node/Cluster. The following additional rules apply:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       The Control Node/Cluster on which the <literal>neutron-server</literal>
       role is deployed needs to be started before starting the node/cluster
       on which the <literal>neutron-l3</literal> role is deployed.
      </para>
     </listitem>
     <listitem>
      <para>
       The Control Node/Cluster on which the <literal>nova-controller</literal>
       role is deployed needs to be started before starting the node/cluster
       on which Heat is deployed.
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Compute Nodess
    </para>
   </listitem>
  </orderedlist>
  <para>
   If multiple roles are deployed on a single Control Node, the services are
   automatically started in the correct order on that node. If you have more
   than one node with multiple roles, make sure they are
   started as closely as possible to the order listed above.
  </para>
  <para>
   If you need to shut down SUSE OpenStack Cloud, the nodes and services need to be
   terminated in reverse order than on start-up:
  </para>
  <orderedlist>
   <listitem>
    <para>
     Compute Nodess
    </para>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which Heat is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which the <literal>nova-controller</literal>
     role is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which the <literal>neutron-l3</literal>
     role is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     All Control Node(s)/Cluster(s) on which neither of the following services
     is deployed: Database, RabbitMQ, and Keystone.
    </para>
   </listitem>
   <listitem>
    <para>
     For Swift:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Storage Node on which the <literal>swift-proxy</literal> role is
       deployed
      </para>
     </listitem>
     <listitem>
      <para>
       Storage Node on which the <literal>swift-storage</literal> role is
       deployed
      </para>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which Keystone is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which RabbitMQ is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     Control Node/Cluster on which the Database is deployed
    </para>
   </listitem>
   <listitem>
    <para>
     If required, gracefully shut down an external Ceph cluster
    </para>
   </listitem>
  </orderedlist>
 </section>

 <section id="upgrade-soc-7-to-8">
  <title>Upgrading from SUSE OpenStack Cloud Crowbar 7 to SUSE OpenStack Cloud Crowbar 8</title>
  <para>
   Upgrading from SUSE OpenStack Cloud Crowbar 7 to SUSE OpenStack Cloud Crowbar 8 can be done either via a
   GUI or from the command line. The non-disruptive upgrade provides a
   fully-functional SUSE OpenStack Cloud operation during most of the upgrade procedure.
  </para>
  <para>
   If the requirements for a non-disruptive upgrade are not met, the
   upgrade procedure will be done in normal mode. When
   live-migration is set up, instances will be migrated to another node
   before the respective Compute Nodes is updated to ensure continuous
   operation.
 </para>
  <important>
    <para>
      Make sure that the STONITH mechanism in your cloud does not rely on the
      state of the Administration Server (for example, no SBD devices are located there,
      and IPMI is not using the network connection relying on the
      Administration Server). Otherwise, this may affect the clusters when the Administration Server is
      rebooted during the upgrade procedure.
     </para>
    </important>

  <section id="upgrade-requirements">
   <title>Requirements</title>
   <para>
    When starting the upgrade process, several checks are performed to
    determine whether the SUSE OpenStack Cloud is in an upgradeable state and whether a
    non-disruptive update would be supported:
   </para>
   <itemizedlist>
    <title>General Upgrade Requirements</title>
    <listitem>
     <para>
      All nodes need to have the latest SUSE OpenStack Cloud Crowbar 7 updates <emphasis
      role="bold">and</emphasis> the latest &slsa; 12 SP2 updates installed.
     </para>
    </listitem>
    <listitem>
     <para>
      All allocated nodes need to be turned on and have to be in state
      <quote>ready</quote>.
     </para>
    </listitem>
    <listitem>
     <para>
      All &barcl; proposals need to have been successfully deployed. If a
      proposal is in state <quote>failed</quote>, the upgrade procedure will
      refuse to start. Fix the issue or&mdash;if possible&mdash;remove the
      proposal.
     </para>
    </listitem>
    <listitem>
     <para>
      If the &pacemaker; &barcl; is deployed, all clusters
      need to be in a healthy state.
     </para>
    </listitem>
    <listitem>
     <para> The upgrade will not start when Ceph is deployed via &crow;. Only
     external Ceph is supported. Documentation for &ses; is available at
    <!--  <link xlink:href="https://www.suse.com/documentation/suse-enterprise-storage-5">SUSE Enterprise Storage 5</link>. -->
     </para>
    </listitem>
    <listitem>
     <para>
      At this time, upgrade is only possible if the <literal>SQL
      Engine</literal> in the <literal>Database</literal> &barcl; is set to
      <guimenu>MariaDB</guimenu>. Migration from PostgreSQL-based setups will
      be provided in a future maintenance update.
     </para>
    </listitem>
    <listitem>
     <para>
      The following repositories need to be available on a server that is
      accessible from the Administration Server. The HA repositories are only needed if you
      have an &hasetup;. It is recommended to use the same server that also
      hosts the respective repositories of the current version.
     </para>
     <simplelist>
      <member><literal>SUSE-OpenStack-Cloud-Crowbar-8-Pool</literal></member>
      <member><literal>SUSE-OpenStack-Cloud-Crowbar-8-Update</literal></member>
      <member><literal>SLES12-SP3-Pool</literal></member>
      <member><literal>SLES12-SP3-Update</literal></member>
      <member><literal>SLE12-SP3-HA-Pool</literal> (for HA setups only)</member>
      <member><literal>SLE12-SP3-HA-Update</literal> (for HA setups only)</member>
     </simplelist>
     <important>
      <para>
      Do not add repositories to the SUSE OpenStack Cloud repository configuration. This
      needs to be done during the upgrade procedure.
      </para>
     </important>
    </listitem>
    <listitem>
     <para>
       A non-disruptive upgrade is not supported if Cinder has been
       deployed with the <literal>raw devices</literal> or <literal>local
       file</literal> back-end. In this case, you have to perform a regular
       upgrade, or change the Cinder back-end for a non-disruptive
       upgrade.
     </para>
    </listitem>
    <listitem>
     <para>
       If &ses; is now deployed using &crow;, it should be migrated to an
       external cluster. You may want to upgrade &ses;, refer to
    <!--   <link xlink:href="https://www.suse.com/documentation/suse-enterprise-storage-5/book_storage_deployment/data/ceph_upgrade_4to5crowbar.html">&ses; Upgrade Instructions</link>. -->
     </para>
    </listitem>
   </itemizedlist>
   <itemizedlist>
    <title>Non-Disruptive Upgrade Requirements</title>
    <listitem>
     <para>
      All Control Nodes need to be set up highly available.
     </para>
    </listitem>
    <listitem>
     <para>
      A non-disruptive upgrade is not supported if the Cinder
      has been deployed with the <literal>raw devices</literal> or
      <literal>local file</literal> back-end. In this case, you have to perform
      a regular upgrade, or change the Cinder back-end for a
      non-disruptive upgrade.
     </para>
    </listitem>
    <listitem>
     <para>
      A non-disruptive upgrade is prevented if the
      <literal>cinder-volume</literal> service is placed on Compute Nodes. For a
      non-disruptive upgrade, <literal>cinder-volume</literal> should either be
      HA-enabled or placed on non-compute nodes.
     </para>
    </listitem>
    <listitem>
     <para>
      A non-disruptive upgrade is prevented if <literal>manila-share</literal>
      service is placed on a Compute Nodes. For more information, see
<!--      <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-8/book_deployment/data/sec_depl_ostack_manila.html">Deploying Manila</link>. -->
     </para>
    </listitem>
    <listitem>
     <para>
      Live-migration support needs to be configured and enabled for the
      Compute Nodess. The amount of free resources (CPU and RAM) on the
      Compute Nodess needs to be sufficient to evacuate the nodes one by one.
     </para>
    </listitem>
    <listitem>
     <para>
       In case of a non-disruptive upgrade, &o_img; must be configured as a
       shared storage if the <guimenu>Default Storage
       Store</guimenu> value in the &o_img; is set to <literal>File</literal>.
     </para>
    </listitem>
    <listitem>
     <para>
       For a non-disruptive upgrade, only KVM-based Compute Nodess with
       the <literal>nova-computer-kvm</literal> role are allowed in SUSE OpenStack Cloud Crowbar 7.
     </para>
    </listitem>
    <listitem>
     <para>
       Non-disruptive upgrade is limited to the following cluster
       configurations:
     </para>
       <itemizedlist>
       <listitem>
         <para>
           Single cluster that has all supported controller roles on it
         </para>
       </listitem>
       <listitem>
         <para>
          Two clusters where one only has
          <systemitem>neutron-network</systemitem> and the other one has the
          rest of the controller roles.
         </para>
       </listitem>
       <listitem>
         <para>
          Two clusters where one only has
          <systemitem>neutron-server</systemitem> plus
          <systemitem>neutron-network</systemitem> and the other one has the
          rest of the controller roles.
         </para>
       </listitem>
       <listitem>
         <para>
           Two clusters, where one cluster runs the database and RabbitMQ
         </para>
       </listitem>
       <listitem>
         <para>
           Three clusters, where one cluster runs database and RabbitMQ,
           another cluster runs APIs, and the third cluster has the
           <systemitem>neutron-network</systemitem> role.
         </para>
       </listitem>
       </itemizedlist>
       <para>
       If your cluster configuration is not supported by the non-disruptive
       upgrade procedure, you can still perform a normal upgrade.
     </para>
    </listitem>
   </itemizedlist>
  <section id="upgrade-web-interface">
   <title>Upgrading Using the Web Interface</title>
   <para>
    The &wi; features a wizard that guides you through the upgrade
    procedure.
   </para>
   <note>
    <para>
     You can cancel the upgrade process by clicking <guimenu>Cancel
     Upgrade</guimenu>. Note that the upgrade operation can be canceled only
     before the Administration Server upgrade is started. When the upgrade has been
     canceled, the nodes return to the ready state. However any user
     modifications must be undone manually. This includes reverting repository
     configuration.
    </para>
   </note>
   <procedure>
    <step>
     <para>
      To start the upgrade procedure, open the &crow; &wi; on the Administration Server and choose <menuchoice>
      <guimenu>Utilities</guimenu> <guimenu>Upgrade</guimenu>
      </menuchoice>. Alternatively, point the browser directly to the upgrade
      wizard on the Administration Server, for example
      <literal>http://192.168.124.10/upgrade/</literal>.
     </para>
    </step>
    <step>
     <para>
      On the first screen of the &wi; you will run preliminary checks, get
      information about the upgrade mode and start the upgrade process.
     </para>
     <informalfigure>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="depl_upgrade7-8_prepare.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="depl_upgrade7-8_prepare.png"/>
       </imageobject>
      </mediaobject>
     </informalfigure>
    </step>
    <step>
     <para>
      Perform the preliminary checks to determine whether the upgrade
      requirements are met by clicking <guimenu>Check</guimenu> in
      <literal>Preliminary Checks</literal>.
     </para>
     <para>
      The &wi; displays the progress of the checks. Make sure all checks are
      passed (you should see a green marker next to each check). If errors
      occur, fix them and run the <guimenu>Check</guimenu> again. Do not
      proceed until all checks are passed.
     </para>
    </step>
    <step>
     <para>
      When all checks in the previous step have passed, <literal>Upgrade
      Mode</literal> shows the result of the upgrade analysis. It will indicate
      whether the upgrade procedure will continue in non-disruptive or in
      normal mode.
     </para>
    </step>
    <step>
     <para>
      To start the upgrade process, click <guimenu>Begin Upgrade</guimenu>.
     </para>
    </step>
    <step>
     <para>
      While the upgrade of the Administration Server is prepared, the upgrade wizard
      prompts you to <guimenu>Download the Backup of the
      Administration Server</guimenu>. When the backup is done, move it to a safe place. If
      something goes wrong during the upgrade procedure of the Administration Server, you
      can restore the original state from this backup using the
      <command>crowbarctl backup restore
      <replaceable>NAME</replaceable></command> command.
     </para>
    </step>
    <step>
     <para>
      Check that the repositories required for upgrading the Administration Server are
      available and updated. To do this, click the <guimenu>Check</guimenu>
      button. If the checks fail, add the software repositories as described in
<!--      <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-8/book_deployment/data/cha_depl_repo_conf.html">Software Repository Setup</link> -->
      of the Deployment Guide. Run the checks again, and click <guimenu>Next</guimenu>.
     </para>
     <informalfigure>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="depl_upgrade7-8_repocheck-admin.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="depl_upgrade7-8_repocheck-admin.png"/>
       </imageobject>
      </mediaobject>
     </informalfigure>
    </step>

    <step>
      <para>
        Click <guimenu>Upgrade Administration Server</guimenu> to upgrade and
        reboot the admin node. Note that this operation may take a while. When
        the Administration Server has been updated, click <guimenu>Next</guimenu>.
      </para>
     <informalfigure>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="depl_upgrade7-8_admin.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="depl_upgrade7-8_admin.png"/>
       </imageobject>
      </mediaobject>
     </informalfigure>
    </step>
    <step>
     <para>
      Check that the repositories required for upgrading all nodes are
      available and updated.  To do this click the <guimenu>Check</guimenu>
      button. If the check fails, add the software repositories as described in
<!--      <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-8/book_deployment/data/cha_depl_repo_conf.html">Software Repository Setup</link> -->
      of the Deployment Guide. Run the checks again, and click <guimenu>Next</guimenu>.
     </para>
     <informalfigure>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="depl_upgrade7-8_repocheck-nodes.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="depl_upgrade7-8_repocheck-nodes.png"/>
       </imageobject>
      </mediaobject>
     </informalfigure>
    </step>
    <step>
     <para>
      Stop the OpenStack services. Before you proceed, be aware that no changes
      can be made to your cloud during and after stopping the services. The
      OpenStack API will not be available until the upgrade process is
      completed. When you are ready, click <guimenu>Stop
      Services</guimenu>. Wait until the services are stopped and click
      <guimenu>Next</guimenu>.
      </para>
    </step>
    <step>
      <para>
        Before upgrading the nodes, the wizard prompts you to <guimenu>Back up
        OpenStack Database</guimenu>. The MariaDB database backup will be
        stored on the Administration Server. It can be used to restore the database in case
        something goes wrong during the upgrade. To back up the database, click
        <guimenu>Create Backup</guimenu>. When the backup operation is
        finished, click <guimenu>Next</guimenu>.
      </para>
    </step>
    <step>
      <para>
        Start the upgrade by clicking <guimenu>Upgrade Nodes</guimenu>. The
        number of nodes determines how long the upgrade process will take. When
        the upgrade is completed, press <guimenu>Finish</guimenu> to return to
        the Dashboard.
      </para>
     <informalfigure>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="depl_upgrade7-8_finished.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="depl_upgrade7-8_finished.png"/>
       </imageobject>
      </mediaobject>
     </informalfigure>
    </step>
   </procedure>
   <note>
   <para>
    With this first maintenance update, only systems already using MariaDB as
    their OpenStack database will be able to upgrade.  In a future maintenance
    update, there will be a way to migrate from PostgreSQL to MariaDB so
    PostgreSQL users will be able to upgrade.
   </para>
   </note>
   <note>
    <para>
     If an error occurs during the upgrade process, the wizard displays a
     message with a description of the error and a possible solution. After
     fixing the error, re-run the step where the error occurred.
    </para>
   </note>
  <section id="upgrade-command-line">
   <title>Upgrading from the Command Line</title>
   <para>
    The upgrade procedure on the command line is performed by using the program
    <command>crowbarctl</command>. For general help, run <command>crowbarctl
    help</command>. To get help on a certain subcommand, run
    <command>crowbarctl <replaceable>COMMAND</replaceable> help</command>.
   </para>
   <para>
    To review the process of the upgrade procedure, you may call
    <command>crowbarctl upgrade status</command> at any time. Steps may have
    three states: <literal>pending</literal>, <literal>running</literal>, and
    <literal>passed</literal>.
   </para>
   <procedure>
    <step>
     <para>
      To start the upgrade procedure from the command line, log in to the
      Administration Server as root.
     </para>
    </step>
    <step>
     <para>
      Perform the preliminary checks to determine whether the upgrade
      requirements are met:
     </para>
     <screen>root # crowbarctl upgrade prechecks</screen>
     <para>
      The command's result is shown in a table. Make sure the column
      <guimenu>Errors</guimenu> does not contain any entries. If there are
      errors, fix them and restart the <command>precheck</command> command
      afterwards. Do not proceed before all checks are passed.
     </para>
<screen>root # crowbarctl upgrade prechecks
+-------------------------------+--------+----------+--------+------+
| Check ID                      | Passed | Required | Errors | Help |
+-------------------------------+--------+----------+--------+------+
| network_checks                | true   | true     |        |      |
| cloud_healthy                 | true   | true     |        |      |
| maintenance_updates_installed | true   | true     |        |      |
| compute_status                | true   | false    |        |      |
| ha_configured                 | true   | false    |        |      |
| clusters_healthy              | true   | true     |        |      |
+-------------------------------+--------+----------+--------+------+</screen>
     <para>
      Depending on the outcome of the checks, it is automatically decided
      whether the upgrade procedure will continue in non-disruptive or in
      normal mode.
     </para>
     <tip>
      <para>
       The non-disruptive update will take longer than an upgrade in normal
       mode, because it performs certain tasks in parallel which are done
       sequentially during the non-disruptive upgrade. Live-migrating guests to
       other Compute Nodess during the non-disruptive
       upgrade takes additional time.
      </para>
      <para>
       Therefore, if a non-disruptive upgrade is not a requirement for you, you
       may want to switch to the normal upgrade mode, even if your setup
       supports the non-disruptive method. To force the normal upgrade mode,
       run:
      </para>
      <screen>root # crowbarctl upgrade mode normal</screen>
      <para>
       To query the current upgrade mode run:
      </para>
      <screen>root # crowbarctl upgrade mode</screen>
      <para>
       To switch back to the non-disruptive mode run:
      </para>
      <screen>root # crowbarctl upgrade mode non_disruptive</screen>
      <para>
       It is possible to call this command at any time during the upgrade
       process until the <literal>services</literal> step is started. After
       that point the upgrade mode can no longer be changed.
      </para>
     </tip>
    </step>
    <step>
     <para>
      Prepare the nodes by transitioning them into the <quote>upgrade</quote>
      state and stopping the chef daemon:
     </para>
     <screen>root # crowbarctl upgrade prepare</screen>
     <para>
      Depending of the size of your SUSE OpenStack Cloud deployment, this step may take
      some time. Use the command <command>crowbarctl upgrade status</command>
      to monitor the status of the process named
      <literal>steps.prepare.status</literal>. It needs to be in state
      <literal>passed</literal> before you proceed:
     </para>
     <screen>root # crowbarctl upgrade status
+--------------------------------+----------------+
| Status                         | Value          |
+--------------------------------+----------------+
| current_step                   | backup_crowbar |
| current_substep                |                |
| current_substep_status         |                |
| current_nodes                  |                |
| current_node_action            |                |
| remaining_nodes                |                |
| upgraded_nodes                 |                |
| crowbar_backup                 |                |
| openstack_backup               |                |
| suggested_upgrade_mode         | non_disruptive |
| selected_upgrade_mode          |                |
| compute_nodes_postponed        | false          |
| steps.prechecks.status         | passed         |
| steps.prepare.status           | passed         |
| steps.backup_crowbar.status    | pending        |
| steps.repocheck_crowbar.status | pending        |
| steps.admin.status             | pending        |
| steps.repocheck_nodes.status   | pending        |
| steps.services.status          | pending        |
| steps.backup_openstack.status  | pending        |
| steps.nodes.status             | pending        |
+--------------------------------+----------------+</screen>
    </step>
    <step>
     <para>
      Create a backup of the existing Administration Server installation. In case something
      goes wrong during the upgrade procedure of the Administration Server you can restore
      the original state from this backup with the command <command>crowbarctl
      backup restore <replaceable>NAME</replaceable></command>
     </para>
     <screen>root # crowbarctl upgrade backup crowbar</screen>
     <para>
      To list all existing backups including the one you have just created, run
      the following command:
     </para>
     <screen>root # crowbarctl backup list
+----------------------------+--------------------------+--------+---------+
| Name                       | Created                  | Size   | Version |
+----------------------------+--------------------------+--------+---------+
| crowbar_upgrade_1534864741 | 2018-08-21T15:19:03.138Z | 219 KB | 4.0     |
+----------------------------+--------------------------+--------+---------+</screen>
    </step>
    <step>
     <para>
      This step prepares the upgrade of the Administration Server by checking the
      availability of the update and pool repositories for SUSE OpenStack Cloud Crowbar
      &productnumber; and &cloudos;. Run the following command:
     </para>
     <screen>root # crowbarctl upgrade repocheck crowbar
+---------------------+----------------------------------------+
| Status              | Value                                  |
+---------------------+----------------------------------------+
| os.available        | false                                  |
| os.repos            | SLES12-SP4-Pool                        |
|                     | SLES12-SP4-Updates                     |
| openstack.available | false                                  |
| openstack.repos     | SUSE-OpenStack-Cloud-Crowbar-9-Pool    |
|                     | SUSE-OpenStack-Cloud-Crowbar-9-Updates |
+---------------------+----------------------------------------+</screen>
     <para>
      All four required repositories are reported as missing, because they have
      not yet been added to the &crow; configuration. To add them to the
      Administration Server proceed as follows.
     </para>
     <para>
      Note that this step is for setting up the repositories for the Administration Server,
      not for the nodes in SUSE OpenStack Cloud (this will be done in a subsequent step).
     </para>
     <substeps>
      <step>
       <para>
        Start <command>yast repositories</command> and proceed with
        <guimenu>Continue</guimenu>. Replace the repositories
        <literal>SLES12-SP3-Pool</literal> and
        <literal>SLES12-SP3-Updates</literal> with the respective SP4
        repositories.
       </para>
       <para>
        If you prefer to use zypper over &yast;, you may alternatively make the
        change using <command>zypper mr</command>.
       </para>
      </step>
      <step>
       <para>
        Next, replace the <literal>SUSE-OpenStack-Cloud-7</literal> update and
        pool repositories with the respective SUSE OpenStack Cloud Crowbar 8 versions.
       </para>
      </step>
      <step>
       <para>
        Check for other (custom) repositories. All &slsa; SP3 repositories need
        to be replaced with the respective &slsa; SP4 version. In case no SP3
        version exists, disable the repository&mdash;the respective packages
        from that repository will be deleted during the upgrade.
       </para>
      </step>
     </substeps>
     <para>
      Once the repository configuration on the Administration Server has been updated, run
      the command to check the repositories again. If the configuration is
      correct, the result should look like the following:
     </para>
     <screen>root # crowbarctl upgrade repocheck crowbar
+---------------------+----------------------------------------+
| Status              | Value                                  |
+---------------------+----------------------------------------+
| os.available        | true                                   |
| os.repos            | SLES12-SP4-Pool                        |
|                     | SLES12-SP4-Updates                     |
| openstack.available | true                                   |
| openstack.repos     | SUSE-OpenStack-Cloud-Crowbar-9-Pool    |
|                     | SUSE-OpenStack-Cloud-Crowbar-9-Updates |
+---------------------+----------------------------------------+</screen>
    </step>
    <step>
     <para>
      Now that the repositories are available, the Administration Server itself will be
      upgraded. The update will run in the background using <command>zypper
      dup</command>. Once all packages have been upgraded, the Administration Server will
      be rebooted and you will be logged out. To start the upgrade run:
     </para>
     <screen>root # crowbarctl upgrade admin</screen>
    </step>
    <step>
     <para>
      After the Administration Server has been successfully updated, the Control Nodes and
      Compute Nodess will be upgraded. At first the availability of the
      repositories used to provide packages for the SUSE OpenStack Cloud nodes is tested.
     </para>
     <note>
       <para>
         When adding new repositories to the nodes, make sure that the new PTF
         repository also contains correct metadata (even if it is empty). To do
         this, run the <command>createrepo-cloud-ptf</command> command.
       </para>
     </note>
     <para>
      Note that the configuration for these repositories differs from the one
      for the Administration Server that was already done in a previous step. In this step
      the repository locations are made available to &crow; rather than to
      libzypp on the Administration Server. To check the repository configuration run the
      following command:
     </para>
     <screen>root # crowbarctl upgrade repocheck nodes
+---------------------------------+----------------------------------------+
| Status                          | Value                                  |
+---------------------------------+----------------------------------------+
| ha.available                    | false                                  |
| ha.repos                        | SLES12-SP4-HA-Pool                     |
|                                 | SLES12-SP4-HA-Updates                  |
| ha.errors.x86_64.missing        | SLES12-SP4-HA-Pool                     |
|                                 | SLES12-SP4-HA- Updates                 |
| os.available                    | false                                  |
| os.repos                        | SLES12-SP4-Pool                        |
|                                 | SLES12-SP4-Updates                     |
| os.errors.x86_64.missing        | SLES12-SP4-Pool                        |
|                                 | SLES12-SP4-Updates                     |
| openstack.available             | false                                  |
| openstack.repos                 | SUSE-OpenStack-Cloud-Crowbar-9-Pool    |
|                                 | SUSE-OpenStack-Cloud-Crowbar-9-Updates |
| openstack.errors.x86_64.missing | SUSE-OpenStack-Cloud-Crowbar-9-Pool    |
|                                 | SUSE-OpenStack-Cloud-Crowbar-9-Updates |
+---------------------------------+----------------------------------------+</screen>
     <para>
      To update the locations for the listed repositories, start <command>yast
      crowbar</command> and proceed as described in <!--<link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-8/book_deployment/data/sec_depl_adm_inst_crowbar_repos.html">Repositories</link>.-->
     </para>
     <para>
      Once the repository configuration for &crow; has been updated, run the
      command to check the repositories again to determine, whether the current
      configuration is correct.
     </para>
     <screen>root # crowbarctl upgrade repocheck nodes
+---------------------+----------------------------------------+
| Status              | Value                                  |
+---------------------+----------------------------------------+
| ha.available        | true                                   |
| ha.repos            | SLE12-SP4-HA-Pool                      |
|                     | SLE12-SP4-HA-Updates                   |
| os.available        | true                                   |
| os.repos            | SLES12-SP4-Pool                        |
|                     | SLES12-SP4-Updates                     |
| openstack.available | true                                   |
| openstack.repos     | SUSE-OpenStack-Cloud-Crowbar-9-Pool    |
|                     | SUSE-OpenStack-Cloud-Crowbar-9-Updates |
+---------------------+----------------------------------------+</screen>

     <important>
      <para>
       If the upgrade is done in normal mode (prechecks compute_status and
       ha_configured have not been passed), you need to shut down all running
       instances now.
      </para>
     </important>
     <important>
      <para>
       To PXE boot new nodes, an additional &cloudos; repository&mdash;a copy
       of the installation system&mdash; is required. Although not required
       during the upgrade procedure, it is recommended to set up this directory
       now. Refer to<!-- <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-8/book_deployment/data/sec_depl_adm_conf_repos_product.html">Copying the Product Media Repositories</link> -->
       for details. If you had also copied the SUSE OpenStack Cloud Crowbar 6 installation media
       (optional), you may also want to provide the SUSE OpenStack Cloud Crowbar
       8 the same way.
      </para>
      <para>
       Once the upgrade procedure has been successfully finished, you may
       delete the previous copies of the installation media in
       <filename>/srv/tftpboot/suse-12.2/x86_64/install</filename> and
       <filename>/srv/tftpboot/suse-12.2/x86_64/repos/Cloud</filename>.
      </para>
     </important>
    </step>
    <step>
     <para>
      To ensure the status of the nodes does not change during the upgrade
      process, the majority of the OpenStack services will be stopped on the
      nodes. As a result, the OpenStack API will no longer be
      accessible. The instances, however, will continue to run and will also
      be accessible. Run the following command:
     </para>
     <screen>root # crowbarctl upgrade services</screen>
     <para>
      This step takes a while to finish. Monitor the process by running
      <command>crowbarctl upgrade status</command>. Do not proceed before
      <literal>steps.services.status</literal> is set to
      <literal>passed</literal>.
     </para>
    </step>
    <step>
     <para>
      The last step before upgrading the nodes is to make a backup of the
      OpenStack PostgreSQL database. The database dump will be stored on the
      Administration Server and can be used to restore the database in case something goes
      wrong during the upgrade.
     </para>
     <screen>root # crowbarctl upgrade backup openstack</screen>
    </step>
    <step>
     <para>
      The final step of the upgrade procedure is upgrading the
      nodes.  To start the process, enter:
     </para>
     <screen>root # crowbarctl upgrade nodes all</screen>
     <para>
      The upgrade process runs in the background and can be queried with
      <command>crowbarctl upgrade status</command>. Depending on the size of
      your SUSE OpenStack Cloud it may take several hours, especially when performing a
      non-disruptive update. In that case, the Compute Nodess are updated
      one-by-one after instances have been live-migrated to other nodes.
     </para>
     <para>
      Instead of upgrading all nodes you may also upgrade
      the Control Nodes first and individual Compute Nodess afterwards. Refer to
      <command>crowbarctl upgrade nodes --help</command> for details. If you
      choose this approach, you can use the <command>crowbarctl upgrade
      status</command> command to monitor the upgrade process. The output of
      this command contains the following entries:
     </para>
      <variablelist>
        <varlistentry>
          <term>
            current_node_action
          </term>
        <listitem>
          <para>
            The current action applied to the node.
          </para>
        </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            current_substep
          </term>
        <listitem>
          <para>
            Shows the current substep of the node upgrade step. For example,
            for the <command>crowbarctl upgrade nodes controllers</command>,
            the <literal>current_substep</literal> entry displays the
            <literal>controller_nodes</literal> status when upgrading controllers.
          </para>
        </listitem>
        </varlistentry>
      </variablelist>
     <para>
       After the controllers have been upgraded, the
       <literal>steps.nodes.status</literal> entry in the output displays the
       <literal>running</literal> status. Check then the status of the
       <literal>current_substep_status</literal> entry. If it displays
       <literal>finished</literal>, you can move to the next step of upgrading
       the Compute Nodess.
     </para>
     <para>
      <emphasis role="bold">Postponing the Upgrade</emphasis>
     </para>
     <para>
      It is possible to stop the upgrade of compute nodes and postpone their
      upgrade with the command:
     </para>
     <screen>root # crowbarctl upgrade nodes postpone</screen>
     <para>
      After the upgrade of compute nodes is postponed, you can go to &crow;
      &wi;, check the configuration. You can also apply some changes, provided
      they do not affect the Compute Nodess. During the postponed upgrade, all
      OpenStack services should be up and running. Compute Nodess are still
      running old version of services.
     </para>
     <para>
      To resume the upgrade, issue the command:
     </para>
     <screen>root # crowbarctl upgrade nodes resume</screen>
     <para>
      And finish the upgrade with either <command>crowbarctl upgrade nodes
      all</command> or upgrade nodes one node by one with <command>crowbarctl
      upgrade nodes <replaceable>NODE_NAME</replaceable></command>.
     </para>
     <para>
       When upgrading individual Compute Nodess using the <command>crowbarctl
       upgrade nodes</command> <replaceable>NODE_NAME</replaceable> command, the
       <literal>current_substep_status</literal> entry changes to
       <literal>node_finished</literal> when the upgrade of a single node is
       done. After all nodes have been upgraded, the
       <literal>current_substep_status</literal> entry displays <literal>finished</literal>.
     </para>
    </step>
   </procedure>
   <note>
    <para>
     If an error occurs during the upgrade process, the output of the
     <command>crowbarctl upgrade status</command> provides a detailed
     description of the failure. In most cases, both the output and the error
     message offer enough information for fixing the issue. When the problem has
     been solved, run the previously-issued upgrade command to resume the
     upgrade process.
    </para>
   </note>
 </section>
</section>
</section>
</section>

 <section id="recover-compute-node-failure">
  <title>Recovering from Compute Nodes Failure</title>
  <para>
   The following procedure assumes that there is at least one Compute Nodes
   already running. Otherwise, see
<!--   <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-8/book_deployment/data/sec_depl_maintenance_bootstrap_compute_plane.html">Bootstrapping Compute Plane</link>. -->
  </para>
  <procedure>
   <title>Procedure for Recovering from Compute Nodes Failure</title>
   <step>
    <para>
     If the Compute Nodes failed, it should have been fenced. Verify that this is
     the case. Otherwise, check <filename>/var/log/pacemaker.log</filename> on
     the &dc; to determine why the Compute Nodes was not fenced.
     The most likely reason is a problem with STONITH devices.
    </para>
   </step>
   <step>
    <para>
     Determine the cause of the Compute Nodes's failure.
    </para>
   </step>
   <step>
    <para>
     Rectify the root cause.
    </para>
   </step>
   <step>
    <para>
     Boot the Compute Nodes again.
    </para>
   </step>
   <step>
    <para>
     Check whether the <systemitem>crowbar_join</systemitem> script ran
     successfully on the Compute Nodes. If this is not the case, check the log
     files to find out the reason. Refer to
  <!--   <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-8/book_deployment/data/sec_deploy_logs_crownodes.html">On All Other Crowbar Nodes</link> -->
     to find the exact location of the log file.
    </para>
   </step>
   <step>
    <para>
     If the <systemitem>chef-client</systemitem> agent triggered by
     <systemitem>crowbar_join</systemitem> succeeded, confirm that the
     <systemitem>pacemaker_remote</systemitem> service is up and running.
    </para>
   </step>
   <step>
    <para>
     Check whether the remote node is registered and considered healthy by the
     core cluster. If this is not the case check
     <filename>/var/log/pacemaker.log</filename> on the &dc;
     to determine the cause. There should be a remote primitive running on the
     core cluster (active/passive). This primitive is responsible for
     establishing a TCP connection to the
     <systemitem>pacemaker_remote</systemitem> service on port 3121 of the
     Compute Nodes. Ensure that nothing is preventing this particular TCP
     connection from being established (for example, problems with NICs,
     switches, firewalls etc.). One way to do this is to run the following
     commands:
    </para>
<screen>tux > lsof -i tcp:3121
tux > tcpdump tcp port 3121
</screen>
   </step>
   <step>
    <para>
     If Pacemaker can communicate with the remote node, it should start the
     <systemitem>nova-compute</systemitem> service on it as part of the cloned
     group <literal>cl-g-nova-compute</literal> using the NovaCompute OCF
     resource agent. This cloned group will block startup of
     <systemitem>nova-evacuate</systemitem> until at least one clone is
     started.
    </para>
   </step>
   <step>
    <para>
     It may happen that <systemitem>NovaCompute</systemitem> has been launched
     correctly on the Compute Nodes by <systemitem>lrmd</systemitem>, but the
     <systemitem>openstack-nova-compute</systemitem> service is still not
     running. This usually happens when <systemitem>nova-evacuate</systemitem>
     did not run correctly.
    </para>
    <para>
     If <systemitem>nova-evacuate</systemitem> is not
     running on one of the core cluster nodes, make sure that the service is
     marked as started (<literal>target-role="Started"</literal>). If this is
     the case, then your cloud does not have any Compute Nodess already running as
     assumed by this procedure.
    </para>
    <para>
     If <systemitem>nova-evacuate</systemitem> is started but it is
     failing, check the Pacemaker logs to determine the cause.
    </para>
    <para>
     If <systemitem>nova-evacuate</systemitem> is started and
     functioning correctly, it should call &o_comp;'s
     <literal>evacuate</literal> API to release resources used by the
     Compute Nodes and resurrect elsewhere any VMs that died when it failed.
    </para>
   </step>
   <step>
    <para>
     If <systemitem>openstack-nova-compute</systemitem> is running, but VMs are
     not booted on the node, check that the service is not disabled or
     forced down using the <command>nova service-list</command> command. In
     case the service is disabled, run the <command>nova service-enable
     <replaceable>SERVICE_ID</replaceable></command> command. If the service is
     forced down, run the following commands:
    </para>
<screen>tux >;fence_nova_param () {
    key="$1"
    cibadmin -Q -A "//primitive[@id='fence-nova']//nvpair[@name='$key']" | \
    sed -n '/.*value="/{s///;s/".*//;p}'
}
tux > fence_compute \
    --auth-url=`fence_nova_param auth-url` \
    --endpoint-type=`fence_nova_param endpoint-type` \
    --tenant-name=`fence_nova_param tenant-name` \
    --domain=`fence_nova_param domain` \
    --username=`fence_nova_param login` \
    --password=`fence_nova_param passwd` \
    -n <replaceable>COMPUTE_HOSTNAME</replaceable> \
    --action=on
</screen>
   </step>
 </procedure>
  <para>
   The above steps should be performed automatically after the node is
   booted. If that does not happen, try the following debugging techniques.
  </para>
  <para>
   Check the <literal>evacuate</literal> attribute for the Compute Nodes in the
   &pacemaker; cluster's <systemitem>attrd</systemitem> service using the
   command:
  </para>
<screen>tux > attrd_updater -p -n evacuate -N <replaceable>NODE</replaceable></screen>
  <para>
   Possible results are the following:
  </para>
  <itemizedlist>
   <listitem>
    <para>The attribute is not set.
    </para>
   </listitem>
   <listitem>
    <para>
     The attribute is set to <literal>yes</literal>. This means that the
     Compute Nodes was fenced, but <systemitem>nova-evacuate</systemitem> never
     initiated the recovery procedure by calling &o_comp;'s evacuate API.
    </para>
   </listitem>
   <listitem>
    <para>
     The attribute contains a time stamp, in which case the recovery procedure
     was initiated at the time indicated by the time stamp, but has not
     completed yet.
    </para>
   </listitem>
   <listitem>
    <para>
     If the attribute is set to <literal>no</literal>, the recovery procedure
     recovered successfully and the cloud is ready for the Compute Nodes to
     rejoin.
    </para>
   </listitem>
  </itemizedlist>
  <para>
   If the attribute is stuck with the wrong value, it can be set to
   <literal>no</literal> using the command:
  </para>
<screen>tux > attrd_updater -n evacuate -U no -N <replaceable>NODE</replaceable></screen>
  <para>
   After standard fencing has been performed, fence agent
   <systemitem>fence_compute</systemitem> should activate the secondary
   fencing device (<literal>fence-nova</literal>). It does this by setting
   the attribute to <literal>yes</literal> to mark the node as needing
   recovery. The agent also calls &o_comp;'s
   <systemitem>force_down</systemitem> API to notify it that the host is down.
   You should be able to see this in
   <filename>/var/log/nova/fence_compute.log</filename> on the node in the core
   cluster that was running the <systemitem>fence-nova</systemitem> agent at
   the time of fencing. During the recovery, <literal>fence_compute</literal>
   tells &o_comp; that the host is up and running again.
  </para>
</section>
 <section id="bootstrap-compute-plane">
  <title>Bootstrapping Compute Plane</title>
  <para>
   If the whole compute plane is down, it is not always obvious how to boot it
   up, because it can be subject to deadlock if evacuate attributes are set on
   every Compute Nodes. In this case, manual intervention is
   required. Specifically, the operator must manually choose one or more
   Compute Nodess to bootstrap the compute plane, and then run the
   <command>attrd_updater -n evacuate -U no -N <replaceable>NODE</replaceable></command>
   command for each
   of those Compute Nodess to indicate that they do not require the resurrection
   process and can have their <literal>nova-compute</literal> start up straight
   away. Once these Compute Nodess are up, this breaks the deadlock allowing
   <literal>nova-evacuate</literal> to start. This way, any other nodes that
   require resurrection can be processed automatically. If no resurrection is
   desired anywhere in the cloud, then the attributes should be set to
   <literal>no</literal> for all nodes.
  </para>
  <important>
   <para>
    Keep in mind that if Compute Nodess are started too long after the
    <literal>remote-*</literal> resources are started on the control plane,
    they will be liable to fencing and so this should be avoided.
   </para>
  </important>
 </section>
</chapter>
