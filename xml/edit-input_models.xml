<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xml:id="edit-input_models" version="5.1">
 <title>Edit Input Models to Add and Configure Virtual Appliances</title>
 <para>
  The following steps should be used to edit the Ardana input model data to add
  and configure the Virtual Appliances that were just created. The process
  assumes that the &productname; is deployed and a valid &lcm; is in place.
 </para>
 <procedure>
  <step>
   <para>
    Edit the following files in
    <filename>~/openstack/my_cloud/definition/data/</filename>:
    <filename>servers.yml</filename>, <filename>disks_app_vm.yml</filename>,
    and <filename>pass_through.yml</filename>. Fill in attribute values
    recorded in the previous step.
   </para>
  </step>
  <step>
   <para>
    Follow the instructions in <filename>pass_through.yml</filename> to encrypt
    your vCenter password using an encryption key.
   </para>
  </step>
  <step>
   <para>
    Export an environment variable for the encryption key.
   </para>
   <screen>ARDANA_USER_PASSWORD_ENCRYPT_KEY=ENCRYPTION_KEY</screen>
  </step>
  <step>
   <para>
    Run the <filename>./ardanaencrypt.py</filename> script. It will prompt for
    <literal>unencrypted value?</literal>. Enter the unencrypted vCenter
    password and it will return an encrypted string.
   </para>
  </step>
  <step>
   <para>
    Copy and paste the encrypted password string in the
    <filename>pass_through.yml</filename> file as a value for the
    <literal>password</literal> field <emphasis role="bold">enclosed in double
    quotes</emphasis>.
   </para>
  </step>
  <step>
   <para>
    Enter the <literal>username</literal>, <literal>ip</literal>, and
    <literal>id</literal> of the vCenter server in the Global section of the
    <filename>pass_through.yml</filename> file. Use the values recorded in the
    previous step.
   </para>
  </step>
   <step>
    <para>
     In the <literal>servers</literal> section of the
     <filename>pass_through.yml</filename> file, add the details about the
     &o_comp; Compute Proxy and OVSvApp VMs that was recorded in the previous
     step.
    </para>
    <screen># Here the 'id' refers to the name of the node running the
      # esx-compute-proxy. This is identical to the 'servers.id' in
      # servers.yml.
      # NOTE: There should be one esx-compute-proxy node per ESX
      # resource pool or cluster.
      # cluster_dvs_mapping in the format
      # 'Datacenter-name/host/Cluster-Name:Trunk-DVS-Name'
      # Here 'host' is a string and should not be changed or
      # substituted.
      # vcenter_id is same as the 'vcenter-uuid' obtained in the global
      # section.
      # 'id': is the name of the appliance manually installed
      # 'vcenter_cluster': Name of the vcenter target cluster
      # esx_hostname: Name of the esx host hosting the ovsvapp
      # NOTE: For every esx host in a cluster there should be an ovsvapp
      # instance running.
      id: esx-compute1
      data:
        vmware:
          vcenter_cluster: &lt;vmware cluster1 name&gt;
          vcenter_id: &lt;vcenter-uuid&gt;
    -
      id: ovsvapp1
      data:
        vmware:
          vcenter_cluster: &lt;vmware cluster1 name&gt;
          cluster_dvs_mapping: &lt;cluster dvs mapping&gt;
          esx_hostname: &lt;esx hostname hosting the ovsvapp&gt;
          vcenter_id: &lt;vcenter-uuid&gt;
    -
      id: ovsvapp2
      data:
        vmware:
          vcenter_cluster: &lt;vmware cluster1 name&gt;
          cluster_dvs_mapping: &lt;cluster dvs mapping&gt;
          esx_hostname: &lt;esx hostname hosting the ovsvapp&gt;
          vcenter_id: &lt;vcenter-uuid&gt;
    </screen>
    <para>
     The VM <literal>id</literal> string should match exactly with the data
     written in the <filename>servers.yml</filename> file.
    </para>
   </step>
   <step>
    <para>
     Edit the <filename>servers.yml</filename> file, adding the &o_comp; Proxy
     VM and OVSvApp information recorded in the previous step.
    </para>
    <screen># Below entries shall be added by the user
    # for entry-scale-kvm-esx after following
    # the doc instructions in creating the
    # esx-compute-proxy VM Appliance and the
    # esx-ovsvapp VM Appliance.
    # Added just for the reference
    # NOTE: There should be one esx-compute per
    # Cluster and one ovsvapp per Hypervisor in
    # the Cluster.
    # id - is the name of the virtual appliance
    # ip-addr - is the Mgmt ip address of the appliance
    # The values shown below are examples and has to be
    # substituted based on your setup.
    # Nova Compute proxy node
    - id: esx-compute1
      server-group: RACK1
      ip-addr: 192.168.24.129
      role: ESX-COMPUTE-ROLE
    # OVSVAPP node
    - id: ovsvapp1
      server-group: RACK1
      ip-addr: 192.168.24.130
      role: OVSVAPP-ROLE
    - id: ovsvapp2
      server-group: RACK1
      ip-addr: 192.168.24.131
      role: OVSVAPP-ROLE
    </screen>
    <para>
     Examples of <filename>pass_through.yml</filename> and
     <filename>servers.yml</filename> files:
    </para>
    <screen>pass_through.yml
product:
  version: 2
pass-through:
  global:
    vmware:
      - username: administrator@vsphere.local
        ip: 10.84.79.3
        port: '443'
        cert_check: false
        password: @hos@U2FsdGVkX19aqGOUYGgcAIMQSN2lZ1X+gyNoytAGCTI=
        id: a0742a39-860f-4177-9f38-e8db82ad59c6
  servers:
    - data:
        vmware:
          vcenter_cluster: QE
          vcenter_id: a0742a39-860f-4177-9f38-e8db82ad59c6
      id: lvm-nova-compute1-esx01-qe
    - data:
        vmware:
          vcenter_cluster: QE
          cluster_dvs_mapping: 'PROVO/host/QE:TRUNK-DVS-QE'
          esx_hostname: esx01.qe.provo
          vcenter_id: a0742a39-860f-4177-9f38-e8db82ad59c6
      id: lvm-ovsvapp1-esx01-qe
    - data:
        vmware:
          vcenter_cluster: QE
          cluster_dvs_mapping: 'PROVO/host/QE:TRUNK-DVS-QE'
          esx_hostname: esx02.qe.provo
          vcenter_id: a0742a39-860f-4177-9f38-e8db82ad59c6
          id: lvm-ovsvapp2-esx02-qe
    </screen>
    <screen>servers.yml
product:
  version: 2
servers:
  - id: deployer
    ilo-ip: 192.168.10.129
    ilo-password: 8hAcPMne
    ilo-user: CLM004
    ip-addr: 192.168.24.125
    is-deployer: true
    mac-addr: '8c:dc:d4:b4:c5:4c'
    nic-mapping: MY-2PORT-SERVER
    role: DEPLOYER-ROLE
    server-group: RACK1
  - id: controller3
    ilo-ip: 192.168.11.52
    ilo-password: 8hAcPMne
    ilo-user: HLM004
    ip-addr: 192.168.24.128
    mac-addr: '8c:dc:d4:b5:ed:b8'
    nic-mapping: MY-2PORT-SERVER
    role: CONTROLLER-ROLE
    server-group: RACK1
  - id: controller2
    ilo-ip: 192.168.10.204
    ilo-password: 8hAcPMne
    ilo-user: HLM004
    ip-addr: 192.168.24.127
    mac-addr: '8c:dc:d4:b5:ca:c8'
    nic-mapping: MY-2PORT-SERVER
    role: CONTROLLER-ROLE
    server-group: RACK2
  - id: controller1
    ilo-ip: 192.168.11.57
    ilo-password: 8hAcPMne
    ilo-user: CLM004
    ip-addr: 192.168.24.126
    mac-addr: '5c:b9:01:89:c6:d8'
    nic-mapping: MY-2PORT-SERVER
    role: CONTROLLER-ROLE
    server-group: RACK3
  # Nova compute proxy for QE cluster added manually
  - id: lvm-nova-compute1-esx01-qe
    server-group: RACK1
    ip-addr: 192.168.24.129
    role: ESX-COMPUTE-ROLE
  # OVSvApp VM for QE cluster added manually
  # First ovsvapp vm in esx01 node
  - id: lvm-ovsvapp1-esx01-qe
    server-group: RACK1
    ip-addr: 192.168.24.132
    role: OVSVAPP-ROLE
  # Second ovsvapp vm in esx02 node
  - id: lvm-ovsvapp2-esx02-qe
    server-group: RACK1
    ip-addr: 192.168.24.131
    role: OVSVAPP-ROLE
baremetal:
  subnet: 192.168.24.0
  netmask: 255.255.255.0
    </screen>
   </step>
   <step>
    <para>
     Edit the <filename>disks_app_vm.yml</filename> file based on your
     <literal>lvm</literal> configuration. The attributes of <literal>Volume
     Group</literal>, <literal>Physical Volume</literal>, and <literal>Logical
     Volumes</literal> must be edited based on the <literal>LVM</literal>
     configuration of the VM.
    </para>
    <para>
     When you partitioned <literal>LVM</literal> during installation, you
     received <literal>Volume Group</literal> name, <literal>Physical
     Volume</literal> name and <literal>Logical Volumes</literal> with their
     partition sizes.
    </para>
    <para>
     This information can be retrieved from any of the VMs (&o_comp; Proxy VM
     or the OVSvApp VM):
    </para>
    <screen>&prompt.sudo;pvdisplay</screen>
    <screen># — Physical volume —
    # PV Name /dev/sda1
    # VG Name system
    # PV Size 80.00 GiB / not usable 3.00 MiB
    # Allocatable yes
    # PE Size 4.00 MiB
    # Total PE 20479
    # Free PE 511
    # Allocated PE 19968
    # PV UUID 7Xn7sm-FdB4-REev-63Z3-uNdM-TF3H-S3ZrIZ</screen>
    <para>
     The Physical Volume Name is <literal>/dev/sda1</literal>. And the Volume
     Group Name is <literal>system</literal>.
    </para>
    <para>
     To find <literal>Logical Volumes</literal>:
    </para>
    <screen>&prompt.sudo;fdisk -l</screen>
    <screen># Disk /dev/sda: 80 GiB, 85899345920 bytes, 167772160 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disklabel type: dos
    # Disk identifier: 0x0002dc70
    # Device Boot Start End Sectors Size Id Type
    # /dev/sda1 * 2048 167772159 167770112 80G 8e Linux LVM
    # Disk /dev/mapper/system-root: 60 GiB, 64424509440 bytes,
    # 125829120 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disk /dev/mapper/system-swap: 2 GiB, 2147483648 bytes, 4194304 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disk /dev/mapper/system-LV_CRASH: 16 GiB, 17179869184 bytes,
    # 33554432 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # NOTE: Even though we have configured the SWAP partition, it is
    # not required to be configured in here. Just configure the root
    # and the LV_CRASH partition</screen>
    <itemizedlist>
     <listitem>
      <para>
       The line with <literal>/dev/mapper/system-root: 60 GiB, 64424509440
       bytes</literal> indicates that the first logical partition is
       <literal>root</literal>.
      </para>
     </listitem>
     <listitem>
      <para>
       The line with <literal>/dev/mapper/system-LV_CRASH: 16 GiB, 17179869184
       bytes</literal> indicates that the second logical partition is
       <literal>LV_CRASH</literal>.
      </para>
     </listitem>
     <listitem>
      <para>
       The line with <literal>/dev/mapper/system-swap: 2 GiB, 2147483648 bytes,
       4194304 sectors</literal> indicates that the third logical partition is
       <literal>swap</literal>.
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Edit the <filename>disks_app_vm.yml</filename> file. It is not necessary
     to configure the <literal>swap</literal> partition.
    </para>
    <screen>volume-groups:
    - name: system (Volume Group Name)
      physical-volumes:
       - /dev/sda1 (Physical Volume Name)
      logical-volumes:
        - name: root   ( Logical Volume 1)
          size: 75%    (Size in percentage)
          fstype: ext4 ( filesystem type)
          mount: /     ( Mount point)
        - name: LV_CRASH   (Logical Volume 2)
          size: 20%        (Size in percentage)
          mount: /var/crash (Mount point)
          fstype: ext4      (filesystem type)
          mkfs-opts: -O large_file
    </screen>
    <para>
     An example <filename>disks_app_vm.yml</filename> file:
    </para>
    <screen>disks_app_vm.yml
---
  product:
    version: 2
  disk-models:
  - name: APP-VM-DISKS
    # Disk model to be used for application vms such as nova-proxy and ovsvapp
    # /dev/sda1 is used as a volume group for /, /var/log and /var/crash
    # Additional disks can be added to either volume group
    #
    # NOTE: This is just an example file and has to filled in by the user
    # based on the lvm partition map for their virtual appliance
    # While installing the operating system opt for the LVM partition and
    # create three partitions as shown below
    # Here is an example partition map
    # In this example we have three logical partitions
    # root partition (75%)
    # swap (5%) and
    # LV_CRASH (20%)
    # Run this command 'sudo pvdisplay' on the virtual appliance to see the
    # output as shown below
    #
    # — Physical volume —
    # PV Name /dev/sda1
    # VG Name system
    # PV Size 80.00 GiB / not usable 3.00 MiB
    # Allocatable yes
    # PE Size 4.00 MiB
    # Total PE 20479
    # Free PE 511
    # Allocated PE 19968
    # PV UUID 7Xn7sm-FdB4-REev-63Z3-uNdM-TF3H-S3ZrIZ
    #
    # Next run the following command on the virtual appliance
    #
    # sudo fdisk -l
    # The output will be as shown below
    #
    # Disk /dev/sda: 80 GiB, 85899345920 bytes, 167772160 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disklabel type: dos
    # Disk identifier: 0x0002dc70
    # Device Boot Start End Sectors Size Id Type
    # /dev/sda1 * 2048 167772159 167770112 80G 8e Linux LVM
    # Disk /dev/mapper/system-root: 60 GiB, 64424509440 bytes,
    # 125829120 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disk /dev/mapper/system-swap: 2 GiB, 2147483648 bytes, 4194304 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disk /dev/mapper/system-LV_CRASH: 16 GiB, 17179869184 bytes,
    # 33554432 sectors
    # Units: sectors of 1 * 512 = 512 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # NOTE: Even though we have configured the SWAP partition, it is
    # not required to be configured in here. Just configure the root
    # and the LV_CRASH partition
    volume-groups:
      - name: system
        physical-volumes:
         - /dev/sda1
        logical-volumes:
          - name: root
            size: 75%
            fstype: ext4
            mount: /
          - name: LV_CRASH
            size: 20%
            mount: /var/crash
            fstype: ext4
            mkfs-opts: -O large_file
    </screen>
   </step>
  </procedure>
 </section>
