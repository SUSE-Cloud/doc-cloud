<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
    type="text/xml"
    title="Profiling step"?>
<!DOCTYPE section [
<!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="maintenance_update">
 <title>&lcm; Maintenance Update Procedure</title>
 <procedure>
  <title>Preparing for Update</title>
  <step>
   <para>
    Ensure that the update repositories have been properly setup on all nodes.
    The easiest way to provide the required repositories on the &lcm; Server is
    to set up an &smt; server as described in
    <xref linkend="app.deploy.smt_lcm"/>. Alternatives to setting up an
    &smt; server are described in <xref linkend="cha.depl.repo_conf_lcm"/>.
   </para>
  </step>
  <step>
   <para>
    Read the Release Notes for the security and maintenance updates that will
    be installed.
   </para>
  </step>
  <step>
   <para>
    Have a backup strategy in place. For further information, see
    <xref linkend="bura_overview"/>.
   </para>
  </step>
  <step>
   <para>
    Ensure that you have a known starting state by resolving any unexpected
    alarms.
   </para>
  </step>
  <step>
   <para>
    Determine if you need to reboot your cloud after updating the software.
    Rebooting is highly recommended to ensure that all affected services are
    restarted. Reboot may be required after installing Linux kernel updates,
    but it can be skipped if the impact on running services is non-existent or
    well understood.
   </para>
  </step>
  <step>
   <para>
    Review steps in <xref linkend="add_network_node"/> and
    <xref linkend="rebootNodes"/> to minimize the impact on existing
    workloads. These steps are critical when the &o_netw; services are not
    provided via external SDN controllers.
   </para>
  </step>
  <step>
   <para>
    Before the update, prepare your working loads by consolidating all of your
    instances to one or more &compnode;s. After the update is complete on the
    evacuated &compnode;s, reboot them and move the images from the remaining
    &compnode;s to the newly booted ones. Then, update the remaining
    &compnode;s.
   </para>
  </step>
 </procedure>
 <section xml:id="perform_update">
  <title>Performing the Update</title>
  <procedure>
   <title>Update Instructions</title>
   <step>
    <para>
     Get status of all your services:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ardana-status.yml</screen>
    <para>
     If status check returns an error for a specific service, run the
     <filename><replaceable>SERVICE</replaceable>-reconfigure.yml</filename>
     playbook. Run then the
     <filename><replaceable>SERVICE</replaceable>-status.yml</filename>
     playbook to check whether the issue has been resolved.
    </para>
   </step>
   <step>
    <para>
     Update and reboot all nodes in the cloud one by one. Start with the
     deployer node, then follow the order recommended in
     <xref linkend="rebootNodes"/>.
    </para>
    <note>
     <para>
      The described workflow also covers cases in which the deployer node is
      also provisioned as an active cloud node.
     </para>
    </note>
    <para>
     To minimize the impact on the existing workloads, the node should first be
     prepared for an update and a subsequent reboot by following the steps
     leading up to stopping services listed in
     <xref linkend="rebootNodes"/>, such as migrating singleton agents on
     &contrnode;s and evacuating &compnode;s. Do not stop services running on
     the node, as they need to be running during the update.
    </para>
    <substeps>
     <step>
      <para>
       Install desired package updates on the target node:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         It is recommended to install all available security and maintenance
         updates using the <command>zypper patch</command> command.
        </para>
       </listitem>
       <listitem>
        <para>
         Update a single package (for example, apply a PTF on a single node or
         on all nodes) by running <command>zypper
         update<replaceable>PACKAGE</replaceable></command>
        </para>
       </listitem>
       <listitem>
        <para>
         Install all package updates using the <command>zypper update</command>
        </para>
       </listitem>
      </itemizedlist>
     </step>
     <step>
      <para>
       If the previous step updates any of the <package>ardana*</package>
       packages, the following actions
       must be performed on the deployer:
      </para>
      <substeps>
       <step>
        <para>
         Run the <systemitem>ardana-init</systemitem> initialization script to
         update the deployer.
         <!-- The referenced section is currently not available. - sknorr, 2018-04-24 -->
         <!-- If you receive a merge error, refer to
         <xref linkend="upgrade_git_merge"/>.-->
         After merge conflicts have been
         resolved, run the initialization script again.
        </para>
       </step>
       <step>
        <para>
         Redeploy cobbler:
        </para>
<screen>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</screen>
       </step>
       <step>
        <para>
         Run the configuration processor:
        </para>
<screen>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
       </step>
       <step>
        <para>
         Update your deployment directory:
        </para>
<screen>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
       </step>
      </substeps>
     </step>
     <step>
      <para>
       On the deployer node, run the update playbook targeted at the node that
       has been updated at the previous step:
      </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ardana-update.yml --limit <replaceable>TARGET_NODE_NAME</replaceable></screen>
     </step>
     <step>
      <para>
       Reboot the node as described in <xref linkend="rebootNodes"/>.
      </para>
     </step>
     <step>
      <para>
       When the node comes up after the reboot, run the
       <filename>spark-start.yml</filename> file:
      </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts spark-start.yml</screen>
     </step>
     <step>
      <para>
       Verify that Spark is running on all &contrnode;s:
      </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts spark-status.yml</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     After all nodes have been updated, check the status of all services:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ardana-status.yml</screen>
   </step>
  </procedure>
 </section>
</section>
