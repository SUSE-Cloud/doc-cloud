<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE appendix
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.deploy.poc">
 <title>Building a &cloud; Test lab</title>
 <sect1 xml:id="sec.depl.poc.scope">
  <title>Document Scope</title>

  <para>
   This document will help you to prepare &suse; and prospective customers for
   a Proof of Concept (PoC) deployment of &cloud;. This document provides
   specific details for a PoC deployment. It serves as an addition to the
   &cloud; &clouddeploy;.
  </para>
 </sect1>
 <sect1 xml:id="sec.depl.poc.features">
  <title>&cloud; Key Features</title>

  <para>
   The latest version &productnumber; of &cloud; supports all &ostack-current;
   release components for best-in-class capabilities to deploy an open source
   private cloud. Here is a brief overview of &cloud; features and
   functionality.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <emphasis>Installation Framework</emphasis> Integration with the Crowbar
     project speeds up and simplifies installation and administration of your
     physical cloud infrastructure.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Mixed Hypervisor Support</emphasis> Enhanced virtualization
     management through support for multi-hypervisor environments that use KVM,
     Xen, &vmware; vSphere, and IBM z/VM.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>High Availability</emphasis> Automated deployment and
     configuration of control plane clusters. This ensures continuous access to
     business services and delivery of enterprise-grade Service Level
     Agreements.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>High availability for KVM and Xen Compute Nodes and
     Workloads</emphasis> Enhanced support for critical workloads not designed
     for cloud architectures.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Docker Support</emphasis> Gives the ability to build and run
     innovative containerized applications through Magnum integration.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Scalability</emphasis> Cloud control system designed to grow
     with your demands.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Open APIs</emphasis> Using the standard APIs, customers can
     enhance and integrate &ostack; with third-party software.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Block Storage Plug-Ins</emphasis> A wide range of block storage
     plug-ins available from storage vendors like EMC, NetApp, and others.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Networking Plug-Ins</emphasis> &cloud; natively supports open
     source SDNs via Open vSwitch, harnessing the power of DPDK in &cloudos;.
     For more flexibility, &cloud; provides support for third-party tools from
     Cisco, Midokura, Infoblox, Nuage Networks, PLUMgrid and even VLAN bridging
     solutions.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Award-Winning Support</emphasis> &cloud; is backed by 24x7
     worldwide-technical support.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Full Integration with SUSE Update Processes</emphasis> Easily
     maintain and patch cloud deployments.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Non-Disruptive Upgrade Capabilities</emphasis> Simplify
     migration to future &cloud; releases.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sec.depl.poc.components">
  <title>Main Components</title>

  <para>
   The following is a brief overview of components for setting up and managing
   &cloud;.
  </para>

  <para>
   <emphasis>Administration Server</emphasis> provides all services needed to
   manage and deploy all other nodes in the cloud. Most of these services are
   provided by the Crowbar tool. Together with Chef, Crowbar automates all the
   required installation and configuration tasks. The services provided by the
   server include DHCP, DNS, NTP, PXE, TFTP.
  </para>

  <para>
   The Administration Server also hosts the software repositories for &sls; and
   &cloud;. These repositories are required for node deployment. If no other
   sources for the software repositories are available, the Administration
   Server can also host the Subscription Management Tool (SMT), providing
   up-to-date repositories with updates and patches for all nodes.
  </para>

  <para>
   <emphasis>Control Nodes</emphasis> host all &ostack; services for
   orchestrating virtual machines deployed on the compute nodes. &ostack; in
   &cloud; uses a PostgreSQL database that is also hosted on the Control Nodes.
   When deployed, the following &ostack; components run on the Control Nodes:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     PostgreSQL
    </para>
   </listitem>
   <listitem>
    <para>
     Image (Glance)
    </para>
   </listitem>
   <listitem>
    <para>
     Identity (Keystone)
    </para>
   </listitem>
   <listitem>
    <para>
     Networking (Neutron)
    </para>
   </listitem>
   <listitem>
    <para>
     Block Storage (Cinder)
    </para>
   </listitem>
   <listitem>
    <para>
     Shared Storage (Manila)
    </para>
   </listitem>
   <listitem>
    <para>
     &ostack; Dashboard
    </para>
   </listitem>
   <listitem>
    <para>
     Keystone
    </para>
   </listitem>
   <listitem>
    <para>
     Pacemaker
    </para>
   </listitem>
   <listitem>
    <para>
     Nova controller
    </para>
   </listitem>
   <listitem>
    <para>
     Message broker
    </para>
   </listitem>
   <listitem>
    <para>
     Swift proxy server
    </para>
   </listitem>
   <listitem>
    <para>
     Hawk monitor
    </para>
   </listitem>
   <listitem>
    <para>
     Orchestration (Heat)
    </para>
   </listitem>
   <listitem>
    <para>
     Ceilometer server and agents
    </para>
   </listitem>
  </itemizedlist>

  <para>
   A single Control Node running multiple services can become a performance
   bottleneck, especially in large &cloud; deployments. It is possible to
   distribute the services listed above on more than one Control Node. This
   includes scenarios where each service runs on its own node.
  </para>

  <para>
   <emphasis>Compute Nodes</emphasis> are a pool of machines for running
   instances. These machines require an adequate number of CPUs and enough RAM
   to start several instances. They also need to provide sufficient storage. A
   Control Node distributes instances within the pool of compute nodes and
   provides the necessary network resources. The &ostack; service Compute
   (Nova) runs on Compute Nodes and provides means for setting up, starting,
   and stopping virtual machines. &cloud; supports several hypervisors such as
   KVM, &vmware; vSphere, and Xen. Each image that can be started with an
   instance is bound to one hypervisor. Each Compute Node can only run one
   hypervisor at a time. For a PoC deployment, &suse; recommends to leverage
   KVM as hypervisor of choice.
  </para>

  <para>
   <emphasis>Optional Storage Nodes</emphasis> Storage Node is a pool of
   machines that provide object or block storage. Object storage supports
   several back-ends.
  </para>
 </sect1>
 <sect1 xml:id="sec.depl.poc.objectives">
  <title>Objectives and Preparations</title>

  <para>
   Although each customer has a specific set of requirements, it is important
   to have 3-5 clearly-defined objectives. This objectives should be provable,
   measurable and have a specific time scale in which proof is required. The
   objectives can be adjusted and amended, provided that both parties are
   agreed on the changes. For a full record of the performed and completed
   work, it is recommended to use this document for making amendments to the
   proof requirements.
  </para>

  <para>
   Before deploying &cloud;, it is necessary to meet certain requirements and
   consider various aspects of the deployment. Some decisions need to be made
   <emphasis>before</emphasis> deploying &cloud;, since they
   <emphasis>cannot</emphasis> be changed afterward.
  </para>

  <para>
   The following procedure covers preparatory steps for the deployment of
   &cloud; along with the software and hardware components required for a
   successful implementation.
  </para>

  <procedure>
   <title>Prerequisites</title>
   <step>
    <para>
     Make sure that the required hardware and virtual machines are provided and
     configured
    </para>
   </step>
   <step>
    <para>
     Check that PXE boot from the first NIC in BIOS is enabled
    </para>
   </step>
   <step>
    <para>
     Ensure that the hardware is certified for use with &cloudos;
    </para>
   </step>
   <step>
    <para>
     Check that booting from ISO images works
    </para>
   </step>
   <step>
    <para>
     Make sure that all NICs are visible
    </para>
   </step>
   <step>
    <para>
     Install <systemitem>sar/sysstat</systemitem> for performance
     troubleshooting
    </para>
   </step>
   <step>
    <para>
     Ensure that all needed subscription records are available. Depending on
     the size of the cloud to be implemented, this includes the following:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       &cloud; subscriptions
      </para>
     </listitem>
     <listitem>
      <para>
       &sls; subscriptions
      </para>
     </listitem>
     <listitem>
      <para>
       SLES High Availability Extensions (HAE) subscriptions
      </para>
     </listitem>
     <listitem>
      <para>
       Optional &ses; (SES) subscriptions
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Check whether all needed channels and updates are available either locally
     or remotely. The following options can be used to provide the repositories
     and channels:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SMT server on the administration server (optional step)
      </para>
     </listitem>
     <listitem>
      <para>
       Existing SMT server
      </para>
     </listitem>
     <listitem>
      <para>
       Existing &susemgr;
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Make sure that networking planed and wired according to the specified
     layout or topology
    </para>
   </step>
   <step>
    <para>
     If &ses; is a part of the PoC deployment, all nodes must be installed,
     configured, and optimized before installing &cloud;. Storage services
     (Nova, Cinder, Glance, Cluster &stonith;,) required by &cloud; 6 must be
     available and accessible.
    </para>
   </step>
   <step>
    <para>
     Check whether <systemitem>network.json</systemitem> is configured
     according to the specific requirements. This step must be discussed and
     completed in advance (see <xref
      linkend="sec.depl.poc.networkjson"/>
     and
     <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/book_cloud_deploy/data/book_cloud_deploy.html"/>)
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec.depl.poc.matrix">
  <title>Hardware and Software Matrix</title>

  <para>
   The hardware and software matrix below has the following requirements:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     All machines must run &cloudos;
    </para>
   </listitem>
   <listitem>
    <para>
     KVM or Xen Hypervisors must be running on bare metal
    </para>
   </listitem>
   <listitem>
    <para>
     The Admin Node can be deployed on a KVM or &vmware; virtual machine
    </para>
   </listitem>
  </itemizedlist>

  <para>
   The sizing recommendation includes an Admin Node (bare metal or VM),
   Controller Nodes, Compute Nodes to host all your &ostack; services, and the
   optional SES Nodes. The matrix also provides information on the necessary
   network equipment and bandwidth requirements.
  </para>

  <note>
   <title>About Recommendations</title>
   <para>
    These recommendations are based on real-world use cases and experience
    gathered by &suse; in the last three years. However, these recommendations
    are meant to serve as guidelines and not as requirements. The final sizing
    decision depends on the actual customer workloads and architecture, which
    must be discussed in depth. The type and number of hardware components such
    as hard disks, CPU, and RAM also serve as starting points for further
    discussion and evaluation depending on workloads.
   </para>
  </note>

  <table>
   <title>BoM/&cloud; Services</title>
   <tgroup cols="4">
    <colspec colnum="1" colname="1" colwidth="25*"/>
    <colspec colnum="2" colname="2" colwidth="25*"/>
    <colspec colnum="3" colname="3" colwidth="25*"/>
    <colspec colnum="4" colname="4" colwidth="25*"/>
    <thead>
     <row>
      <entry>
       <para>
        Number of Units
       </para>
      </entry>
      <entry>
       <para>
        Function
       </para>
      </entry>
      <entry>
       <para>
        Configuration
       </para>
      </entry>
      <entry>
       <para>
        &ostack; Component
       </para>
      </entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry>
       <para>
        3
       </para>
      </entry>
      <entry>
       <para>
        Compute nodes
       </para>
      </entry>
      <entry>
       <para>
        2 hard disks
       </para>
       <para>
        2 Quad Core Intel or AMD processors
       </para>
       <para>
        256GB RAM
       </para>
       <para>
        2 or 4 10Gb Ethernet NICs
       </para>
      </entry>
      <entry>
       <para>
        Nova-multi-compute
       </para>
       <para>
        ML2 Agent
       </para>
       <para>
        OVS Agent
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        1
       </para>
      </entry>
      <entry>
       <para>
        Admin Node or VM
       </para>
      </entry>
      <entry>
       <para>
        2 hard disks
       </para>
       <para>
        1 Quad Core Intel or AMD processor
       </para>
       <para>
        8GB RAM
       </para>
       <para>
        2 or 4 10Gb Ethernet NICs
       </para>
      </entry>
      <entry>
       <para>
        Crowbar, tftpboot, PXE
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        3
       </para>
      </entry>
      <entry>
       <para>
        Control node
       </para>
      </entry>
      <entry>
       <para>
        2 hard disks
       </para>
       <para>
        2 Quad Core Intel or AMD processors
       </para>
       <para>
        2x64GB RAM
       </para>
       <para>
        2 or 4 10Gb Ethernet NICs
       </para>
      </entry>
      <entry>
       <para>
        Horizon
       </para>
       <para>
        Rabbit MQ
       </para>
       <para>
        Nova multi-controller
       </para>
       <para>
        Cinder
       </para>
       <para>
        Glance
       </para>
       <para>
        Heat
       </para>
       <para>
        Ceilometer
       </para>
       <para>
        Neutron-Server
       </para>
       <para>
        ML2 Agent
       </para>
       <para>
        Keystone
       </para>
       <para>
        &mariadb;
       </para>
       <para>
        Neutron ML2 Plugin
       </para>
       <para>
        L2/L3 Agents
       </para>
       <para>
        DHCP Agent
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para></para>
      </entry>
      <entry>
       <para>
        CloudFoundry
       </para>
      </entry>
      <entry>
       <para>
        48 vCPUs
       </para>
       <para>
        256GB RAM
       </para>
       <para>
        Min 2TB Storage
       </para>
      </entry>
      <entry>
       <para>
        &cap;
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        4
       </para>
      </entry>
      <entry>
       <para>
        Storage Server – &ses;
       </para>
      </entry>
      <entry>
       <para>
        2 hard disks
       </para>
       <para>
        2 Quad Core Intel or AMD processors
       </para>
       <para>
        64GB RAM
       </para>
       <para>
        2 or 4 10Gb Ethernet NICs
       </para>
      </entry>
      <entry>
       <para>
        Admin – Server
       </para>
       <para>
        MON - Server
       </para>
       <para>
        OSD - Server
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        1
       </para>
      </entry>
      <entry>
       <para>
        Switch min. 10 GbE ports
       </para>
      </entry>
      <entry>
       <para></para>
      </entry>
      <entry>
       <para>
        All VLANs/Tagged or Untagged
       </para>
      </entry>
     </row>
     <row>
      <entry align="center" namest="1" nameend="4">OS: &cloudos;</entry>
     </row>
     <row>
      <entry>
       <para>
        DHCP, DNS
       </para>
      </entry>
      <entry>
       <para>
        Isolated within administrator network
       </para>
      </entry>
      <entry>
       <para></para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        HA
       </para>
      </entry>
      <entry>
       <para>
        3 Control Nodes
       </para>
      </entry>
      <entry>
       <para></para>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </table>
 </sect1>
 <sect1 xml:id="sec.depl.poc.topology">
  <title>Network Topology</title>

  <para>
   Configuring and managing your network are <emphasis>two of the most
   challenging tasks of deploying a &cloud;</emphasis>. Therefore they need to
   be planned carefully. Just as &ostack; provides flexibility and agility for
   compute and storage, SDN in &ostack; gives cloud administrators more control
   over their networks. However, building and manually configuring the virtual
   network infrastructure for &ostack; is difficult and error-prone. &cloud;
   solve this by delivering a structured installation process for &ostack;
   which could be customized to adapt the given environment.
  </para>

  <sect2 xml:id="sec.depl.poc.networkjson">
   <title>The network.json Network Control File</title>
   <para>
    The deployment of the network configuration is done while setting up an
    Administrator Node. As a requirement for the deployment, the entire network
    configuration needs to be specified in the
    <systemitem>network.json</systemitem> file.
   </para>
   <para>
    The Crowbar network barclamp provides two functions for the system:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Initialization of network interfaces on the Crowbar managed systems
     </para>
    </listitem>
    <listitem>
     <para>
      Address pool management. While the addresses can be managed with the YaST
      Crowbar module, complex network setups require to manually edit the
      network barclamp template file
      <systemitem>/etc/crowbar/network.json</systemitem>. For more detailed
      explanation and description see
      <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/pdfdoc/book_cloud_deploy/book_cloud_deploy.pdf#page=240&amp;zoom=auto,63.779,788.031" />
     </para>
    </listitem>
   </itemizedlist>
   <para>
    The network definitions contain IP address assignments, the bridge and VLAN
    setup, and settings for the router preference. Each network is also
    assigned to a logical interface. These VLAN IDs and networks can be
    modified according to the customer's environment.
   </para>
  </sect2>

  <sect2 xml:id="sec.depl.poc.networkmodes">
   <title>The Network Mode</title>
   <para>
    &cloud; supports three network modes: single, dual and team. As of &cloud;
    6, the network mode is applied to all nodes and the Administration Server.
    That means that all machines need to meet the hardware requirements for the
    chosen mode. The following network modes are available:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis>Single Network Mode</emphasis> In single mode one Ethernet card
      is used for all the traffic.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Dual Network Mode</emphasis> Dual mode needs two Ethernet cards
      (on all nodes but Administration Server). This allows to completely
      separate traffic to and from the administrator network and to and from
      the public network.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Team Network Mode</emphasis> The team mode is almost identical
      to single mode, except it combines several Ethernet cards to a so-called
      bond (network device bonding). Team mode requires two or more Ethernet
      cards.
     </para>
    </listitem>
   </itemizedlist>
   <note>
    <title>Team Network Mode for HA</title>
    <para>
     In an HA configuration, make sure that &cloud; is deployed with the team
     network mode.
    </para>
   </note>
   <figure>
    <title>Network Modes</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="depl_poc_network_mode.png" width="100%" format="png"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="depl_poc_network_mode.png" width="100%" format="png"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 xml:id="sec.depl.poc.defaultlayout">
   <title>Default Layout</title>
   <para>
    The following networks are pre-defined for use with &cloud;.
   </para>
   <table>
    <title>Administrator Network Layout</title>
    <tgroup cols="3">
     <colspec colnum="1" colname="1" colwidth="33*"/>
     <colspec colnum="2" colname="2" colwidth="33*"/>
     <colspec colnum="3" colname="3" colwidth="33*"/>
     <thead>
      <row>
       <entry>
        <para>
         Network Name
        </para>
       </entry>
       <entry>
        <para>
         VLAN
        </para>
       </entry>
       <entry>
        <para>
         IP Range
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         Router
        </para>
       </entry>
       <entry>
        <para>
         No - untagged
        </para>
       </entry>
       <entry>
        <para>
         192.168.124.1
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Admin
        </para>
       </entry>
       <entry>
        <para>
         No - untagged
        </para>
       </entry>
       <entry>
        <para>
         192.168.124.10 – 192.168.124.11
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         DHCP
        </para>
       </entry>
       <entry>
        <para>
         No - untagged
        </para>
       </entry>
       <entry>
        <para>
         192.168.124.21 – 192.168.124.80
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Host
        </para>
       </entry>
       <entry>
        <para>
         No - untagged
        </para>
       </entry>
       <entry>
        <para>
         192.168.124.81 – 192.168.124.160
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         BMC VLAN Host
        </para>
       </entry>
       <entry>
        <para>
         100
        </para>
       </entry>
       <entry>
        <para>
         192.168.124.61
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         BMC Host
        </para>
       </entry>
       <entry>
        <para>
         No - untagged
        </para>
       </entry>
       <entry>
        <para>
         192.168.124.162 – 192.168.124.240
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Switch
        </para>
       </entry>
       <entry>
        <para>
         No - untagged
        </para>
       </entry>
       <entry>
        <para>
         192.168.124.241 – 192.168.124.250
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <table>
    <title>Private Network Layout</title>
    <tgroup cols="3">
     <colspec colnum="1" colname="1" colwidth="33*"/>
     <colspec colnum="2" colname="2" colwidth="33*"/>
     <colspec colnum="3" colname="3" colwidth="33*"/>
     <thead>
      <row>
       <entry>
        <para>
         Network Name
        </para>
       </entry>
       <entry>
        <para>
         VLAN
        </para>
       </entry>
       <entry>
        <para>
         IP Range
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         Router
        </para>
       </entry>
       <entry>
        <para>
         500
        </para>
       </entry>
       <entry>
        <para>
         192.168.123.1 – 192.168.123.49
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         DHCP
        </para>
       </entry>
       <entry>
        <para>
         500
        </para>
       </entry>
       <entry>
        <para>
         192.168.123.50 – 192.168.123.254
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <table>
    <title>Public/Nova Floating Network Layout/Externally Provided</title>
    <tgroup cols="3">
     <colspec colnum="1" colname="1" colwidth="33*"/>
     <colspec colnum="2" colname="2" colwidth="33*"/>
     <colspec colnum="3" colname="3" colwidth="33*"/>
     <thead>
      <row>
       <entry>
        <para>
         Network Name
        </para>
       </entry>
       <entry>
        <para>
         VLAN
        </para>
       </entry>
       <entry>
        <para>
         IP Range
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         Public Host
        </para>
       </entry>
       <entry>
        <para>
         300
        </para>
       </entry>
       <entry>
        <para>
         192.168.126.2 – 192.168.126.49
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Public DHCP
        </para>
       </entry>
       <entry>
        <para>
         300
        </para>
       </entry>
       <entry>
        <para>
         192.168.126.50 – 192.168.126.127
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Floating Host
        </para>
       </entry>
       <entry>
        <para>
         300
        </para>
       </entry>
       <entry>
        <para>
         192.168.126.129 – 192.168.126.191
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <table>
    <title>Storage Network Layout</title>
    <tgroup cols="3">
     <colspec colnum="1" colname="1" colwidth="33*"/>
     <colspec colnum="2" colname="2" colwidth="33*"/>
     <colspec colnum="3" colname="3" colwidth="33*"/>
     <thead>
      <row>
       <entry>
        <para>
         Network Name
        </para>
       </entry>
       <entry>
        <para>
         VLAN
        </para>
       </entry>
       <entry>
        <para>
         IP Range
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         Host
        </para>
       </entry>
       <entry>
        <para>
         200
        </para>
       </entry>
       <entry>
        <para>
         192.168.125.2 – 192.168.125.254
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <para>
    The default IP addresses can be changed using YaST Crowbar module or by
    editing the appropriate JSON file. It is also possible to customize the
    network setup for your environment. This can be done by editing the network
    barclamp template.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.depl.poc.architecture">
  <title>Network Architecture</title>

  <para>
   &cloud; requires a complex network setup consisting of several networks
   configured during installation. These networks are reserved for cloud usage.
   Access to these networks from an existing network requires a router.
  </para>

  <important>
   <title>Network Configuration with Crowbar</title>
   <para>
    The network configuration on the nodes in the &cloud; network is controlled
    by Crowbar. Any network configuration changes done outside Crowbar will be
    automatically overwritten. After the cloud is deployed, network settings
    cannot be changed without reinstalling the cloud.
   </para>
  </important>

  <para>
   <emphasis>Controller Node</emphasis> serves as the front-end for API calls
   to the compute, image, volume, network, and orchestration services. In
   addition to that, the node hosts multiple Neutron plug-ins and agents. The
   node also aggregates all route traffic within tenant and between tenant
   network and outside world.
  </para>

  <para>
   <emphasis>Compute Node</emphasis> creates on-demand virtual machines using
   chosen hypervisor for customer application.
  </para>

  <para>
   <emphasis>Administrator Node</emphasis> automates the installation processes
   via Crowbar using pre-defined cookbooks for configuring and deploying a
   Control Node and Compute and Network Nodes.
  </para>

  <note>
   <title>DHCP/PXE Environment for Administrator Node</title>
   <para>
    The Administrator Node requires a dedicated local and isolated DHCP/PXE
    environment controlled by Crowbar.
   </para>
  </note>

  <para>
   <emphasis>Optional storage access</emphasis>. Cinder is used for block
   storage access exposed through iSCSI or NFS (FC connection is not supported
   in the current release of &ostack;). This could also be a dedicated Storage
   Node.
  </para>

  <note>
   <title>High-Performance Network for &ceph;</title>
   <para>
    Implementation of &ceph; as a cloud storage requires a high-performance
    network. The Storage Net in the following network topology would allow the
    respective &ostack; services to connect to the external &ceph; storage
    cluster public network. It is recommended to run a &ceph; storage cluster
    with two networks: a public network and a cluster network. To support two
    networks, each Ceph node must have more than one NIC.
   </para>
  </note>

  <para>
   <emphasis>Network mode</emphasis>. What mode to choose for a PoC deployment
   depends on the High Availability (HA) requirements. The team network mode is
   required for an HA setup of &cloud;.
  </para>

  <sect2 xml:id="sec.depl.poc.vlans">
   <title>Network Architecture: Pre-Defined VLANs</title>
   <para>
    VLAN support for the administrator network must be handled at the switch
    level. The following networks are predefined when setting up &cloud;. The
    listed default IP addresses can be changed using the YaST Crowbar module.
    It is also possible to customize the network setup.
   </para>
   <note>
    <title>Limitations of the Default Network Proposal</title>
    <para>
     The default network proposal described below allows maximum 80 Compute
     Nodes, 61 floating IP addresses, and 204 addresses in the nova_fixed
     network. To overcome these limitations, you need to reconfigure the
     network setup by using appropriate address ranges manually.
    </para>
   </note>
   <figure>
    <title>Network Architecture</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="depl_network_arch.png" width="100%" format="png"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="depl_network_arch.png" width="100%" format="png"/>
     </imageobject>
    </mediaobject>
   </figure>
   <variablelist>
    <varlistentry>
     <term>Administrator Network (192.168.124/24)</term>
     <listitem>
      <para>
       A private network to access the Administration Server and all nodes for
       administration purposes. The default setup lets you also access the
       Baseboard Management Controller (BMC) data via Intelligent Platform
       Management Interface (IPMI) from this network. If required, BMC access
       can be swapped to a separate network.
      </para>
      <para>
       You have the following options for controlling access to this network:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         Do not allow access from the outside and keep the administrator
         network completely separated
        </para>
       </listitem>
       <listitem>
        <para>
         Allow access to the administration server from a single network (for
         example, your company's administration network) via the “bastion
         network” option configured on an additional network card with a
         fixed IP address
        </para>
       </listitem>
       <listitem>
        <para>
         Allow access from one or more networks via a gateway
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Storage Network (192.168.125/24)</term>
     <listitem>
      <para>
       Private &cloud; internal virtual network. This network is used by Ceph
       and Swift only. It should not be accessed by users.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Private Network (nova-fixed, 192.168.123/24)</term>
     <listitem>
      <para>
       Private &cloud; internal virtual network. This network is used for
       communication between instances and provides them with access to the
       outside world. &cloud; automatically provides the required gateway.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Public Network (nova-floating, public, 192.168.126/24)</term>
     <listitem>
      <para>
       The only public network provided by &cloud;. On this network, you can
       access the Nova Dashboard and all instances (provided they are equipped
       with a floating IP). This network can only be accessed via a gateway
       that needs to be provided externally. All &cloud; users and
       administrators need to be able to access the public network.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Software Defined Network (os_sdn, 192.168.130/24)</term>
     <listitem>
      <para>
       Private &cloud; internal virtual network. This network is used when
       Neutron is configured to use <systemitem>openvswitch</systemitem> with
       GRE tunneling for the virtual networks. It should not be accessed by
       users.
      </para>
      <para>
       &cloud; supports different network modes: single, dual, and team.
       Starting with &cloud; 6, the networking mode is applied to all nodes and
       the Administration Server. This means that all machines need to meet the
       hardware requirements for the chosen mode. The network mode can be
       configured using the YaST Crowbar module (see
       <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/book_cloud_deploy/data/sec_depl_adm_inst_crowbar.html"/>).
       The network mode cannot be changed after the cloud is deployed.
      </para>
      <para>
       More flexible network mode setups can be configured by editing the
       Crowbar network configuration files (see
       <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/book_cloud_deploy/data/app_deploy_network_json.html"/>
       for more information). SUSE or a partner can assist you in creating a
       custom setup within the scope of a consulting services agreement. For
       more information on &suse; consulting, visit
       <link xlink:href="http://www.suse.com/consulting/"/>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <important>
    <title>Team Network Mode Is Required for HA</title>
    <para>
     Team network mode is required for an HA setup of &cloud;. If you are
     planning to move your cloud to an HA setup later, deploy &cloud; with team
     network mode right from the beginning. Migration to an HA setup is not
     supported.
    </para>
   </important>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.depl.poc.services">
  <title>Services Architecture</title>

  <para>
   &cloud; is based on &cloudos;, &ostack;, Crowbar and Chef. &sls; is used as
   the underlying operating system for all infrastructure nodes. Crowbar and
   Chef are used to automatically deploy and manage the &ostack; nodes from a
   central Administration Server.
  </para>

  <figure>
   <title>Services Architecture</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="depl_poc_services_architecture.png" width="75%" format="png"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="depl_poc_services_architecture.png" width="75%" format="png"/>
    </imageobject>
   </mediaobject>
  </figure>
 </sect1>
 <sect1 xml:id="sec.depl.poc.testcases">
  <title>Proof of Concept Test Cases</title>

  <para>
   After you have successfully deployed &ostack;, you need to test the
   environment by using either the Dashboard or the command line interface.
   This document provides the most important procedures and steps to perform
   functional tests agreed upon. A detailed list of test case should be
   provided with this document.
  </para>

  <note>
   <title>About Test Cases</title>
   <para>
    All test cases are work in progress and by no means complete. Test cases
    have to be formulated by the entire team according to the requirements and
    type of workloads.
   </para>
  </note>
 </sect1>
</chapter>
