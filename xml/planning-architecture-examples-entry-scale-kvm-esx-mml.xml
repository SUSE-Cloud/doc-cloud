<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="entry-scale-kvm-esx-mml" version="5.1">
 <title>Single-Region Entry-Scale Cloud with Metering and Monitoring Services, and a Mix of KVM and ESX Hypervisors</title>
 <para>
  This example deploys a cloud which mixes KVM and ESX hypervisors, provides
  metering and monitoring services, and runs the database and messaging
  services in their own cluster.
 </para>
 <variablelist>
  <varlistentry>
   <term>Control Plane</term>
   <listitem>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis role="bold">Cluster1</emphasis> 2 nodes of type
       <literal>CONTROLLER-ROLE</literal> run the core &ostack; services, such
       as &o_ident;, &o_comp; API, &o_img; API, &o_netw; API, &o_dash;, and
       &o_orch; API.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Cluster2</emphasis> 3 nodes of type
       <literal>MTRMON-ROLE</literal>, run the &ostack; services for metering
       and monitoring (for example, &o_meter;, &o_monitor; and Logging).
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Cluster3</emphasis> 3 nodes of type
       <literal>DBMQ-ROLE</literal>, run clustered database and RabbitMQ
       services to support the cloud infrastructure. 3 nodes are required for
       high availability.
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>&lcm;</term>
   <listitem>
    <para>
     The &lcm; runs on one of the control-plane nodes of type
     <literal>CONTROLLER-ROLE</literal>. The IP address of the node that will
     run the &lcm; needs to be included in the
     <filename>data/servers.yml</filename> file.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>Resource Nodes</term>
   <listitem>
    <itemizedlist>
     <listitem>
      <para>
       Compute:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         <emphasis role="bold">KVM</emphasis> runs &o_comp; Computes and
         associated services. It runs on nodes of role type
         <literal>COMPUTE-ROLE</literal>.
        </para>
       </listitem>
       <listitem>
        <para>
         <emphasis role="bold">ESX</emphasis> provides ESX Compute services. OS
         and software on this node is installed by user.
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </itemizedlist>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term> ESX Resource Requirements </term>
   <listitem>
    <orderedlist>
     <listitem>
      <para>
       User needs to supply vSphere server
      </para>
     </listitem>
     <listitem>
      <para>
       User needs to deploy the ovsvapp network resources using the
       neutron-create-ovsvapp-resources.yml playbook
      </para>
      <para>
       The following DVS and DVPGs need to be created and configured for each
       cluster in each ESX hypervisor that will host an OvsVapp appliance. The
       settings for each DVS and DVPG are specific to your system and network
       policies. A JSON file example is provided in the documentation, but it
       needs to be edited to match your requirements.
      </para>
      <itemizedlist>
       <listitem>
        <para>
         ESX-CONF (DVS and DVPG) connected to ovsvapp eth0 and compute-proxy
         eth0
        </para>
       </listitem>
       <listitem>
        <para>
         MANAGEMENT (DVS and DVPG) connected to ovsvapp eth1 and compute-proxy
         eth1
        </para>
       </listitem>
       <listitem>
        <para>
         GUEST (DVS and DVPG) connected to ovsvapp eth2
        </para>
       </listitem>
       <listitem>
        <para>
         TRUNK (DVS and DVPG) connected to ovsvapp eth3
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
     <listitem>
      <para>
       User needs to deploy ovsvapp appliance (<literal>OVSVAPP-ROLE</literal>)
       and nova-proxy appliance (<literal>ESX-COMPUTE-ROLE</literal>)
      </para>
     </listitem>
     <listitem>
      <para>
       User needs to add required information related to compute proxy and
       OVSvApp Nodes
      </para>
     </listitem>
    </orderedlist>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>Networking</term>
   <listitem>
    <para>
     This example requires the following networks:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis role="bold">IPMI</emphasis>network connected to the
       lifecycle-manager and the IPMI ports of all nodes, except the ESX
       hypervisors.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Nodes require a pair of bonded NICs which are used by the following
     networks:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis
           role="bold">External API</emphasis> The network for
       making requests to the cloud.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis
           role="bold">External VM</emphasis> The network that
       provides access to VMs (via floating IP addresses).
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis
           role="bold">Cloud Management</emphasis> This
       network is used for all internal traffic between the cloud services. It
       is also used to install and configure the nodes. The network needs to be
       on an untagged VLAN.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Guest</emphasis> This is the network that will
       carry traffic between VMs on private networks within the cloud.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">TRUNK</emphasis> is the network that will be used
       to apply security group rules on tenant traffic. It is managed by the
       cloud admin and is restricted to the vCenter environment.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis
        role="bold">ESX-CONF-NET</emphasis> network is used
       only to configure the ESX compute nodes in the cloud. This network
       should be different from the network used with PXE to stand up the cloud
       control-plane.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     This example's set of networks is defined in
     <filename>data/networks.yml</filename>. The file needs to be modified to
     reflect your environment.
    </para>
    <para>
     The example uses the devices <filename>hed3</filename> and
     <filename>hed4</filename> as a bonded network interface for all services.
     The name given to a network interface by the system is configured in the
     file <filename>data/net_interfaces.yml</filename>. That file needs to be
     edited to match your system.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>Local Storage</term>
   <listitem>
    <para>
     All servers should present a single OS disk, protected by a RAID
     controller. This disk needs to be at least 512Â GB in capacity. In
     addition, the example configures additional disk depending on the node's
     role:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis role="bold">Controllers</emphasis>
       <filename>/dev/sdb</filename> and <filename>/dev/sdc</filename> are
       configured to be used by &swift;.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Compute Servers</emphasis>
       <filename>/dev/sdb</filename> is configured as an additional Volume
       Group to be used for VM storage
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Additional disks can be configured for any of these roles by editing the
     corresponding <filename>data/disks_*.yml</filename> file
    </para>
   </listitem>
  </varlistentry>
 </variablelist>
</section>
