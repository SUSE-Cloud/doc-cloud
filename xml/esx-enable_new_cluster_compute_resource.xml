<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="sec.esx.new-cluster">
 <title>Enabling a New Cluster as a Compute Resource</title>
 <para>
  When a new cluster is created in vCenter, EON's periodic pooling task fetches
  the new cluster information and updates the inventory. Currently, the state
  of a new cluster is <emphasis role="bold">imported</emphasis>.
 </para>

 <!-- FIXME: Deduplicate via xpointers? Originally from:
 installation/installing_esx_kvm_vsa.dita#install_esx/activate-cluster -->
 <section xml:id="idg-all-esx-enable_new_cluster_compute_resource-xml-6">
  <title>Activate Clusters</title>
  <para>
   This involves using the activation template to register the cloud network
   configuration for the vCenter.
  </para>
  <note>
   <para>
    The minimum disk space required for a cluster activation is
    <literal>(<replaceable>HOSTS_CLUSTER</replaceable> + 1 ) *
    45Â GB</literal> where <replaceable>HOSTS_CLUSTER</replaceable> signifies
    the number of hosts in that cluster.
   </para>
  </note>
  <para>
   This process spawns one compute proxy VM per cluster and one OVSvApp VM per
   host and configures the networking as defined in the JSON template. This
   process also updates the input model with the service VM details and
   triggers the ansible playbooks on the new nodes.
  </para>
  <orderedlist>
   <listitem>
    <para>
     Activate the cluster for the selected vCenter.
    </para>
<screen># eon resource-activate &lt;RESOURCE_ID&gt; --config-json /home/user/&lt;ACTIVATION_JSON_NAME&gt;</screen>
   </listitem>
   <listitem>
    <para>
     Execute the following command to view the status of the cluster:
    </para>
<screen>eon resource-list
+--------------------------------------+-----------+-------------+--------------------------------------+------------+-------+------------+------------+
| ID                                   | Name      | Moid        | Resource Manager ID                  | IP Address | Port  | Type       | State      |
+--------------------------------------+-----------+-------------+--------------------------------------+------------+-------+------------+------------+
| 1228fce5-df5d-445c-834e-ae633ac7e426 | Cluster2  | domain-c184 | BC9DED4E-1639-481D-B190-2B54A2BF5674 | UNSET      | UNSET | esxcluster | imported   |
| 469710f6-e9f2-48a4-aace-1f00cbd60487 | virtClust | domain-c943 | BC9DED4E-1639-481D-B190-2B54A2BF5674 | UNSET      | UNSET | esxcluster | activated  |
| a3003a32-6e3a-4d89-a072-ec64a4247fb0 | Cluster1  | domain-c21  | BC9DED4E-1639-481D-B190-2B54A2BF5674 | UNSET      | UNSET | esxcluster | imported   |
+--------------------------------------+-----------+-------------+--------------------------------------+------------+-------+------------+------------+</screen>
    <para>
     When the state is <literal>activated</literal>, the input model is updated
     with the service VM details, a git commit has been performed, the required
     playbooks and the post activation checks are completed successfully.
    </para>
   </listitem>
  </orderedlist>
 </section>

 <!-- FIXME: Deduplicate via xpointers? Originally from:
 installation/installing_esx_kvm_vsa.dita#install_esx/modify-volume-config -->
 <section xml:id="idg-all-esx-enable_new_cluster_compute_resource-xml-8">
  <title>Modify the Volume Configuration File</title>
  <para>
   Once the cluster is activated you must configure the volume.
  </para>
  <para>
   Perform the following steps to modify the volume configuration files:
  </para>
  <procedure>
   <step>
    <para>
     Change the directory.
    </para>
<screen>cd /var/lib/ardana/openstack/my_cloud/config/cinder</screen>
   </step>
   <step>
    <para>
     Modify the <filename>cinder.conf.j2</filename>.
    </para>
<screen># Configure the enabled backends
enabled_backends=&lt;unique-section-name&gt;

# Start of section for VMDK block storage
#
# If you have configured VMDK Block storage for cinder you must
# uncomment this section, and replace all strings in angle brackets
# with the correct values for vCenter you have configured. You
# must also add the section name to the list of values in the
# 'enabled_backends' variable above. You must provide unique section
# each time you configure a new backend.

#[&lt;unique-section-name&gt;]
#vmware_api_retry_count = 10
#vmware_tmp_dir = /tmp
#vmware_image_transfer_timeout_secs = 7200
#vmware_task_poll_interval = 0.5
#vmware_max_objects_retrieval = 100
#vmware_volume_folder = cinder-volumes
#volume_driver = cinder.volume.drivers.vmware.vmdk.VMwareVcVmdkDriver
#vmware_host_ip = &lt;ip_address_of_vcenter&gt;
#vmware_host_username = &lt;vcenter_username&gt;
#vmware_host_password = &lt;password&gt;
#
#volume_backend_name = &lt;vmdk-backend-name&gt;
#
# End of section for VMDK block storage</screen>
   </step>
  </procedure>
 </section>

  <!-- FIXME: Deduplicate via xpointers? Originally from:
 installation/installing_esx_kvm_vsa.dita#install_esx/modify-volume-config -->
 <section xml:id="idg-all-esx-enable_new_cluster_compute_resource-xml-10">
  <title>Validate the compute</title>
  <para>
   You can validate that the ESX compute cluster is added to the cloud
   successfully using the following command:
  </para>
<screen>#  nova service-list</screen>
<screen>
<?dbsuse-fo font-size="0.65em"?>
+----+------------------+-----------------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host                  | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+-----------------------+----------+---------+-------+----------------------------+-----------------+
| 3  | nova-conductor   | doc-cp1-c1-m2-mgmt    | internal | enabled | up    | 2018-05-31T21:16:00.000000 | -               |
| 17 | nova-conductor   | doc-cp1-c1-m1-mgmt    | internal | enabled | up    | 2018-05-31T21:15:59.000000 | -               |
| 25 | nova-scheduler   | doc-cp1-c1-m2-mgmt    | internal | enabled | up    | 2018-05-31T21:16:00.000000 | -               |
| 27 | nova-scheduler   | doc-cp1-c1-m1-mgmt    | internal | enabled | up    | 2018-05-31T21:15:51.000000 | -               |
| 29 | nova-consoleauth | doc-cp1-c1-m1-mgmt    | internal | enabled | up    | 2018-05-31T21:15:59.000000 | -               |
| 57 | nova-compute     | doc-cp1-comp0001-mgmt | nova     | enabled | up    | 2018-05-31T21:15:55.000000 | -               |
| 59 | nova-compute     | doc-cp1-comp0002-mgmt | nova     | enabled | up    | 2018-05-31T21:15:56.000000 | -               |
+----+------------------+-----------------------+----------+---------+-------+----------------------------+-----------------+
</screen>
  <para>
   Verify the Hypervisor hostname and its status.
  </para>
<screen># nova hypervisor-list</screen>
<screen >+----+-------------------------------------------------+-------+----------+
| ID | Hypervisor hostname                             | State | Status   |
+----+-------------------------------------------------+-------+----------+
| 9  | domain-c40.9FDCFA66-6677-42A1-83FF-16DC32448021 | up    | enabled  |
+----+-------------------------------------------------+-------+----------+</screen>
 </section>

  <!-- FIXME: Deduplicate via xpointers? Originally from:
 installation/installing_esx_kvm_vsa.dita#install_esx/verify-neutron -->
 <section xml:id="verify-neutron">
  <title>Validating the &o_netw; Installation</title>
  <para>
   You can validate that the ESX compute cluster is added to the cloud
   successfully using the following command:
  </para>
<screen># neutron agent-list</screen>
<screen>
<?dbsuse-fo font-size="0.65em"?>
+------------------+----------------------+-----------------------+-------------------+-------+----------------+---------------------------+
| id               | agent_type           | host                  | availability_zone | alive | admin_state_up | binary                    |
+------------------+----------------------+-----------------------+-------------------+-------+----------------+---------------------------+
| 05ca6ef...999c09 | L3 agent             | doc-cp1-comp0001-mgmt | nova              | :-)   | True           | neutron-l3-agent          |
| 3b9179a...28e2ef | Metadata agent       | doc-cp1-comp0001-mgmt |                   | :-)   | True           | neutron-metadata-agent    |
| 3d756d7...a719a2 | Loadbalancerv2 agent | doc-cp1-comp0001-mgmt |                   | :-)   | True           | neutron-lbaasv2-agent     |
| 4e8f84f...c9c58f | Metadata agent       | doc-cp1-comp0002-mgmt |                   | :-)   | True           | neutron-metadata-agent    |
| 55a5791...c17451 | L3 agent             | doc-cp1-c1-m1-mgmt    | nova              | :-)   | True           | neutron-vpn-agent         |
| 5e3db8f...87f9be | Open vSwitch agent   | doc-cp1-c1-m1-mgmt    |                   | :-)   | True           | neutron-openvswitch-agent |
| 6968d9a...b7b4e9 | L3 agent             | doc-cp1-c1-m2-mgmt    | nova              | :-)   | True           | neutron-vpn-agent         |
| 7b02b20...53a187 | Metadata agent       | doc-cp1-c1-m2-mgmt    |                   | :-)   | True           | neutron-metadata-agent    |
| 8ece188...5c3703 | Open vSwitch agent   | doc-cp1-comp0002-mgmt |                   | :-)   | True           | neutron-openvswitch-agent |
| 8fcb3c7...65119a | Metadata agent       | doc-cp1-c1-m1-mgmt    |                   | :-)   | True           | neutron-metadata-agent    |
| 9f48967...36effe | Loadbalancerv2 agent | doc-cp1-comp0002-mgmt |                   | :-)   | True           | neutron-lbaasv2-agent     |
| a2a0b78...026da9 | Open vSwitch agent   | doc-cp1-comp0001-mgmt |                   | :-)   | True           | neutron-openvswitch-agent |
| a2fbd4a...28a1ac | DHCP agent           | doc-cp1-c1-m2-mgmt    | nova              | :-)   | True           | neutron-dhcp-agent        |
| b2428d5...ee60b2 | DHCP agent           | doc-cp1-c1-m1-mgmt    | nova              | :-)   | True           | neutron-dhcp-agent        |
| c0983a6...411524 | Open vSwitch agent   | doc-cp1-c1-m2-mgmt    |                   | :-)   | True           | neutron-openvswitch-agent |
| c32778b...a0fc75 | L3 agent             | doc-cp1-comp0002-mgmt | nova              | :-)   | True           | neutron-l3-agent          |
+------------------+----------------------+-----------------------+-------------------+-------+----------------+---------------------------+
</screen>
 </section>
<!---->
</section>
