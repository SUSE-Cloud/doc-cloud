<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="Integrating-Kibana-with-Splunk">
 <title>Integrating Your Logs with Splunk</title>
 <section xml:id="idg-all-operations-tutorials-integrating-logstash-splunk-xml-2">
  <title>Integrating with Splunk</title>
  <para>
   The &product; logging solution provides a flexible and extensible
   framework to centralize the collection and processing of logs from all nodes
   in your cloud. The logs are shipped to a highly available and fault-tolerant
   cluster where they are transformed and stored for better searching and
   reporting. The &product; logging solution uses the ELK stack
   (&elasticsearch;, Logstash and Kibana) as a production-grade implementation
   and can support other storage and indexing technologies.
  </para>
  <para>
   You can configure Logstash, the service that aggregates and forwards the
   logs to a searchable index, to send the logs to a third-party target, such
   as Splunk.
  </para>
  <para>
   For how to integrate the &product; centralized
   logging solution with Splunk, including the steps to set up and forward
   logs, please refer to <xref linkend="splunk-integration" />.
  </para>
 </section>
</section>
