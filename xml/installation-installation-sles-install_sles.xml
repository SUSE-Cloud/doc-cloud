<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xml:id="install_sles"
 xmlns="http://docbook.org/ns/docbook" version="5.1"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>Using the &lcm; to Deploy &slsa; Compute Nodes</title>
 <para>
  The method used for deploying &slsa; compute nodes using Cobbler on the
  &lcm; uses legacy BIOS.
 </para>
 <note>
  <para>
   UEFI and Secure boot are currently not supported on &slsa; compute.
  </para>
 </note>
 <section>
  <title>Deploying legacy BIOS &slsa; compute nodes</title>
  <para>
   <!-- FIXME: This paragraph is now saying that installing SLES is like
   installing SLES because we replaced hlinux->SLES. - sknorr, 2018-02-05 -->
   The installation process for &slsa; nodes is almost identical to that of
   &hlinux; nodes as described in <xref linkend="install_kvm"/>.
   The key differences are:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     The standard &slsa; ISO (SLE-12-SP3-Server-DVD-x86_64-GM-DVD1.iso) must be
     accessible via <literal>/home/stack/sles12sp3.iso</literal>. Rename the ISO
     or create a symbolic link:
    </para>
<screen>mv SLE-12-SP3-Server-DVD-x86_64-GM-DVD1.iso /home/stack/sles12sp3.iso</screen>
   </listitem>
   <listitem>
    <para>
     The contents of the &slsa; SDK ISO (SLE-12-SP3-SDK-DVD-x86_64-GM-DVD1.iso)
     must be mounted or copied to
     <literal>/srv/www/suse-12.3/x86_64/repos/ardana/sles12/zypper/SDK/</literal>. If you choose
     to mount the ISO, we recommend creating an <literal>/etc/fstab</literal>
     entry to ensure the ISO is mounted after a reboot.
    </para>
   </listitem>
   <listitem>
    <para>
     You must identify the node(s) on which you want to install &slsa;, by adding
     the key/value pair <literal>distro-id: sles12sp3-x86_64</literal> to
     server details in <literal>servers.yml</literal>. You will also need to
     update <literal>net_interfaces.yml</literal>,
     <literal>server_roles.yml</literal>, <literal>disk_compute.yml</literal>
     and <literal>control_plane.yml</literal>. For more information on
     configuration of the Input Model for &slsa;, see
     <xref linkend="sles_compute_model"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     &kw-hos; playbooks currently do not take care of the SDK, therefore it
     needs to be added manually. The following command needs to be run on every
     &slsa; compute node:
    </para>
<screen>
<?dbsuse-fo font-size="0.70em"?>
deployer_ip=192.168.10.254
zypper addrepo --no-gpgcheck --refresh http://$deployer_ip:79/ardana/sles12/zypper/SDK SLES-SDK</screen>
    <para>
     There is no need to add OS repo as in case of
     <xref linkend="provisioning_sles"/>, because &slsa; already
     comes with OS repo populated after a Cobbler-managed install.
    </para>
   </listitem>
  </itemizedlist>
 </section>
 <!-- FIXME: Comment from DITA original: "Removing for SLES since we don't
 know if there is support for UEFI and Secure Boot. Once tested, the UEFI and
 Secure Boot content might be able to be added back." -->
 <!-- <section>
     <title>Deploying UEFI &slsa; compute nodes</title>
     <sectiondiv id="sles_uefi_overview">
         <p><keyword keyref="kw-hos-phrase-30"/> required a manual procedure if you wanted to
             use the &lcm; to install &cloudos; on UEFI nodes as described in
             the article <xref linkend="install_rhel_compute"/>. This procedure has been
             automated in the &lcm;. </p>
     </sectiondiv>
     <p>Before you attempt to use the &lcm; to install &slsa; on UEFI nodes, you
         should install any &hlinux; nodes or any &slsa; on legacy BIOS nodes
         first.</p>
     <p> Execute the following steps to re-image one or more nodes after you have run the
             <codeph>ready-deployment.yml</codeph> playbook: <ol>
             <li>Prior to beginning these steps, the following must be true:
                 <ul
                     id="ul_eqk_vng_zx">
                     <li>All of your nodes using &hlinux; must already be
                         installed, either manually or via Cobbler.</li>
                     <li>Your input model should be configured for your &slsa; nodes, per the
                         instructions at <xref keyref="sles_compute_model"> &slsa; Compute
                             Model</xref>.</li>
                     <li>You should have run the configuration processor and the
                             <codeph>ready-deployment.yml</codeph> playbook.</li>
                 </ul></li>
             <li>Run the following playbook, which will extract the
                     <codeph>grubx64.efi</codeph> file which will be needed when imaging your
                 &slsa; UEFI nodes. <b outputclass="highlightThis">This section needs &slsa; yml files and examples</b>
                 <codeblock>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook prepare-rhel-loader.yml</codeblock></li>
             <li>Run the following playbook, ensuring that you specify only your UEFI &slsa;
                 nodes using the nodelist. This playbook will reconfigure Cobbler for the
                 nodes
                 listed.<codeblock>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook prepare-rhel-grub2.yml -e nodelist=node1[,node2,node3]</codeblock></li>
             <li>Re-image the node(s), ensuring that you only specify your UEFI &slsa; nodes
                 using the
                 nodelist.<codeblock>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml -e nodelist=node1[,node2,node3]</codeblock></li>
             <li>Make backups of the <codeph>grub.cfg-*</codeph> and
                     <codeph>grubx64.efi</codeph> files in <codeph>/srv/tftp/grub/</codeph>
                 as they will be overwritten when running the cobbler-deploy playbook on the
                 next step. You will need these files if you need to reimage the nodes in the
                 future.</li>
             <li>Run the <codeph>cobbler-deploy</codeph> playbook, which will reset Cobbler
                 back to the default
                 values:<codeblock>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock></li>
         </ol>
     </p>

     <p><b>UEFI Secure Boot</b></p>
     <p>Secure Boot is a method used to restrict binaries execution for
         booting the system. With this option enabled, system BIOS will only allow boot
         loaders with trusted cryptographic signatures to be executed, thus enable
         preventing malware from hiding embedded code in the boot chain. Each boot loader
         launched during the boot process is digitally signed and that signature is
         validated against a set of trusted certificates embedded in the UEFI BIOS.
         Secure Boot is completely implemented in the BIOS and does not require special
         hardware.</p>
     <p>Thus Secure Boot is: </p>
     <ol>
         <li>Intended to prevent boot-sector malware or kernel code injection.</li>
         <li>Hardware-based code signing.</li>
         <li>Extension of the UEFI BIOS architecture.</li>
         <li>Optional with the ability to enable or disable it through the BIOS.</li>
     </ol>
     <p>In Boot Options of RBSU, <codeph>Boot Mode</codeph> needs to be set to
         <codeph>UEFI Mode</codeph> and <codeph>UEFI Optimized Boot</codeph> should
         be <codeph>Enabled</codeph>. </p>
     <p> Secure Boot is enabled at
         <codeblock>System Configuration > BIOS/Platform Configuration (RBSU) > Server Security > Secure Boot Configuration > Secure Boot Enforcement
         </codeblock>
     </p>
 </section> -->
</section>
