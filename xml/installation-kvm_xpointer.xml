<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xml:id="sec.install_kvm_xpointer"
 xmlns="http://docbook.org/ns/docbook" version="5.1"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>XPointer File for SOC/HOS KVM Installation</title>

 <!-- FIXME: IDs are a huge issue here... we _need_ IDs on most of those
 sections. - sknorr, 2018-01-03 -->

 <!-- To include this section: <xi:include xpointer="element(/1/2)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Important Notes</title>
  <itemizedlist>
   <listitem>
    <para>
     If you are looking for information about when to use the GUI installer and
     when to use the CLI, see the <xref linkend="install_overview"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Review the <xref linkend="min_hardware"/> that we have listed.
    </para>
   </listitem>
   <listitem>
    <para>
     Review the release notes to make
     yourself aware of any known issues and limitations.
    </para>
   </listitem>
   <listitem>
    <para>
     The installation process can occur in different phases. For example, you
     can install the control plane only and then add Compute nodes afterwards
     if you would like.
    </para>
   </listitem>
   <!-- FIXME: Comment from DITA original: "consider including steps to
   achieve this" -->
   <listitem>
    <para>
     If you run into issues during installation, we have put together a list of
     <xref linkend="troubleshooting_installation"/> you can reference.
    </para>
   </listitem>
   <listitem>
    <para>
     Make sure all disks on the system(s) are wiped before you begin the
     install. (For Swift, refer to <xref linkend="topic_d1s_hht_tt"/>)
    </para>
   </listitem>
   <listitem>
    <para>
     There is no requirement to have a dedicated network for OS-install and
     system deployment, this can be shared with the management network. More
     information can be found in
     <xref linkend="example_configurations"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     You may see the terms deployer and lifecycle manager used interchangeably.
     These are referring to the same nodes in your environment.
    </para>
   </listitem>
   <listitem>
    <para>
     When running the Ansible playbook in this installation guide, if a runbook
     fails you will see in the error response to use the
     <literal>--limit</literal> switch when retrying a playbook. This should be
     avoided. You can simply re-run any playbook without this switch.
    </para>
   </listitem>
   <listitem>
    <para>
     DVR is not supported with ESX compute.
    </para>
   </listitem>
   <listitem>
    <para>
     When you attach a Cinder volume to the VM running on the ESXi host, the
     volume will not get detected automatically. Make sure to set the image
     metadata <emphasis role="bold">vmware_adaptertype=lsiLogicsas</emphasis>
     for image before launching the instance. This will help to discover the
     volume change appropriately.
    </para>
   </listitem>
  </itemizedlist>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/3)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Before You Start</title>
  <para>
   We have put together a <xref linkend="preinstall_checklist"/> that should
   help with the recommended pre-installation tasks.
  </para>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/4)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Setting Up the Lifecycle Manager</title>
  <para>
   <emphasis role="bold">Installing the Lifecycle Manager</emphasis>
  </para>
  <para>
   The lifecycle manager will contain the installation scripts and
   configuration files to deploy your cloud. You can set up the lifecycle
   manager on a dedicated node or you do so on your first controller node. The
   default choice is to use the first controller node as the lifecycle manager.
  </para>
  <procedure>
   <step>
    <para>
     Sign in and download the product and signature files at the link below:
    </para>
     <substeps>
	<step>
      <para>
       <link xlink:href="http://www.hpe.com/software/entitlements">Software
       Entitlement Portal</link>
      </para>
	 </step>
     </substeps>
   </step>
   <step>
    <para>
     You can verify the download was complete via the signature verification
     process outlined
     <link xlink:href="https://h20392.www2.hpe.com/portal/swdepot/displayProductInfo.do?productNumber=HPLinuxCodeSigning">here</link>.
    </para>
   </step>
   <step>
    <para>
     Boot your lifecycle manager from the ISO contained in the download.
    </para>
   </step>
   <step>
    <para>
     Enter "install" to start installation.
    </para>
    <note>
     <para>
      "install" is all lower case
     </para>
    </note>
   </step>
   <step>
    <para>
     Select the language. Note that only the English language selection is
     currently supported.
    </para>
   </step>
   <step>
    <para>
     Select the location.
    </para>
   </step>
   <step>
    <para>
     Select the keyboard layout.
    </para>
   </step>
   <step>
    <para>
     Select the primary network interface, if prompted:
    </para>
     <substeps>
	<step>
      <para>
       Assign IP address, subnet mask, and default gateway
      </para>
     </step>
	</substeps>
   </step>
   <step>
    <para>
     Create new account:
    </para>
     <substeps>
	<step>
      <para>
       Enter a username.
      </para>
     </step>
     <step>
      <para>
       Enter a password.
      </para>
     </step>
     <step>
      <para>
       Enter time zone.
      </para>
	</step>
     </substeps>
   </step>
  </procedure>
  <para>
   Once the initial installation is finished, complete the lifecycle manager
   setup with these steps:
  </para>
  <procedure>
   <step>
    <para>
     Ensure your lifecycle manager has a valid DNS nameserver specified in
     <literal>/etc/resolv.conf</literal>.
    </para>
   </step>
   <step>
    <para>
     Set the environment variable LC_ALL:
    </para>
<screen>export LC_ALL=C</screen>
    <note>
     <para>
      This can be added to <literal>~stack/.bashrc</literal> or
      <literal>/etc/bash.bashrc</literal>.
     </para>
    </note>
   </step>
  </procedure>
  <para>
   At the end of this section you should have a node set up with Linux for HPE
   Helion on it.
  </para>
  <para>
   <emphasis role="bold">Configure and Run the Lifecycle Manager</emphasis>
  </para>
  <important>
   <para>
    It is critical that you don't run any of the commands below as the
    <literal>root</literal> user or use <literal>sudo</literal>, unless it is
    stated explicitly in the steps. Run then as the user you just created (or
    <literal>stack</literal> if you left the default of "stack").
   </para>
  </important>
  <procedure>
   <step>
    <para>
     Log into your lifecycle manager as the user you created and mount the
     install media at <literal>/media/cdrom</literal>. It may be necessary to
     use <literal>wget</literal> or another file transfer method to transfer
     the install media to the lifecycle manager before completing this step.
     Here is the command to mount the media:
    </para>
    <para>
     Example for &kw-hos-tm; &kw-hos-version;:
    </para>
<screen>sudo mount HelionOpenStack-5.0.iso /media/cdrom</screen>
   </step>
   <step>
    <para>
     Unpack the tarball that is in the <literal>/media/cdrom/hos/</literal>
     directory:
    </para>
    <para>
     Example for &kw-hos-phrase;
    </para>
<screen>tar xvf /media/cdrom/hos/hos-5.0.0-&lt;timestamp&gt;.tar</screen>
   </step>
   <step>
    <para>
     Run the hos-init.bash script which is included in the build:
    </para>
    <para>
     Example for &kw-hos-tm; &kw-hos-version;
    </para>
<screen>~/hos-5.0.0/hos-init.bash</screen>
    <para>
     You will be prompted to enter an optional SSH passphrase when running
     <literal>hos-init.bash</literal>. This passphrase is used to protect the
     key used by Ansible when connecting to its client nodes. If you do not
     want to use a passphrase then just press <keycap function="enter"/>
     at the prompt.
    </para>
    <para>
     For automated installation (for example CI) it is possible to disable SSH
     passphrase prompting by setting the <literal>HOS_INIT_AUTO</literal>
     environment variable before running <literal>hos-init.bash</literal>, like
     this:
    </para>
<screen>export HOS_INIT_AUTO=y</screen>
   </step>
  </procedure>
  <para>
   If you have protected the SSH key with a passphrase then execute the
   following commands to avoid having to enter the passphrase on every attempt
   by Ansible to connect to its client nodes:
  </para>
<screen>eval $(ssh-agent)
ssh-add ~/.ssh/id_rsa</screen>
  <para>
   At the end of this section you should have a local directory structure, as
   described below:
  </para>
<screen>
<?dbsuse-fo font-size="0.70em"?>
~/helion/                        Top level directory
~/helion/examples/               Directory contains the config input files of the example clouds
~/helion/my_cloud/definition/    Directory contains the config input files
~/helion/my_cloud/config/        Directory contains .j2 files which are symlinks to the ~/helion/hos/ansible directory
~/helion/hos/                    Directory contains files used by the installer</screen>
  <warning>
   <para>
    It is important that you do not add any extra files in the
    <filename>~/helion</filename> directory on your lifecycle manager. This
    includes temporary save files. Doing so will cause errors during the
    installation.
   </para>
  </warning>
  <important>
   <para>
    Be aware that the files in the
    <filename>~/helion/my_cloud/config/</filename> directory are symlinks to
    the <filename>~/helion/hos/ansible/</filename> directory. For example,
    <filename>~/helion/my_cloud/config/keepalived/defaults.yml</filename> is
    a symbolic link to
    <filename>~/helion/hos/ansible/roles/keepalived/defaults/main.yml</filename>.
   </para>
<screen>
<?dbsuse-fo font-size="0.70em"?>
ls -al ~/helion/my_cloud/config/keepalived/defaults.yml
lrwxrwxrwx 1 stack stack 55 May 24 20:38 /home/stack/helion/my_cloud/config/keepalived/defaults.yml -> ../../../hos/ansible/roles/keepalived/defaults/main.yml
</screen>
   <para>
    If you are using a tool like <command>sed</command> to make edits to
    files in this directory, you might break the symbolic link and create a
    new copy of the file. To maintain the link, you will need to force
    <command>sed</command> to follow the link:
   </para>
   <screen>sed -i --follow-symlinks \
's$keepalived_vrrp_offset: 0$keepalived_vrrp_offset: 2$' \
~/helion/my_cloud/config/keepalived/defaults.yml</screen>
   <para>
    Alternatively, directly edit the target of the link
    <filename>~/helion/hos/ansible/roles/keepalived/defaults/main.yml</filename>.
   </para>
  </important>
  <para>
   For any troubleshooting information regarding these steps, see
    <xref linkend="sec.trouble-deployer_setup"/>.
  </para>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/5)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Configuring Your Environment</title>
  <para>
   During the configuration phase of the installation you will be making
   modifications to the example configuration input files to match your cloud
   environment. You should use the <xref linkend="example_configurations"/>
   documentation for detailed information on how to do this. There is also a
   <filename>README.md</filename> file included in each of the example
   directories on the lifecycle manager that has useful information about the
   models.
  </para>
  <para>
   In the steps below we show how to set up the directory structure with the
   example input files as well as use the optional encryption methods for your
   sensitive data.
  </para>
  <procedure>
   <step>
    <para>
     Setup your configuration files, as follows:
    </para>
     <substeps>
	<step>
      <para>
       Copy the example configuration files into the required setup directory
       and edit them to contain the details of your environment.
      </para>
      <para>
       For example, if you want to use the Helion Mid-scale KVM with VSA model,
       you can use this command to copy the files to your cloud definition
       directory:
      </para>
<screen>
<?dbsuse-fo font-size="0.70em"?>
cp -r ~/helion/examples/mid-scale-kvm-vsa/* ~/helion/my_cloud/definition/</screen>
      <para>
       If you want to use the Helion Entry-scale KVM with VSA model, you can
       use this command to copy the files to your cloud definition directory:
      </para>
<screen>cp -r ~/helion/examples/entry-scale-kvm-vsa/* ~/helion/my_cloud/definition/</screen>
     </step>
     <step>
      <para>
       Begin inputting your environment information into the configuration
       files in the <literal>~/helion/my_cloud/definition</literal> directory.
      </para>
      <para>
       If you are using the Mid-scale or Entry-scale KVM with VSA model, see
       <xref linkend="modify_entryscale_kvm_vsa"/> for details.
      </para>
      <para>
       If you are using the Entry-scale KVM with Ceph model, see
       <!-- FIXME: <xref linkend="ceph_overview"/> --> for details.
      </para>
      </step>
     </substeps>
   </step>

   <!-- To include this listitem: <xi:include xpointer="element(/1/5/4/2)" href="installation-kvm_xpointer.xml"/> -->
   <step> <!-- xml:id="hosencrypt" -->
    <para>
     [OPTIONAL] - You can use the <literal>hosencrypt.py</literal> script to
     encrypt your iLo passwords. This script uses OpenSSL.
    </para>
     <substeps>
	<step>
      <para>
       Change to the Ansible directory:
      </para>
<screen>cd ~/helion/hos/ansible</screen>
     </step>
     <step>
      <para>
       Put the encryption key into the following environment variable:
      </para>
<screen>export HOS_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</screen>
     </step>
     <step>
      <para>
       Run the python script below and follow the instructions. Enter a
       password that you want to encrypt.
      </para>
<screen>./hosencrypt.py</screen>
     </step>
     <step>
      <para>
       Take the string generated and place it in the
       <literal>"ilo-password"</literal> field in your
       <literal>~/helion/my_cloud/definition/data/servers.yml</literal> file,
       remembering to enclose it in quotes.
      </para>
     </step>
     <step>
      <para>
       Repeat the above for each server.
      </para>
      <note>
       <para>
        Before you run any playbooks, remember that you need to export the
        encryption key in the following environment variable: <literal>export
        HOS_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</literal>
       </para>
      </note>
	</step>
     </substeps>
   </step>

   <!-- To include this listitem: <xi:include xpointer="element(/1/5/4/3)" href="installation-kvm_xpointer.xml"/> -->
   <step> <!-- xml:id="commit" -->
    <para>
     Commit your configuration to the local git repo (<xref linkend="using_git"/>), as follows:
    </para>
<screen>cd ~/helion/hos/ansible
git add -A
git commit -m "My config or other commit message"</screen>
    <important>
     <para>
      This step needs to be repeated any time you make changes to your
      configuration files before you move onto the following steps. See
      <xref linkend="using_git"/> for more information.
     </para>
    </important>
   </step>
  </procedure>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/6)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Provisioning Your Baremetal Nodes</title>
  <para>
   To provision the baremetal nodes in your cloud deployment you can either use
   the automated operating system installation process provided by &kw-hos; or
   you can use the 3rd party installation tooling of your choice. We will
   outline both methods below:
  </para>
  <para>
   <emphasis role="bold">Using 3rd Party Baremetal Installers</emphasis>
  </para>
  <para>
   If you do not wish to use the automated operating system installation
   tooling included with &kw-hos-version; then the requirements that have to be
   met using the installation tooling of your choice are:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     The operating system must be installed via the HPE Linux for &kw-hos; ISO
     provided on the
     <link xlink:href="http://www.hpe.com/software/entitlements">Software
     Entitlement Portal</link>.
    </para>
   </listitem>
   <listitem>
    <para>
     Each node must have SSH keys in place that allows the same user from the
     lifecycle manager node who will be doing the deployment to SSH to each
     node without a password.
    </para>
   </listitem>
   <listitem>
    <para>
     Passwordless sudo needs to be enabled for the user.
    </para>
   </listitem>
   <listitem>
    <para>
     There should be a LVM logical volume as <literal>/root</literal> on each
     node.
    </para>
   </listitem>
   <listitem>
    <para>
     If the LVM volume group name for the volume group holding the "root" LVM
     logical volume is hlm-vg then it will align with the disk input models in
     the examples.
    </para>
   </listitem>
   <listitem>
    <para>
     <phrase>Ensure that <literal>openssh-server</literal>,
     <literal>python</literal>, <literal>python-apt</literal>, and
     <literal>rsync</literal> are installed.</phrase>
    </para>
   </listitem>
  </itemizedlist>
  <para>
   If you chose this method for installing your baremetal hardware, skip
   forward to the <!-- FIXME: this seems to be the wrong reference <xref linkend="install_kvm"/> - sknorr, 2018-01-19 --> step.
  </para>
  <para>
   If you would like to use the automated operating system installation tools
   provided by &kw-hos-version; then complete all of the steps below.
  </para>
  <para>
   <emphasis role="bold">Using the Automated Operating System Installation
   Provided by &kw-hos;</emphasis>
  </para>
  <para>
   <emphasis role="bold">Part One: Deploy Cobbler</emphasis>
  </para>
  <para>
   This phase of the install process takes the baremetal information that was
   provided in <literal>servers.yml</literal> and installs the Cobbler
   provisioning tool and loads this information into Cobbler. This sets each
   node to <literal>netboot-enabled: true</literal> in Cobbler. Each node will
   be automatically marked as <literal>netboot-enabled: false</literal> when it
   completes its operating system install successfully. Even if the node tries
   to PXE boot subsequently, Cobbler will not serve it. This is deliberate so
   that you can't reimage a live node by accident.
  </para>
  <para>
   The <literal>cobbler-deploy.yml</literal> playbook prompts for a password -
   this is the password that will be encrypted and stored in Cobbler, which is
   associated with the user running the command on the lifecycle manager, that
   you will use to log in to the nodes via their consoles after install. The
   username is the same as the user set up in the initial dialogue when
   installing the lifecycle manager from the iso, and is the same user that is
   running the cobbler-deploy play.
  </para>
  <procedure>
   <step>
    <para>
     Run the following playbook which confirms that there is iLo connectivity
     for each of your nodes so that they are accessible to be re-imaged in a
     later step:
    </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-power-status.yml</screen>
   </step>
   <step>
    <para>
     Run the following playbook to deploy Cobbler:
    </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</screen>
   </step>
  </procedure>
  <para>
   <emphasis role="bold">Part Two: Image the Nodes</emphasis>
  </para>
  <para>
   This phase of the install process goes through a number of distinct steps:
  </para>
  <orderedlist>
   <listitem>
    <para>
     Powers down the nodes to be installed
    </para>
   </listitem>
   <listitem>
    <para>
     Sets the nodes hardware boot order so that the first option is a network
     boot.
    </para>
   </listitem>
   <listitem>
    <para>
     Powers on the nodes. (The nodes will then boot from the network and be
     installed using infrastructure set up in the previous phase)
    </para>
   </listitem>
   <listitem>
    <para>
     Waits for the nodes to power themselves down (this indicates a success
     install). This can take some time.
    </para>
   </listitem>
   <listitem>
    <para>
     Sets the boot order to hard disk and powers on the nodes.
    </para>
   </listitem>
   <listitem>
    <para>
     Waits for the nodes to be ssh-able and verifies that they have the
     signature expected.
    </para>
   </listitem>
  </orderedlist>
  <para>
   The reimage command is:
  </para>
<screen>
<?dbsuse-fo font-size="0.70em"?>
cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml [-e nodelist=node1,node2,node3]</screen>
  <para>
   If a nodelist is not specified then the set of nodes in cobbler with
   <literal>netboot-enabled: True</literal> is selected. The playbook pauses at
   the start to give you a chance to review the set of nodes that it is
   targeting and to confirm that it's correct.
  </para>
  <para>
   You can use the command below which will list all of your nodes with the
   <literal>netboot-enabled: True</literal> flag set:
  </para>
<screen>sudo cobbler system find --netboot-enabled=1</screen>
  <para>
   For any troubleshooting information regarding these steps, see
   <xref linkend="sec.trouble-deploy_cobbler"/>.
  </para>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/7)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Running the Configuration Processor</title>
  <para>
   Once you have your configuration files setup you need to run the
   configuration processor to complete your configuration.
  </para>
  <para>
   When you run the configuration processor you will be prompted for two
   passwords. Enter the first password to make the configuration processor
   encrypt its sensitive data, which consists of the random inter-service
   passwords that it generates and the ansible <literal>group_vars</literal>
   and <literal>host_vars</literal> that it produces for subsequent deploy
   runs. You will need this password for subsequent ansible deploy and
   configuration processor runs. If you wish to change an encryption password
   that you have already used when running the configuration processor then
   enter the new password at the second prompt, otherwise just press
   <keycap function="enter"/> to bypass this.
  </para>
  <para>
   Run the configuration processor with this command:
  </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
  <para>
   For automated installation (for example CI) you can specify the required passwords
   on the ansible command line. For example, the command below will disable
   encryption by the configuration processor
  </para>
<screen>
<?dbsuse-fo font-size="0.70em"?>
ansible-playbook -i hosts/localhost config-processor-run.yml -e encrypt="" -e rekey=""</screen>
  <para>
   If you receive an error during this step then there is probably an issue
   with one or more of your configuration files. We recommend that you verify
   that all of the information in each of your configuration files is correct
   for your environment and then commit those changes to git using the
   instructions in the previous section before re-running the configuration
   processor again.
  </para>
  <para>
   For any troubleshooting information regarding these steps, see
   <xref linkend="sec.trouble-config_processor"/>.
  </para>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/8)" href="installation-kvm_xpointer.xml"/>-->
 <section>
  <title>Configuring TLS</title>
  <important>
   <para>
    This section is optional, but recommended, for a &kw-hos; installation.
   </para>
  </important>
  <para>
   After you run the configuration processor the first time, the IP addresses
   for your environment will be generated and populated in the
   <literal>~/helion/my_cloud/info/address_info.yml</literal> file. It's at
   this point that you will want to take into consideration whether or not you
   want to configure TLS and setup a SSL certificate for your environment.
   Please read <xref linkend="tls30"/> before proceeding for
   how to achieve this.
  </para>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/9)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Deploying the Cloud</title>
  <procedure>
   <step>
    <para>
     Use the playbook below to create a deployment directory:
    </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
   </step>
   <step>
    <para>
     [OPTIONAL] - Run the <literal>wipe_disks.yml</literal> playbook to ensure
     all of your partitions on your nodes are completely wiped before
     continuing with the installation. If you are using fresh machines this
     step may not be necessary.
    </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts wipe_disks.yml</screen>
    <para>
     If you have used an encryption password when running the configuration
     processor use the command below and enter the encryption password when
     prompted:
    </para>
<screen>ansible-playbook -i hosts/verb_hosts wipe_disks.yml --ask-vault-pass</screen>
   </step>
   <step>
    <para>
     Run the <literal>site.yml</literal> playbook below:
    </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts site.yml</screen>
    <para>
     If you have used an encryption password when running the configuration
     processor use the command below and enter the encryption password when
     prompted:
    </para>
<screen>ansible-playbook -i hosts/verb_hosts site.yml --ask-vault-pass </screen>
    <note>
     <para>
      The step above runs <literal>osconfig</literal> to configure the cloud
      and <literal>hlm-deploy</literal> to deploy the cloud. Therefore, this
      step may run for a while, perhaps 45 minutes or more, depending on the
      number of nodes in your environment.
     </para>
    </note>
   </step>
   <step>
    <para>
     Verify that the network is working correctly. Ping each IP in the
     <literal>/etc/hosts</literal> file from one of the controller nodes.
    </para>
   </step>
  </procedure>
  <para>
   For any troubleshooting information regarding these steps, see
   <xref linkend="sec.trouble-deploy_cloud"/>.
  </para>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/10)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Configuring a Block Storage Backend (Optional)</title>
  <para>
   &kw-hos; supports VSA, 3PAR, and Ceph as block storage backend options. You
   can utilize one or more of these as setting up multiple block storage
   backends and multiple volume types is supported.
  </para>
  <para>
   Regardless of whether you have a single or multiple block storage backends
   defined in your <literal>cinder.conf.j2</literal> file then you can create
   one or more volume types using the specific attributes associated with the
   backend. You can find details on how to do that for each of the supported
   backend types here:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     <xref linkend="config_vsa"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="ceph_overview"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="config_3par"/>
    </para>
   </listitem>
  </itemizedlist>
 </section>

 <!-- To include this section: <xi:include xpointer="element(/1/11)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Post-Installation Verification and Administration</title>
  <para>
   We recommend verifying the installation using the instructions in
   <xref linkend="cloud_verification"/>.
  </para>
  <para>
   There are also a list of other common post-installation administrative tasks
   listed in the <xref linkend="postinstall_checklist"/> list.
  </para>
 </section>
</section>
