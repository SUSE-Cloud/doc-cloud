<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<section xml:id="sec.install_kvm_xpointer"
 xmlns="http://docbook.org/ns/docbook" version="5.1"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>XPointer File for SOC/HOS KVM Installation</title>
<!--
 IMPORTANT: Working With This File

 If you MAKE STRUCTURAL CHANGES to this file, do not forget to
 UPDATE ALL FILES THAT EMBED SECTIONS from this file.

 Add new sections only at the end.
 To find all files embedding sections of this file, do:
 $ grep -m1 "href=[\"']installation-kvm_xpointer.xml[\"']" xml/*
 (-m1 means you only get the line with first XInclude within each file.)
 -->
<!-- To include this section: <xi:include xpointer="element(/1/2)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Important Notes</title>
  <itemizedlist>
   <listitem>
    <para>
     For information about when to use the GUI installer and when to use the
     command line (CLI), see <xref linkend="preinstall_overview"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Review the <xref linkend="min_hardware"/> that we have listed.
    </para>
   </listitem>
   <listitem>
    <para>
     Review the release notes to make yourself aware of any known issues and
     limitations.
    </para>
   </listitem>
   <listitem>
    <para>
     The installation process can occur in different phases. For example, you
     can install the control plane only and then add Compute nodes afterwards
     if you would like.
    </para>
   </listitem>
<!-- FIXME: Comment from DITA original: "consider including steps to
   achieve this" -->
   <listitem>
    <para>
     If you run into issues during installation, we have put together a list of
     <xref linkend="troubleshooting_installation"/> you can reference.
    </para>
   </listitem>
   <listitem>
    <para>
     Make sure all disks on the system(s) are wiped before you begin the
     install. (For Swift, refer to <xref linkend="topic_d1s_hht_tt"/>.)
    </para>
   </listitem>
   <listitem>
    <para>
     There is no requirement to have a dedicated network for OS-install and
     system deployment, this can be shared with the management network. More
     information can be found in <xref linkend="example_configurations"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     The terms deployer and &clm; are used interchangeably. They refer to the
     same nodes in your cloud environment.
    </para>
   </listitem>
   <listitem>
    <para>
     When running the Ansible playbook in this installation guide, if a runbook
     fails you will see in the error response to use the
     <literal>--limit</literal> switch when retrying a playbook. This should be
     avoided. You can simply re-run any playbook without this switch.
    </para>
   </listitem>
   <listitem>
    <para>
     DVR is not supported with ESX compute.
    </para>
   </listitem>
   <listitem>
    <para>
     When you attach a Cinder volume to the VM running on the ESXi host, the
     volume will not get detected automatically. Make sure to set the image
     metadata <emphasis role="bold">vmware_adaptertype=lsiLogicsas</emphasis>
     for image before launching the instance. This will help to discover the
     volume change appropriately.
    </para>
   </listitem>
   <listitem>
    <para>
     The installation process will create several &ostack; roles. Not all roles
     will be relevant for a cloud with &o_objstore; only, but they will not cause
     problems.
    </para>
   </listitem>
  </itemizedlist>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/3)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Prepare for Cloud Installation</title>
  <procedure>
   <step>
    <para>
     Review the <xref linkend="preinstall_checklist"/> about recommended
     pre-installation tasks.
    </para>
   </step>
   <step>
    <para>
     Prepare the &clm; node. The &clm; must be accessible either directly or via
     <literal>ssh</literal>, and have &cloudos; installed. All nodes must
     be accessible to the &clm;. If the nodes do not have direct access to
     online Cloud subscription channels, the &clm; node will need to host the
     Cloud repositories.
    </para>
    <substeps>
     <step>
      <para>
       If you followed the installation instructions for &clm; server (see <xref
       linkend="cha.depl.dep_inst"/>), &productname; software should already be
       installed. Double-check whether &sle; and &productname; are properly
       registered at the &scc; by starting &yast; and running <menuchoice>
       <guimenu>Software</guimenu> <guimenu>Product
       Registration</guimenu></menuchoice>.
      </para>
      <para>
       If you have not yet installed &productname;, do so by starting &yast; and
       running <menuchoice> <guimenu>Software</guimenu> <guimenu>Product
       Registration</guimenu> <guimenu>Select
       Extensions</guimenu></menuchoice>. Choose <guimenu>&productname;</guimenu>
       and follow the on-screen instructions. Make sure to register
       &productname; during the installation process and to install the software
       pattern <literal>patterns-cloud-ardana</literal>.
      </para>
      <screen>&prompt.sudo;zypper -n in patterns-cloud-ardana</screen>
     </step>
     <step>
      <para>
       Ensure the &productname; media repositories and updates repositories are
       made available to all nodes in your deployment. This can be accomplished
       either by configuring the &clm; server as an SMT mirror as described in
       <xref linkend="app.deploy.smt_lcm" /> or by syncing or mounting the
       Cloud and updates repositories to the &clm; server as described in <xref
       linkend="cha.depl.repo_conf_lcm"/>.
      </para>
     </step>
     <step>
      <para>
       Configure passwordless <command>sudo</command> for the user created when
       setting up the node (as described in <xref
       linkend="sec.depl.adm_inst.user"/>). Note that this is
       <emphasis>not</emphasis> the user <systemitem
       class="username">ardana</systemitem> that will be used later in this
       procedure. In the following we assume you named the user <systemitem
       class="username">cloud</systemitem>. Run the command
       <command>visudo</command> as user &rootuser; and add the following line
       to the end of the file:
      </para>
      <screen><replaceable>CLOUD</replaceable> ALL = (root) NOPASSWD:ALL</screen>
      <para>
       Make sure to replace <replaceable>CLOUD</replaceable> with your user name
       choice.
      </para>
     </step>
     <step>
      <para>
       Set the password for the user
       <systemitem class="username">ardana</systemitem>:
      </para>
<screen>&prompt.sudo;passwd ardana</screen>
     </step>
     <step>
      <para>
       Become the user <systemitem class="username">ardana</systemitem>:
      </para>
<screen>&prompt.user;su - ardana</screen>
     </step>
     <step>
      <para>
       Place a copy of the &cloudos; <filename>.iso</filename> in the
       <systemitem class="username">ardana</systemitem> home directory,
       <filename>var/lib/ardana</filename>, and rename it to
       <filename>sles12sp4.iso</filename>.
      </para>
     </step>
     <step>
      <para>
       Install the templates, examples, and working model directories:
      </para>
      <screen>&prompt.ardana;/usr/bin/ardana-init</screen>
     </step>
    </substeps>
   </step>
  </procedure>
</section>
<!-- To include this section: <xi:include xpointer="element(/1/4)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Setting Up the &clm;</title>
  <section>
   <title>Installing the &clm;</title>
   <para>
    Running the <command>ARDANA_INIT_AUTO=1</command> command is optional to
    avoid stopping for authentication at any step. You can also run
    <command>ardana-init</command>to launch the &clm;.  You will be prompted to
    enter an optional SSH passphrase, which is used to protect the key used by
    Ansible when connecting to its client nodes.  If you do not want to use a
    passphrase, press <keycap function="enter"/> at the prompt.
   </para>
   <para>
    If you have protected the SSH key with a passphrase, you can avoid having
    to enter the passphrase on every attempt by Ansible to connect to its
    client nodes with the following commands:
   </para>
<screen>&prompt.ardana;eval $(ssh-agent)
&prompt.ardana;ssh-add ~/.ssh/id_rsa
</screen>
   <para>
    The &clm; will contain the installation scripts and configuration files to
    deploy your cloud. You can set up the &clm; on a dedicated node or you do
    so on your first controller node. The default choice is to use the first
    controller node as the &clm;.
   </para>
   <procedure>
    <step>
     <para>
      Download the product from:
     </para>
     <substeps>
      <step>
       <para>
        <link xlink:href="https://scc.suse.com/">SUSE Customer Center</link>
       </para>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Boot your &clm; from the &slsa; ISO contained in the download.
     </para>
    </step>
    <step>
     <para>
      Enter <literal>install</literal> (all lower-case, exactly as spelled out
      here) to start installation.
     </para>
    </step>
    <step>
     <para>
      Select the language. Note that only the English language selection is
      currently supported.
     </para>
    </step>
    <step>
     <para>
      Select the location.
     </para>
    </step>
    <step>
     <para>
      Select the keyboard layout.
     </para>
    </step>
    <step>
     <para>
      Select the primary network interface, if prompted:
     </para>
     <substeps>
      <step>
       <para>
        Assign IP address, subnet mask, and default gateway
       </para>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Create new account:
     </para>
     <substeps>
      <step>
       <para>
        Enter a username.
       </para>
      </step>
      <step>
       <para>
        Enter a password.
       </para>
      </step>
      <step>
       <para>
        Enter time zone.
       </para>
      </step>
     </substeps>
    </step>
   </procedure>
   <para>
    Once the initial installation is finished, complete the &clm; setup with
    these steps:
   </para>
   <procedure>
    <step>
     <para>
      Ensure your &clm; has a valid DNS nameserver specified in
      <literal>/etc/resolv.conf</literal>.
     </para>
    </step>
    <step>
     <para>
      Set the environment variable LC_ALL:
     </para>
<screen>export LC_ALL=C</screen>
     <note>
      <para>
       This can be added to <filename>~/.bashrc</filename> or
       <filename>/etc/bash.bashrc</filename>.
      </para>
     </note>
    </step>
   </procedure>
   <para>
    The node should now have a working &slsa; setup.
   </para>
  </section>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/5)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Configuring Your Environment</title>
  <para>
   During the configuration phase of the installation you will be making
   modifications to the example configuration input files to match your cloud
   environment. You should use the <xref linkend="example_configurations"/>
   documentation for detailed information on how to do this. There is also a
   <filename>README.md</filename> file included in each of the example
   directories on the &clm; that has useful information about the models.
  </para>
  <para>
   In the steps below we show how to set up the directory structure with the
   example input files as well as use the optional encryption methods for your
   sensitive data.
  </para>
  <procedure>
   <step>
    <para>
     Set up your configuration files, as follows:
    </para>
    <substeps>
     <step>
      <para>
       Copy the example configuration files into the required setup directory
       and edit them to contain the details of your environment.
      </para>
      <para>
       For example, if you want to use the &productname; Mid-scale KVM model,
       you can use this command to copy the files to your cloud definition
       directory:
      </para>
<screen>&prompt.ardana;cp -r ~/openstack/examples/mid-scale-kvm/* \
~/openstack/my_cloud/definition/</screen>
      <para>
       If you want to use the &productname; Entry-scale KVM model, you can use
       this command to copy the files to your cloud definition directory:
      </para>
<screen>&prompt.ardana;cp -r ~/openstack/examples/entry-scale-kvm/* \
~/openstack/my_cloud/definition/</screen>
     </step>
     <step>
      <para>
       Begin inputting your environment information into the configuration
       files in the <filename>~/openstack/my_cloud/definition</filename>
       directory.
      </para>
     </step>
    </substeps>
   </step>
<!-- To include this listitem: <xi:include xpointer="element(/1/5/4/2)" href="installation-kvm_xpointer.xml"/> -->
   <step performance="optional"> <!-- xml:id="ardanaencrypt" -->
    <para>
     You can use the <literal>ardanaencrypt.py</literal> script to
     encrypt your IPMI passwords. This script uses OpenSSL.
    </para>
    <substeps>
     <step>
      <para>
       Change to the Ansible directory:
      </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible</screen>
     </step>
     <step>
      <para>
       Put the encryption key into the following environment variable:
      </para>
<screen>export ARDANA_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</screen>
     </step>
     <step>
      <para>
       Run the python script below and follow the instructions. Enter a
       password that you want to encrypt.
      </para>
<screen>&prompt.ardana;./ardanaencrypt.py</screen>
     </step>
     <step>
      <para>
       Take the string generated and place it in the
       <literal>ilo-password</literal> field in your
       <filename>~/openstack/my_cloud/definition/data/servers.yml</filename>
       file, remembering to enclose it in quotes.
      </para>
     </step>
     <step>
      <para>
       Repeat the above for each server.
      </para>
      <note>
       <para>
        Before you run any playbooks, remember that you need to export the
        encryption key in the following environment variable: <literal>export
        ARDANA_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</literal>
       </para>
      </note>
     </step>
    </substeps>
   </step>
<!-- To include this listitem: <xi:include xpointer="element(/1/5/4/3)" href="installation-kvm_xpointer.xml"/> -->
   <step> <!-- xml:id="commit" -->
    <para>
     Commit your configuration to the local git repo
     (<xref linkend="using_git"/>), as follows:
    </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;git add -A
&prompt.ardana;git commit -m "My config or other commit message"</screen>
    <important>
     <para>
      This step needs to be repeated any time you make changes to your
      configuration files before you move on to the following steps. See
      <xref linkend="using_git"/> for more information.
     </para>
    </important>
   </step>
  </procedure>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/6)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Provisioning Your Baremetal Nodes</title>
  <para>
   To provision the baremetal nodes in your cloud deployment you can either use
   the automated operating system installation process provided by &productname; or
   you can use the 3rd party installation tooling of your choice. We will
   outline both methods below:
  </para>
  <section>
   <title>Using Third Party Baremetal Installers</title>
   <para>
    If you do not wish to use the automated operating system installation
    tooling included with &productname; then the requirements that have to be met
    using the installation tooling of your choice are:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      The operating system must be installed via the &slsa; ISO provided on
      the <link xlink:href="https://scc.suse.com/">SUSE Customer Center</link>.
     </para>
    </listitem>
    <listitem>
     <para>
      Each node must have SSH keys in place that allows the same user from the
      &clm; node who will be doing the deployment to SSH to each node without a
      password.
     </para>
    </listitem>
    <listitem>
     <para>
      Passwordless sudo needs to be enabled for the user.
     </para>
    </listitem>
    <listitem>
     <para>
      There should be a LVM logical volume as <literal>/root</literal> on each
      node.
     </para>
    </listitem>
    <listitem>
     <para>
      If the LVM volume group name for the volume group holding the
      <literal>root</literal> LVM logical volume is
      <literal>ardana-vg</literal>, then it will align with the disk input
      models in the examples.
     </para>
    </listitem>
    <listitem>
     <para>
      <phrase>Ensure that <literal>openssh-server</literal>,
      <literal>python</literal>, <literal>python-apt</literal>, and
      <literal>rsync</literal> are installed.</phrase>
     </para>
    </listitem>
   </itemizedlist>
   <para>
    If you chose this method for installing your baremetal hardware, skip
    forward to the step
    <citetitle>Running the Configuration Processor</citetitle>.
   </para>
  </section>
  <section>
   <title>Using the Automated Operating System Installation Provided by &productname;</title>
   <para>
    If you would like to use the automated operating system installation tools
    provided by &productname;, complete the steps below.
   </para>
   <section>
    <title>Deploying Cobbler</title>
    <para>
     This phase of the install process takes the baremetal information that was
     provided in <literal>servers.yml</literal> and installs the Cobbler
     provisioning tool and loads this information into Cobbler. This sets each
     node to <literal>netboot-enabled: true</literal> in Cobbler. Each node
     will be automatically marked as <literal>netboot-enabled: false</literal>
     when it completes its operating system install successfully. Even if the
     node tries to PXE boot subsequently, Cobbler will not serve it. This is
     deliberate so that you cannot reimage a live node by accident.
    </para>
    <para>
     The <literal>cobbler-deploy.yml</literal> playbook prompts for a password
     - this is the password that will be encrypted and stored in Cobbler, which
     is associated with the user running the command on the &clm;, that you
     will use to log in to the nodes via their consoles after install. The
     username is the same as the user set up in the initial dialogue when
     installing the &clm; from the ISO, and is the same user that is running
     the cobbler-deploy play.
    </para>
    <procedure>
     <step>
      <para>
       Run the following playbook which confirms that there is IPMI connectivity
       for each of your nodes so that they are accessible to be re-imaged in a
       later step:
      </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost bm-power-status.yml</screen>
     </step>
     <step>
      <para>
       Run the following playbook to deploy Cobbler:
      </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost cobbler-deploy.yml</screen>
     </step>
    </procedure>
   </section>
   <section>
    <title>Imaging the Nodes</title>
    <para>
     This phase of the install process goes through a number of distinct steps:
    </para>
    <procedure>
     <step>
      <para>
       Powers down the nodes to be installed
      </para>
     </step>
     <step>
      <para>
       Sets the nodes hardware boot order so that the first option is a network
       boot.
      </para>
     </step>
     <step>
      <para>
       Powers on the nodes. (The nodes will then boot from the network and be
       installed using infrastructure set up in the previous phase)
      </para>
     </step>
     <step>
      <para>
       Waits for the nodes to power themselves down (this indicates a
       successful install). This can take some time.
      </para>
     </step>
     <step>
      <para>
       Sets the boot order to hard disk and powers on the nodes.
      </para>
     </step>
     <step>
      <para>
       Waits for the nodes to be reachable by SSH and verifies that they have the
       signature expected.
      </para>
     </step>
    </procedure>
    <para>
     Deploying nodes has been automated in the &clm; and requires the
     following:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       All of your nodes using &slsa; must already be installed, either
       manually or via Cobbler.
      </para>
     </listitem>
     <listitem>
      <para>
       Your input model should be configured for your &slsa; nodes.
      </para>
     </listitem>
     <listitem>
      <para>
       You should have run the configuration processor and the
       <filename>ready-deployment.yml</filename> playbook.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Execute the following steps to re-image one or more nodes after you have
     run the <filename>ready-deployment.yml</filename> playbook.
    </para>
    <procedure>
     <step>
      <para>
       Run the following playbook, specifying your &slsa; nodes using the
       nodelist. This playbook will reconfigure Cobbler for the nodes listed.
      </para>
      <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook prepare-sles-grub2.yml -e \
      nodelist=node1[,node2,node3]</screen>
     </step>
     <step>
      <para>
       Re-image the node(s) with the following command:
      </para>
      <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost bm-reimage.yml \
      -e nodelist=node1[,node2,node3]</screen>
     </step>
    </procedure>
    <para>
     If a nodelist is not specified then the set of nodes in Cobbler with
     <literal>netboot-enabled: True</literal> is selected. The playbook pauses
     at the start to give you a chance to review the set of nodes that it is
     targeting and to confirm that it is correct.
    </para>
    <para>
     You can use the command below which will list all of your nodes with the
     <literal>netboot-enabled: True</literal> flag set:
    </para>
<screen>sudo cobbler system find --netboot-enabled=1</screen>
   </section>
  </section>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/7)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Running the Configuration Processor</title>
  <para>
   Once you have your configuration files setup, you need to run the
   configuration processor to complete your configuration.
  </para>
  <para>
   When you run the configuration processor, you will be prompted for two
   passwords. Enter the first password to make the configuration processor
   encrypt its sensitive data, which consists of the random inter-service
   passwords that it generates and the ansible <literal>group_vars</literal>
   and <literal>host_vars</literal> that it produces for subsequent deploy
   runs. You will need this password for subsequent Ansible deploy and
   configuration processor runs. If you wish to change an encryption password
   that you have already used when running the configuration processor then
   enter the new password at the second prompt, otherwise just press
   <keycap function="enter"/> to bypass this.
  </para>
  <para>
   Run the configuration processor with this command:
  </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
  <para>
   For automated installation (for example CI), you can specify the required
   passwords on the ansible command line. For example, the command below will
   disable encryption by the configuration processor:
  </para>
<screen>&prompt.ardana;ansible-playbook -i hosts/localhost config-processor-run.yml \
  -e encrypt="" -e rekey=""</screen>
  <para>
   If you receive an error during this step, there is probably an issue with
   one or more of your configuration files. Verify that all information in each
   of your configuration files is correct for your environment. Then commit
   those changes to Git using the instructions in the previous section before
   re-running the configuration processor again.
  </para>
  <para>
   For any troubleshooting information regarding these steps, see
   <xref linkend="sec.trouble-config_processor"/>.
  </para>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/8)" href="installation-kvm_xpointer.xml"/>-->
 <section>
  <title>Configuring TLS</title>
  <important>
   <para>
    This section is optional, but recommended, for a &productname; installation.
   </para>
  </important>
  <para>
   After you run the configuration processor the first time, the IP addresses
   for your environment will be generated and populated in the
   <filename>~/openstack/my_cloud/info/address_info.yml</filename> file. At
   this point, consider whether to configure TLS and set up an SSL certificate
   for your environment. Please read <xref linkend="tls30"/> before proceeding
   for how to achieve this.
  </para>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/9)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Deploying the Cloud</title>
  <procedure>
   <step>
    <para>
     Use the playbook below to create a deployment directory:
    </para>
<screen>cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
   </step>
   <step>
    <para>
     [OPTIONAL] - Run the <literal>wipe_disks.yml</literal> playbook to ensure
     all of your partitions on your nodes are completely wiped before
     continuing with the installation. The <filename>wipe_disks.yml</filename>
     playbook is only meant to be run on systems immediately after running
     <filename>bm-reimage.yml</filename>. If used for any other case, it may
     not wipe all of the expected partitions.
    </para>
    <para>
     If you are using fresh machines this step may not be necessary.
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts wipe_disks.yml</screen>
    <para>
     If you have used an encryption password when running the configuration
     processor use the command below and enter the encryption password when
     prompted:
    </para>
<screen>&prompt.ardana;ansible-playbook -i hosts/verb_hosts wipe_disks.yml --ask-vault-pass</screen>
   </step>
   <step>
    <para>
     Run the <literal>site.yml</literal> playbook below:
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts site.yml</screen>
    <para>
     If you have used an encryption password when running the configuration
     processor use the command below and enter the encryption password when
     prompted:
    </para>
<screen>&prompt.ardana;ansible-playbook -i hosts/verb_hosts site.yml --ask-vault-pass </screen>
    <note>
     <para>
      The step above runs <literal>osconfig</literal> to configure the cloud
      and <literal>ardana-deploy</literal> to deploy the cloud. Therefore, this
      step may run for a while, perhaps 45 minutes or more, depending on the
      number of nodes in your environment.
     </para>
    </note>
   </step>
   <step>
    <para>
     Verify that the network is working correctly. Ping each IP in the
     <literal>/etc/hosts</literal> file from one of the controller nodes.
    </para>
   </step>
  </procedure>
  <para>
   For any troubleshooting information regarding these steps, see
   <xref linkend="sec.trouble-deploy_cloud"/>.
  </para>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/10)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Configuring a Block Storage Backend (Optional)</title>
  <para>
   &productname; supports multiple block storage backend options. You can use one or
   more of these for setting up multiple block storage backends. Multiple
   volume types are also supported.
  </para>
  <para>
   Whether you have a single or multiple block storage backends defined in your
   <filename>cinder.conf.j2</filename> file, you can create one or more volume
   types using the specific attributes associated with the backend. For more
   information, see <xref linkend="config_3par"/>.
  </para>
 </section>
<!-- To include this section: <xi:include xpointer="element(/1/11)" href="installation-kvm_xpointer.xml"/> -->
 <section>
  <title>Post-Installation Verification and Administration</title>
  <para>
   We recommend verifying the installation using the instructions in
   <xref linkend="cloud_verification"/>.
  </para>
  <para>
   There are also a list of other common post-installation administrative tasks
   listed in the <xref linkend="postinstall_checklist"/> list.
  </para>
 </section>
</section>
