<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xml:id="ironic-multi-control-plane"
 xmlns="http://docbook.org/ns/docbook" version="5.1"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>&o_iron; in Multiple Control Plane</title>
 <para>
  &kw-hos-phrase; introduces the concept of multiple control planes - see the
  Input Model documentation for the relevant <xref
  linkend="concept-controlplanes-regions"/> and <xref
  linkend="configobj-multiple-control-planes"/>. This document covers the use
  of an &o_iron; region in a multiple control plane cloud model in &kw-hos;.
 </para>
 <section>
  <title>Networking for Baremetal in Multiple Control Plane</title>
  <para>
   <emphasis role="bold">IRONIC-FLAT-NET</emphasis> is the network
   configuration for baremetal control plane.
  </para>
  <para>
   You need to set the environment variable <emphasis
   role="bold">OS_REGION_NAME</emphasis> to the &o_iron; region in baremetal
   control plane. This will set up the &o_iron; flat networking in
   &o_netw;.
  </para>
<screen>export OS_REGION_NAME=&lt;ironic_region&gt;</screen>
  <para>
   To see details of the <literal>IRONIC-FLAT-NETWORK</literal> created during
   configuration, use the following command:
  </para>
  <screen>neutron net-list</screen>
  <para>
   Referring to the diagram below, the &clm; is a shared service that runs in a
   Core API Controller in a Core API Cluster. &o_iron; Python Agent (IPA) must
   be able to make REST API calls to the &o_iron; API (the connection is
   represented by the green line to Internal routing). The IPA connect to
   &swift; to get user images (the gray line connecting to Swift routing).
  </para>
  <figure>
   <title>Architecture of Multiple Control Plane with &o_iron;</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="media-ironic-ironic_multi_control_plane.png" width="75%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="media-ironic-ironic_multi_control_plane.png"/>
    </imageobject>
   </mediaobject>
  </figure>
 </section>
 <section>
  <title>Handling Optional &swift; Service</title>
  <para>
   &swift; is very resource-intensive and as a result, it is now optional in the
   &kw-hos; control plane. A number of services depend on &swift;, and if it is
   not present, they must provide a fallback strategy. For example, &o_img; can
   use the filesystem in place of &swift; for its backend store.
  </para>
  <para>
   In &o_iron;, agent-based drivers require &swift;. If it is not present, it is
   necessary to disable access to this &o_iron; feature in the control plane. The
   <literal>enable_agent_driver</literal> flag has been added to the &o_iron;
   configuration data and can have values of <literal>true</literal> or
   <literal>false</literal>. Setting this flag to <literal>false</literal> will
   disable &swift; configurations and the agent based drivers in the &o_iron;
   control plane.
  </para>
 </section>
 <section>
  <title>Instance Provisioning</title>
  <para>
   In a multiple control plane cloud setup, changes for &o_img; container name
   in the &swift; namespace of <literal>ironic-conductor.conf</literal>
   introduces a conflict with the one in <literal>glance-api.conf</literal>.
   Provisioning with agent-based drivers requires the container name to be the
   same in &o_iron; and &o_img;. Hence, on instance provisioning with agent-based
   drivers (&swift;-enabled), the agent is not able to fetch the images from
   &o_img; store and fails at that point.
  </para>
  <para>
   You can resolve this issue using the following steps:
  </para>
  <procedure>
   <step>
    <para>
     Copy the value of <literal>swift_store_container</literal> from the file
     <literal>/opt/stack/service/glance-api/etc/glance-api.conf</literal>
    </para>
   </step>
   <step>
    <para>
     Log in to the &clm; and use the value for
     <literal>swift_container</literal> in glance namespace of
     <literal>~/scratch/ansible/next/ardana/ansible/roles/ironic-common/templates/ironic-conductor.conf.j2</literal>
    </para>
   </step>
   <step>
    <para>
     Run the following playbook:
    </para>
<screen>
cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml
</screen>
   </step>
  </procedure>
 </section>
</section>
