<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<!---->
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="rebootNodes"><title>&kw-hos-tm; &kw-hos-version-50;: Rolling Reboot of the Cloud</title><abstract><para><para>If you have a planned maintenance and need to bring
      down your entire cloud and restart services while minimizing downtime, follow the steps here
      to safely restart your cloud.</para></para>
</abstract>
    <!---->
    <sidebar xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-4"><para>If you have a planned maintenance and need to bring down your entire cloud and restart
        services while minimizing downtime, follow the steps here to safely restart your cloud. If
        you don't mind your services being down, then another option for planned maintenance can be
        found at <xref linkend="stop_restart"/>.</para>
</sidebar>

    <sidebar xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-5"><title>Recommended node reboot order</title><para>To ensure that rebooted nodes reintegrate into the cluster, the key is having enough time
        between controller reboots.</para>
<para>The recommended way to achieve this is as follows:</para>
<orderedlist>
        <listitem><para>Reboot controller nodes one-by-one with a suitable interval in between. If you alternate
          between controllers and compute nodes you will gain more time between the controller
          reboots. </para>
</listitem>
        <listitem><para>Reboot of compute nodes (if present in your cloud).</para>
</listitem>
        <listitem><para>Reboot of Swift nodes (if present in your cloud).</para>
</listitem>
        <listitem><para>Reboot of VSA nodes (if present in your cloud)</para>
</listitem>
        <listitem><para>Reboot of Ceph nodes (if present in your cloud).</para>
</listitem>
        <listitem><para>Reboot of ESX nodes (if present in your cloud).</para>
</listitem>
      </orderedlist></sidebar>

    <para>
      Expand All
      Collapse All
    </para>




    <formalpara xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-7"><title>Rebooting controller nodes</title><para><para><emphasis role="bold">Migrate singleton services first</emphasis></para><para>The first consideration before rebooting any controller nodes is that there are a few
          services that run as singletons (non-HA), thus they will be unavailable while the
          controller they run on is down. Typically this is a very small window, but if you want to
          retain the service during the reboot of that server you should take special action to
          maintain service, such as migrating the service.</para><para>For these steps, if your singleton services are running on controller1 and you move them
          to controller2, then ensure you move them back to controller1 before proceeding to reboot
          controller2.</para><para><emphasis role="bold">For the <literal>cinder-volume</literal> singleton service:</emphasis></para><para>Execute the following command on each controller node to determine which node is hosting
          the cinder-volume singleton. It should be running on only one node: </para></para>
<screen >ps auxww | grep cinder-volume | grep -v grep</screen>
<para><para>Run the <literal>cinder-migrate-volume.yml</literal> playbook - details about the Cinder
          volume and backup migration instructions can be found in <xref linkend="topic_l1p_vpy_jt"/>.</para><para><emphasis role="bold">For the <literal>nova-consoleauth</literal> singleton service:</emphasis></para><para>The <literal>nova-consoleauth</literal> component runs by default on the first controller
          node, that is, the host with <literal>consoleauth_host_index=0</literal>. To move it to
          another controller node before rebooting controller 0, run the ansible playbook
            <literal>nova-start.yml</literal> and pass it the index of the next controller node. For
          example, to move it to controller 2 (index of 1), run:
          <screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts nova-start.yml --extra-vars "consoleauth_host_index=1"</screen></para><para>After you run this command you may now see two instances of the
            <literal>nova-consoleauth</literal> service, which will show as being in
            <literal>disabled</literal> state, when you run the <literal>nova service-list</literal>
          command. You can then delete the service using these steps.</para></para>
<orderedlist xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-8">
          <listitem><para>Obtain the service ID for the duplicated nova-consoleauth
              service:</para>
<screen>nova service-list</screen><para>Example:</para>
<screen>$ nova service-list
+----+------------------+---------------------------+----------+----------+-------+----------------------------+-----------------+
| Id | Binary           | Host                      | Zone     | Status   | State | Updated_at                 | Disabled Reason |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+-----------------+
| 1  | nova-conductor   | hlm106a-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:48.000000 | -               |
| 10 | nova-conductor   | hlm106a-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:47.000000 | -               |
| 13 | nova-conductor   | hlm106a-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:48.000000 | -               |
| 16 | nova-scheduler   | hlm106a-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:39.000000 | -               |
| 19 | nova-scheduler   | hlm106a-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:41.000000 | -               |
| 22 | nova-scheduler   | hlm106a-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:44.000000 | -               |
| 25 | nova-consoleauth | hlm106a-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:45.000000 | -               |
| 49 | nova-compute     | hlm106a-cp1-comp0001-mgmt | nova     | enabled  | up    | 2016-08-25T12:11:48.000000 | -               |
| 52 | nova-compute     | hlm106a-cp1-comp0002-mgmt | nova     | enabled  | up    | 2016-08-25T12:11:41.000000 | -               |
| 55 | nova-compute     | hlm106a-cp1-comp0003-mgmt | nova     | enabled  | up    | 2016-08-25T12:11:43.000000 | -               |
<emphasis role="bold">| 70 | nova-consoleauth | hlm106a-cp1-c1-m3-mgmt    | internal | disabled | down  | 2016-08-25T12:10:40.000000 | -               |</emphasis>
+----+------------------+---------------------------+----------+----------+-------+----------------------------+-----------------+</screen>
</listitem>
          <listitem><para>Delete the disabled duplicate service with this command:
              </para>
<screen>nova service-delete &lt;service_ID&gt;</screen><para>Given the example in the
              previous step, the command could
            be:</para>
<screen>nova service-delete 70</screen></listitem>
        </orderedlist>
<para><para><emphasis role="bold">For the SNAT namespace singleton service:</emphasis></para><para>If you reboot the controller node hosting the SNAT namespace service on it, Compute
          instances without floating IPs will lose network connectivity when that controller is
          rebooted. To prevent this from happening, you can use these steps to determine which
          controller node is hosting the SNAT namespace service and migrate it to one of the other
          controller nodes while that node is rebooted.</para></para>
<orderedlist>
          <listitem><para>Locate the SNAT node where the router is providing the active
              <literal>snat_service</literal>: </para>
<orderedlist>
              <listitem><para>From the lifecycle manager, list out your ports to determine which port is serving
                as the router gateway:
                </para>
<screen>source ~/service.osrc
neutron port-list --device_owner network:router_gateway</screen><para>Example:
                </para>
<screen>$ neutron port-list --device_owner network:router_gateway
+--------------------------------------+------+-------------------+-------------------------------------------------------------------------------------+
| id                                   | name | mac_address       | fixed_ips                                                                           |
+--------------------------------------+------+-------------------+-------------------------------------------------------------------------------------+
| 287746e6-7d82-4b2c-914c-191954eba342 |      | fa:16:3e:2e:26:ac | {"subnet_id": "f4152001-2500-4ebe-ba9d-a8d6149a50df", "ip_address": "10.247.96.29"} |
+--------------------------------------+------+-------------------+-------------------------------------------------------------------------------------+</screen></listitem>
              <listitem><para>Look at the details of this port to determine what the
                  <literal>binding:host_id</literal> value is, which will point to the host in which
                the port is bound to:
                  </para>
<screen>neutron port-show &lt;port_id&gt;</screen><para>Example, with the value
                  you need in
                  bold:</para>
<screen>$ neutron port-show 287746e6-7d82-4b2c-914c-191954eba342
+-----------------------+--------------------------------------------------------------------------------------------------------------+
| Field                 | Value                                                                                                        |
+-----------------------+--------------------------------------------------------------------------------------------------------------+
| admin_state_up        | True                                                                                                         |
| allowed_address_pairs |                                                                                                              |
<emphasis role="bold">| binding:host_id       | helion-cp1-c1-m2-mgmt</emphasis>                                                                                        |
| binding:profile       | {}                                                                                                           |
| binding:vif_details   | {"port_filter": true, "ovs_hybrid_plug": true}                                                               |
| binding:vif_type      | ovs                                                                                                          |
| binding:vnic_type     | normal                                                                                                       |
| device_id             | e122ea3f-90c5-4662-bf4a-3889f677aacf                                                                         |
| device_owner          | network:router_gateway                                                                                       |
| dns_assignment        | {"hostname": "host-10-247-96-29", "ip_address": "10.247.96.29", "fqdn": "host-10-247-96-29.openstacklocal."} |
| dns_name              |                                                                                                              |
| extra_dhcp_opts       |                                                                                                              |
| fixed_ips             | {"subnet_id": "f4152001-2500-4ebe-ba9d-a8d6149a50df", "ip_address": "10.247.96.29"}                          |
| id                    | 287746e6-7d82-4b2c-914c-191954eba342                                                                         |
| mac_address           | fa:16:3e:2e:26:ac                                                                                            |
| name                  |                                                                                                              |
| network_id            | d3cb12a6-a000-4e3e-82c4-ee04aa169291                                                                         |
| security_groups       |                                                                                                              |
| status                | DOWN                                                                                                         |
| tenant_id             |                                                                                                              |
+-----------------------+--------------------------------------------------------------------------------------------------------------+</screen>
<para>In
                  this example, the <literal>helion-cp1-c1-m2-mgmt</literal> is the node hosting the
                  SNAT namespace service.</para>
</listitem>
            </orderedlist></listitem>
          <listitem><para>SSH to the node hosting the SNAT namespace service and check the SNAT namespace,
            specifying the router_id that has the interface with the subnet that you are interested
              in:</para>
<screen>ssh &lt;IP_of_SNAT_namespace_host&gt;
sudo ip netns exec snat-&lt;router_ID&gt; bash</screen><para>Example:</para>
<screen>sudo ip netns exec snat-e122ea3f-90c5-4662-bf4a-3889f677aacf bash</screen>
</listitem>
          <listitem><para>Obtain the ID for the L3 Agent for the node hosting your SNAT
              namespace:</para>
<screen>source ~/service.osrc
neutron agent-list</screen><para>Example,
              with the entry you need given the examples
            above:</para>
<screen>$ neutron agent-list
+--------------------------------------+----------------------+--------------------------+-------+----------------+---------------------------+
| id                                   | agent_type           | host                     | alive | admin_state_up | binary                    |
+--------------------------------------+----------------------+--------------------------+-------+----------------+---------------------------+
| 0126bbbf-5758-4fd0-84a8-7af4d93614b8 | DHCP agent           | helion-cp1-c1-m3-mgmt    | :-)   | True           | neutron-dhcp-agent        |
| 33dec174-3602-41d5-b7f8-a25fd8ff6341 | Metadata agent       | helion-cp1-c1-m2-mgmt    | :-)   | True           | neutron-metadata-agent    |
| 3bc28451-c895-437b-999d-fdcff259b016 | L3 agent             | helion-cp1-c1-m1-mgmt    | :-)   | True           | neutron-vpn-agent         |
| 4af1a941-61c1-4e74-9ec1-961cebd6097b | L3 agent             | helion-cp1-comp0001-mgmt | :-)   | True           | neutron-l3-agent          |
| 58f01f34-b6ca-4186-ac38-b56ee376ffeb | Loadbalancerv2 agent | helion-cp1-comp0001-mgmt | :-)   | True           | neutron-lbaasv2-agent     |
| 65bcb3a0-4039-4d9d-911c-5bb790953297 | Open vSwitch agent   | helion-cp1-c1-m1-mgmt    | :-)   | True           | neutron-openvswitch-agent |
| 6981c0e5-5314-4ccd-bbad-98ace7db7784 | L3 agent             | helion-cp1-c1-m3-mgmt    | :-)   | True           | neutron-vpn-agent         |
| 7df9fa0b-5f41-411f-a532-591e6db04ff1 | Metadata agent       | helion-cp1-comp0001-mgmt | :-)   | True           | neutron-metadata-agent    |
| 92880ab4-b47c-436c-976a-a605daa8779a | Metadata agent       | helion-cp1-c1-m1-mgmt    | :-)   | True           | neutron-metadata-agent    |
<emphasis role="bold">| a209c67d-c00f-4a00-b31c-0db30e9ec661 | L3 agent             | helion-cp1-c1-m2-mgmt</emphasis>    | :-)   | True           | neutron-vpn-agent         |
| a9467f7e-ec62-4134-826f-366292c1f2d0 | DHCP agent           | helion-cp1-c1-m1-mgmt    | :-)   | True           | neutron-dhcp-agent        |
| b13350df-f61d-40ec-b0a3-c7c647e60f75 | Open vSwitch agent   | helion-cp1-c1-m2-mgmt    | :-)   | True           | neutron-openvswitch-agent |
| d4c07683-e8b0-4a2b-9d31-b5b0107b0b31 | Open vSwitch agent   | helion-cp1-comp0001-mgmt | :-)   | True           | neutron-openvswitch-agent |
| e91d7f3f-147f-4ad2-8751-837b936801e3 | Open vSwitch agent   | helion-cp1-c1-m3-mgmt    | :-)   | True           | neutron-openvswitch-agent |
| f33015c8-f4e4-4505-b19b-5a1915b6e22a | DHCP agent           | helion-cp1-c1-m2-mgmt    | :-)   | True           | neutron-dhcp-agent        |
| fe43c0e9-f1db-4b67-a474-77936f7acebf | Metadata agent       | helion-cp1-c1-m3-mgmt    | :-)   | True           | neutron-metadata-agent    |
+--------------------------------------+----------------------+--------------------------+-------+----------------+---------------------------+</screen></listitem>
          <listitem><para>Also obtain the ID for the L3 Agent of the node you are going to move the SNAT
            namespace service to using the same commands as the previous step.</para>
</listitem>
          <listitem><para>Use these commands to move the SNAT namespace service, with the
              <literal>qrouter_id</literal> being the same value as the ID for router:</para>
<orderedlist>
              <listitem><para>Remove the L3 Agent for the old host:
                  </para>
<screen>neutron l3-agent-router-remove &lt;agent_id_of_snat_namespace_host&gt; &lt;qrouter_uuid&gt;</screen><para>Example:</para>
<screen>$ neutron l3-agent-router-remove a209c67d-c00f-4a00-b31c-0db30e9ec661 e122ea3f-90c5-4662-bf4a-3889f677aacf
Removed router e122ea3f-90c5-4662-bf4a-3889f677aacf from L3 agent</screen>
</listitem>
              <listitem><para>Remove the SNAT namespace:
                  </para>
<screen>sudo ip netns delete snat-&lt;router_id&gt;</screen><para>Example:</para>
<screen>$ sudo ip netns delete snat-e122ea3f-90c5-4662-bf4a-3889f677aacf</screen>
</listitem>
              <listitem><para>Create a new L3 Agent for the new
                  host:</para>
<screen>neutron l3-agent-router-add &lt;agent_id_of_new_snat_namespace_host&gt; &lt;qrouter_uuid&gt;</screen><para>Example:</para>
<screen>$ neutron l3-agent-router-add 3bc28451-c895-437b-999d-fdcff259b016 e122ea3f-90c5-4662-bf4a-3889f677aacf
Added router e122ea3f-90c5-4662-bf4a-3889f677aacf to L3 agent</screen>
</listitem>
            </orderedlist><para>Confirm that it's been moved by listing the details of your port from step 1b
            above, noting the value of <literal>binding:host_id</literal> which should be updated to
            the host you moved your SNAT namespace
              to:</para>
<screen>neutron port-show &lt;port_ID&gt;</screen><para>Example:</para>
<screen>$ neutron port-show 287746e6-7d82-4b2c-914c-191954eba342
+-----------------------+--------------------------------------------------------------------------------------------------------------+
| Field                 | Value                                                                                                        |
+-----------------------+--------------------------------------------------------------------------------------------------------------+
| admin_state_up        | True                                                                                                         |
| allowed_address_pairs |                                                                                                              |
<emphasis role="bold">| binding:host_id       | helion-cp1-c1-m1-mgmt</emphasis>                                                                                        |
| binding:profile       | {}                                                                                                           |
| binding:vif_details   | {"port_filter": true, "ovs_hybrid_plug": true}                                                               |
| binding:vif_type      | ovs                                                                                                          |
| binding:vnic_type     | normal                                                                                                       |
| device_id             | e122ea3f-90c5-4662-bf4a-3889f677aacf                                                                         |
| device_owner          | network:router_gateway                                                                                       |
| dns_assignment        | {"hostname": "host-10-247-96-29", "ip_address": "10.247.96.29", "fqdn": "host-10-247-96-29.openstacklocal."} |
| dns_name              |                                                                                                              |
| extra_dhcp_opts       |                                                                                                              |
| fixed_ips             | {"subnet_id": "f4152001-2500-4ebe-ba9d-a8d6149a50df", "ip_address": "10.247.96.29"}                          |
| id                    | 287746e6-7d82-4b2c-914c-191954eba342                                                                         |
| mac_address           | fa:16:3e:2e:26:ac                                                                                            |
| name                  |                                                                                                              |
| network_id            | d3cb12a6-a000-4e3e-82c4-ee04aa169291                                                                         |
| security_groups       |                                                                                                              |
| status                | DOWN                                                                                                         |
| tenant_id             |                                                                                                              |
+-----------------------+--------------------------------------------------------------------------------------------------------------+</screen></listitem>
        </orderedlist>
<para><para><emphasis role="bold">Reboot the controllers</emphasis></para><para>In order to reboot the controller nodes, you must first retrieve a list of nodes in your
          cloud running control plane services.</para></para>
<screen >for i in $(grep -w cluster-prefix ~/helion/my_cloud/definition/data/control_plane.yml | awk '{print $2}'); do grep $i ~/scratch/ansible/next/hos/ansible/hosts/verb_hosts | grep ansible_ssh_host | awk '{print $1}'; done</screen>
<para><para>Then perform the following steps from your lifecycle manager for each of your controller
          nodes:</para></para>
<orderedlist>
          <listitem><para>If any singleton services are active on this node, they will be unavailable while the
            node is down. If you want to retain the service during the reboot, you should take
            special action to maintain the service, such as migrating the service as appropriate as
            noted above.</para>
</listitem>
          <listitem><para>Stop all services on the controller node that you are rebooting first:
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit &lt;controller node&gt;</screen></listitem>
          <listitem><para>Reboot the controller node, e.g. run the following command on the controller itself:
              </para>
<screen>sudo reboot</screen><para>Note that the current node being rebooted could
              be hosting the lifecycle manager.</para>
</listitem>
          <listitem><para>Wait for the controller node to become ssh-able and allow an additional minimum of
            five minutes for the controller node to settle. Start all services on the controller
            node:
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit &lt;controller node&gt;</screen></listitem>
          <listitem><para>Verify that the status of all services on that is OK on the controller node:
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-status.yml --limit &lt;controller node&gt;</screen></listitem>
          <listitem><para>When above start operation has completed successfully, you may proceed to the next
            controller node. Ensure that you migrate your singleton services off the node
            first.</para>
</listitem>
        </orderedlist>
</formalpara>


    <formalpara xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-9"><title>Rebooting compute nodes</title><para><para>To reboot a compute node the following operations will need to be performed:</para></para>
<itemizedlist>

          <listitem><para>Disable provisioning of the node to take the node offline to prevent further instances
            being scheduled to the node during the reboot. </para>
</listitem>
          <listitem><para>Identify instances that exist on the compute node, and then either: </para>
<itemizedlist>
              <listitem><para>Live migrate the instances off the node before actioning the reboot. OR </para>
</listitem>
              <listitem><para>Stop the instances</para>
</listitem>
            </itemizedlist></listitem>
          <listitem><para>Reboot the node </para>
</listitem>
          <listitem><para>Restart the Nova services </para>
</listitem>

        </itemizedlist>
<orderedlist>
          <listitem><para>Disable provisioning:
            </para>
<screen>nova service-disable --reason "&lt;describe reason&gt;" &lt;node name&gt; nova-compute</screen><para>If
            the node has existing instances running on it these instances will need to be migrated
            or stopped prior to re-booting the node.</para>
</listitem>
          <listitem><para> Live migrate existing instances. Identify the instances on the compute node. Note:
            The following command must be run with nova admin
            credentials.</para>
<screen>nova list --host &lt;hostname&gt; --all-tenants</screen></listitem>
          <listitem><para> Migrate or Stop the instances on the compute node. </para>
<para> Migrate the instances off the
              node by running one of the following commands for each of the instances:</para>
<para>If your
              instance is booted from a volume and has any number of Cinder volume attached, use the
              nova live-migration
            command:</para>
<screen>nova live-migration &lt;instance uuid&gt; [&lt;target compute host&gt;]</screen><para>
            If your instance has local (ephemeral) disk(s) only, you can use the --block-migrate
            option:</para>
<screen>nova live-migration --block-migrate &lt;instance uuid&gt; [&lt;target compute host&gt;]</screen><para>
            Note: The [&lt;target compute host&gt;] option is optional. If you do not specify a
            target host then the nova scheduler will choose a node for you.</para>
<para>OR</para>
<para>Stop the
              instances on the node by running the following command for each of the
            instances:</para>
<screen>nova stop &lt;instance-uuid&gt;</screen></listitem>
          <listitem><para>Stop all services on the Compute node:
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit &lt;compute node&gt;</screen></listitem>
          <listitem><para>SSH to your Compute nodes and reboot them: </para>
<screen>sudo reboot</screen><para>The
              operating system cleanly shuts down services and then automatically reboots. If you
              want to be very thorough, run your backup jobs just before you reboot.</para>
</listitem>
          <listitem><para>Run the hlm-start.yml playbook from the lifecycle manager. If needed, use the
            bm-power-up.yml playbook to restart the node. Specify just the node(s) you want to start
            in the 'nodelist' parameter arguments, i.e.
            nodelist=&lt;node1&gt;[,&lt;node2&gt;][,&lt;node3&gt;].</para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-power-up.yml -e nodelist=&lt;compute node&gt;</screen></listitem>
          <listitem><para>Execute the <emphasis role="bold">hlm-start.yml </emphasis>playbook. Specifying the node(s) you want to start in
            the 'limit' parameter arguments. This parameter accepts wildcard arguments and also
            '@&lt;filename&gt;' to process all hosts listed in the file.
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit &lt;compute node&gt;</screen></listitem>
          <listitem><para>Re-enable provisioning on the node:
            </para>
<screen>nova service-enable &lt;node-name&gt; nova-compute</screen></listitem>
          <listitem><para> Restart any instances you
            stopped.</para>
<screen>nova start &lt;instance-uuid&gt;</screen></listitem>
        </orderedlist>
</formalpara>



    <formalpara xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-10"><title>Rebooting Swift nodes</title><para><para>If your Swift services are on controller node,
          please follow the controller node reboot instructions above.</para><para xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-11">For a
          dedicated Swift PAC cluster or Swift Object resource node: </para>For each Swift host </para>
<orderedlist>
          <listitem><para>Stop all services on the Swift node:
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit &lt;swift node&gt;</screen></listitem>
          <listitem><para>Reboot the Swift node by running the following command on the Swift node itself:
            </para>
<screen>sudo reboot</screen></listitem>
          <listitem><para>Wait for the node to become ssh-able and then start all services on the Swift node:
            </para>
<screen>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit &lt;swift node&gt; </screen></listitem>
        </orderedlist>
</formalpara>


    <formalpara xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-12"><title>Rebooting VSA nodes</title><para><para>If your cloud is deployed with VSA, then the reboot sequence will be as follows:</para></para>
<orderedlist>
          <listitem><para>Identify all VSA nodes of a given cluster </para>
</listitem>
          <listitem><para>Pick one of the VSA nodes of the cluster and reboot it manually</para>
</listitem>
          <listitem><para>Check VSA VM's status :
            </para>
<screen>ansible-playbook -i hosts/verb_hosts vsa-status.yml --limit &lt;vsa_node name&gt;</screen></listitem>
          <listitem><para>Wait for VSA to come up, Check cluster status using CMC ( status should be
            "normal")</para>
</listitem>
          <listitem><para>Run the following command from your first controller node which will open the HP
            StoreVirtual Centralized Management Console (CMC) GUI
            </para>
<screen>/opt/HP/StoreVirtual/UI/jre/bin/java -jar /opt/HP/StoreVirtual/UI/UI.jar </screen></listitem>
          <listitem><para>To view the cluster status , go to: management group -&gt; click on the respective
            cluster -&gt; check for status</para>
</listitem>
          <listitem><para>Repeat steps 2-4 for the other remaining nodes of the same VSA cluster. </para>
</listitem>
          <listitem><para>Go to step 1 and repeat all steps for the other clusters.</para>
</listitem>
        </orderedlist>
</formalpara>

    <formalpara xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-13"><title>Rebooting ceph</title><para><!----><para>There are two categories of ceph nodes:</para></para>
<itemizedlist>
          <listitem><para>monitor nodes</para>
</listitem>
          <listitem><para>OSD nodes</para>
</listitem>
        </itemizedlist>
<para><para>Ceph nodes should be rebooted in their position in the overall sequence described in
          the reboot order section above.</para><para>You should reboot both categories of ceph nodes in
          the order: monitor nodes, then OSD nodes. All ceph nodes should reboot one-by-one, in
          series. </para> If a monitor is deployed on controller node, then the rebooting sequence of
        the controller caters for the monitor nodes, so you need to additionally reboot only the OSD
        nodes. <para>If the monitor is deployed as a standalone; i.e., as separate set of resource
          nodes, you should reboot the monitor nodes before rebooting the OSD nodes.</para> For
        example, if there are three monitor nodes and three OSD nodes say, MON1, MON2 and MON3, with
        OSD1, OSD2, OSD3, then you should reboot MON1, then MON2 and then MON3 followed by OSD1,
        then OSD2 and so on In both cases, please ensure that you are serializing the reboot of a
        given family (monitor or OSD or controller); that is, don't reboot them all at the same
        time. This will ensure that each service is up and running and there is no impact on the
        client side. To reboot Ceph nodes, follow the sequence below to safely reboot the entire
        Ceph cluster: </para>
<orderedlist>
          <listitem><para>Reboot a Ceph monitor node in the cluster. </para>
</listitem>
          <listitem><para>Once the monitor node comes up, wait for a minute and then execute the following
            command:
            </para>
<screen>ansible-playbook -i hosts/verb_hosts ceph-status.yml --limit &lt;monitor-hostname&gt;</screen></listitem>
          <listitem><para>If the above playbook executes successfully, repeat from step 1 to reboot the next
            Ceph monitor node in the cluster. </para>
</listitem>
          <listitem><para>Once all the monitor nodes have been rebooted, execute
            </para>
<screen>ceph quorum_status </screen><para>on a monitor node and ensure that all the
            monitors have joined the quorum by observing that in the output, the "quorum_names"
            section lists all the monitors in the Ceph cluster. </para>
</listitem>
          <listitem><para>Login to the OSD node to be rebooted and execute the following command to avoid the
            cluster rebalancing itself: </para>
<screen>ceph osd set noout</screen></listitem>
          <listitem><para>Stop all the OSD services on the current node by executing below command:
            </para>
<screen>sudo systemctl stop  ceph-osd@*</screen></listitem>
          <listitem><para>Now reboot the OSD node. </para>
</listitem>
          <listitem><para>Once the OSD node is up, log in and execute the following command and observe that a
            line similar to "osd.0 192.17.11.7:6801/3824 boot" appears for all the OSDs on the node:
            </para>
<screen>ceph -w</screen><para> To quit, this command press Ctrl + C </para>
</listitem>
          <listitem><para>Verify that all the OSDs on this node are 'up' by executing following command (and
            observing that all the OSDs under the current host are reported as 'up')
            </para>
<screen>ceph osd tree</screen><para> If any of the OSDs are reported as 'down', please
            check the logs for the corresponding OSD (in the
              <literal>/var/log/ceph/&lt;cluster-name&gt;-osd.&lt;osd_number&gt;.log</literal> file) for
            resolving the issue. </para>
</listitem>
          <listitem><para>Now execute the following command from the re-booted OSD node, to unset the cluster
            from noout : </para>
<screen>ceph osd unset noout</screen></listitem>
          <listitem><para>Execute the following playbook from the lifecycle manager node to check the status of
            the OSDs that have just come up:
            </para>
<screen>ansible-playbook -i hosts/verb_hosts ceph-status.yml --limit &lt;OSD-hostname&gt;</screen></listitem>
          <listitem><para>If the above playbook does not report any errors, repeat from step 5 for another Ceph
            OSD node in the cluster. </para>
</listitem>
          <listitem><para>Once the entire cluster is rebooted, execute this command
            </para>
<screen>ceph health detail</screen><para> to ensure that you see HEALTH_OK. </para>
</listitem>
        </orderedlist>
</formalpara>

    <formalpara xml:id="idg-all-operations-maintenance-reboot_cloud_rolling-xml-14"><title>Get list of status playbooks</title><para><para>Running the following command will yield a list of
          status
        playbooks:</para></para>
<screen >cd ~/scratch/ansible/next/hos/ansible
ls *status*</screen>
<para> Here
        is the list:
        </para>
<screen >stack@helion-control-plane-cluster1-m1-mgmt:~/scratch/ansible/next/hos/ansible$ ls *status*
bm-power-status.yml    eon-status.yml      heat-status.yml      logging-producer-status.yml  monasca-status.yml      rabbitmq-status.yml
ceilometer-status.yml  FND-AP2-status.yml  hlm-status.yml       logging-server-status.yml    neutron-status.yml      ceph-status.yml        
FND-CLU-status.yml     horizon-status.yml  logging-status.yml  nova-status.yml swift-status.yml
cinder-status.yml      freezer-status.yml  ironic-status.yml    memcached-status.yml         ops-console-status.yml  vsa-status.yml
cmc-status.yml         glance-status.yml   keystone-status.yml  monasca-agent-status.yml     percona-status.yml      zookeeper-status.yml</screen>
</formalpara>


  </section>
