<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="sr-iov"><title>&kw-hos-tm; &kw-hos-version-50;: SR-IOV and PCI Passthrough Support</title>
    <para>&kw-hos-phrase; supports both single-root I/O virtualization (SR-IOV) and
      PCI passthrough (PCIPT). Both technologies provide for better network performance. <!----></para>

    <para>This improves network I/O, decreases latency, and reduces processor overhead.
      </para>
<important><para>RHEL is not supported for SR-IOV and PCI-PT.</para>
</important>

    <sidebar><title>SR-IOV</title><para>A PCI-SIG Single Root I/O Virtualization and Sharing (SR-IOV) Ethernet interface is a
        physical PCI Ethernet NIC that implements hardware-based virtualization mechanisms to expose
        multiple virtual network interfaces that can be used by one or more virtual machines
        simultaneously.With SR-IOV based NICs, the traditional virtual bridge is no longer required.
        Each SR-IOV port is associated with a virtual function (VF).</para>
<para>When compared with a PCI Passthtrough Ethernet interface, an SR-IOV Ethernet interface: </para>
<itemizedlist xml:id="ul_bmw_1hr_pw">
          <listitem><para>Provides benefits similar to those of a PCI Passthtrough Ethernet interface, including
            lower latency packet processing. </para>
</listitem>
          <listitem><para>Scales up more easily in a virtualized environment by providing multiple VFs that can
            be attached to multiple virtual machine interfaces.</para>
</listitem>
          <listitem><para>Shares the same limitations, including the lack of support for LAG, QoS, ACL, and live
            migration.</para>
</listitem>
          <listitem><para>Has the same requirements regarding the VLAN configuration of the access
            switches.</para>
</listitem>
        </itemizedlist>
<para>The process for configuring SR-IOV includes creating a VLAN provider network and subnet,
        then attaching VMs to that network. </para>
<para>With SR-IOV based NICs, the traditional virtual bridge is no longer required. Each SR-IOV
        port is associated with a virtual function (VF)</para>
</sidebar>
    <sidebar><title>PCI passthrough Ethernet interfaces </title><para>A passthrough Ethernet interface is a physical PCI Ethernet NIC on a compute node to which
        a virtual machine is granted direct access. PCI passthrough allows a VM to have direct
        access to the hardware without being brokered by the hypervisor. This minimizes packet
        processing delays but at the same time demands special operational considerations. For all
        purposes, a PCI passthrough interface behaves as if it were physically attached to the
        virtual machine. Therefore any potential throughput limitations coming from the virtualized
        environment, such as the ones introduced by internal copying of data buffers, are
        eliminated. However, by bypassing the virtualized environment, the use of PCI passthrough
        Ethernet devices introduces several restrictions that must be taken into consideration. They
        include: </para>
<itemizedlist xml:id="ul_a55_2hr_pw">
          <listitem><para>no support for LAG, QoS, ACL, or host interface monitoring </para>
</listitem>
          <listitem><para>no support for live migration </para>
</listitem>
          <listitem><para>no access to the compute node's OVS switch </para>
</listitem>
        </itemizedlist>
<para>A passthrough interface bypasses the compute node's OVS switch completely, and is attached
        instead directly to the provider network's access switch. Therefore, proper routing of
        traffic to connect the passthrough interface to a particular tenant network depends entirely
        on the VLAN tagging options configured on both the passthrough interface and the access port
        on the switch (TOR). </para>
<para>The access switch routes incoming traffic based on a VLAN ID, which ultimately determines
        the tenant network to which the traffic belongs. The VLAN ID is either explicit, as found in
        incoming tagged packets, or implicit, as defined by the access port's default VLAN ID when
        the incoming packets are untagged. In both cases the access switch must be configured to
        process the proper VLAN ID, which therefore has to be known in advance</para>
</sidebar>
    
    <sidebar><title>Supported Intel 82599 Devices</title><para>Intel 82599 devices supported with SRIOV and PCIPT.
        </para>
<table xml:id="intel-82599-table" colsep="1" rowsep="1"><title/><tgroup cols="3" align="center">
            <colspec colname="c1" colnum="1" colwidth="1*"/>
            <colspec colname="c2" colnum="2" colwidth="1.34*"/>
            <colspec colname="c3" colnum="3" colwidth="2.23*"/>
            <thead>
              <row>
                <entry>Vendor</entry>
                <entry>Device</entry>
                <entry>Title</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>Intel Corporation</entry>
                <entry>10f8</entry>
                <entry>82599 10 Gigabit Dual Port Backplane Connection</entry>
              </row>
              <row>
                <entry>Intel Corporation</entry>
                <entry>10f9</entry>
                <entry>82599 10 Gigabit Dual Port Network Connection</entry>
              </row>
              <row>
                <entry>Intel Corporation</entry>
                <entry>10fb</entry>
                <entry>82599ES 10-Gigabit SFI/SFP+ Network Connection</entry>
              </row>
              <row>
                <entry>Intel Coproration</entry>
                <entry>10fc</entry>
                <entry>82599 10 Gigabit Dual Port Network Connection</entry>
              </row>
            </tbody>
          </tgroup></table>
</sidebar>
    
    <sidebar><title>SRIOV PCIPT configuration</title><para>If you plan to take advantage of SR-IOV support in &kw-hos; you will need
        to plan in advance to meet the following requirements:</para>
<orderedlist xml:id="ol_vk3_c2l_pw">
          <listitem><para>Use one of the supported NIC cards: 
    
            </para>
<itemizedlist xml:id="ul_ugj_vzk_pw">
              <listitem><para>HP Ethernet 10Gb 2-port 560FLR-SFP+ Adapter (Intel Niantic). Product part number:
                665243-B21  -- Same part number for the following card options:
                </para>
<itemizedlist>
                  <listitem><para>FlexLOM card</para>
</listitem>
                  <listitem><para>PCI slot adapter card</para>
</listitem>
                </itemizedlist></listitem>
              <!---->
            </itemizedlist></listitem>
         <listitem><para>Identify the NIC ports to be used for PCI Passthrough devices and SRIOV devices from
          each compute node</para>
</listitem>
  
      <listitem><para>Ensure that:
          </para>
<itemizedlist xml:id="ul_vgj_vzk_pw">
            <listitem><para>SRIOV is enabled in the BIOS</para>
</listitem>
            <listitem><para>HP Shared memory is disabled in the BIOS on the compute nodes.</para>
</listitem>
            <listitem><para>The Intel boot agent is disabled on the compute (<link xlink:href="#sr-iov/bootutil">Intel bootutils</link> can be used to perform this)</para>
</listitem>
          </itemizedlist></listitem>    
        </orderedlist>
<para>If the above prerequisites are met, then SR-IOV or PCIPT can be reconfigured at any time.
        There is no need to do it at install time. </para>
</sidebar>
    <sidebar><title>Deployment use cases</title><para> The following are typical use cases that should cover your particular needs:</para>
<orderedlist xml:id="ol_wgj_vzk_pw">
        <listitem><para>A device on the host needs to be enabled for both PCI-passthrough and PCI-SRIOV during
          deployment. At run time Nova decides whether to use physical functions or virtual function
          depending on vnic_type of the port used for booting the VM.</para>
</listitem>
        <listitem><para>A device on the host needs to be configured only for PCI-passthrough.</para>
</listitem>
        <listitem><para>A device on the host needs to be configured only for PCI-SRIOV virtual functions.</para>
</listitem>
      </orderedlist></sidebar>
    <sidebar><title>Input model updates</title><para>&kw-hos-phrase; provides various options for the user to configure the
        network for tenant VMs. These options have been enhanced to support SRIOV and PCIPT.</para>
<para>The HLM input model changes to support SRIOV and PCIPT are as follows. If you were familiar
        with the configuration settings previously, you will notice these changes.</para>
<para><emphasis role="bold">net_interfaces.yml:</emphasis> This file defines the interface details of the nodes. In it, the
        following fields have been added under the compute node interface section:</para>
<informaltable xml:id="table_bdq_c1d_5w" colsep="1" rowsep="1"><tgroup cols="2">
          <colspec colnum="1" colname="col1"/>
          <colspec colnum="2" colname="col2"/>
          <thead>
            <row>
              <entry>Key</entry>
              <entry>Value</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>sriov_only: </entry>
              <entry>Indicates that only SR-IOV be enabled on the interface. This should be set to
                true if you want to dedicate the NIC interface to support only SR-IOV
                functionality.</entry>
            </row>
            <row>
              <entry>pci-pt: </entry>
              <entry>When this value is set to true, it indicates that PCIPT should be enabled on
                the interface.</entry>
            </row>
            <row>
              <entry>vf-count: </entry>
              <entry>Indicates the number of VFs to be configured on a given interface.</entry>
            </row>
          </tbody>
        </tgroup></informaltable><para>In control_plane.yml, under Compute resource neutron-sriov-nic-agent has been added as
        service components </para>
<para>under resources:</para>
<informaltable xml:id="idg-all-networking-pcipt_sriov_config-xml-12" colsep="1" rowsep="1"><tgroup cols="2">
          <colspec colnum="1" colname="col1"/>
          <colspec colnum="2" colname="col2"/>
          <thead>
            <row>
              <entry>Key</entry>
              <entry>Value</entry>
            </row>
          </thead>
          <tbody>

            <row>
              <entry>name:</entry>
              <entry> Compute</entry>
            </row>
            <row>
              <entry>resource-prefix:</entry>
              <entry> Comp</entry>
            </row>
            <row>
              <entry>server-role:</entry>
              <entry> COMPUTE-ROLE</entry>
            </row>
            <row>
              <entry>allocation-policy:</entry>
              <entry> Any</entry>
            </row>
            <row>
              <entry>min-count:</entry>
              <entry> 0</entry>
            </row>
            <row>
              <entry>service-components:</entry>
              <entry>ntp-client</entry>
            </row>
            <row>
              <entry> </entry>
              <entry>nova-compute</entry>
            </row>
            <row>
              <entry> </entry>
              <entry>nova-compute-kvm</entry>
            </row>
            <row>
              <entry> </entry>
              <entry>neutron-l3-agent</entry>
            </row>
            <row>
              <entry> </entry>
              <entry>neutron-metadata-agent</entry>
            </row>
            <row>
              <entry> </entry>
              <entry>neutron-openvswitch-agent</entry>
            </row>
            <row>
              <entry> </entry>
              <entry>neutron-lbaasv2-agent</entry>
            </row>
            <row>
              <entry> </entry>
              <entry>- neutron-sriov-nic-agent*</entry>
            </row>
          </tbody>
        </tgroup></informaltable><para><emphasis role="bold">nic_device_data.yml:</emphasis> This is the new file added with this release to support SRIOV
        and PCIPT configuration details. It contains information about the specifics of a nic, and
        is found here: <literal>~/helion/hos/services/osconfig/nic_device_data.yml</literal>. The
        fields in this file are as follows.</para>
<orderedlist>
        <listitem><para><emphasis role="bold">nic-device-types:</emphasis> The nic-device-types section contains the following key-value
            pairs:</para>
<informaltable xml:id="table_vmt_zbl_pw" colsep="1" rowsep="1"><tgroup cols="2">
              <colspec colname="c1" colnum="1" colwidth="1*"/>
              <colspec colname="c2" colnum="2" colwidth="5.25*"/>
              <thead>
                <row>
                  <entry>Key</entry>
                  <entry>Value</entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>name:</entry>
                  <entry>The name of the nic-device-types that will be referenced in
                    nic_mappings.yml</entry>
                </row>
                <row>
                  <entry>family:</entry>
                  <entry>The name of the nic-device-families to be used with this
                    nic_device_type</entry>
                </row>
                <row>
                  <entry>device_id:</entry>
                  <entry>Device ID as specified by the vendor for the particular NIC</entry>
                </row>
                <row>
                  <entry>type:</entry>
                  <entry>The value of this field can be "simple-port" or "multi-port". If a single
                    bus address is assigned to more than one nic it will be multi-port ,else if
                    there is a one-to one mapping between bus address and the nic then it will be
                    simple-port.</entry>
                </row>
              </tbody>
            </tgroup></informaltable></listitem>
        <listitem><para><emphasis role="bold">nic-device-families:</emphasis> The nic-device-families section contains the following
          key-value pairs:</para>
<informaltable xml:id="table_cjf_3cl_pw" colsep="1" rowsep="1"><tgroup cols="2">
              <colspec colname="c1" colnum="1" colwidth="1*"/>
              <colspec colname="c2" colnum="2" colwidth="4.13*"/>
              <thead>
                <row>
                  <entry>Key</entry>
                  <entry>Value</entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>name:</entry>
                  <entry>The name of the device family that can be used for reference in
                    nic-device-types.</entry>
                </row>
                <row>
                  <entry>vendor-id: </entry>
                  <entry>Vendor ID of the NIC</entry>
                </row>
                <row>
                  <entry>config-script:</entry>
                  <entry>A script file used to create the virtual functions (VF) on the Compute
                    node.</entry>
                </row>
                <row>
                  <entry>driver:</entry>
                  <entry>Indicates the NIC driver that needs to be used.</entry>
                </row>
                <row>
                  <entry>vf-count-type:</entry>
                  <entry>This value can be either "port" or "driver". </entry>
                </row>
                <row>
                  <entry>“port”: </entry>
                  <entry>Indicates that the device supports per-port virtual function (VF) counts.
                  </entry>
                </row>
                <row>
                  <entry>“driver:”</entry>
                  <entry>Indicates that all ports using the same driver will be configured with the
                    same number of VFs, whether or not the interface model specifies a vf-count
                    attribute for the port. If two or more ports specify different vf-count values,
                    the config processor errors out.</entry>
                </row>
                <row>
                  <entry>Max-vf-count:</entry>
                  <entry>This field indicates the maximum VFs that can be configured on an interface
                    as defined by the vendor.</entry>
                </row>
              </tbody>
            </tgroup></informaltable></listitem>
      </orderedlist><para><emphasis role="bold">control_plane.yml:</emphasis> This file provides the information about the services to be run on
        a particular node. To support SR-IOV on a particular compute node, you must run
        neutron-sriov-nic-agent on that node. </para>
<para><emphasis role="bold">Mapping the use cases with various fields in input model</emphasis></para>
<informaltable xml:id="table_wt5_kdl_pw" colsep="1" rowsep="1"><tgroup cols="7">
          <colspec colnum="1" colname="col1" colwidth="2.48*"/>
          <colspec colnum="2" colname="col2" colwidth="2.1*"/>
          <colspec colnum="3" colname="col3" colwidth="1.25*"/>
          <colspec colnum="4" colname="col4" colwidth="1*"/>
          <colspec colnum="5" colname="col5" colwidth="1.14*"/>
          <colspec colnum="6" colname="col6" colwidth="2.49*"/>
          <colspec colnum="7" colname="col7" colwidth="2.11*"/>
          <thead>
            <row>
              <entry/>
              <entry>Vf-count</entry>
              <entry>SR-IOV</entry>
              <entry>PCIPT</entry>
              <entry>OVS bridge</entry>
              <entry>Can be NIC bonded</entry>
              <entry>Use case</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>sriov-only: true</entry>
              <entry>Mandatory</entry>
              <entry>Yes</entry>
              <entry>No</entry>
              <entry>No</entry>
              <entry>No</entry>
              <entry>Dedicated to SRIOV</entry>
            </row>
            <row>
              <entry>pci-pt : true</entry>
              <entry>Not Specified</entry>
              <entry>No</entry>
              <entry>Yes</entry>
              <entry>No</entry>
              <entry>No</entry>
              <entry>Dedicated to PCI-PT</entry>
            </row>
            <row>
              <entry>pci-pt : true</entry>
              <entry>Specified</entry>
              <entry>Yes</entry>
              <entry>Yes</entry>
              <entry>No</entry>
              <entry>No</entry>
              <entry>PCI-PT or SRIOV</entry>
            </row>
            <row>
              <entry>pci-pt and sriov-only keywords are not specified</entry>
              <entry>Specified</entry>
              <entry>Yes</entry>
              <entry>No</entry>
              <entry>Yes</entry>
              <entry>No</entry>
              <entry>SRIOV with PF used by host</entry>
            </row>
            <row>
              <entry>pci-pt and sriov-only keywords are not specified</entry>
              <entry>Not Specified</entry>
              <entry>No</entry>
              <entry>No</entry>
              <entry>Yes</entry>
              <entry>Yes</entry>
              <entry>Traditional/Usual use case</entry>
            </row>
          </tbody>
        </tgroup></informaltable></sidebar>
    <para><emphasis role="bold">Mappings between nic_mappings.yml and net_interfaces.yml</emphasis></para>

    <para>The following diagram shows which fields in nic_mappings.yml map to corresponding fields in
      net_interfaces.yml:</para>

    <mediaobject xml:id="image_wqb_vth_tw"><imageobject role="fo"><imagedata fileref="media-sriov_pcpit.png" width="75%" format="PNG"/></imageobject><imageobject role="html"><imagedata fileref="media-sriov_pcpit.png"/></imageobject></mediaobject>
 
    <!---->
    <sidebar><title>Example Use Cases for Intel</title><orderedlist>
        <listitem><para><emphasis role="bold">Nic-device-types and nic-device-families</emphasis> with Intel 82559 with ixgbe as
          the driver.
          </para>
<screen>nic-device-types:
    - name: ''8086:10fb
      family: INTEL-82599
      device-id: '10fb'
      type: simple-port
nic-device-families:
    # Niantic
    - name: INTEL-82599
      vendor-id: '8086'
      config-script: intel-82599.sh
      driver: ixgbe
      vf-count-type: port
      max-vf-count: 63</screen></listitem>
        <listitem><para><emphasis role="bold">net_interfaces.yml</emphasis> for the SRIOV-only use case:
          </para>
<screen>- name: COMPUTE-INTERFACES
   - name: hed1
     device:
       name: hed1
       sriov-only: true
       vf-count: 6
     network-groups:
      - GUEST1</screen></listitem>
        <listitem><para><emphasis role="bold">net_interfaces.yml</emphasis> for the PCIPT-only use case:
          </para>
<screen>- name: COMPUTE-INTERFACES
   - name: hed1
     device:
       name: hed1
       pci-pt: true
    network-groups:
     - GUEST1</screen></listitem>
        <listitem><para><emphasis role="bold">net_interfaces.yml</emphasis> for the SRIOV and PCIPT use case
          </para>
<screen> - name: COMPUTE-INTERFACES
    - name: hed1
      device:
        name: hed1
        pci-pt: true
        vf-count: 6
      network-groups:
      - GUEST1</screen></listitem>
        <listitem><para><emphasis role="bold">net_interfaces.yml</emphasis> for SRIOV and Normal Virtio use case
          </para>
<screen>- name: COMPUTE-INTERFACES
   - name: hed1
     device:
        name: hed1
        vf-count: 6
      network-groups:
      - GUEST1</screen></listitem>
      </orderedlist></sidebar>
    
<!---->

    <sidebar><title> Launching Virtual Machines</title><para>Provisioning a VM with SR-IOV NIC is a two-step process.</para>
<orderedlist>
        <listitem><para>Create a Neutron port with <literal>vnic_type = direct</literal>.
          </para>
<screen>neutron port-create $net_id --name sriov_port --binding:vnic_type direct</screen></listitem>
        <listitem><para>Boot a VM with the created <literal>port-id</literal>.
          </para>
<screen>nova boot --flavor m1.large --image ubuntu_14.04 --nic port-id=$port_id test-sriov</screen></listitem>
      </orderedlist><para> Provisioning a VM with PCI PT NIC is also a two-step process. </para>
<orderedlist>
        <listitem><para>Create a Neutron port with <literal>vnic_type = direct-physical</literal>.
          </para>
<screen>neutron port-create $net_id --name pci_port --binding:vnic_type direct-physical</screen></listitem>
        <listitem><para>Boot a VM with the created <literal>port-id</literal>.
          </para>
<screen>nova boot --flavor m1.large --image ubuntu_14.04 --nic port-id=$port_id test-pcipt</screen></listitem>
      </orderedlist></sidebar>

    <para>If PCI-PT VM gets stuck (hangs) at boot time when using an Intel NIC, the boot agent
      should be disabled.</para>

    <sidebar xml:id="bootutil"><para> When Intel cards are used for PCI-PT, a tenant VM can get stuck at boot
      time. When this happens, you should download Intel bootutils and use it to should disable
      bootagent. </para>
<orderedlist>
        <listitem><para>Download Preebot.tar.gz from <link xlink:href="https://downloadcenter.intel.com/download/19186/Intel-Ethernet-Connections-Boot-Utility-Preboot-Images-and-EFI-Drivers">https://downloadcenter.intel.com/download/19186/Intel-Ethernet-Connections-Boot-Utility-Preboot-Images-and-EFI-Drivers</link></para>
</listitem>
        <listitem><para>Untar the <literal>Preboot.tar.gz</literal> on the compute node where the PCI-PT VM is to
          be hosted. </para>
</listitem>
        <listitem><para>Go to ~/APPS/BootUtil/Linux_x64</para>
<screen>cd ~/APPS/BootUtil/Linux_x64</screen><para> and
          run following command </para>
<screen>./bootutil64e -BOOTENABLE disable -all</screen></listitem>
        <listitem><para>Boot the PCI-PT VM and it should boot without getting stuck.</para>
</listitem>
      </orderedlist></sidebar>
    <sidebar><title>Making input model changes and implementing PCI PT and SR-IOV</title><para> To implent
      the configuration you require, log into the lifecycle manager node and update the HLM model
      files to enable SR-IOV or PCIPT following the relevent use case explained above. You will need
      to edit </para>
<itemizedlist>
        <listitem><para>net_interfaces.yml </para>
</listitem>
        <listitem><para>nic_device_data.yml </para>
</listitem>
        <listitem><para>control_plane.yml</para>
</listitem>
      </itemizedlist><para> To make the edits, </para>
<orderedlist>
        <listitem><para>Check out the site branch of the local git repository and change to the correct
          directory:</para>
<screen>git checkout site
cd ~/helion/my_cloud/definition/data/</screen></listitem>
        <listitem><para>Open each file in vim or another editor and make the necessary changes. Save each file,
          then commit to the local git repository:
          </para>
<screen>git add -A
git commit -m "your commit message goes here in quotes"</screen></listitem>
        <listitem><para>Here you will have the Helion lifecycle manager enable your changes by running the
          necessary playbooks:
          </para>
<screen>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml
ansible-playbook -i hosts/localhost ready-deployment.yml
cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts site.yml</screen></listitem>
      </orderedlist><para>You can set the number of
        virtual functions that must be enabled on a compute node at install time. You can update the
        number of virtual functions after deployment. If any VMs have been spawned before you change
        the number of virtual functions, those VMs may lose connectivity. Therefore, it is always
        recommended that if any virtual function is used by any tenant VM, you should not
        reconfigure the virtual functions. Instead, you should delete/migrate all the VMs on that
        NIC before reconfiguring the number of virtual functions.</para>
</sidebar>
    <sidebar><title>Limitations</title><itemizedlist>
        <listitem><para>Security groups are not applicable for PCI-PT and SRIOV ports. </para>
</listitem>
        <listitem><para>Live migration is not supported for VMs with PCI-PT and SRIOV ports. </para>
</listitem>
        <listitem><para>Rate limiting (QoS) is not applicable on SRIOV and PCI-PT ports.</para>
</listitem>
        <listitem><para>SRIOV/PCIPT is not supported for VxLAN network.</para>
</listitem>
        <listitem><para>DVR is not supported with SRIOV/PCIPT.</para>
</listitem>
        <listitem><para>For Intel cards, the same NIC cannot be used for both SRIOV and normal VM boot.</para>
</listitem>
        <listitem><para>Current upstream OpenStack code does not support this hot plugin of SRIOV/PCIPT
          interface using the nova <literal>attach_interface</literal> command. See <link xlink:href="https://review.openstack.org/#/c/139910/">https://review.openstack.org/#/c/139910/</link> for more information.</para>
</listitem>
        <listitem><para>Neutron port-update when admin state is down will not work.</para>
</listitem>
      </itemizedlist></sidebar>
  <xi:include  href="all-networking-enabling_pcipt_on_gen9.xml"/></section>
