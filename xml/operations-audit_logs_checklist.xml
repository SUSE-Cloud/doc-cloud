<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="idg-all-operations-audit_logs_checklist-xml-1">
 <title>Audit Logging Checklist</title>
 <para>
  Before enabling audit logging, make sure you understand how much disk space
  you will need, and configure the disks that will store the logging data. Use
  the following table to complete these tasks:
 </para>
 <informaltable colsep="1" rowsep="1">
  <tgroup cols="2">
   <colspec colname="c1" colnum="1" colwidth="1*"/>
   <colspec colname="c2" colnum="2" colwidth="19*"/>
   <thead>
    <row>
     <entry>☐</entry>
     <entry>Item</entry>
    </row>
   </thead>
   <tbody>
    <row>
     <entry/>
     <entry>
      <para>
       <xref linkend="audit_FAQ"/>
      </para>
     </entry>
    </row>
    <row>
     <entry/>
     <entry>
      <para>
       <xref linkend="audit_log_est"/>
      </para>
     </entry>
    </row>
    <row>
     <entry/>
     <entry>
      <para>
       <xref linkend="audit_add_disks"/>
      </para>
     </entry>
    </row>
    <row>
     <entry/>
     <entry>
      <para>
       <xref linkend="audit_update_disks"/>
      </para>
     </entry>
    </row>
    <row>
     <entry/>
     <entry>
      <para>
       <xref linkend="audit_save_update_disks"/>
      </para>
     </entry>
    </row>
   </tbody>
  </tgroup>
 </informaltable>
 <section xml:id="audit_FAQ">
  <title>Frequently Asked Questions</title>
<!-- FIXME: Use qandaset? -->
  <variablelist>
   <varlistentry>
    <term>How are audit logs generated?</term>
    <listitem>
     <para>
      The audit logs are created by services running in the cloud management
      controller nodes. The events that create auditing entries are formatted
      using a structure that is compliant with Cloud Auditing Data Federation
      (CADF) policies. The formatted audit entries are then saved to disk
      files. For more information, see the
      <link xlink:href="http://www.dmtf.org/standards/cadf">Cloud Auditing Data
      Federation Website.</link>
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Where are audit logs stored?</term>
    <listitem>
     <para>
      We strongly recommend adding a dedicated disk volume for
      <literal>/var/audit</literal>.
     </para>
<!-- FIXME for SOC 9: DiscCalculator, quo vadis? - sknorr, 2018-03-29 -->
<!-- <para>
      To calculate the correct disk
      size for the audit volume based on your setup, see
      <xref linkend="hw_support_diskcalc"/> . This will ensure that you
      have adequate disk space available to meet the security compliance
      requirements.
     </para> -->
     <para>
      If the disk templates for the controllers are not updated to create a
      separate volume for <filename>/var/audit</filename>,
      the audit logs will still be created in
      the root partition under the folder <filename>/var/audit</filename>. This
      could be problematic if the root partition does not have adequate space to
      hold the audit logs.
     </para>
     <warning>
      <para>
       We recommend that you do <emphasis role="bold">not</emphasis> store
       audit logs in the <filename>/var/log</filename> volume. The
       <filename>/var/log</filename> volume is used for storing operational logs
       and logrotation/alarms have been preconfigured for various services
       based on the size of this volume. Adding audit logs here may impact
       these causing undesired alarms. This would also impact the retention
       times for the operational logs.
      </para>
     </warning>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Are audit logs centrally stored?</term>
    <listitem>
     <para>
      Yes. The existing operational log profiles have been configured to
      centrally log audit logs as well, once their generation has been enabled.
      The audit logs will be stored in separate &elasticsearch; indices separate
      from the operational logs.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>How long are audit log files retained?</term>
    <listitem>
     <para>
      By default, audit logs are configured to be retained for 7 days on disk.
      The audit logs are rotated each day and the rotated files are stored in a
      compressed format and retained up to 7 days (configurable). The backup
      service has been configured to back up the audit logs to a location
      outside of the controller nodes for much longer retention periods.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Do I lose audit data if a management controller node goes down?</term>
    <listitem>
     <para>
      Yes. For this reason, it is strongly recommended that you back up the
      audit partition in each of the management controller nodes for protection
      against any data loss.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </section>
 <section xml:id="audit_log_est">
  <title>Estimate Disk Size</title>
  <para>
   The table below provides estimates from each service of audit log size
   generated per day. The estimates are provided for environments with 100
   nodes, 300 nodes, and 500 nodes.
  </para>
  <informaltable colsep="1" rowsep="1">
   <tgroup cols="4">
    <colspec colname="c1" colnum="1" colwidth="1*"/>
    <colspec colname="c2" colnum="2" colwidth="1*"/>
    <colspec colname="c3" colnum="3" colwidth="1*"/>
    <colspec colname="c4" colnum="4" colwidth="1*"/>
    <thead>
     <row>
      <entry>Service</entry>
      <entry>
       <para>
        Log File Size: 100 nodes
       </para>
      </entry>
      <entry>
       <para>
        Log File Size: 300 nodes
       </para>
      </entry>
      <entry>
       <para>
        Log File Size: 500 nodes
       </para>
      </entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry>Barbican</entry>
      <entry>2.6 MB</entry>
      <entry>4.2 MB</entry>
      <entry>5.6 MB</entry>
     </row>
     <row>
      <entry>Keystone</entry>
      <entry>96 - 131 MB</entry>
      <entry>288 - 394 MB</entry>
      <entry>480 - 657 MB</entry>
     </row>
     <row>
      <entry>Nova</entry>
      <entry>186 (with a margin of 46) MB</entry>
      <entry>557 (with a margin of 139) MB</entry>
      <entry>928 (with a margin of 232) MB</entry>
     </row>
     <row>
      <entry>Ceilometer</entry>
      <entry>12 MB</entry>
      <entry>12 MB</entry>
      <entry>12 MB</entry>
     </row>
     <row>
      <entry>Cinder</entry>
      <entry>2 - 250 MB</entry>
      <entry>2 - 250 MB</entry>
      <entry>2 - 250 MB</entry>
     </row>
     <row>
      <entry>Neutron</entry>
      <entry>145 MB</entry>
      <entry>433 MB</entry>
      <entry>722 MB</entry>
     </row>
     <row>
      <entry>Glance</entry>
      <entry>20 (with a margin of 8) MB</entry>
      <entry>60 (with a margin of 22) MB</entry>
      <entry>100 (with a margin of 36) MB</entry>
     </row>
     <row>
      <entry>Heat</entry>
      <entry>432 MB (1 transaction per second)</entry>
      <entry>432 MB (1 transaction per second)</entry>
      <entry>432 MB (1 transaction per second)</entry>
     </row>
     <row>
      <entry>Swift</entry>
      <entry>33 GB (700 transactions per second)</entry>
      <entry>102 GB (2100 transactions per second)</entry>
      <entry>172 GB (3500 transactions per second)</entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </section>
 <section xml:id="audit_add_disks">
  <title>Add disks to the controller nodes</title>
  <para>
   You need to add disks for the audit log partition to store the data in a
   secure manner. The steps to complete this task will vary depending on the
   type of server you are running. Please refer to the manufacturer’s
   instructions on how to add disks for the type of server node used by the
   management controller cluster. If you already have extra disks in the
   controller node, you can identify any unused one and use it for the audit
   log partition.
  </para>
 </section>
 <section xml:id="audit_update_disks">
  <title>Update the disk template for the controller nodes</title>
  <para>
   Since audit logging is disabled by default, the audit volume groups in the
   disk templates are commented out. If you want to turn on audit logging, the
   template needs to be updated first. If it is not updated, there will be no
   back-up volume group. To update the disk template, you will need to copy
   templates from the examples folder to the definition folder and then edit
   the disk controller settings. Changes to the disk template used for
   provisioning cloud nodes must be made prior to deploying the nodes.
  </para>
  <para>
   To update the disk controller template:
  </para>
  <orderedlist>
   <listitem>
    <para>
     Log in to your &lcm;.
    </para>
   </listitem>
   <listitem>
    <para>
     To copy the example templates folder, run the following command:
    </para>
    <important>
     <para>
      If you already have the required templates in the definition folder, you
      can skip this step.
     </para>
    </important>
<screen>&prompt.ardana;cp -r ~/openstack/examples/entry-scale-esx/* ~/openstack/my_cloud/definition/</screen>
   </listitem>
   <listitem>
    <para>
     To change to the data folder, run:
    </para>
<screen>&prompt.ardana;cd ~/openstack/my_cloud/definition/</screen>
   </listitem>
   <listitem>
    <para>
     To edit the disks controller settings, open the file that matches your
     server model and disk model in a text editor:
    </para>
    <informaltable colsep="1" rowsep="1">
     <tgroup cols="2">
      <colspec colname="c1" colnum="1" colwidth="1*"/>
      <colspec colname="c2" colnum="2" colwidth="3.88*"/>
      <thead>
       <row>
        <entry>Model</entry>
        <entry>File</entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>entry-scale-kvm</entry>
        <entry>
<screen>disks_controller_1TB.yml</screen>
<screen>disks_controller_600GB.yml</screen>
        </entry>
       </row>
       <row>
        <entry>mid-scale</entry>
        <entry>
<screen>disks_compute.yml</screen>
<screen>disks_control_common_600GB.yml</screen>
<screen>disks_dbmq_600GB.yml</screen>
<screen>disks_mtrmon_2TB.yml</screen>
<screen>disks_mtrmon_4.5TB.yml</screen>
<screen>disks_mtrmon_600GB.yml</screen>
<screen>disks_swobj.yml</screen>
<screen>disks_swpac.yml</screen>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </informaltable>
   </listitem>
   <listitem>
    <para>
     To update the settings and enable an audit log volume group, edit the
     appropriate file(s) listed above and remove the '#' comments from these
     lines, confirming that they are appropriate for your environment.
    </para>
<screen>- name: audit-vg
  physical-volumes:
    - /dev/sdz
  logical-volumes:
    - name: audit
      size: 95%
      mount: /var/audit
      fstype: ext4
      mkfs-opts: -O large_file</screen>
   </listitem>
  </orderedlist>
 </section>
 <section xml:id="audit_save_update_disks">
  <title>Save your changes</title>
  <para>
   To save your changes you will use the GIT repository to add the setup disk
   files.
  </para>
  <para>
   To save your changes:
  </para>
  <orderedlist>
   <listitem>
    <para>
     To change to the openstack directory, run:
    </para>
<screen>&prompt.ardana;cd ~/openstack </screen>
   </listitem>
   <listitem>
    <para>
     To add the new and updated files, run:
    </para>
<screen>&prompt.ardana;git add -A </screen>
   </listitem>
   <listitem>
    <para>
     To verify the files are added, run:
    </para>
<screen>&prompt.ardana;git status</screen>
   </listitem>
   <listitem>
    <para>
     To commit your changes, run:
    </para>
<screen>&prompt.ardana;git commit -m "Setup disks for audit logging"</screen>
   </listitem>
  </orderedlist>
 </section>
</section>
