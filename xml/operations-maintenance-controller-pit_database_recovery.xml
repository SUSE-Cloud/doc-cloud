<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="pit_database_recovery">
 <title>Point-in-Time &mariadb; Database Recovery</title>
 <para>
  In this scenario, everything is still running (&lcm;, cloud
  controller nodes, and compute nodes) but you want to restore the &mariadb;
  database to a previous state.
 </para>
 <section>
  <title>Restore from a Swift backup</title>
  <orderedlist>
   <listitem>
    <para>
     Log in to the &lcm;.
    </para>
   </listitem>
   <listitem>
    <para>
     Determine which node is the first host member in the
     <literal>FND-MDB</literal> group, which will be the first node hosting the
     &mariadb; service in your cloud. You can do this by using these commands:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
grep -A1 FND-MDB--first-member hosts/verb_hosts</screen>
    <para>
     Example output:
    </para>
<screen>$ grep -A1 FND-MDB--first-member hosts/verb_hosts
[FND-MDB--first-member:children]
ardana-cp1-c1-m1</screen>
   </listitem>
   <listitem>
    <para>
     Log in to the first host member from the <literal>FND-MDB</literal> group.
    </para>
   </listitem>
   <listitem>
    <para>
     Become root:
    </para>
<screen>sudo su</screen>
   </listitem>
   <listitem>
    <para>
     Source the backup environment file
    </para>
<screen>source /home/stack/backup.osrc</screen>
   </listitem>
   <listitem>
    <para>
     List the jobs
    </para>
<screen>freezer-scheduler -c &lt;hostname&gt; job-list</screen>
   </listitem>
   <listitem>
    <para>
     Get the id corresponding to the job <literal>&lcm; Default: Mysql restore
     from Swift</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     Launch the restore.
    </para>
<screen>freezer-scheduler -c &lt;hostname&gt; job-start -j &lt;job-id&gt;</screen>
   </listitem>
   <listitem>
    <para>
     This will take some time. While you wait you can follow the progress in
     the <literal>/var/log/freezer-agent/freezer-scheduler.log</literal> log
     file.
    </para>
   </listitem>
   <listitem>
    <para>
     Log in to the &lcm;.
    </para>
   </listitem>
   <listitem>
    <para>
     Stop the Percona DB service:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts percona-stop.yml</screen>
   </listitem>
   <listitem>
    <para>
     Log back in to the first node running the &mariadb; service. (Same node as
     step #3)
    </para>
   </listitem>
   <listitem>
    <para>
     Clean the &mariadb; directory using this command:
    </para>
<screen>sudo rm -r /var/lib/mariadb/*</screen>
   </listitem>
   <listitem>
    <para>
     Copy the restored files back to the &mariadb; directory:
    </para>
<screen>sudo cp -pr /tmp/mariadb_restore/* /var/lib/mariadb</screen>
   </listitem>
   <listitem>
    <para>
     Log in to each of the other nodes in your &mariadb; cluster (the other nodes
     determined from step #2) and remove the <literal>grastate.dat</literal>
     file from each of them:
    </para>
<screen>sudo rm /var/lib/mariadb/grastate.dat</screen>
   <note>
    <para>
     Do not remove this file from the first node in your &mariadb; cluster.
     Ensure you only do this from the other cluster nodes.
    </para>
   </note>
   </listitem>
   <listitem>
    <para>
     Log back in to the &lcm;.
    </para>
   </listitem>
   <listitem>
    <para>
     Start the Percona DB service back up:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts galera-bootstrap.yml</screen>
   </listitem>
  </orderedlist>
 </section>
 <section>
  <title>Restore from an SSH backup</title>
  <para>
   Follow the same procedure as the one for Swift but select the job
   <literal>&lcm; Default: &mariadb; restore from SSH</literal>.
  </para>
 </section>
 <section>
  <title>Restore &mariadb; manually</title>
  <para>
   If restoring &mariadb; fails during the procedure outlined above, you can follow
   this procedure to manually restore &mariadb;:
  </para>
  <orderedlist>
   <listitem>
    <para>
     Log in to the &lcm;.
    </para>
   </listitem>
   <listitem>
    <para>
     Stop the &mariadb; cluster:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts percona-stop.yml</screen>
   </listitem>
   <listitem>
    <para>
     On all of the nodes running the &mariadb; service, which should be all of your
     controller nodes, run the following command to purge the old database:
    </para>
<screen>sudo rm -r /var/lib/mariadb/*</screen>
   </listitem>
   <listitem>
    <para>
     On the first node running the &mariadb; service restore the backup with the
     command below. If you have already restored to a temporary directory, copy
     the files again.
    </para>
<screen>sudo cp -pr /tmp/mariadb_restore/* /var/lib/mariadb</screen>
   </listitem>
   <listitem>
    <para>
     If you need to restore the files manually from SSH, follow these steps:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Become root:
      </para>
<screen>sudo su</screen>
     </listitem>
     <listitem>
      <para>
       Create the <literal>/root/mariadb_restore.ini</literal> file with the
       contents below. Be careful to substitute the <literal>{{ values
       }}</literal>. Note that the SSH information refers to the SSH server you
       configured for backup before installing.
      </para>
<screen>[default]
action = restore
storage = ssh
ssh_host = {{ freezer_ssh_host }}
ssh_username = {{ freezer_ssh_username }}
container = {{ freezer_ssh_base_dir }}/freezer_mariadb_backup
ssh_key = /etc/freezer/ssh_key
backup_name = freezer_mariadb_backup
restore_abs_path = /var/lib/mariadb/
log_file = /var/log/freezer-agent/freezer-agent.log
hostname = {{ hostname of the first &mariadb; node }}</screen>
     </listitem>
     <listitem>
      <para>
       Execute the restore job:
      </para>
<screen>freezer-agent --config /root/mariadb_restore.ini</screen>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Also on the first node running the &mariadb; service, follow the next steps to
     start the cluster.
    </para>
    <orderedlist>
     <listitem>
      <para>
       Become root:
      </para>
<screen>sudo su</screen>
     </listitem>
     <listitem>
      <para>
       When the last step executed successfully, start the &mariadb; cluster:
      </para>
<screen>/etc/init.d/mariadb bootstrap-pxc</screen>
     </listitem>
     <listitem>
      <para>
       Start the process with systemctl to make sure the process is monitored
       by upstard:
      </para>
<screen>systemctl start mariadb</screen>
     </listitem>
     <listitem>
      <para>
       Make sure the mariadb process started successfully by getting the status:
      </para>
<screen>systemctl status mariadb</screen>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Log back in to the &lcm;.
    </para>
   </listitem>
   <listitem>
    <para>
     From the &lcm;, execute the following playbook to start all
     &mariadb; instances:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts percona-start.yml</screen>
   </listitem>
   <listitem>
    <para>
     &mariadb; cluster status can be checked using the <literal>percona-status.yml
     </literal>playbook:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts percona-status.yml</screen>
   </listitem>
   <listitem>
    <para>
     On all of the nodes running the &mariadb; service, run the following commands
     as root:
    </para>
<screen>sudo su
touch /var/lib/mariadb/percona.initialised
chown mariadb:mariadb /var/lib/mariadb/percona.initialised</screen>
   </listitem>
   <listitem>
    <para>
     After approximately 10-15 minutes, the output of the
     <literal>percona-status.yml</literal> playbook should show all the &mariadb;
     nodes in sync. &mariadb; cluster status can be checked using this playbook:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts percona-status.yml</screen>
    <para>
     An example output is as follows:
    </para>
<screen>TASK: [FND-MDB | status | Report status of "{{ mariadb_service }}"] *************
  ok: [ardana-cp1-c1-m1-mgmt] =&gt; {
  "msg": "mariadb is synced."
  }
  ok: [ardana-cp1-c1-m2-mgmt] =&gt; {
  "msg": "mariadb is synced."
  }
  ok: [ardana-cp1-c1-m3-mgmt] =&gt; {
  "msg": "mariadb is synced."
  }</screen>
   </listitem>
  </orderedlist>
 </section>
</section>
