<?xml version="1.0"?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [ <!ENTITY % entities SYSTEM "entities.ent"> %entities; ]>
<!-- Copyright FUJITSU LIMITED 2017 -->
<section id="idg-osoperator-shared-appendix-r-metricsadditional-xml-1">
 <title>Additional Metrics</title>
 <para>
  <phrase>CMM</phrase> supports the additional metrics described below for
  monitoring specific servers and services. The metrics are grouped by metrics
  types. Each metrics type references a set of related metrics.
 </para>
 <para>
  Depending on the services running on the host where you install a Metrics
  Agent, some or all of these metrics are automatically added to the agent
  configuration. You should check the individual <literal>yaml</literal> files
  and change or correct the settings as required, or remove individual
  <literal>yaml</literal> files from the agent configuration if you do not want
  to monitor the metrics they include.
 </para>
 <para>
  Note that in addition to the metrics below, many more metrics are provided by
  the Monasca project. These are not automatically installed by
  <phrase>CMM</phrase>. For details on the complete set of metrics provided by
  the Monasca project, refer to the
  <ulink url="https://github.com/openstack/monasca-agent/blob/stable/ocata/docs/Plugins.md">
  Monasca documentation </ulink>.
 </para>
 <bridgehead renderas="sect4">apache.yaml</bridgehead>
 <para>
  Apache Web Server checks collect metrics from an Apache Web Server. If you
  want the installer to automatically configure the checks, update the
  <literal>apache.cnf</literal> file in the <literal>root</literal> directory
  before installing the agent.
 </para>
 <para>
  Example configuration for <literal>apache.cnf</literal>:
 </para>
<screen>[client]
url=http://localhost/server-status?auto
user=root
password=password</screen>
 <para>
  Specify the configuration information in the <literal>apache.yaml</literal>
  file after the installation.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- apache_status_url: http://localhost/server-status?auto
  apache_user: root
  apache_password: password</screen>
 <bridgehead renderas="sect4">crash.yaml</bridgehead>
 <para>
  Crash checks provide information on system crash dumps. The default directory
  where the crash dumps are provided is <literal>/var/crash</literal>.
 </para>
 <para>
  The agent installer automatically checks whether a crash kernel is loaded on
  the machine where the agent is installed. If so, the detected settings are
  saved to the <literal>crash.yaml</literal> configuration file, and the
  configuration is automatically provided in the
  <literal>/etc/monasca/agent/conf.d/</literal> directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: Crash
  name: crash_stats</screen>
 <bridgehead renderas="sect4">elastic.yaml</bridgehead>
 <para>
  Elastic checks gather metrics for Elasticsearch databases, such as the Log
  Database of <phrase>CMM</phrase>. The configuration file must specify the URL
  for HTTP requests. If basic authentication is used, for example,
  <literal>elasticsearch-http-basic</literal>, the configuration file must also
  specify the user name and password for every instance that requires
  authentication.
 </para>
 <para>
  The agent installer automatically creates the <literal>elastic.yaml</literal>
  configuration file in the <literal>/etc/monasca/agent/conf.d/</literal>
  directory. If there is an Elasticsearch database instance installed on the
  machine where the agent is installed, you have to specify the configuration
  information in the <literal>elastic.yaml</literal> file after the
  installation.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- dimensions:
    component: elasticsearch
    service: monitoring
  url: http://localhost:9200
  username: username
  password: password</screen>
 <bridgehead renderas="sect4">host_alive.yaml</bridgehead>
 <para>
  Host alive checks perform checks on a remote host to determine whether it is
  alive. The checks use ping (ICMP) or SSH.
 </para>
 <para>
  SSH checks provide extensive tests on the availability of remote host
  machines. They check the banner that is returned. A remote host machine may
  still respond to a ping request but may not return an SSH banner. Therefore
  it is recommended that you use SSH checks instead of ping checks.
 </para>
 <para>
  The agent installer automatically creates the
  <literal>host_alive.yaml</literal> configuration file in the
  <literal>/etc/monasca/agent/conf.d/</literal> directory. If there are
  applications and processes running on the machine where the agent is
  installed, you have to specify the configuration information in the
  <literal>host_alive.yaml</literal> file after the installation.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config:
    ping_timeout: 1
    ssh_port: 22
    ssh_timeout: 0.5
instances:
-   alive_test: ssh
    host_name: 10.140.18.53
    name: openstack</screen>
 <bridgehead renderas="sect4">http_check.yaml</bridgehead>
 <para>
  HTTP endpoint checks perform up/down checks on HTTP endpoints. Based on a
  list of URLs, the agent sends an HTTP request and reports success or failure
  to the Monitoring Service.
 </para>
 <para>
  The agent installer auto-detects HTTP endpoints on the machine where the
  agent is installed. It saves the detected settings to the
  <literal>http_check.yaml</literal> configuration file, and the configuration
  is automatically provided in the
  <literal>/etc/monasca/agent/conf.d/</literal> directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: MonAPI
  dimensions:
    component: monasca-api
    service: monitoring
  include_content: false
  name: monitoring-monasca-api healthcheck
  timeout: 5
  url: http://localhost:8081/healthcheck</screen>
 <bridgehead renderas="sect4">http_metrics.yaml</bridgehead>
 <para>
  HTTP metrics checks retrieve metrics from any URL that returns a JSON
  response. Based on a list of URLs, the agent can dispatch an HTTP request and
  parse the desired metrics from the JSON response.
 </para>
 <para>
  The agent installer auto-detects applications and processes on the machine
  where the agent is installed. It saves the detected settings to the
  <literal>http_metrics.yaml</literal> configuration file, and the
  configuration is automatically provided in the
  <literal>/etc/monasca/agent/conf.d/</literal> directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: MonAPI
  dimensions:
    component: monasca-api
    service: monitoring
  name: monitoring-monasca-api metrics
  timeout: 5
  url: http://localhost:8081/metrics
  whitelist:
  - name: jvm.memory.total.max
    path: gauges/jvm.memory.total.max/value
    type: gauge
  - name: jvm.memory.total.used
    path: gauges/jvm.memory.total.used/value
    type: gauge
  - name: metrics.published
    path: meters/monasca.api.app.MetricService.metrics.published/count
    type: rate</screen>
 <bridgehead renderas="sect4">kafka_consumer.yaml</bridgehead>
 <para>
  Kafka consumer checks gather metrics related to services consuming Kafka
  topics, such as the Persister or Notification Engine of <phrase>CMM</phrase>.
 </para>
 <para>
  For Kafka consumer checks, the Kafka consumer module
  (<literal>kafka-python</literal>) must be installed in the virtualenv
  environment of the Metrics Agent. To install it in the default directory,
  execute the following command:
 </para>
<screen># source /opt/monasca-agent/bin/activate 
# pip install kafka-python 
# deactivate </screen>
 <para>
  The agent installer automatically detects services that are consuming Kafka
  topics on the machine where the agent is installed. If such services are
  detected, the corresponding settings are saved to the
  <literal>kafka_consumer.yaml</literal> configuration file, and the
  configuration is automatically provided in the
  <literal>/etc/monasca/agent/conf.d/</literal> directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: Kafka
  consumer_groups:
    1_alarm-state-transitions:
      alarm-state-transitions: []
    1_metrics:
      metrics: []
    log-metric:
      transformed-log: []
    logstash-persister:
      transformed-log: []
    thresh-event:
      events: []
    thresh-metric:
      metrics: []
    transformer-logstash-consumer:
      log: []
  kafka_connect_str: 10.140.18.49:9092
  name: 10.140.18.49:9092
  per_partition: false  </screen>
 <bridgehead renderas="sect4">kibana.yaml </bridgehead>
 <para>
  Kibana checks gather metrics from a Kibana server. The checks access the
  status endpoint of Kibana (<literal>curl -XGET
  http://localhost:5601/api/status</literal>). The configuration information in
  the <literal>kibana.yaml</literal> file corresponds to the Kibana
  configuration.
 </para>
 <para>
  The agent installer automatically checks whether a Kibana server instance is
  installed on the machine where the agent is installed. If a Kibana server
  instance is detected, the corresponding settings are saved to the
  <literal>kibana.yaml</literal> configuration file, and the configuration is
  automatically provided in the <literal>/etc/monasca/agent/conf.d/</literal>
  directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config:
  url: http://10.140.18.49:5601/api/status
instances:
- built_by: Kibana
  metrics:
  - load
  - heap_size
  - heap_used
  - req_sec
  - resp_time_max
  - resp_time_avg</screen>
 <bridgehead renderas="sect4">libvirt.yaml</bridgehead>
 <para>
  Libvirt checks provide metrics for virtual machines that run on a hypervisor.
  The checks provide a set of metrics for the owner of the virtual machine as
  well as for the owner of the hypervisor.
 </para>
 <note>
  <para>
   The user specified in the configuration file must be assigned the
   <literal>admin</literal> role.
  </para>
  <para>
   With Red Hat Enterprise Linux OpenStack Platform as underlying platform
   technology, the <literal>admin_tenant_name</literal> must be set to
   <literal>services</literal>.
  </para>
 </note>
 <para>
  Example configuration:
 </para>
<screen>init_config:
    admin_password: password
    admin_tenant_name: services
    admin_user: nova
    identity_uri: 'http://192.168.10.5:35357/v2.0'
    cache_dir: /dev/shm
    nova_refresh: 14400
    vm_probation: 300
    vm_cpu_check_enable: True
    vm_disks_check_enable: True
    vm_extended_disks_check_enable: True
    vm_network_check_enable: True
instances:
    - {}</screen>
 <bridgehead renderas="sect4">mysql.yaml</bridgehead>
 <para>
  MySQL checks gather metrics from a MySQL database server. MariaDB is also
  supported. The metrics are related to the server status variables of MySQL.
 </para>
 <para>
  The agent installer automatically configures the MySQL checks. As a
  prerequisite, you must update the <literal>.my.cnf</literal> file in the
  <literal>root</literal> directory before installing the agent.
 </para>
 <para>
  Example configuration for <literal>.my.cnf</literal>:
 </para>
<screen>[client]
host=localhost
user=root
password=password</screen>
 <note>
  <para>
   Make sure that the password is set correctly. The agent installer fails if
   you specify the password enclosed in quotation marks.
  </para>
 </note>
 <para>
  In addition, the MySQL module (<literal>pymysql</literal>) must be installed
  in the virtualenv environment of the Metrics Agent. To install it in the
  default directory, execute the following command:
 </para>
<screen># source /opt/monasca-agent/bin/activate 
# pip install pymysql
# deactivate </screen>
 <para>
  The agent installer automatically checks whether a MySQL database instance is
  installed on the machine where the agent is installed. If so, the detected
  settings are saved to the <literal>mysql.yaml</literal> configuration file,
  and the configuration is automatically provided in the
  <literal>/etc/monasca/agent/conf.d/</literal> directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: MySQL
  name: localhost
  pass: ''
  port: 3306
  server: localhost
  sock: /var/lib/mysql/mysql.sock
  ssl_ca: null
  ssl_cert: null
  ssl_key: null
  user: root</screen>
 <bridgehead renderas="sect4">ntp.yaml</bridgehead>
 <para>
  Network Time Protocol checks monitor the time offset between the NTP server
  and the host machine. The configuration file must specify the parameters that
  you want to monitor.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- host: pool.ntp.org
  port: ntp
  version: 3
  timeout: 5</screen>
 <bridgehead renderas="sect4">ovs.yaml</bridgehead>
 <para>
  Open vSwitch Neutron Router Monitoring checks monitor neutron virtual routers
  implemented with OpenVSwitch. The checks include rate metrics as well as
  health-related metrics.
 </para>
 <para>
  The agent installer automatically checks whether a neutron virtual router is
  installed on an OpenStack host. If so, the detected settings are saved to the
  <literal>ovs.yaml</literal> configuration file, and the configuration is
  automatically provided in the <literal>/etc/monasca/agent/conf.d/</literal>
  directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config:
  admin_password: password
  admin_tenant_name: services
  admin_user: neutron
  cache_dir: /dev/shm
  identity_uri: http://10.140.18.53:35357/v2.0
  included_interface_re: qg.*|vhu.*|sg.*
  network_use_bits: false
  neutron_refresh: 14400
  ovs_cmd: sudo /usr/bin/ovs-vsctl
  region_name: RegionOne
  use_absolute_metrics: true
  use_health_metrics: true
  use_rate_metrics: true
instances: {}</screen>
 <bridgehead renderas="sect4">postfix.yaml</bridgehead>
 <para>
  Postfix checks monitor a Postfix mail server. For running the Postfix checks,
  the user who installs the agent must have passwordless
  <literal>sudo</literal> access to the <literal>find</literal> command. The
  passwordless <literal>sudo</literal> access must be configured before
  installing the agent.
 </para>
 <para>
  Example for a corresponding entry in the <literal>/etc/sudoers</literal>
  file:
 </para>
<screen>monasca-agent ALL=(ALL) NOPASSWD:/usr/bin/find</screen>
 <para>
  The agent installer automatically checks whether a Postfix mail server
  instance is installed on the machine where the agent is installed. If so, the
  detected settings are saved to the <literal>postfix.yaml</literal>
  configuration file, and the configuration is automatically provided in the
  <literal>/etc/monasca/agent/conf.d/</literal> directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: Postfix
  directory: /var/spool/postfix
  name: /var/spool/postfix
  queues:
  - incoming
  - active
  - deferred</screen>
 <bridgehead renderas="sect4">postgres.yaml</bridgehead>
 <para>
  Postgres checks gather metrics from a PostgreSQL database.
 </para>
 <para>
  For PostgreSQL checks, the <literal>postgresql-devel</literal> RPM package
  and the <literal>psycopg2</literal> Python package are required. The Python
  package must be installed in the virtualenv environment of the Metrics Agent.
  To install the packages in the default directory, execute the following
  command:
 </para>
<screen># yum install postgresql-devel
# source /opt/monasca-agent/bin/activate
# pip install psycopg2
# deactivate</screen>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
  - host: localhost
    port: 5432
    username: my_username
    password: my_password
    dbname: db_name
    relations:
      - my_table
      - my_other_table</screen>
 <bridgehead renderas="sect4">process.yaml</bridgehead>
 <para>
  Process checks verify that a defined set of processes is up and running. The
  processes can be identified by specifying the process name or a pattern
  match.
 </para>
 <para>
  The agent installer auto-detects processes that are running on the machine
  where the agent is installed. It saves the detected settings to the
  <literal>process.yaml</literal> configuration file, and the configuration is
  automatically provided in the <literal>/etc/monasca/agent/conf.d/</literal>
  directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: MySQL
  detailed: true
  dimensions:
    service: mysql
  exact_match: true
  name: mysqld
  search_string:
  - mysqld
- built_by: Nova
  detailed: true
  dimensions:
    component: nova-compute
    service: compute
  exact_match: false
  name: nova-compute
  search_string:
  - nova-compute</screen>
 <bridgehead renderas="sect4">rabbitmq.yaml</bridgehead>
 <para>
  RabbitMQ checks gather metrics on nodes, exchanges, and queues from a
  RabbitMQ server. If you want the installer to automatically configure the
  checks, update the <literal>/root/rabbitmq.cnf</literal> file before
  installing the agent.
 </para>
 <para>
  Example configuration for <literal>rabbitmq.cnf</literal>:
 </para>
<screen>[client]
user=guest
password=pass
nodes=rabbit@devstack
queues=conductor
exchanges=nova,cinder,ceilometer,glance,keystone,neutron,heat</screen>
 <para>
  For RabbitMQ checks, the RabbitMQ Management plugin must be installed. It is
  included in the RabbitMQ distribution. To enable the plugin, execute the
  following command:
 </para>
<screen>rabbitmq-plugins enable rabbitmq_management</screen>
 <para>
  Specify the configuration information in the <literal>rabbitmq.yaml</literal>
  file after the installation. It must specify the names of the exchanges and
  queues to be monitored.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
  - exchanges: [nova, cinder, ceilometer, glance, keystone, neutron, heat]
    nodes: [rabbit@devstack]
    queues: [conductor]
    rabbitmq_api_url: http://localhost:15672/api
    rabbitmq_user: user
    rabbitmq_pass: pass</screen>
 <bridgehead renderas="sect4">zk.yaml</bridgehead>
 <para>
  ZooKeeper checks gather metrics on nodes and connections covered by
  ZooKeeper, a centralized service for maintaining configuration information,
  naming, providing distributed synchronization, and providing group services.
  The check parses the result of the ZooKeeper <literal>stat</literal> admin
  command.
 </para>
 <para>
  The agent installer automatically checks whether a Zookeeper instance is
  installed on the machine where the agent is installed. If a Zookeper instance
  is detected, the corresponding settings are saved to the
  <literal>zk.yaml</literal> configuration file, and the configuration is
  automatically provided in the <literal>/etc/monasca/agent/conf.d/</literal>
  directory.
 </para>
 <para>
  Example configuration:
 </para>
<screen>init_config: null
instances:
- built_by: Zookeeper
  host: localhost
  name: localhost
  port: 2181
  timeout: 3</screen>
</section>
