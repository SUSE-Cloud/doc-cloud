<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<!---->
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
        xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="ts_compute">
 <title>Troubleshooting Compute Service</title>
 <para>
  Troubleshooting scenarios with resolutions for the Nova service.
 </para>
 <para>
  Nova offers scalable, on-demand, self-service access to compute resources.
  You can use this guide to help with known issues and troubleshooting of Nova
  services.
 </para>
<!---->
 <section xml:id="idg-all-operations-troubleshooting-ts_compute-xml-6">
  <title>How can I reset the state of a compute instance?</title>
  <para>
   If you have an instance that is stuck in a non-Active state, such as
   <literal>Deleting</literal> or <literal>Rebooting</literal> and you want to
   reset the state so you can interact with the instance again, there is a way
   to do this.
  </para>
  <para>
   The Nova command-line tool (also known as the Nova CLI or python-novaclient)
   has a command, <literal>nova reset-state</literal>, that allows you to reset
   the state of a server.
  </para>
  <para>
   Here is the content of the help information about the command which shows
   the syntax:
  </para>
<screen>$ nova help reset-state
        usage: nova reset-state [--active] &lt;server&gt; [&lt;server&gt; ...]

        Reset the state of a server.

        Positional arguments:
        &lt;server&gt;  Name or ID of server(s).

        Optional arguments:
        --active  Request the server be reset to "active" state instead of "error"
        state (the default).</screen>
  <para>
   If you had an instance that was stuck in a <literal>Rebooting</literal>
   state you would use this command to reset it back to
   <literal>Active</literal>:
  </para>
<screen>nova reset-state --active &lt;instance_id&gt;</screen>
 </section>
 <section xml:id="nova-consoleauth.troubleshoot">
  <title>Troubleshooting nova-consoleauth</title>
  <para>
   The nova-consoleauth service runs by default on the first controller node,
   that is, the host with <literal>consoleauth_host_index=0</literal>. If
   nova-consoleauth fails on the first controller node, you can switch it to
   another controller node by running the ansible playbook nova-start.yml and
   passing it the index of the next controller node.
  </para>
  <para>
   The command to switch nova-consoleauth to another controller node
   (controller 2 for instance) is:
  </para>
<screen>ansible-playbook -i hosts/verb_hosts nova-start.yml --extra-vars "consoleauth_host_index=1"</screen>
  <para>
   After you run this command you may now see two instances of the
   <literal>nova-consoleauth</literal> service, which will show as being in
   <literal>disabled</literal> state, when you run the <literal>nova
   service-list</literal> command. You can then delete the service using these
   steps.
  </para>
  <procedure>
   <step>
    <para>
     Obtain the service ID for the duplicated nova-consoleauth service:
    </para>
<screen>nova service-list</screen>
    <para>
     Example:
    </para>
<screen>$ nova service-list
+----+------------------+---------------------------+----------+----------+-------+----------------------------+-----------------+
| Id | Binary           | Host                      | Zone     | Status   | State | Updated_at                 | Disabled Reason |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+-----------------+
| 1  | nova-conductor   | ...a-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:48.000000 | -               |
| 10 | nova-conductor   | ...a-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:47.000000 | -               |
| 13 | nova-conductor   | ...a-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:48.000000 | -               |
| 16 | nova-scheduler   | ...a-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:39.000000 | -               |
| 19 | nova-scheduler   | ...a-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:41.000000 | -               |
| 22 | nova-scheduler   | ...a-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:44.000000 | -               |
| 25 | nova-consoleauth | ...a-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2016-08-25T12:11:45.000000 | -               |
| 49 | nova-compute     | ...a-cp1-comp0001-mgmt | nova     | enabled  | up    | 2016-08-25T12:11:48.000000 | -               |
| 52 | nova-compute     | ...a-cp1-comp0002-mgmt | nova     | enabled  | up    | 2016-08-25T12:11:41.000000 | -               |
| 55 | nova-compute     | ...a-cp1-comp0003-mgmt | nova     | enabled  | up    | 2016-08-25T12:11:43.000000 | -               |
<emphasis role="bold">| 70 | nova-consoleauth | ...a-cp1-c1-m3-mgmt    | internal | disabled | down  | 2016-08-25T12:10:40.000000 | -               |</emphasis>
+----+------------------+---------------------------+----------+----------+-------+----------------------------+-----------------+</screen>
   </step>
   <step>
    <para>
     Delete the disabled duplicate service with this command:
    </para>
<screen>nova service-delete &lt;service_ID&gt;</screen>
    <para>
     Given the example in the previous step, the command could be:
    </para>
<screen>nova service-delete 70</screen>
   </step>
  </procedure>
 </section>
 <section xml:id="ts_resize">
  <title>Enabling the migrate or resize functions in Nova post-installation when using encryption</title>
  <para>
   If you have used encryption for your data when running the configuration
   processor during your cloud deployment and are enabling the Nova resize and
   migrate functionality after the initial installation, there is an issue that
   arises if you have made additional configuration changes that required you to
   run the configuration processor before enabling these features.
  </para>
  <para>
   You will only experience an issue if you have enabled encryption. If you
   haven't enabled encryption, then there is no need to follow the procedure
   below. If you are using encryption and you have made a configuration change
   and run the configuration processor after your initial install or upgrade,
   and you have run the <filename>ready-deployment.yml</filename> playbook, and
   you want to enable migrate or resize in Nova, then the following steps will
   allow you to proceed. Note that the ansible vault key referred to below is
   the encryption key that you have provided to the configuration processor.
  </para>
  <procedure>
   <step>
    <para>
     Log in to the &lcm;.
    </para>
   </step>
   <step>
    <para>
     Checkout the ansible branch of your local git:
    </para>
<screen>cd ~/openstack
git checkout ansible</screen>
   </step>
   <step>
    <para>
     Do a git log, and pick the previous commit:
    </para>
<screen>git log</screen>
    <para>
     In this example below, the commit is
     <literal>ac54d619b4fd84b497c7797ec61d989b64b9edb3</literal>:
    </para>
<screen>$ git log

              commit 69f95002f9bad0b17f48687e4d97b2a791476c6a
              Merge: 439a85e ac54d61
              Author: git user &lt;user@company.com&gt;
              Date:   Fri May 6 09:08:55 2016 +0000

              Merging promotion of saved output

              commit 439a85e209aeeca3ab54d1a9184efb01604dbbbb
              Author: git user &lt;user@company.com&gt;
              Date:   Fri May 6 09:08:24 2016 +0000

              Saved output from CP run on 1d3976dac4fd7e2e78afad8d23f7b64f9d138778

              commit <emphasis role="bold">ac54d619b4fd84b497c7797ec61d989b64b9edb3</emphasis>
              Merge: a794083 66ffe07
              Author: git user &lt;user@company.com&gt;
              Date:   Fri May 6 08:32:04 2016 +0000

              Merging promotion of saved output</screen>
   </step>
   <step>
    <para>
     Checkout the commit:
    </para>
<screen>git checkout &lt;commit_ID&gt;</screen>
    <para>
     Using the same example above, here is the command:
    </para>
<screen>$ git checkout ac54d619b4fd84b497c7797ec61d989b64b9edb3
              Note: checking out 'ac54d619b4fd84b497c7797ec61d989b64b9edb3'.

              You are in 'detached HEAD' state. You can look around, make experimental
              changes and commit them, and you can discard any commits you make in this
              state without impacting any branches by performing another checkout.

              If you want to create a new branch to retain commits you create, you may
              do so (now or later) by using -b with the checkout command again. Example:

              git checkout -b new_branch_name

              HEAD is now at ac54d61... Merging promotion of saved output</screen>
   </step>
   <step>
    <para>
     Change to the ansible output directory:
    </para>
<screen>cd ~/openstack/my_cloud/stage/ansible/group_vars/</screen>
   </step>
   <step>
    <para>
     View the <literal>group_vars</literal> file from the ansible vault - it
     will be of the form below, with your compute cluster name being the
     indicator:
    </para>
<screen>&lt;cloud name&gt;-&lt;control plane name&gt;-&lt;compute cluster name&gt;</screen>
    <para>
     View this group_vars file from the ansible vault with this command which
     will prompt you for your vault password:
    </para>
<screen>ansible-vault view &lt;group_vars_file&gt;</screen>
   </step>
   <step>
    <para>
     Search the contents of this file for the <literal>nova_ssh_key</literal>
     section which will contain both the private and public SSH keys which you
     should then save into a temporary file so you can use it in a later step.
    </para>
    <para>
     Here is an example snippet, with the bold part being what you need to
     save:
    </para>
<screen>NOV_KVM:
                vars:
                <emphasis role="bold">              nova_ssh_key:
                  private: '-----BEGIN RSA PRIVATE KEY-----
                  MIIEpAIBAAKCAQEAv/hhekzykD2K8HnVNBKZcJWYrVlUyb6gR8cvE6hbh2ISzooA
                  jQc3xgglIwpt5TuwpTY3LL0C4PEHObxy9WwqXTHBZp8jg/02RzD02bEcZ1WT49x7
                  Rj8f5+S1zutHlDv7PwEIMZPAHA8lihfGFG5o+QHUmsUHgjShkWPdHXw1+6mCO9V/
                  eJVZb3nDbiunMOBvyyk364w+fSzes4UDkmCq8joDa5KkpTgQK6xfw5auEosyrh8D
                  zocN/JSdr6xStlT6yY8naWziXr7p/QhG44RPD9SSD7dhkyJh+bdCfoFVGdjmF8yA
                  h5DlcLu9QhbJ/scb7yMP84W4L5GwvuWCCFJTHQIDAQABAoIBAQCCH5O7ecMFoKG4
                  JW0uMdlOJijqf93oLk2oucwgUANSvlivJX4AGj9k/YpmuSAKvS4cnqZBrhDwdpCG
                  Q0XNM7d3mk1VCVPimNWc5gNiOBpftPNdBcuNryYqYq4WBwdq5EmGyGVMbbFPk7jH
                  ZRwAJ2MCPoplKl7PlGtcCMwNu29AGNaxCQEZFmztXcEFdMrfpTh3kuBI536pBlEi
                  Srh23mRILn0nvLXMAHwo94S6bI3JOQSK1DBCwtA52r5YgX0nkZbi2MvHISY1TXBw
                  SiWgzqW8dakzVu9UNif9nTDyaJDpU0kr0/LWtBQNdcpXnDSkHGjjnIm2pJVBC+QJ
                  SM9o8h1lAoGBANjGHtG762+dNPEUUkSNWVwd7tvzW9CZY35iMR0Rlux4PO+OXwNq
                  agldHeUpgG1MPl1ya+rkf0GD62Uf4LHTDgaEkUfiXkYtcJwHbjOnj3EjZLXaYMX2
                  LYBE0bMKUkQCBdYtCvZmo6+dfC2DBEWPEhvWi7zf7o0CJ9260aS4UHJzAoGBAOK1
                  P//K7HBWXvKpY1yV2KSCEBEoiM9NA9+RYcLkNtIy/4rIk9ShLdCJQVWWgDfDTfso
                  sJKc5S0OtOsRcomvv3OIQD1PvZVfZJLKpgKkt20/w7RwfJkYC/jSjQpzgDpZdKRU
                  vRY8P5iryptleyImeqV+Vhf+1kcH8t5VQMUU2XAvAoGATpfeOqqIXMpBlJqKjUI2
                  QNi1bleYVVQXp43QQrrK3mdlqHEU77cYRNbW7OwUHQyEm/rNN7eqj8VVhi99lttv
                  fVt5FPf0uDrnVhq3kNDSh/GOJQTNC1kK/DN3WBOI6hFVrmZcUCO8ewJ9MD8NQG7z
                  4NXzigIiiktayuBd+/u7ZxMCgYEAm6X7KaBlkn8KMypuyIsssU2GwHEG9OSYay9C
                  Ym8S4GAZKGyrakm6zbjefWeV4jMZ3/1AtXg4tCWrutRAwh1CoYyDJlUQAXT79Phi
                  39+8+6nSsJimQunKlmvgX7OK7wSp24U+SPzWYPhZYzVaQ8kNXYAOlezlquDfMxxv
                  GqBE5QsCgYA8K2p/z2kGXCNjdMrEM02reeE2J1Ft8DS/iiXjg35PX7WVIZ31KCBk
                  wgYTWq0Fwo2W/EoJVl2o74qQTHK0Bs+FTnR2nkVF3htEOAW2YXQTTN2rEsHmlQqE
                  A9iGTNwm9hvzbvrWeXtx8Zk/6aYfsXCoxq193KglS40shOCaXzWX0w==
                  -----END RSA PRIVATE KEY-----'
                  public: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC/+GF6TPKQPYrwedU0Epl
                  wlZitWVTJvqBHxy8TqFuHYhLOigCNBzfGCCUjCm3lO7ClNjcsvQLg8Qc5vHL1bCpdMc
                  FmnyOD/TZHMPTZsRxnVZPj3HtGPx/n5LXO60eUO/s/AQgxk8AcDyWKF8YUbmj5Ad
                  SaxQeCNKGRY90dfDX7qYI71X94lVlvecNuK6cw4G/LKTfrjD59LN6zhQOSYKryOgNrkq
                  SlOBArrF/Dlq4SizKuHwPOhw38lJ2vrFK2VPrJjydpbOJevun9CEbjhE8P1JIPt2GTImH5t0
                  J+gVUZ2OYXzICHkOVwu71CFsn+xxvvIw/zhbgvkbC+5YIIUlMd
                  Generated Key for Nova User</emphasis>
                NTP_CLI:</screen>
   </step>
   <step>
    <para>
     Switch back to the <literal>site</literal> branch by checking it out:
    </para>
<screen>cd ~/openstack
git checkout site</screen>
   </step>
   <step>
    <para>
     Navigate to your group_vars directory in this branch:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible/group_vars</screen>
   </step>
   <step>
    <para>
     Edit your compute group_vars file, which will prompt you for your vault
     password:
    </para>
<screen>ansible-vault edit &lt;group_vars_file&gt;
              Vault password:
              Decryption successful</screen>
   </step>
   <step>
    <para>
     Search the contents of this file for the <literal>nova_ssh_key</literal>
     section and replace the private and public keys with the contents that you
     had saved in a temporary file in step #7 earlier.
    </para>
   </step>
   <step>
    <para>
     Remove the temporary file that you created earlier. You are now ready to
     run the deployment. For information about enabling Nova resizing and
     migration, see <xref linkend="enabling_the_nova_resize"/>.
    </para>
   </step>
  </procedure>
 </section>
 <section xml:id="idg-all-operations-troubleshooting-ts_compute-xml-9">
  <title>Compute (ESX)</title>
  <para>
<!---->
   <emphasis role="bold">Unable to Create Instance Snapshot when Instance is
   Active</emphasis>
  </para>
  <para>
   There is a known issue with VMWare vCenter where if you have a compute
   instance in <literal>Active</literal> state you will receive the error below
   when attempting to take a snapshot of it:
  </para>
<screen>An error occurred while saving the snapshot: Failed to quiesce the virtual machine</screen>
  <para>
   The workaround for this issue is to stop the instance. Here are steps to
   achieve this using the command line tool:
  </para>
  <procedure>
   <step>
    <para>
     Stop the instance using the NovaClient:
    </para>
<screen>nova stop &lt;instance UUID&gt;</screen>
   </step>
   <step>
    <para>
     Take the snapshot of the instance.
    </para>
   </step>
   <step>
    <para>
     Start the instance back up:
    </para>
<screen>nova start &lt;instance UUID&gt;</screen>
   </step>
  </procedure>
 </section>
</section>
