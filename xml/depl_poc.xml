<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE appendix
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-deploy-poc">
 <title>Building a &cloud; Test lab</title>
 <info>
<dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
    <dm:maintainer>dpopov</dm:maintainer>
    <dm:status>editing</dm:status>
    <dm:deadline/>
    <dm:priority/>
    <dm:translation>no</dm:translation>
    <dm:languages/>
</dm:docmanager>
</info>

<sect1 xml:id="sec-depl-poc-scope">
  <title>Document Scope</title>
  <para>
    This document will help you to prepare &suse; and prospective customers for a
    Proof of Concept (PoC) deployment of &cloud;. This document provides specific
    details for a PoC deployment. It serves as an addition to the &cloud;
    &clouddeploy;.</para>
</sect1>
<sect1 xml:id="sec-depl-poc-features">
  <title>&cloud; Key Features</title>
  <para>
    The latest version 8 of &cloud; supports all OpenStack Pike release components for best-in-class capabilities to deploy an open source private cloud. Here is a brief overview of &cloud; features and functionality.
  </para>
  <itemizedlist mark="bullet" spacing="normal">
    <listitem>
      <para>
        <emphasis>Installation Framework</emphasis> Integration with the Crowbar project speeds up and simplifies installation and administration of your physical cloud infrastructure.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Mixed Hypervisor Support</emphasis> Enhanced virtualization management through support for multi-hypervisor environments that use KVM, Xen, &vmware; vSphere, and IBM z/VM.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>High Availability</emphasis> Automated deployment and configuration of control plane clusters. This ensures continuous access to business services and delivery of enterprise-grade Service Level Agreements.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>High availability for KVM and Xen Compute Nodes and Workloads</emphasis> Enhanced support for critical workloads not designed for cloud architectures.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Docker Support</emphasis> Gives the ability to build and run innovative containerized applications through Magnum integration.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Scalability</emphasis> Cloud control system designed to grow with your demands.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Open APIs</emphasis> Using the standard APIs, customers can enhance and integrate OpenStack with third-party software.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Block Storage Plug-Ins</emphasis> A wide range of block storage plug-ins available from storage vendors like EMC, NetApp, and others.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Networking Plug-Ins</emphasis> &cloud; natively supports open source SDNs via Open vSwitch, harnessing the power of DPDK in &cloudos;. For more flexibility, &cloud; provides support for third-party tools from Cisco, Midokura, Infoblox, Nuage Networks, PLUMgrid and even VLAN bridging solutions.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Award-Winning Support</emphasis> &cloud; is backed by 24x7 worldwide-technical support.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Full Integration with SUSE Update Processes</emphasis> Easily maintain and patch cloud deployments.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Non-Disruptive Upgrade Capabilities</emphasis> Simplify migration to future &cloud; releases.
      </para>
    </listitem>
  </itemizedlist>
</sect1>

<sect1 xml:id="sec-depl-poc-components">
    <title>Main Components</title>
    <para>
      The following is a brief overview of components for setting up and managing &cloud;.
    </para>

    <para>
      <emphasis>Administration Server</emphasis> provides all services needed to manage and deploy all other nodes in the cloud. Most of these services are provided by the Crowbar tool. Together with Chef, Crowbar automates all the required installation and configuration tasks. The services provided by the server include DHCP, DNS, NTP, PXE, TFTP.
    </para>

    <para>
      The Administration Server also hosts the software repositories for &sls; and &cloud;. These repositories are required for node deployment. If no other sources for the software repositories are available, the Administration Server can also host the Subscription Management Tool (SMT), providing up-to-date repositories with updates and patches for all nodes.
    </para>

    <para>
      <emphasis>Control Nodes</emphasis> host all OpenStack services for orchestrating virtual machines deployed on the compute nodes. OpenStack in &cloud; uses a PostgreSQL database that is also hosted on the Control Nodes. When deployed, the following OpenStack components run on the Control Nodes:
    </para>

    <itemizedlist>
      <listitem>
        <para>PostgreSQL</para>
      </listitem>
      <listitem>
        <para>Image (Glance)</para>
      </listitem>
      <listitem>
        <para>Identity (Keystone)</para>
      </listitem>
      <listitem>
        <para>Networking (Neutron)</para>
      </listitem>
      <listitem>
        <para>Block Storage (Cinder)</para>
      </listitem>
      <listitem>
        <para>Shared Storage (Manila)</para>
      </listitem>
      <listitem>
        <para>OpenStack Dashboard</para>
      </listitem>
      <listitem>
        <para>Keystone</para>
      </listitem>
     <listitem>
        <para>Pacemaker</para>
      </listitem>
     <listitem>
        <para>Nova controller</para>
      </listitem>
     <listitem>
        <para>Message broker</para>
      </listitem>
     <listitem>
        <para>Swift proxy server</para>
      </listitem>
     <listitem>
        <para>Hawk monitor</para>
      </listitem>
     <listitem>
        <para>Heat an orchestration engine</para>
      </listitem>
     <listitem>
        <para>Ceilometer server and agents</para>
      </listitem>
     <listitem>
        <para>Trove a Database-as-a-Service</para>
      </listitem>
    </itemizedlist>

    <para>
      A single Control Node running multiple services can become a performance bottleneck, especially in large &cloud; deployments. It is possible to distribute the services listed above on more than one Control Node. This includes scenarios where each service runs on its own node.
    </para>

    <para>
      <emphasis>Compute Nodes</emphasis> are a pool of machines for running instances. These machines require an adequate number of CPUs and enough RAM to start several instances. They also need to provide sufficient storage. A Control Node distributes instances within the pool of compute nodes and provides the necessary network resources. The OpenStack service Compute (Nova) runs on Compute Nodes and provides means for setting up, starting, and stopping virtual machines. &cloud; supports several hypervisors such as KVM, &vmware; vSphere, and Xen. Each image that can be started with an instance is bound to one hypervisor. Each Compute Node can only run one hypervisor at a time. For a PoC deployment, SUSE recommends to leverage KVM  as hypervisor of choice.
    </para>

      <para>
        <emphasis>Optional Storage Nodes</emphasis> Storage Node is a pool of machines that provide object or block storage. Object storage supports several back-ends.
      </para>
</sect1>
<sect1 xml:id="sec-depl-poc-objectives">
  <title>Objectives and Preparations</title>
  <para>
    Although each customer has a specific set of requirements, it is important to have 3-5 clearly-defined objectives. This objectives should be provable, measurable and have a specific time scale in which proof is required. The objectives can be adjusted and amended, provided that both parties are agreed on the changes. For a full record of the performed and completed work, it is recommended to use this document for making amendments to the proof requirements.
  </para>
    <para>
      Before deploying &cloud;, it is necessary to meet certain requirements and consider various aspects of the deployment. Some decisions need to be made <emphasis>before</emphasis> deploying &cloud;, since they <emphasis>cannot</emphasis> be changed afterward.
    </para>

    <para>
      The following procedure covers preparatory steps for the deployment of &cloud; along with the software and hardware components required for a successful implementation.
    </para>
    <procedure>
      <title>Prerequisites</title>
      <step>
        <para>
          Make sure that the required hardware and virtual machines are provided and configured
        </para>
      </step>
      <step>
        <para>
          Check that PXE boot from the first NIC in BIOS is enabled
        </para>
      </step>
      <step>
        <para>
          Ensure that the hardware is certified for use with &cloudos;
        </para>
      </step>
      <step>
        <para>
          Check that booting from ISO images works
        </para>
      </step>
      <step>
        <para>
          Make sure that all NICs are visible
        </para>
      </step>
      <step>
        <para>
          Install <systemitem>sar/sysstat</systemitem> for performance troubleshooting
        </para>
      </step>
      <step>
        <para>
          Ensure that all needed subscription records are available. Depending on the size of the cloud to be implemented, this includes the following:
        </para>
        <itemizedlist>
          <listitem>
            <para>
              &cloud; subscriptions
            </para>
          </listitem>
          <listitem>
            <para>
              &sls; subscriptions
            </para>
          </listitem>
          <listitem>
            <para>
              SLES High Availability Extensions (HAE) subscriptions
            </para>
          </listitem>
          <listitem>
            <para>
              Optional &ses; (SES) subscriptions
            </para>
          </listitem>
        </itemizedlist>
      </step>
      <step>
        <para>
          Check whether all needed channels and updates are available either locally or remotely. The following options can be used to provide the repositories and channels:
        </para>
        <itemizedlist>
          <listitem>
            <para>
              SMT server on the administration server (optional step)
            </para>
          </listitem>
          <listitem>
            <para>
              Existing SMT server
            </para>
          </listitem>
          <listitem>
            <para>
              Existing &susemgr;
            </para>
          </listitem>
        </itemizedlist>
      </step>
      <step>
        <para>
          Make sure that networking planed and wired according to the specified layout or topology
        </para>
      </step>
      <step>
        <para>
          If &ses; is a part of the PoC deployment, all nodes must be
installed, configured, and optimized before installing &cloud;. Storage services (Nova, Cinder, Glance, Cluster &stonith;,) required by &cloud; 6 must be available and accessible.
        </para>
      </step>
      <step>
        <para>
          Check whether <systemitem>network.json</systemitem> is configured according to the specific requirements. This step must be discussed and completed in advance (see <xref
      linkend="sec-depl-poc-networkjson"/> and <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/book_cloud_deploy/data/book_cloud_deploy.html"/>)
        </para>
      </step>
    </procedure>
</sect1>

<sect1 xml:id="sec-depl-poc-matrix">
  <title>Hardware and Software Matrix</title>
  <para>The hardware and software matrix below has the following requirements:</para>
  <itemizedlist>
    <listitem>
      <para>
        All machines must run &cloudos;
      </para>
    </listitem>
    <listitem>
      <para>
    KVM or Xen Hypervisors must be running on bare metal
      </para>
    </listitem>
    <listitem>
      <para>
        The Admin Node can be deployed on a KVM or &vmware; virtual machine
      </para>
    </listitem>
  </itemizedlist>

  <para>
The sizing recommendation includes an Admin Node (bare metal or VM), Controller Nodes, Compute Nodes to host all your OpenStack services, and the optional SES Nodes. The matrix also provides information on the necessary network equipment and bandwidth requirements.
  </para>

  <note>
    <title>About Recommendations</title>
    <para>
      These recommendations are based on real-world use cases and experience gathered by &suse; in the last three years. However, these recommendations are meant to serve as guidelines and not as requirements. The final sizing decision depends on the actual customer workloads and architecture, which must be discussed in depth. The type and number of hardware components such as hard disks, CPU, and RAM also serve as starting points for further discussion and evaluation depending on workloads.
     </para>
    </note>

    <table>
      <title>BoM/&cloud; Services</title>
      <tgroup cols="4">
        <colspec colnum="1" colname="1" colwidth="25*"/>
        <colspec colnum="2" colname="2" colwidth="25*"/>
        <colspec colnum="3" colname="3" colwidth="25*"/>
        <colspec colnum="4" colname="4" colwidth="25*"/>
        <thead>
          <row>
            <entry><para>Number of Units</para></entry>
            <entry><para>Function</para></entry>
            <entry><para>Configuration</para></entry>
            <entry><para>OpenStack Component</para></entry>
           </row>
          </thead>
          <tbody>
            <row>
              <entry><para>3</para></entry>
              <entry><para>Compute nodes</para></entry>
              <entry><para>2 hard disks</para>
              <para>2 Quad Core Intel or AMD processors</para>
              <para>256GB RAM</para>
              <para>2 or 4 10Gb Ethernet NICs</para></entry>
              <entry><para>Nova-multi-compute</para>
              <para>ML2 Agent</para>
              <para>OVS Agent</para></entry>
             </row>
            <row>
              <entry><para>1</para></entry>
              <entry><para>Admin Node or VM</para></entry>
              <entry><para>2 hard disks</para>
              <para>1 Quad Core Intel or AMD processor</para>
              <para>8GB RAM</para>
              <para>2 or 4 10Gb Ethernet NICs</para></entry>
              <entry><para>Crowbar, tftpboot, PXE</para>
              </entry>
             </row>
            <row>
              <entry><para>3</para></entry>
              <entry><para>Control node</para></entry>
              <entry><para>2 hard disks</para>
              <para>2 Quad Core Intel or AMD processors</para>
              <para>2x64GB RAM</para>
              <para>2 or 4 10Gb Ethernet NICs</para></entry>
              <entry><para>Horizon</para>
              <para>Rabbit MQ</para>
              <para>Nova multi-controller</para>
              <para>Cinder</para>
              <para>Glance</para>
              <para>Heat</para>
              <para>Ceilometer</para>
              <para>Neutron-Server</para>
              <para>ML2 Agent</para>
              <para>Keystone</para>
              <para>&mariadb;</para>
              <para>Neutron ML2 Plugin</para>
              <para>L2/L3 Agents</para>
              <para>DHCP Agent</para>
              </entry>
             </row>
            <row>
              <entry><para></para></entry>
              <entry><para>CloudFoundry</para></entry>
              <entry><para>48 vCPUs</para>
              <para>256GB RAM</para>
              <para>Min 2TB Storage</para>
              </entry>
              <entry><para>&cap;</para>
              </entry>
             </row>
            <row>
              <entry><para>4</para></entry>
              <entry><para>Storage Server – &ses;</para></entry>
              <entry><para>2 hard disks</para>
              <para>2  Quad Core Intel or AMD processors</para>
              <para>64GB RAM</para>
              <para>2 or 4  10Gb Ethernet NICs </para>
              </entry>
              <entry><para>Admin – Server</para>
              <para>MON - Server</para>
              <para>OSD - Server</para>
              </entry>
            </row>
            <row>
              <entry><para>1</para></entry>
              <entry><para>Switch min. 10 GbE ports</para></entry>
              <entry><para></para></entry>
              <entry><para>All VLANs/Tagged or Untagged</para>
              </entry>
            </row>
            <row>
              <entry align="center" namest="1" nameend="4">OS: &cloudos;</entry>
            </row>
            <row>
              <entry><para>DHCP, DNS</para></entry>
              <entry><para>Isolated within administrator network</para></entry>
              <entry><para></para>
              </entry>
            </row>
            <row>
              <entry><para>HA</para></entry>
              <entry><para>3 Control Nodes</para></entry>
              <entry><para></para>
              </entry>
            </row>
            </tbody>
           </tgroup>
          </table>


</sect1>
<sect1 xml:id="sec-depl-poc-topology">
  <title>Network Topology</title>
  <para>
    Configuring and managing your network are <emphasis>two of the most challenging tasks of deploying a &cloud;</emphasis>. Therefore they need to be planned carefully. Just as OpenStack provides flexibility and agility for compute and storage, SDN in OpenStack gives cloud administrators more control over their networks. However, building and manually configuring the virtual network infrastructure for OpenStack is difficult and error-prone. &cloud; solve this by delivering a structured installation process for OpenStack which could be customized to adapt the given environment.
  </para>
<sect2 xml:id="sec-depl-poc-networkjson">
  <title>The network.json Network Control File</title>
  <para>
    The deployment of the network configuration is done while setting up an Administrator Node. As a requirement for the deployment, the entire network configuration needs to be specified in the <systemitem>network.json</systemitem> file.
  </para>

  <para>
    The Crowbar network barclamp provides two functions for the system:
  </para>
  <itemizedlist>
    <listitem>
      <para>
        Initialization of network interfaces on the Crowbar managed systems
      </para>
    </listitem>
    <listitem>
      <para>
        Address pool management. While the addresses can be managed with the YaST Crowbar module, complex network setups require to manually edit the network barclamp template file <systemitem>/etc/crowbar/network.json</systemitem>. For more detailed explanation and description see <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/pdfdoc/book_cloud_deploy/book_cloud_deploy.pdf#page=240&amp;zoom=auto,63.779,788.031" />
      </para>
    </listitem>
  </itemizedlist>
  <para>
    The network definitions contain IP address assignments, the bridge and VLAN setup, and settings for the router preference. Each network is also assigned to a logical interface. These VLAN IDs and networks can be modified according to the customer's environment.
  </para>
</sect2>
<sect2 xml:id="sec-depl-poc-networkmodes">
  <title>The Network Mode</title>
  <para>
    &cloud; supports three network modes: single, dual and team. As of &cloud; 6, the network mode is applied to all nodes and the Administration Server. That means that all machines need to meet the hardware requirements for the chosen mode. The following network modes are available:
  </para>
  <itemizedlist>
    <listitem>
      <para>
        <emphasis>Single Network Mode</emphasis> In single mode one Ethernet card is used for all the traffic.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Dual Network Mode</emphasis> Dual mode needs two Ethernet cards (on
        all nodes but Administration Server). This allows to completely separate traffic to and from the administrator network and to and from the public network.
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>Team Network Mode</emphasis> The team mode is almost identical to single mode, except it combines several Ethernet cards to a so-called bond (network device bonding). Team mode requires two or more Ethernet cards.
      </para>
    </listitem>
  </itemizedlist>
  <note>
    <title>Team Network Mode for HA</title>
    <para>
      In an HA configuration, make sure that &cloud; is deployed with the team network mode.
     </para>
   </note>

   <figure>
     <title>Network Modes</title>
     <mediaobject>
       <imageobject role="fo">
         <imagedata fileref="depl_poc_network_mode.png" width="100%" format="png"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="depl_poc_network_mode.png" width="100%" format="png"/>
         </imageobject>
        </mediaobject>
</figure>

</sect2>
<sect2 xml:id="sec-depl-poc-defaultlayout">
  <title>Default Layout</title>
  <para>
    The following networks are pre-defined for use with &cloud;.
  </para>
  <table>
    <title>Administrator Network Layout</title>
    <tgroup cols="3">
      <colspec colnum="1" colname="1" colwidth="33*"/>
      <colspec colnum="2" colname="2" colwidth="33*"/>
      <colspec colnum="3" colname="3" colwidth="33*"/>
      <thead>
        <row>
          <entry><para>Network Name</para></entry>
          <entry><para>VLAN</para></entry>
          <entry><para>IP Range</para></entry>
         </row>
        </thead>
        <tbody>
          <row>
            <entry><para>Router</para></entry>
            <entry><para>No - untagged</para></entry>
            <entry><para>192.168.124.1</para></entry>
           </row>
          <row>
            <entry><para>Admin</para></entry>
            <entry><para>No - untagged</para></entry>
            <entry><para>192.168.124.10 – 192.168.124.11</para></entry>
           </row>
          <row>
            <entry><para>DHCP</para></entry>
            <entry><para>No - untagged</para></entry>
            <entry><para>192.168.124.21 – 192.168.124.80</para></entry>
           </row>
          <row>
            <entry><para>Host</para></entry>
            <entry><para>No - untagged</para></entry>
            <entry><para>192.168.124.81 – 192.168.124.160</para></entry>
           </row>
          <row>
            <entry><para>BMC VLAN Host</para></entry>
            <entry><para>100</para></entry>
            <entry><para>192.168.124.61</para></entry>
           </row>
          <row>
            <entry><para>BMC Host</para></entry>
            <entry><para>No - untagged</para></entry>
            <entry><para>192.168.124.162 – 192.168.124.240</para></entry>
           </row>
          <row>
            <entry><para>Switch</para></entry>
            <entry><para>No - untagged</para></entry>
            <entry><para>192.168.124.241 – 192.168.124.250</para></entry>
           </row>
          </tbody>
         </tgroup>
        </table>

        <table>
          <title>Private Network Layout</title>
          <tgroup cols="3">
            <colspec colnum="1" colname="1" colwidth="33*"/>
            <colspec colnum="2" colname="2" colwidth="33*"/>
            <colspec colnum="3" colname="3" colwidth="33*"/>
            <thead>
              <row>
                <entry><para>Network Name</para></entry>
                <entry><para>VLAN</para></entry>
                <entry><para>IP Range</para></entry>
        </row>
</thead>
<tbody>
  <row>
    <entry><para>Router</para></entry>
    <entry><para>500</para></entry>
    <entry><para>192.168.123.1 – 192.168.123.49</para></entry>
   </row>
<row>
    <entry><para>DHCP</para></entry>
    <entry><para>500</para></entry>
    <entry><para>192.168.123.50 – 192.168.123.254</para></entry>
   </row>
  </tbody>
 </tgroup>
</table>

<table>
  <title>Public/Nova Floating Network Layout/Externally Provided</title>
  <tgroup cols="3">
    <colspec colnum="1" colname="1" colwidth="33*"/>
    <colspec colnum="2" colname="2" colwidth="33*"/>
    <colspec colnum="3" colname="3" colwidth="33*"/>
    <thead>
      <row>
        <entry><para>Network Name</para></entry>
        <entry><para>VLAN</para></entry>
        <entry><para>IP Range</para></entry>
</row></thead>
<tbody>
  <row>
    <entry><para>Public Host</para></entry>
    <entry><para>300</para></entry>
    <entry><para>192.168.126.2 – 192.168.126.49</para></entry>
   </row>
<row>
    <entry><para>Public DHCP</para></entry>
    <entry><para>300</para></entry>
    <entry><para>192.168.126.50 – 192.168.126.127</para></entry>
   </row>
<row>
    <entry><para>Floating Host</para></entry>
    <entry><para>300</para></entry>
    <entry><para>192.168.126.129 – 192.168.126.191</para></entry>
   </row>
  </tbody>
 </tgroup>
</table>

<table>
  <title>Storage Network Layout</title>
  <tgroup cols="3">
    <colspec colnum="1" colname="1" colwidth="33*"/>
    <colspec colnum="2" colname="2" colwidth="33*"/>
    <colspec colnum="3" colname="3" colwidth="33*"/>
    <thead>
      <row>
        <entry><para>Network Name</para></entry>
        <entry><para>VLAN</para></entry>
        <entry><para>IP Range</para></entry>
</row></thead>
<tbody>
  <row>
    <entry><para>Host</para></entry>
    <entry><para>200</para></entry>
    <entry><para>192.168.125.2 – 192.168.125.254</para></entry>
   </row>
  </tbody>
 </tgroup>
</table>

<para>
 The default IP addresses can be changed using YaST Crowbar module or by editing the appropriate JSON file. It is also possible to customize the network setup for your environment. This can be done by editing the network barclamp template.
</para>

</sect2>
</sect1>
<sect1 xml:id="sec-depl-poc-architecture">
  <title>Network Architecture</title>
  <para>
    &cloud; requires a complex network setup consisting of several networks configured during installation. These networks are reserved for cloud usage. Access to these networks from an existing network requires a router.
  </para>
  <important>
    <title>Network Configuration with Crowbar</title>
    <para>
      The network configuration on the nodes in the &cloud; network is controlled by Crowbar. Any network configuration changes done outside Crowbar will be automatically overwritten. After the cloud is deployed, network settings cannot be changed without reinstalling the cloud.
    </para>
  </important>
  <para>
    <emphasis>Controller Node</emphasis> serves as the front-end for API calls to the compute, image, volume, network, and orchestration services. In addition to that, the node hosts multiple Neutron plug-ins and agents. The node also aggregates all route traffic within tenant and between tenant network and outside world.
  </para>
  <para>
    <emphasis>Compute Node</emphasis> creates on-demand virtual machines using chosen hypervisor for customer application.
  </para>

  <para>
    <emphasis>Administrator Node</emphasis> automates the installation processes via Crowbar using pre-defined cookbooks for configuring and deploying a Control Node and Compute and Network Nodes.
  </para>

  <note>
    <title>DHCP/PXE Environment for Administrator Node</title>
    <para>
      The Administrator Node requires a dedicated local and isolated DHCP/PXE environment controlled by Crowbar.
    </para>
  </note>

  <para>
    <emphasis>Optional storage access</emphasis>. Cinder is used for block storage access exposed through iSCSI or NFS (FC connection is not supported in the current release of OpenStack). This could also be a dedicated Storage Node.
  </para>
  <note>
    <title>High-Performance Network for &ceph;</title>
    <para>
      Implementation of &ceph; as a cloud storage requires a high-performance
      network. The Storage Net in the following network topology would allow
      the respective OpenStack services to connect to the external &ceph;
      storage cluster public network. It is recommended to run a &ceph; storage
      cluster with two networks: a public network and a cluster network. To
      support two networks, each Ceph node must have more than one NIC.
    </para>
  </note>
  <para>
    <emphasis>Network mode</emphasis>. What mode to choose for a PoC deployment depends on the High Availability (HA) requirements. The team network mode is required for an HA setup of &cloud;.
  </para>
<sect2 xml:id="sec-depl-poc-vlans">
  <title>Network Architecture: Pre-Defined VLANs</title>
  <para>
    VLAN support for the administrator network must be handled at the switch level. The following networks are predefined when setting up &cloud;. The listed default IP addresses can be changed using the YaST Crowbar module. It is also possible to customize the network setup.
  </para>
  <note>
    <title>Limitations of the Default Network Proposal</title>
    <para>
      The default network proposal described below allows maximum 80 Compute Nodes, 61 floating IP addresses, and 204 addresses in the nova_fixed network. To overcome these limitations, you need to reconfigure the network setup by using appropriate address ranges manually.
    </para>
  </note>

  <figure>
    <title>Network Architecture</title>
    <mediaobject>
      <imageobject role="fo">
        <imagedata fileref="depl_network_arch.png" width="100%" format="png"/>
</imageobject>
<imageobject role="html">
  <imagedata fileref="depl_network_arch.png" width="100%" format="png"/>
 </imageobject>
</mediaobject></figure>

  <variablelist>
    <varlistentry>
      <term>
        Administrator Network (192.168.124/24)
      </term>
      <listitem>
        <para>
          A private network to access the Administration Server and all nodes for administration purposes. The default setup lets you also access the Baseboard Management Controller (BMC) data via Intelligent Platform Management Interface (IPMI) from this network. If required, BMC access can be swapped to a separate network.
        </para>
        <para>
          You have the following options for controlling access to this network:
        </para>
        <itemizedlist>
          <listitem>
            <para>
              Do not allow access from the outside and keep the administrator network completely separated
            </para>
          </listitem>
          <listitem>
            <para>
              Allow access to the administration server from a single network (for example, your company's administration network) via the “bastion network” option configured on an additional network card with a fixed IP address
            </para>
          </listitem>
          <listitem>
            <para>
              Allow access from one or more networks via a gateway
            </para>
          </listitem>
        </itemizedlist>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>
        Storage Network (192.168.125/24)
      </term>
      <listitem>
        <para>
          Private &cloud; internal virtual network. This network is used by Ceph and Swift only. It should not be accessed by users.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>
        Private Network (nova-fixed, 192.168.123/24)
      </term>
      <listitem>
        <para>
          Private &cloud; internal virtual network. This network is used for communication between instances and provides them with access to the outside world. &cloud; automatically provides the required gateway.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>
        Public Network (nova-floating, public, 192.168.126/24)
      </term>
      <listitem>
        <para>
          The only public network provided by &cloud;. On this network, you can access the Nova Dashboard and all instances (provided they are equipped with a floating IP). This network can only be accessed via a gateway that needs to be provided
externally. All &cloud; users and administrators need to be able to access the public network.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>
        Software Defined Network (os_sdn, 192.168.130/24)
      </term>
      <listitem>
        <para>
          Private &cloud; internal virtual network. This network is used when Neutron is configured to use <systemitem>openvswitch</systemitem> with GRE tunneling for the virtual networks. It should not be accessed by users.
        </para>

        <para>
          &cloud; supports different network modes: single, dual, and team. Starting with &cloud; 6, the networking mode is applied to all nodes and the Administration Server. This means that all machines need to meet the hardware requirements for the chosen mode. The network mode can be configured using the YaST Crowbar module (see <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/book_cloud_deploy/data/sec_depl_adm_inst_crowbar.html"/>). The network mode cannot be changed after the cloud is deployed.
        </para>
        <para>
          More flexible network mode setups can be configured by editing the Crowbar
          network configuration files (see <link xlink:href="https://www.suse.com/documentation/suse-openstack-cloud-6/book_cloud_deploy/data/app_deploy_network_json.html"/> for more information). SUSE or a partner can assist you in creating a custom setup within the scope of a consulting services agreement.
          For more information on &suse; consulting, visit <link xlink:href="http://www.suse.com/consulting/"/>.
        </para>
      </listitem>
    </varlistentry>
  </variablelist>
  <important>
    <title>Team Network Mode Is Required for HA</title>
    <para>
      Team network mode is required for an HA setup of &cloud;. If you are
      planning to move your cloud to an HA setup later, deploy &cloud; with
      team network mode right from the beginning. Migration to an HA setup is not supported.
    </para>
  </important>
</sect2>
</sect1>
<sect1 xml:id="sec-depl-poc-services">
  <title>Services Architecture</title>
  <para>
    &cloud; is based on &cloudos;, OpenStack, Crowbar and Chef. &sls; is used as the underlying operating system for all infrastructure nodes. Crowbar and Chef are used to automatically deploy and manage the OpenStack nodes from a central Administration Server.
  </para>
  <figure>
    <title>Services Architecture</title>
    <mediaobject>
      <imageobject role="fo">
        <imagedata fileref="depl_poc_services_architecture.png" width="75%" format="png"/>
</imageobject>
<imageobject role="html">
  <imagedata fileref="depl_poc_services_architecture.png" width="75%" format="png"/>
 </imageobject>
</mediaobject></figure>

</sect1>
<sect1 xml:id="sec-depl-poc-testcases">
  <title>Proof of Concept Test Cases</title>
  <para>
    After you have successfully deployed OpenStack, you need to test the environment by using either the Dashboard or the command line interface. This document provides the most important procedures and steps to perform functional tests agreed upon. A detailed list of test case should be provided with this document.
  </para>
  <note>
    <title>About Test Cases</title>
    <para>
      All test cases are work in progress and by no means complete. Test cases
      have to be formulated by the entire team according to the requirements and type of workloads.
    </para>
    </note>
<sect2 xml:id="sec-depl-poc-testbasic">
  <title>Basic Test Cases</title>
  <para>
    Add your own test cases here.
  </para>
</sect2>
<sect2 xml:id="sec-depl-poc-testadvanced">
  <title>Advanced Test Cases</title>
  <para>
    Add your own test cases here.
  </para>
 </sect2>
</sect1>
</chapter>
