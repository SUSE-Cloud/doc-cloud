<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="recover_downed_cluster">
 <title>Restarting Controller Nodes After a Reboot</title>
 <para>
  Steps to follow if one or more of your controller nodes lose network
  connectivity or power, which includes if the node is either rebooted or needs
  hardware maintenance.
 </para>
<!-- Comment from DITA original: -->
<!-- WHEN, WHY? -->
 <para>
  When a controller node is rebooted, needs hardware maintenance, loses
  network connectivity or loses power, these steps will help you recover the
  node.
 </para>
 <para>
  These steps may also be used if the Host Status (ping) alarm is triggered
  for one or more of your controller nodes. Here is what the alarm looks like
  in the Operations Console:
 </para>
<!-- Comment from DITA original: -->
<!-- HOW, WHO, WHERE -->
 <section xml:id="idg-all-operations-maintenance-controller-restart_controller-xml-7">
  <title>Prerequisites</title>
  <para>
   The following conditions must be true in order to perform these steps
   successfully:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     Each of your controller nodes should be powered on.
    </para>
   </listitem>
   <listitem>
    <para>
     Each of your controller nodes should have network connectivity, verified
     by SSH connectivity from the &lcm; to them.
    </para>
   </listitem>
   <listitem>
    <para>
     The operator who performs these steps will need access to the lifecycle
     manager.
    </para>
   </listitem>
  </itemizedlist>
 </section>
 <section xml:id="mysql">
  <title>Recovering the &mariadb; Database</title>
  <para>
   The recovery process for your &mariadb; database cluster will depend on how
   many of your controller nodes need to be recovered. We will cover two
   scenarios, detailed below:
  </para>
  <para>
   <emphasis role="bold">If you need to recover one or two of your controller
   nodes but not the entire cluster</emphasis>
  </para>
  <para>
   If you need to recover one or two of your controller nodes but not the
   entire cluster, then use these steps:
  </para>
  <orderedlist>
   <listitem>
    <para>
     Ensure the controller nodes have power and are booted to the command
     prompt.
    </para>
   </listitem>
   <listitem>
    <para>
     If the &mariadb; service is not started, start it with this command:
    </para>
<screen>sudo service mariadb start</screen>
   </listitem>
   <listitem>
    <para>
     If &mariadb; fails to start using the above command then look in the section
     below for the bootstrap process which should resolve the issue.
    </para>
   </listitem>
  </orderedlist>
  <para>
   <emphasis role="bold">If you need to recover the whole controller cluster
   or the steps above failed in a one or two controller node
   scenario</emphasis>
  </para>
  <para>
   If you need to recover your entire control plane cluster or if the scenario
   above failed for your one or two controller node issue then use the
   bootstrap command described below to recover the &mariadb; database.
  </para>
  <para>
   The node that you perform these steps on should be the last node to go
   down. So if only one of your controller nodes went down, then you would
   skip to step #2 and run the bootstrap commands on that node. If multiple
   controller nodes went down then you should use the instructions in step #1
   to determine which was the last node to go down and then proceed to run the
   rest of the steps on that node.
  </para>
  <orderedlist>
   <listitem>
    <para>
     Make sure there is no <literal>mysqld</literal> daemon running on any node
     in the cluster before you continue with the steps in this procedure. If
     there is a <literal>mysqld</literal> daemon running then use the command
     below to shutdown the daemon.
    </para>
<screen>sudo service mariadb stop</screen>
    <para>
     If the daemon does not go down following the service stop, then kill the
     daemon using <literal>kill -9</literal> before continuing.
    </para>
   </listitem>
   <listitem>
    <para>
     SSH into each controller node that went down and use the commands below to
     get the log sequence number:
    </para>
<screen>sudo /usr/bin/mysqld_safe --wsrep-recover
sudo grep --text 'Recovered position' /var/log/mysql/error.log| tail -1</screen>
    <para>
     The following example highlights the log sequence numbers from a
     three-controller node cluster:
    </para>
    <important>
     <para>
      In this example, two nodes have the same sequence number which means you
      can run the bootstrap on either node but you can only run the bootstrap
      command once and only on one node.
     </para>
    </important>
<screen>stack@ardana-cp-c1-m1-mgmt:~$ sudo /usr/bin/mysqld_safe --wsrep-recover
stack@ardana-cp-c1-m1-mgmt:~$ sudo grep --text 'Recovered position' /var/log/mysql/error.log| tail -1
151119 14:37:12 32123 [Note] WSREP: Recovered position: a0cd6b29-f027-11e5-b9e3-fb0ed503c0ac:<emphasis role="bold">165002105</emphasis>

stack@ardana-cp-c1-m2-mgmt:~$ sudo /usr/bin/mysqld_safe --wsrep-recover
stack@ardana-cp-c1-m2-mgmt:~$ sudo grep --text 'Recovered position' /var/log/mysql/error.log| tail -1
151119 14:37:1214:37:52 32336 [Note] WSREP: Recovered position: a0cd6b29-f027-11e5-b9e3-fb0ed503c0ac:<emphasis role="bold">165252407</emphasis>

stack@ardana-cp-c1-m3-mgmt:~$  sudo /usr/bin/mysqld_safe --wsrep-recover
stack@ardana-cp-c1-m3-mgmt:~$ sudo grep --text 'Recovered position' /var/log/mysql/error.log| tail -1
151119 14:37:1214:37:52 32332 [Note] WSREP: Recovered position: a0cd6b29-f027-11e5-b9e3-fb0ed503c0ac:<emphasis role="bold">165252407</emphasis></screen>
   </listitem>
   <listitem>
    <para>
     If the node with the highest log sequence number is a shared lifecycle
     manager/controller node then run this playbook from the &lcm;:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts galera-bootstrap.yml</screen>
    <para>
     If the node with the highest log sequence number is a standalone
     controller node then SSH into the node and bootstrap the cluster with this
     command:
    </para>
<screen>sudo /etc/init.d/mariadb bootstrap-pxc</screen>
   </listitem>
   <listitem>
    <para>
     Log back into the &lcm; and run this playbook to start &mariadb;
     back up:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts percona-start.yml</screen>
   </listitem>
   <listitem>
    <para>
     Wait for a few minutes for the services to be fully up and synced.
    </para>
   </listitem>
  </orderedlist>
 </section>
 <section xml:id="cassandra">
  <title>Recovering the Cassandra Database</title>
  <para>
   To recover your Cassandra databases, run the following playbook:
  </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts monasca-cassandra-recovery.yml</screen>
  <para>
   or if you have encryption enabled, use:
  </para>
<screen>ansible-playbook -i hosts/verb_hosts monasca-cassandra-recovery.yml --ask-vault-pass</screen>
 </section>
 <section xml:id="hlm">
  <title>Restarting Services on the Controller Nodes</title>
  <para>
   From the &lcm; you should execute the
   <literal>ardana-start.yml</literal> playbook for each node that was brought
   down so the services can be started back up.
  </para>
  <para>
   If you have a dedicated (separate) &lcm; node you can use this
   syntax:
  </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ardana-start.yml --limit=&lt;hostname_of_node&gt;</screen>
  <para>
   If you have a shared &lcm;/controller setup and need to restart
   services on this shared node, you can use <literal>localhost</literal> to
   indicate the shared node, like this:
  </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ardana-start.yml --limit=&lt;hostname_of_node&gt;,localhost</screen>
  <note>
   <para>
    If you leave off the <literal>--limit</literal> switch, the playbook will
    be run against all nodes.
   </para>
  </note>
 </section>
 <section xml:id="monasca">
  <title>Restart the Monitoring Agents</title>
  <para>
   As part of the recovery process, you should also restart the
   <literal>monasca-agent</literal> and these steps will show you how:
  </para>
  <orderedlist>
   <listitem>
    <para>
     Log in to the &lcm;.
    </para>
   </listitem>
   <listitem>
    <para>
     Stop the <literal>monasca-agent</literal>:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts monasca-agent-stop.yml</screen>
   </listitem>
   <listitem>
    <para>
     Restart the <literal>monasca-agent</literal>:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts monasca-agent-start.yml</screen>
   </listitem>
   <listitem>
    <para>
     You can then confirm the status of the <literal>monasca-agent</literal>
     with this playbook:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts monasca-agent-status.yml</screen>
   </listitem>
  </orderedlist>
 </section>
</section>
