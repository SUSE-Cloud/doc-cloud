<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xml:id="ses.integration"
 xmlns="http://docbook.org/ns/docbook" version="5.1"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>&ses; Integration</title>
 <para>
  The current version of &productname; supports integration with &ses;
  (SES). Integrating &ses; enables &ceph; block storage as well as object and
  image storage services in &productname;.
 </para>
  <section xml:id="ses.installation">
  <title>Enabling &ses; Integration</title>
  <para>
   The &ses; integration is provided through the <package>ardana-ses</package>
   RPM package. This package is included in the
   <systemitem>patterns-cloud-ardana</systemitem> pattern, its installation is
   covered in <xref linkend="cha.depl.dep_inst"/>. The update repositories and
   the installation covered there are required to support &ses;
   integration. The latest updates should be applied before proceeding.
  </para>
  </section>
<section xml:id="ses.config">
  <title>Configuration</title>
  <para>
   After the &ses; integration package has been installed, it must be
   configured. Files that contain relevant &ses;/&ceph; deployment information
   must be placed into a directory on the deployer node. This includes the
   configuration file that describes various aspects of the &ceph; environment
   as well as keyrings for each user and pool created in the &ceph;
   environment. In addition to that, you need to edit the
   <filename>settings.yml</filename> file to enable the &ses; integration to
   run and update all of the &productname; service configuration files.
  </para>
  <para>
   The <filename>settings.yml</filename> file must reside in the
   <filename>~/openstack/my_cloud/config/ses/</filename> directory. Open the
   file for editing, uncomment the <literal>ses_config_path:</literal>
   parameter, and specify the location on the deployer host containing the
   <filename>ses_config.yml</filename> and keyring files as the parameter's
   value. After you have done that, the <filename>site.yml</filename> and
   <filename>ardana-reconfigure.yml</filename> playbooks activates the &ses;
   integration and configures the &o_blockstore;, &o_img;, and &o_comp;
   services.
  </para>
  <important>
   <para>
    For security reasons, you should use a unique UUID in the
    <filename>settings.yml</filename> file for
    <literal>ses_secret_id</literal>, replacing the fixed, hard-coded UUID in
    that file. You can generate a UUID that will be unique to your deployment
    using the command <command>uuidgen</command>.
   </para>
  </important>
  <para>
   For SES deployments that have version 5.5 and higher, there is a Salt runner
   that can create all the users and pools. It will also generate a yaml
   configuration that is needed to integrate with &cloud;. The integration
   runner will create separate users for &o_blockstore;, &o_blockstore; backup,
   and &o_img;. Both the &o_blockstore; and &o_comp; services will have the same
   user, as &o_blockstore; needs access to create objects that &o_comp; uses.
  </para>
  <para>
   Login in as root to run the SES 5.5 Salt runner on the salt admin host.
  </para>
  <screen>&prompt.root;salt-run --out=yaml openstack.integrate prefix=<replaceable>mycloud</replaceable></screen>
  <para>
   The prefix parameter allows pools to be created with the specified
   prefix. In this way, multiple cloud deployments can use different users and
   pools on the same SES deployment.
  </para>
  <para>
   The sample yaml output:
  </para>
   <screen>ceph_conf:
 cluster_network: 10.84.56.0/21
 fsid: d5d7c7cb-5858-3218-a36f-d028df7b0673
 mon_host: 10.84.56.8, 10.84.56.9, 10.84.56.7
 mon_initial_members: ses-osd1, ses-osd2, ses-osd3
 public_network: 10.84.56.0/21
 cinder:
 key: AQCdfIRaxefEMxAAW4zp2My/5HjoST2Y8mJg8A==
 rbd_store_pool: mycloud-cinder
 rbd_store_user: cinder
 cinder-backup:
 key: AQBb8hdbrY2bNRAAqJC2ZzR5Q4yrionh7V5PkQ==
 rbd_store_pool: mycloud-backups
 rbd_store_user: cinder-backup
 glance:
 key: AQD9eYRachg1NxAAiT6Hw/xYDA1vwSWLItLpgA==
 rbd_store_pool: mycloud-glance
 rbd_store_user: glance
 nova:
 rbd_store_pool: mycloud-nova
 radosgw_urls:
     - http://10.84.56.7:80/swift/v1
     - http://10.84.56.8:80/swift/v1 </screen>
  <para>
   After you have run the <literal>openstack.integrate</literal> runner, copy
   the yaml into the <filename>ses_config.yml</filename> file on the deployer
   node. Then edit the <filename>settings.yml</filename> file to enable &ses;
   integration to run and update all of the &cloud; service configuration
   files. The <filename>settings.yml</filename> file resides in the
   <filename>~/openstack/my_cloud/config/ses</filename> directory. Open the
   <filename>settings.yml</filename> file for editing, uncomment the
   <literal>ses_config_path:</literal> parameter, and specify the location on
   the deployer host containing the <filename>ses_config.yml</filename> file.
  </para>
   <procedure>
    <step>
     <para>
      Commit your configuration to your local git repo.
     </para>
     <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;git add -A
&prompt.ardana;git commit -m "add SES integration"</screen>
    </step>
    <step>
     <para>
      Run the configuration processor.
     </para>
     <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
    </step>
    <step>
     <para>
      Create a deployment directory.
     </para>
     <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
    </step>
    <step>
     <para>
      Run a series of reconfiguration playbooks.
     </para>
     <screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ses-deploy.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts cinder-reconfigure.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts glance-reconfigure.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts nova-reconfigure.yml</screen>
    </step>
    <step>
     <para>
      Reconfigure the &lcm; to complete the deployment.
     </para>
     <screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-reconfigure.yml</screen>
    </step>
   </procedure>
  <para>
   In the <filename>control_plane.yml</filename> file, the &o_img;
   <literal>default_store</literal> option must be adjusted.
  </para>
  <screen>- glance-api:
            glance_default_store: 'rbd'</screen>
  <para>
   For &ceph;, it is necessary to create pools and users to allow the
   &productname; services to use the &ses;/&ceph; cluster. Pools and users must
   be created for &o_blockstore;, &o_blockstore; backup, &o_comp; and
   &o_img;. Instructions for creating and managing pools, users and keyrings is
   covered in the &ses; documentation under <link
   xlink:href="https://www.suse.com/documentation/suse-enterprise-storage-5/book_storage_admin/data/storage_cephx_keymgmt.html">Key
   Management</link>.
   </para>
   <para>
    After the required pools and users are set up on the &ses;/&ceph;
    cluster, you have to create a <filename>ses_config.yml</filename>
    configuration file (see the example below). This file is used during
    deployment to configure all of the services. The
    <filename>ses_config.yml</filename> and the keyring files should be placed
    in a separate directory.
   </para>
   <para>
    If you are integrating with &ses; do not want &o_comp; to store images in
    &ceph;, the following setting is required:
   </para>
   <para>
    Edit <filename>ses_config.yml</filename> and change the line
    <literal>ses_nova_set_images_type: True</literal>
    to <literal>ses_nova_set_images_type: False</literal>
   </para>
   <example>
    <title>ses_config.yml Example</title>
<screen>ses_cluster_configuration:
    ses_cluster_name: ceph
    ses_radosgw_url: "https://192.168.56.8:8080/swift/v1"

    conf_options:
        ses_fsid: d5d7c7cb-5858-3218-a36f-d028df7b1111
        ses_mon_initial_members: ses-osd2, ses-osd3, ses-osd1
        ses_mon_host: 192.168.56.8, 192.168.56.9, 192.168.56.7
        ses_public_network: 192.168.56.0/21
        ses_cluster_network: 192.168.56.0/21

    cinder:
        rbd_store_pool: cinder
        rbd_store_pool_user: cinder
        keyring_file_name: ceph.client.cinder.keyring

    cinder-backup:
        rbd_store_pool: backups
        rbd_store_pool_user: cinder_backup
        keyring_file_name: ceph.client.cinder-backup.keyring

    # Nova uses the cinder user to access the nova pool, cinder pool
    # So all we need here is the nova pool name.
    nova:
        rbd_store_pool: nova

    glance:
        rbd_store_pool: glance
        rbd_store_pool_user: glance
        keyring_file_name: ceph.client.glance.keyring</screen>
   </example>
   <para>
     The path to this directory must be specified in the
     <filename>settings.yml</filename> file, as in the example below. After
     making the changes, follow the steps to complete the configuration.
   </para>
   <screen>settings.yml
...
ses_config_path: /var/lib/ardana/ses/
ses_config_file: ses_config.yml

# The unique uuid for use with virsh for cinder and nova
 ses_secret_id: <replaceable>SES_SECRET_ID</replaceable></screen>
   <procedure>
    <step>
     <para>
      After modifying these files, commit your configuration to the local git
    repo. For more information, see <xref linkend="using_git"/>.
   </para>
   <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;git add -A
&prompt.ardana;git commit -m "configure SES 5"</screen>
    </step>
    <step>
     <para>
      Run the configuration processor
     </para>
     <screen>&prompt.ardana;ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
    </step>
    <step>
     <para>
      Create a deployment directory
     </para>
     <screen>&prompt.ardana;ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
    </step>
    <step>
     <para>
      Reconfigure Ardana
     </para>
     <screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-reconfigure.yml</screen>
    </step>
   </procedure>
   <para>
    <emphasis role="bold">Configuring &ses; for Integration with &rados; Gateway</emphasis>
   </para>
   <para>
    &rados; gateway integration can be enabled (disabled) by adding (removing)
    the following line in the <filename>ses_config.yml</filename>:
   </para>
   <screen>ses_radosgw_url: "https://192.168.56.8:8080/swift/v1"</screen>
   <para>
    If &rados; gateway integration is enabled, additional &ses; configuration is
    needed. &rados; gateway must be configured to use &o_ident; for
    authentication. This is done by adding the configuration statements below
    to the rados section of <filename>ceph.conf</filename> on the &rados; node.
   </para>
   <screen>[client.rgw.<replaceable>HOSTNAME</replaceable>]
rgw frontends = "civetweb port=80+443s"
rgw enable usage log = true
rgw keystone url = <replaceable>KEYSTONE_ENDPOINT</replaceable> (for example:
https://192.168.24.204:5000)
rgw keystone admin user = <replaceable>KEYSTONE_ADMIN_USER</replaceable>
rgw keystone admin password = <replaceable>KEYSTONE_ADMIN_PASSWORD</replaceable>
rgw keystone admin project = <replaceable>KEYSTONE_ADMIN_PROJECT</replaceable>
rgw keystone admin domain = <replaceable>KEYSTONE_ADMIN_DOMAIN</replaceable>
rgw keystone api version = 3
rgw keystone accepted roles = admin,Member,_member_
rgw keystone accepted admin roles = admin
rgw keystone revocation interval = 0
rgw keystone verify ssl = false # If keystone is using self-signed
   certificate</screen>
   <para>
    After making these changes to <filename>ceph.conf</filename>, the &rados;
    gateway service needs to be restarted.
   </para>
   <para>
    Enabling &rados; gateway replaces the existing &objstore; endpoint with the
    &rados; gateway endpoint.
   </para>
   <para>
    <emphasis role="bold">Enabling HTTPS, Creating and Importing a Certificate</emphasis>
   </para>
   <para>
    &ses; integration uses the HTTPS protocol to connect to the &rados;
    gateway. However, with &ses; 5, HTTPS is not enabled by default. To enable the
    gateway role to communicate securely using SSL, you need to either have a
    CA-issued certificate or create a self-signed one. Instructions for both
    are available in the <link
    xlink:href="https://www.suse.com/documentation/suse-enterprise-storage-5/book_storage_admin/data/ceph_rgw_access.html">&ses;
    documentation</link>.
   </para>
   <para>
    The certificate needs to be installed on your &lcm;. On the &lcm;, copy the
    cert to <filename>/tmp/ardana_tls_cacerts</filename>. Then deploy it.
   </para>
   <screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts tls-trust-deploy.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts tls-reconfigure.yml</screen>
   <para>
    When creating the certificate, the <literal>subjectAltName</literal> must
    match the <literal>ses_radosgw_url</literal> entry in
    <filename>ses_config.yml</filename>. Either an IP address or FQDN can be
    used, but these values must be the same in both places.
   </para>
  </section>
  <section>
   <title>Deploying &ses; Configuration for &rados; Integration</title>
   <para>
    The following steps will deploy your configuration.
   </para>
   <procedure>
    <step>
     <para>
      Commit your configuration to your local git repo.
     </para>
     <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;git add -A
&prompt.ardana;git commit -m "add SES integration"</screen>
    </step>
    <step>
     <para>
      Run the configuration processor.
     </para>
     <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
    </step>
    <step>
     <para>
      Create a deployment directory.
     </para>
     <screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
    </step>
    <step>
     <para>
      Run a series of reconfiguration playbooks.
     </para>
     <screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ses-deploy.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts cinder-reconfigure.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts glance-reconfigure.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts nova-reconfigure.yml</screen>
    </step>
    <step>
     <para>
      Reconfigure the &lcm; to complete the deployment.
     </para>
     <screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-reconfigure.yml</screen>
    </step>
   </procedure>
  </section>
</section>
