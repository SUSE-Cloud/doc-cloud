<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="sec.operation.manage-block-storage">
 <title>Managing Cinder Volume and Backup Services</title>
 <important>
  <title>Use Only When Needed</title>
  <para>
   If the host running the <literal>cinder-volume</literal> service fails for
   any reason, it should be restarted as quickly as possible. Often, the host
   running Cinder services also runs high availability (HA) services such as
   MySQL and RabbitMQ. These HA services are at risk while one of the nodes in
   the cluster is down. If it will take a significant amount of time to recover
   the failed node, then you may migrate the <literal>cinder-volume</literal>
   service to one of the other controller nodes. When the node has been
   recovered you should migrate the <literal>cinder-volume</literal> service
   back to the original (default) node.
  </para>
 </important>
 <section xml:id="idg-all-operations-blockstorage-managing_cinder_volumebackup_services-xml-5">
  <title>Migrating the cinder-volume service</title>
  <para>
   Use the following steps to migrate the cinder-volume service.
  </para>
  <orderedlist>
   <listitem>
    <para>
     Log in to the &clm; node.
    </para>
   </listitem>
   <listitem>
    <para>
     Determine the host index numbers for each of your control plane nodes.
     This host index number will be used in a later step. They can be obtained
     by running this playbook:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts cinder-show-volume-hosts.yml</screen>
    <para>
     Here is an example snippet showing the output of a single three node
     control plane, with the host index numbers in bold:
    </para>
<screen>TASK: [_CND-CMN | show_volume_hosts | Show Cinder Volume hosts index and hostname] ***
ok: [ardana-cp1-c1-m1] =&gt; (item=(0, 'ardana-cp1-c1-m1')) =&gt; {
    "item": [
        <emphasis role="bold">0</emphasis>,
        "ardana-cp1-c1-m1"
    ],
    "msg": "Index 0 Hostname ardana-cp1-c1-m1"
}
ok: [ardana-cp1-c1-m1] =&gt; (item=(1, 'ardana-cp1-c1-m2')) =&gt; {
    "item": [
        <emphasis role="bold">1</emphasis>,
        "ardana-cp1-c1-m2"
    ],
    "msg": "Index 1 Hostname ardana-cp1-c1-m2"
}
ok: [ardana-cp1-c1-m1] =&gt; (item=(2, 'ardana-cp1-c1-m3')) =&gt; {
    "item": [
        <emphasis role="bold">2</emphasis>,
        "ardana-cp1-c1-m3"
    ],
    "msg": "Index 2 Hostname ardana-cp1-c1-m3"
}</screen>
   </listitem>
   <listitem>
    <para>
     Locate the control plane fact file for the control plane you need to
     migrate the service from. It will be located in the following directory:
    </para>
<screen>/etc/ansible/facts.d/</screen>
    <para>
     These fact files use the following naming convention:
    </para>
<screen>cinder_volume_run_location_<emphasis>&lt;control_plane_name&gt;</emphasis>.fact</screen>
   </listitem>
   <listitem>
    <para>
     Edit the fact file to include the host index number of the control plane
     node you wish to migrate the <literal>cinder-volume</literal> services to.
     For example, if they currently reside on your first controller node, host
     index 0, and you wish to migrate them to your second controller, you would
     change the value in the fact file to <literal>1</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     If you are using data encryption on your &clm;, ensure you
     have included the encryption key in your environment variables:
    </para>
<screen>export HOS_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</screen>
   </listitem>
   <listitem>
    <para>
     Once you have edited the control plane fact file, run the Cinder volume
     migration playbook for the control plane nodes involved in the migration.
     This at minimum includes the one to start cinder-volume manager on and the
     one on which to stop it:
    </para>
<screen>cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts cinder-migrate-volume.yml --limit=&lt;limit_pattern1,limit_pattern2&gt;</screen>
    <note>
     <para>
      <emphasis>&lt;limit_pattern&gt;</emphasis> is the pattern used to limit
      the hosts that are selected to those within a specific control plane.
     </para>
    </note>
   </listitem>
   <listitem>
    <para>
     Ensure that once your maintenance or other tasks are completed that you
     migrate the <literal>cinder-volume</literal> services back to their
     original node using these same steps.
    </para>
   </listitem>
  </orderedlist>
 </section>
</section>
