<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xml:id="rhel_compute_model" version="5.1" xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>&rhla; Compute Nodes</title>
 <para>
  Before you install the software required for &rhel; &compnode;s, perform
  the following tasks.
 </para>
 <procedure>
  <step>
   <para>
    Configure the &obs; &centos; software repository on the deployer node and
    on the &rhel; &compnode;s using the following URL:
    <link xlink:href="https://download.opensuse.org/repositories/systemsmanagement:/Ardana:/8:/CentOS/CentOS_7.3"/>.
   </para>
  </step>
  <step>
   <para>
    &ostack; service and its components are installed on &rhel; &compnode;s via
    virtualenv (venv). So you need to install the following venv packages from
    the &obs; &centos; repository on the deployer node:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <package>venv-openstack-nova-rhel-x86_64</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>venv-openstack-neutron-rhel-x86_64</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>venv-openstack-monasca_agent-rhel-x86_64</package>
     </para>
    </listitem>
   </itemizedlist>
   <para>
    On the deployer node, the &obs; &centos; repository needs to be configured
    with lower priority than &sles; repositories. This ensures that packages
    present in both repos are preferably installed from the &cloudos;
    repository.
   </para>
<screen><?dbsuse-fo font-size="0.6em"?>
zypper ar --priority 100 \
  https://download.opensuse.org/repositories/systemsmanagement:/Ardana:/8:/CentOS/CentOS_7.3/systemsmanagement:Ardana:8:CentOS.repo</screen>
   <para>
    Review and accept the certificate for the new repository.
   </para>
<screen>zypper ref</screen>
   <para>
    venv RPM packages can be specifically installed from the &obs; &centos;
    repository:
   </para>
<screen>zypper install --from systemsmanagement_Ardana_8_CentOS \
  venv-openstack-nova-rhel-x86_64</screen>
   <para>
    Run the following command to add the venv packages to package indexes.
   </para>
<screen>/usr/bin/create_index --dir=/opt/ardana_packager/ardana-8/rhel_venv/x86_64</screen>
  </step>
  <step>
   <para>
    On &rhel; &compnode;s, configure the &obs; &centos; repository to download
    specific RPM packages required by cloud tooling, &ostack; &o_comp; and
    &o_netw; &comp; components. The following RPM packages are required from
    the &obs; &centos; repository on the &compnode;:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <package>python-ardana-packager</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>openvswitch</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>python-PyYAML</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>python-Beaver</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>python-monascaclient</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>openstack-freezer-api</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>openstack-freezer-agent</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>openstack-freezer-scheduler</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>python-python-logstash</package>
     </para>
    </listitem>
   </itemizedlist>
  </step>
  <step>
   <para>
    Installing the &ostack-current; release &o_comp; &comp; version requires
    <package>qemu-kvm</package> version 2.1.0 or higher. It is recommended to
    install the required packages via &rhel; subscription to ensure continuous
    updates. Alternatively, these packages can be installed manually from
    <link xlink:href="http://vault.centos.org/7.3.1611/virt/x86_64/"/>. This
    includes the following packages:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <package>qemu-img-ev-2.6.0-28.el7.10.1.x86_64.rpm</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>qemu-kvm-common-ev-2.6.0-28.el7.10.1.x86_64.rpm</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>qemu-kvm-ev-2.6.0-28.el7.10.1.x86_64.rpm</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>qemu-kvm-tools-ev-2.6.0-28.el7.10.1.x86_64.rpm</package>
     </para>
    </listitem>
   </itemizedlist>
  </step>
 </procedure>
 <para>
  Below are alternative configurations for &rhel; &compnode;s:
 </para>
 <variablelist>
  <varlistentry>
   <term><filename>net_interfaces.yml</filename></term>
   <listitem>
<screen>- name: <emphasis role="bold">RHEL-COMPUTE-INTERFACES</emphasis>
 network-interfaces:
   - name: BOND0
     device:
         name: bond0
     bond-data:
         options:
             mode: active-backup
             miimon: 200
             primary: hed1
         provider: linux
         devices:
             - name: hed1
             - name: hed2
     network-groups:
       - EXTERNAL-VM
       - GUEST
       - MANAGEMENT</screen>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term><filename>servers.yml</filename></term>
   <listitem>
<screen>    - id: compute1
      ip-addr: 10.13.111.15
      <emphasis role="bold">role: RHEL-COMPUTE-ROLE</emphasis>
      server-group: RACK1
      nic-mapping: DL360p_G8_2Port
      mac-addr: ec:b1:d7:77:d0:b0
      ilo-ip: 10.12.13.14
      ilo-password: *********
      ilo-user: Administrator
      <emphasis role="bold">distro-id: rhel73-x86_64</emphasis></screen>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term><filename>server_roles.yml</filename></term>
   <listitem>
<screen>- name: <emphasis role="bold">RHEL-COMPUTE-ROLE</emphasis>
  interface-model: <emphasis role="bold">RHEL-COMPUTE-INTERFACES</emphasis>
  disk-model: <emphasis role="bold">RHEL-COMPUTE-DISKS</emphasis></screen>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term><filename>server_roles.yml</filename></term>
   <listitem>
<screen>  - name: <emphasis role="bold">RHEL-COMPUTE-DISKS</emphasis>
    volume-groups:
      - name: ardana-vg
        physical-volumes:
         - /dev/sda_root

        logical-volumes:
        # The policy is not to consume 100% of the space of each volume group.
        # 5% should be left free for snapshots and to allow for some flexibility.
          - name: root
            size: 35%
            fstype: ext4
            mount: /
          - name: log
            size: 50%
            mount: /var/log
            fstype: ext4
            mkfs-opts: -O large_file
          - name: crash
            size: 10%
            mount: /var/crash
            fstype: ext4
            mkfs-opts: -O large_file

      - name: vg-comp
        # this VG is dedicated to Nova Compute to keep VM IOPS off the OS disk
        physical-volumes:
          - /dev/sdb
        logical-volumes:
          - name: compute
            size: 95%
            mount: /var/lib/nova
            fstype: ext4
            mkfs-opts: -O large_file</screen>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term><filename>control_plane.yml</filename></term>
   <listitem>
<screen>  control-planes:
    - name: control-plane-1
      control-plane-prefix: cp1
      region-name: region1
....
      resources:
        - name: <emphasis role="bold">rhel-compute</emphasis>
          resource-prefix: <emphasis role="bold">rhel-comp</emphasis>
          server-role: <emphasis role="bold">RHEL-COMPUTE-ROLE</emphasis>
          allocation-policy: any
          min-count: 1
          service-components:
            - ntp-client
            - nova-compute
            - nova-compute-kvm
            - neutron-l3-agent
            - neutron-metadata-agent
            - neutron-openvswitch-agent
            - neutron-lbaasv2-agent</screen>
   </listitem>
  </varlistentry>
 </variablelist>
</section>
