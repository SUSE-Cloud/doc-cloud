<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="system_alarmdefinitions">
  <title>System Alarms</title>
  <para>These alarms show under the System section and are setup per <literal>hostname</literal>
    and/or <literal>mount_point</literal>.</para>
  <informaltable colsep="1" rowsep="1">
    <tgroup cols="5">
      <colspec colname="c1" colnum="1"/>
      <colspec colname="c2" colnum="2"/>
      <colspec colname="c3" colnum="3"/>
      <colspec colname="c4" colnum="4"/>
      <colspec colname="c5" colnum="5"/>
      <thead>
        <row>
          <entry>Service</entry>
          <entry>Alarm Name</entry>
          <entry>Description</entry>
          <entry>Likely Cause</entry>
          <entry>Mitigation Tasks to Perform</entry>
        </row>
      </thead>
      <tbody>
        <row>
          <entry morerows="11">system</entry>
          <entry>CPU Usage</entry>
          <entry>Alarms on high CPU usage.</entry>
          <entry>Heavy load or runaway processes.</entry>
          <entry>Log onto the reporting host and diagnose the heavy CPU usage.</entry>
        </row>
        <row>
          <entry>Elasticsearch Low Watermark</entry>
          <entry>
            <screen>component = elasticsearch</screen>
            <para>Elasticsearch Disk LOW Watermark. Backup indices. If high watermark is reached,
              indices will be deleted. Adjust curator_low_watermark_percent,
              curator_high_watermark_percent, and elasticsearch_max_total_indices_size_in_bytes if
              needed.</para>
          </entry>
          <entry>Running out of disk space for <literal>/var/lib/elasticsearch</literal>.</entry>
          <entry>
            <para>Free up space by removing indices (backing them up first if desired).
              Alternatively, adjust <literal>curator_low_watermark_percent</literal>,
                <literal>curator_high_watermark_percent</literal>, and/or
                <literal>elasticsearch_max_total_indices_size_in_bytes</literal> if needed.</para>
            <para>For more information about how to back up your centralized logs, see <xref
                linkend="central_log_configure_settings"/>.</para>
          </entry>
        </row>
        <row>
          <entry>Elasticsearch High Watermark</entry>
          <entry>
            <screen>component = elasticsearch</screen>
            <para>Elasticsearch Disk HIGH Watermark. Attempting to delete indices to free disk
              space. Adjust <literal>curator_low_watermark_percent</literal>,
                <literal>curator_high_watermark_percent</literal>, and
                <literal>elasticsearch_max_total_indices_size_in_bytes</literal> if needed.</para>
          </entry>
          <entry>Running out of disk space for <literal>/var/lib/elasticsearch</literal>.</entry>
          <entry>
            <para>Verify that disk space was freed up by the curator. If needed, free up additional
              space by removing indices (backing them up first if desired). Alternatively, adjust
              curator_low_watermark_percent, curator_high_watermark_percent, and/or
              elasticsearch_max_total_indices_size_in_bytes if needed.</para>
            <para>For more information about how to back up your centralized logs, see <xref
                linkend="central_log_configure_settings"/>.</para>
          </entry>
        </row>
        <row>
          <entry>Log Partition Low Watermark</entry>
          <entry>The <literal>/var/log</literal> disk space usage has crossed the low watermark. If
            the high watermark is reached, <literal>logrotate</literal> will be run to free up disk
            space. Adjust <literal>var_log_low_watermark_percent</literal> if needed.</entry>
          <entry>This could be due to a service set to <literal>DEBUG</literal> instead of
              <literal>INFO</literal> level. Another reason could be due to a repeating error
            message filling up the log files. Finally, it could be due to log rotate not configured
            properly so old log files are not being deleted properly.</entry>
          <entry>Find the service that is consuming too much disk space. Look at the logs. If
              <literal>DEBUG</literal> log entries exist, set the logging level to
              <literal>INFO</literal>. If the logs are repeatedly logging an error message, do what
            is needed to resolve the error. If old log files exist, configure log rotate to remove
            them. You could also choose to remove old log files by hand after backing them up if
            needed.</entry>
        </row>
        <row>
          <entry>Log Partition High Watermark</entry>
          <entry>The <literal>/var/log</literal> volume is running low on disk space. Logrotate will
            be run now to free up space. Adjust <literal>var_log_high_watermark_percent</literal> if
            needed.</entry>
          <entry>This could be due to a service set to <literal>DEBUG</literal> instead of
              <literal>INFO</literal> level. Another reason could be due to a repeating error
            message filling up the log files. Finally, it could be due to log rotate not configured
            properly so old log files are not being deleted properly.</entry>
          <entry>Find the service that is consuming too much disk space. Look at the logs. If
              <literal>DEBUG</literal> log entries exist, set the logging level to
              <literal>INFO</literal>. If the logs are repeatedly logging an error message, do what
            is needed to resolve the error. If old log files exist, configure log rotate to remove
            them. You could also choose to remove old log files by hand after backing them up if
            needed.</entry>
        </row>
        <row>
          <entry>Crash Dump Count</entry>
          <entry>Alarms if it receives any metrics with <literal>crash.dump_count</literal> &gt;
            0</entry>
          <entry>When a crash dump is generated by kdump, the crash dump file is put into the
              <literal>/var/crash</literal> directory by default. Any crash dump files in this
            directory will cause the <literal>crash.dump_count</literal> metric to show a value
            greater than 0.</entry>
          <entry>
            <para>Analyze the crash dump file(s) located in <literal>/var/crash</literal> on the
              host that generated the alarm to try to determine if a service or hardware caused the
              crash.</para>
            <para>Move the file to a new location so that a developer can take a look at it. Make
              sure all of the processes are back up after the crash (run the
                <literal>&lt;service&gt;-status.yml</literal> playbooks). When the
                <literal>/var/crash</literal> directory is empty the Crash Dump Count alarm should
              transition back to OK.</para>
          </entry>
        </row>
        <row>
          <entry>Disk Inode Usage</entry>
          <entry>Nearly out of inodes for a partition, as indicated by the
              <literal>mount_point</literal> reported.</entry>
          <entry>Many files on the disk.</entry>
          <entry>Investigate cleanup of data or migration to other partitions.<!----></entry>
        </row>
        <row>
          <entry>Disk Usage</entry>
          <entry>High disk usage, as indicated by the <literal>mount_point</literal>
            reported.</entry>
          <entry>Large files on the disk.</entry>
          <entry>
            <para>Investigate cleanup of data or migration to other partitions. </para>
            <para>If the <literal>mount_point</literal> is <literal>/var/vertica</literal> then see
                <xref linkend="recover_vertica"/> for details on how to resolve.</para>
          </entry>
        </row>
        <row>
          <entry>Host Status</entry>
          <entry>
            <para>Alerts when a host is unreachable.</para>

            <screen>test_type = ping</screen>

          </entry>
          <entry>Host or network is down.</entry>
          <entry>If a single host, attempt to restart the system. If multiple hosts, investigate
            network issues.</entry>
        </row>
        <row>
          <entry>Memory Usage</entry>
          <entry>High memory usage.</entry>
          <entry>Overloaded system or services with memory leaks.</entry>
          <entry>Log onto the reporting host to investigate high memory users.</entry>
        </row>
        <row>
          <entry>Network Errors</entry>
          <entry>Alarms on a high network error rate.</entry>
          <entry>Bad network or cabling.</entry>
          <entry>Take this host out of service until the network can be fixed.</entry>
        </row>
        <row>
          <entry>NTP Time Sync</entry>
          <entry>Alarms when the NTP time offset is high.</entry>
          <entry/>
          <entry>
            <para>Log in to the reported host and check if the ntp service is running. </para>
            <para>If it is running, then use these steps:</para>

            <orderedlist xml:id="ol_hdn_kzp_mx">
              <listitem>
                <para>Stop the service. </para>
                <para>On a Linux for HPE Helion host:</para>
                <screen>service ntp stop</screen>
                <para>On a RHEL host:</para>
                <screen>service ntpd stop</screen>
              </listitem>
              <listitem>
                <para>Resync the nodes time: </para>
                <screen>/usr/sbin/ntpdate -b  &lt;ntp-server&gt;</screen>
              </listitem>
              <listitem>
                <para>Restart the ntp service back up. </para>
                <para>On a Linux for HPE Helion host:</para>
                <screen>service ntp start</screen>
                <para>On a RHEL host:</para>
                <screen>service ntpd start</screen>
              </listitem>
              <listitem>
                <para>Restart rsyslog: </para>
                <screen>service rsyslog restart</screen>
              </listitem>
            </orderedlist>
          </entry>
        </row>
      </tbody>
    </tgroup>
  </informaltable>
</section>
