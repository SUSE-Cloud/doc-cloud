<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entities.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="entry-scale-kvm-esx" version="5.1">
 <title>Single-Region Entry-Scale Cloud with a Mix of KVM and ESX Hypervisors</title>
 <para>
  This example deploys a cloud which mixes KVM and ESX hypervisors.
 </para>
 <variablelist>
  <varlistentry>
   <term>Control Plane</term>
   <listitem>
    <para>
     <emphasis role="bold">Cluster1</emphasis> 3 nodes of type
     <literal>CONTROLLER-ROLE</literal> run the core &ostack; services, such as
     &o_ident;, &o_comp; API, &o_img; API, &o_netw; API, &o_dash;, and &o_orch;
     API.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>&lcm;</term>
   <listitem>
    <para>
     The &lcm; runs on one of the control-plane nodes of type
     <literal>CONTROLLER-ROLE</literal>. The IP address of the node that will
     run the &lcm; needs to be included in the
     <filename>data/servers.yml</filename> file.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>Resource Nodes</term>
   <listitem>
    <itemizedlist>
     <listitem>
      <para>
       Compute:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         <emphasis role="bold">KVM</emphasis> runs &o_comp; Computes and
         associated services. It runs on nodes of role type
         <literal>COMPUTE-ROLE</literal>.
        </para>
       </listitem>
       <listitem>
        <para>
         <emphasis role="bold">ESX</emphasis> provides ESX Compute services. OS
         and software on this node is installed by user.
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </itemizedlist>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>ESX Resource Requirements</term>
   <listitem>
    <orderedlist>
     <listitem>
      <para>
       User needs to supply vSphere server
      </para>
     </listitem>
     <listitem>
      <para>
       User needs to deploy the ovsvapp network resources using the
       <literal>neutron-create-ovsvapp-resources.yml</literal> playbook
      </para>
      <para>
       The following DVS and DVPGs need to be created and configured for each
       cluster in each ESX hypervisor that will host an OvsVapp appliance. The
       settings for each DVS and DVPG are specific to your system and network
       policies. A JSON file example is provided in the documentation, but it
       needs to be edited to match your requirements.
      </para>
      <itemizedlist>
       <listitem>
        <para>
         ESX-CONF (DVS and DVPG) connected to ovsvapp eth0 and compute-proxy
         eth0
        </para>
       </listitem>
       <listitem>
        <para>
         MANAGEMENT (DVS and DVPG) connected to ovsvapp eth1 and compute-proxy
         eth1
        </para>
       </listitem>
       <listitem>
        <para>
         GUEST (DVS and DVPG) connected to ovsvapp eth2
        </para>
       </listitem>
       <listitem>
        <para>
         TRUNK (DVS and DVPG) connected to ovsvapp eth3
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
     <listitem>
      <para>
       User needs to deploy ovsvapp appliance (<literal>OVSVAPP-ROLE</literal>)
       and nova-proxy appliance (<literal>ESX-COMPUTE-ROLE</literal>)
      </para>
     </listitem>
     <listitem>
      <para>
       User needs to add required information related to compute proxy and
       OVSvApp Nodes
      </para>
     </listitem>
    </orderedlist>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>Networking</term>
   <listitem>
    <para>
     This example requires the following networks:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis role="bold">IPMI</emphasis>network connected to the
       lifecycle-manager and the IPMI ports of all nodes, except the ESX
       hypervisors.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Nodes require a pair of bonded NICs which are used by the following
     networks:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis role="bold">External API</emphasis> The network for
       making requests to the cloud.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">External VM</emphasis> The network that
       provides access to VMs via floating IP addresses.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Cloud Management</emphasis> The network
       used for all internal traffic between the cloud services. It is also
       used to install and configure the nodes. The network needs to be on an
       untagged VLAN.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Guest</emphasis> This network carries
       traffic between VMs on private networks within the cloud.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">SES</emphasis> This is the network that
       control-plane and compute-node clients use to talk to the external &ses;.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">TRUNK</emphasis> is the network that is used
       to apply security group rules on tenant traffic. It is managed by the
       cloud admin and is restricted to the vCenter environment.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">ESX-CONF-NET</emphasis> network is used
       only to configure the ESX compute nodes in the cloud. This network
       should be different from the network used with PXE to stand up the cloud
       control-plane.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     This example's set of networks is defined in
     <filename>data/networks.yml</filename>. The file needs to be modified to
     reflect your environment.
    </para>
    <para>
     The example uses the devices <filename>hed3</filename> and
     <filename>hed4</filename> as a bonded network interface for all services.
     The name given to a network interface by the system is configured in the
     file <filename>data/net_interfaces.yml</filename>. That file needs to be
     edited to match your system.
    </para>
   </listitem>
  </varlistentry>
  <varlistentry>
   <term>Local Storage</term>
   <listitem>
    <para>
     All servers should present a single OS disk, protected by a RAID
     controller. This disk needs to be at least 512Â GB in capacity. In addition,
     the example configures additional disk depending on the node's role:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis role="bold">Controllers</emphasis>
       <filename>/dev/sdb</filename> and <filename>/dev/sdc</filename> are
       configured to be used by &swift;
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Compute Servers</emphasis>
       <filename>/dev/sdb</filename> is configured as an additional Volume
       Group to be used for VM storage
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Additional disks can be configured for any of these roles by editing the
     corresponding <filename>data/disks_*.yml</filename> file.
    </para>
   </listitem>
  </varlistentry>
 </variablelist>
</section>
