<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="topic_odg_33x_rt">
 <title>Networking for ESXi Hypervisor (OVSvApp)</title>
<!-- Comment from DITA original: -->
<!--Needs Work; fnf edit on 10/27; some of the explanation below needs clarification-->
 <para>
  To provide the network as a service for tenant VM's hosted on ESXi
  Hypervisor, a service VM named OVSvApp VM is deployed on each ESXi Hypervisor
  within a cluster managed by OpenStack Nova, as shown in the following figure.
 </para>
 <informalfigure>
  <mediaobject>
   <imageobject role="fo">
    <imagedata fileref="media-esx-esx_ovsvapp.png" width="75%"/>
   </imageobject>
   <imageobject role="html">
    <imagedata fileref="media-esx-esx_ovsvapp.png"/>
   </imageobject>
  </mediaobject>
 </informalfigure>
 <para>
  The OVSvApp VM runs &slsa; as a guest operating system, and has Open vSwitch
  2.1.0 or above installed. It also runs an agent called OVSvApp agent, which
  is responsible for dynamically creating the port groups for the tenant VMs
  and manages OVS bridges, which contain the flows related to security groups
  and L2 networking.
 </para>
 <para>
  To facilitate fault tolerance and mitigation of data path loss for tenant
  VMs, run the <emphasis role="bold">neutron-ovsvapp-agent-monitor</emphasis>
  process as part of the <emphasis role="bold">neutron-ovsvapp-agent
  service</emphasis>, responsible for monitoring the Open vSwitch module within
  the OVSvApp VM. It also uses a <literal>nginx</literal> server to provide the
  health status of the Open vSwitch module to the Neutron server for mitigation
  actions. There is a mechanism to keep the
  <emphasis role="bold">neutron-ovsvapp-agent service</emphasis> alive through
  a <literal>systemd</literal> script.
 </para>
 <para>
  When a OVSvApp Service VM crashes, an agent monitoring mechanism starts a
  cluster mitigation process. You can mitigate data path traffic loss for VMs
  on the failed ESX host in that cluster by putting the failed ESX host in the
  maintenance mode. This, in turn, triggers the vCenter DRS migrates tenant VMs
  to other ESX hosts within the same cluster. This ensures data path continuity
  of tenant VMs traffic.
 </para>
 <para>
  might need to suggest installing some software right here.
 </para>
 <section>
  <title>More Information</title>
  <para>
   For more information on the Networking for ESXi Hypervisor (OVSvApp), see
   the following references:
  </para>
  <itemizedlist xml:id="ul_b2c_n2c_vt">
   <listitem>
    <para>
     VBrownBag session in Vancouver OpenStack Liberty Summit:
    </para>
    <para>
     <link xlink:href="https://www.youtube.com/watch?v=icYA_ixhwsM&amp;feature=youtu.be"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Wiki Link:
    </para>
    <para>
     <link xlink:href="https://wiki.openstack.org/wiki/Neutron/Networking-vSphere"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Codebase:
    </para>
    <para>
     <link xlink:href="https://github.com/openstack/networking-vsphere/"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Whitepaper:
    </para>
    <para>
     <link xlink:href="https://github.com/hp-networking/ovsvapp/blob/master/OVSvApp_Solution.pdf"/>
    </para>
   </listitem>
  </itemizedlist>
 </section>
</section>
