<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.1">
  <title>Configure neutron agents</title>
  <para>Plug-ins typically have requirements for particular software that must
            be run on each node that handles data packets. This includes any node
            that runs nova-compute and nodes that run dedicated OpenStack Networking
            service agents such as <literal>neutron-dhcp-agent</literal>, <literal>neutron-l3-agent</literal>,
            <literal>neutron-metering-agent</literal> or <literal>neutron-lbaasv2-agent</literal>.</para>
  <para>A data-forwarding node typically has a network interface with an IP
            address on the management network and another interface on the data
            network.</para>
  <para>This section shows you how to install and configure a subset of the
            available plug-ins, which might include the installation of switching
            software (for example, <literal>Open vSwitch</literal>) and as agents used to communicate
            with the <literal>neutron-server</literal> process running elsewhere in the data center.</para>
  <section>
    <title>Configure data-forwarding nodes</title>
    <section>
      <title>Node set up: NSX plug-in</title>
      <para>If you use the NSX plug-in, you must also install Open vSwitch on each
                    data-forwarding node. However, you do not need to install an additional
                    agent on each node.</para>
      <warning>
        <para>It is critical that you run an Open vSwitch version that is
              compatible with the current version of the NSX Controller software.
              We recommend using the Open vSwitch version that is provided on
              the VMware support portal for your NSX Controller version.</para>
      </warning>
      <para>
        <emphasis role="bold">To set up each node for the NSX plug-in</emphasis>
      </para>
      <procedure>
        <step>
          <para>Ensure that each data-forwarding node has an IP address on the
                            management network, and an IP address on the data network that is used
                            for tunneling data traffic. For full details on configuring your
                            forwarding node, see the <link xlink:href="https://pubs.vmware.com/NSX-62/index.jsp#com.vmware.nsx.admin.doc/GUID-B5C70003-8194-4EC3-AB36-54C848508818.html">NSX Administration Guide</link>.</para>
        </step>
        <step>
          <para>Use the NSX Administrator Guide to add the node as a Hypervisor
                            by using the NSX Manager GUI. Even if your forwarding node has no
                            VMs and is only used for services agents like <literal>neutron-dhcp-agent</literal>
                            or <literal>neutron-lbaas-agent</literal>, it should still be added to NSX as a
                            Hypervisor.</para>
        </step>
        <step>
          <para>After following the NSX Administrator Guide, use the page for this
                            Hypervisor in the NSX Manager GUI to confirm that the node is properly
                            connected to the NSX Controller Cluster and that the NSX Controller
                            Cluster can see the <literal>br-int</literal> integration bridge.</para>
        </step>
      </procedure>
    </section>
  </section>
  <section>
    <title>Configure DHCP agent</title>
    <para>The DHCP service agent is compatible with all existing plug-ins and is
                required for all deployments where VMs should automatically receive IP
                addresses through DHCP.</para>
    <para>
      <emphasis role="bold">To install and configure the DHCP agent</emphasis>
    </para>
    <procedure>
      <step>
        <para>You must configure the host running the neutron-dhcp-agent as a data
                        forwarding node according to the requirements for your plug-in.</para>
      </step>
      <step>
        <para>Install the DHCP agent:</para>
        <screen language="console"># apt-get install neutron-dhcp-agent</screen>
      </step>
      <step>
        <para>Update any options in the <literal>/etc/neutron/dhcp_agent.ini</literal> file
                        that depend on the plug-in in use. See the sub-sections.</para>
        <important>
          <para>If you reboot a node that runs the DHCP agent, you must run the
                            <command>neutron-ovs-cleanup</command> command before the <literal>neutron-dhcp-agent</literal>
                            service starts.</para>
          <para>On SUSE based systems, the <literal>neutron-ovs-cleanup</literal> service runs
                the <command>neutron-ovs-cleanup</command> command automatically.</para>
        </important>
      </step>
    </procedure>
    <para>Networking dhcp-agent can use
                <link xlink:href="http://www.thekelleys.org.uk/dnsmasq/doc.html">dnsmasq</link> driver which
                supports stateful and stateless DHCPv6 for subnets created with
                <literal>--ipv6_address_mode</literal> set to <literal>dhcpv6-stateful</literal> or
                <literal>dhcpv6-stateless</literal>.</para>
    <para>For example:</para>
    <screen language="console">$ openstack subnet create --ip-version 6 --ipv6-ra-mode dhcpv6-stateful \
  --ipv6-address-mode dhcpv6-stateful --network NETWORK --subnet-range \
  CIDR SUBNET_NAME</screen>
    <screen language="console">$ openstack subnet create --ip-version 6 --ipv6-ra-mode dhcpv6-stateless \
  --ipv6-address-mode dhcpv6-stateless --network NETWORK --subnet-range \
  CIDR SUBNET_NAME</screen>
    <para>If no dnsmasq process for subnet’s network is launched, Networking will
                launch a new one on subnet’s dhcp port in <literal>qdhcp-XXX</literal> namespace. If
                previous dnsmasq process is already launched, restart dnsmasq with a new
                configuration.</para>
    <para>Networking will update dnsmasq process and restart it when subnet gets
                updated.</para>
    <note>
      <para>For dhcp-agent to operate in IPv6 mode use at least dnsmasq v2.63.</para>
    </note>
    <para>After a certain, configured timeframe, networks uncouple from DHCP
                agents when the agents are no longer in use. You can configure the DHCP
                agent to automatically detach from a network when the agent is out of
                service, or no longer needed.</para>
    <para>This feature applies to all plug-ins that support DHCP scaling. For more
                information, see the <link xlink:href="https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#dhcp-agent">DHCP agent configuration
                    options</link>
                listed in the OpenStack Configuration Reference.</para>
    <section>
      <title>DHCP agent setup: OVS plug-in</title>
      <para>These DHCP agent options are required in the
                    <literal>/etc/neutron/dhcp_agent.ini</literal> file for the OVS plug-in:</para>
      <screen language="bash">[DEFAULT]
enable_isolated_metadata = True
interface_driver = openvswitch</screen>
    </section>
    <section>
      <title>DHCP agent setup: NSX plug-in</title>
      <para>These DHCP agent options are required in the
                    <literal>/etc/neutron/dhcp_agent.ini</literal> file for the NSX plug-in:</para>
      <screen language="bash">[DEFAULT]
enable_metadata_network = True
enable_isolated_metadata = True
interface_driver = openvswitch</screen>
    </section>
    <section>
      <title>DHCP agent setup: Linux-bridge plug-in</title>
      <para>These DHCP agent options are required in the
                    <literal>/etc/neutron/dhcp_agent.ini</literal> file for the Linux-bridge plug-in:</para>
      <screen language="bash">[DEFAULT]
enabled_isolated_metadata = True
interface_driver = linuxbridge</screen>
    </section>
  </section>
  <section>
    <title>Configure L3 agent</title>
    <para>The OpenStack Networking service has a widely used API extension to
                allow administrators and projects to create routers to interconnect L2
                networks, and floating IPs to make ports on private networks publicly
                accessible.</para>
    <para>Many plug-ins rely on the L3 service agent to implement the L3
                functionality. However, the following plug-ins already have built-in L3
                capabilities:</para>
    <itemizedlist>
      <listitem>
        <para>Big Switch/Floodlight plug-in, which supports both the open source
                        <link xlink:href="http://www.projectfloodlight.org/floodlight/">Floodlight</link>
                        controller and the proprietary Big Switch controller.</para>
        <note>
          <para>Only the proprietary BigSwitch controller implements L3
                            functionality. When using Floodlight as your OpenFlow controller,
                            L3 functionality is not available.</para>
        </note>
      </listitem>
      <listitem>
        <para>IBM SDN-VE plug-in</para>
      </listitem>
      <listitem>
        <para>MidoNet plug-in</para>
      </listitem>
      <listitem>
        <para>NSX plug-in</para>
      </listitem>
      <listitem>
        <para>PLUMgrid plug-in</para>
      </listitem>
    </itemizedlist>
    <warning>
      <para>Do not configure or use <literal>neutron-l3-agent</literal> if you use one of these
                    plug-ins.</para>
    </warning>
    <para>
      <emphasis role="bold">To install the L3 agent for all other plug-ins</emphasis>
    </para>
    <procedure>
      <step>
        <para>Install the <literal>neutron-l3-agent</literal> binary on the network node:</para>
        <screen language="console"># apt-get install neutron-l3-agent</screen>
      </step>
      <step>
        <para>To uplink the node that runs <literal>neutron-l3-agent</literal> to the external network,
                        create a bridge named <literal>br-ex</literal> and attach the NIC for the external
                        network to this bridge.</para>
        <para>For example, with Open vSwitch and NIC eth1 connected to the external
                        network, run:</para>
        <screen language="console"># ovs-vsctl add-br br-ex
# ovs-vsctl add-port br-ex eth1</screen>
        <para>When the <literal>br-ex</literal> port is added to the <literal>eth1</literal> interface, external
                        communication is interrupted. To avoid this, edit the
                        <literal>/etc/network/interfaces</literal> file to contain the following information:</para>
        <screen language="shell">## External bridge
auto br-ex
iface br-ex inet static
address 192.27.117.101
netmask 255.255.240.0
gateway 192.27.127.254
dns-nameservers 8.8.8.8

## External network interface
auto eth1
iface eth1 inet manual
up ifconfig $IFACE 0.0.0.0 up
up ip link set $IFACE promisc on
down ip link set $IFACE promisc off
down ifconfig $IFACE down</screen>
        <note>
          <para>The external bridge configuration address is the external IP address.
                            This address and gateway should be configured in
                            <literal>/etc/network/interfaces</literal>.</para>
        </note>
        <para>After editing the configuration, restart <literal>br-ex</literal>:</para>
        <screen language="console"># ifdown br-ex &amp;&amp; ifup br-ex</screen>
        <para>Do not manually configure an IP address on the NIC connected to the
                        external network for the node running <literal>neutron-l3-agent</literal>. Rather, you
                        must have a range of IP addresses from the external network that can be
                        used by OpenStack Networking for routers that uplink to the external
                        network. This range must be large enough to have an IP address for each
                        router in the deployment, as well as each floating IP.</para>
      </step>
      <step>
        <para>The <literal>neutron-l3-agent</literal> uses the Linux IP stack and iptables to perform L3
                        forwarding and NAT. In order to support multiple routers with
                        potentially overlapping IP addresses, <literal>neutron-l3-agent</literal> defaults to
                        using Linux network namespaces to provide isolated forwarding contexts.
                        As a result, the IP addresses of routers are not visible simply by running
                        the <command>ip addr list</command> or <command>ifconfig</command> command on the node.
                        Similarly, you cannot directly <command>ping</command> fixed IPs.</para>
        <para>To do either of these things, you must run the command within a
                        particular network namespace for the router. The namespace has the name
                        <literal>qrouter-ROUTER_UUID</literal>. These example commands run in the router
                        namespace with UUID 47af3868-0fa8-4447-85f6-1304de32153b:</para>
        <screen language="console"># ip netns exec qrouter-47af3868-0fa8-4447-85f6-1304de32153b ip addr list</screen>
        <screen language="console"># ip netns exec qrouter-47af3868-0fa8-4447-85f6-1304de32153b ping FIXED_IP</screen>
        <important>
          <para>If you reboot a node that runs the L3 agent, you must run the
                            <command>neutron-ovs-cleanup</command> command before the <literal>neutron-l3-agent</literal>
                            service starts.</para>
          <para>On SUSE based systems, the <literal>neutron-ovs-cleanup</literal>
                service runs the <command>neutron-ovs-cleanup</command> command
                automatically.</para>
        </important>
      </step>
    </procedure>
    <para><emphasis role="bold">How routers are assigned to L3 agents</emphasis>
                By default, a router is assigned to the L3 agent with the least number
                of routers (LeastRoutersScheduler). This can be changed by altering the
                <literal>router_scheduler_driver</literal> setting in the configuration file.</para>
  </section>
  <section>
    <title>Configure metering agent</title>
    <para>The Neutron Metering agent resides beside neutron-l3-agent.</para>
    <para>
      <emphasis role="bold">To install the metering agent and configure the node</emphasis>
    </para>
    <procedure>
      <step>
        <para>Install the agent by running:</para>
        <screen language="console"># apt-get install neutron-metering-agent</screen>
      </step>
      <step>
        <para>If you use one of the following plug-ins, you need to configure the
                        metering agent with these lines as well:</para>
        <itemizedlist>
          <listitem>
            <para>An OVS-based plug-in such as OVS, NSX, NEC, BigSwitch/Floodlight:</para>
            <screen language="ini">interface_driver = openvswitch</screen>
          </listitem>
          <listitem>
            <para>A plug-in that uses LinuxBridge:</para>
            <screen language="ini">interface_driver = linuxbridge</screen>
          </listitem>
        </itemizedlist>
      </step>
      <step>
        <para>To use the reference implementation, you must set:</para>
        <screen language="ini">driver = iptables</screen>
      </step>
      <step>
        <para>Set the <literal>service_plugins</literal> option in the <literal>/etc/neutron/neutron.conf</literal>
                        file on the host that runs <literal>neutron-server</literal>:</para>
        <screen language="ini">service_plugins = metering</screen>
        <para>If this option is already defined, add <literal>metering</literal> to the list, using a
                        comma as separator. For example:</para>
        <screen language="ini">service_plugins = router,metering</screen>
      </step>
    </procedure>
  </section>
  <section>
    <title>Configure Load-Balancer-as-a-Service (LBaaS v2)</title>
    <para>For the back end, use either <literal>Octavia</literal> or <literal>HAProxy</literal>.
                This example uses Octavia.</para>
    <para>
      <emphasis role="bold">To configure LBaaS V2</emphasis>
    </para>
    <procedure>
      <step>
        <para>Install Octavia using your distribution’s package manager.</para>
      </step>
      <step>
        <para>Edit the <literal>/etc/neutron/neutron_lbaas.conf</literal> file and change
                        the <literal>service_provider</literal> parameter to enable Octavia:</para>
        <screen language="ini"><?dbsuse-fo font-size="8pt"?>service_provider = LOADBALANCERV2:Octavia:neutron_lbaas.drivers.octavia.driver.OctaviaDriver:default</screen>
      </step>
      <step>
        <para>Edit the <literal>/etc/neutron/neutron.conf</literal> file and add the
                        <literal>service_plugins</literal> parameter to enable the load-balancing plug-in:</para>
        <screen language="ini">service_plugins = neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2</screen>
        <para>If this option is already defined, add the load-balancing plug-in to
                        the list using a comma as a separator. For example:</para>
        <screen language="ini"><?dbsuse-fo font-size="8pt"?>service_plugins = [already defined plugins],neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2</screen>
      </step>
      <step>
        <para>Create the required tables in the database:</para>
        <screen language="console"># neutron-db-manage --subproject neutron-lbaas upgrade head</screen>
      </step>
      <step>
        <para>Restart the <literal>neutron-server</literal> service.</para>
      </step>
      <step>
        <para>Enable load balancing in the Project section of the dashboard.</para>
        <warning>
          <para>Horizon panels are enabled only for LBaaSV1. LBaaSV2 panels are still
                            being developed.</para>
        </warning>
        <para>By default, the <literal>enable_lb</literal> option is <literal>True</literal> in the <literal>local_settings.py</literal>
                        file.</para>
        <screen language="python">OPENSTACK_NEUTRON_NETWORK = {
    'enable_lb': True,
    ...
}</screen>
        <para>Apply the settings by restarting the web server. You can now view the
                        Load Balancer management options in the Project view in the dashboard.</para>
      </step>
    </procedure>
  </section>
  <section>
    <title>Configure Hyper-V L2 agent</title>
    <para>Before you install the OpenStack Networking Hyper-V L2 agent on a
                Hyper-V compute node, ensure the compute node has been configured
                correctly using these
                <link xlink:href="https://docs.openstack.org/ocata/config-reference/compute/hypervisor-hyper-v.html">instructions</link>.</para>
    <para>
      <emphasis role="bold">To install the OpenStack Networking Hyper-V agent and configure the node</emphasis>
    </para>
    <procedure>
      <step>
        <para>Download the OpenStack Networking code from the repository:</para>
        <screen language="console">&gt; cd C:\OpenStack\
&gt; git clone https://git.openstack.org/openstack/neutron</screen>
      </step>
      <step>
        <para>Install the OpenStack Networking Hyper-V Agent:</para>
        <screen language="console">&gt; cd C:\OpenStack\neutron\
&gt; python setup.py install</screen>
      </step>
      <step>
        <para>Copy the <literal>policy.json</literal> file:</para>
        <screen language="console">&gt; xcopy C:\OpenStack\neutron\etc\policy.json C:\etc\</screen>
      </step>
      <step>
        <para>Create the <literal>C:\etc\neutron-hyperv-agent.conf</literal> file and add the proper
                        configuration options and the <link xlink:href="https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#cloudbase-hyper-v-agent-configuration-options">Hyper-V related
                            options</link>. Here is a sample config file:</para>
        <screen language="ini">[DEFAULT]
control_exchange = neutron
policy_file = C:\etc\policy.json
rpc_backend = neutron.openstack.common.rpc.impl_kombu
rabbit_host = IP_ADDRESS
rabbit_port = 5672
rabbit_userid = guest
rabbit_password = &lt;password&gt;
logdir = C:\OpenStack\Log
logfile = neutron-hyperv-agent.log

[AGENT]
polling_interval = 2
physical_network_vswitch_mappings = *:YOUR_BRIDGE_NAME
enable_metrics_collection = true

[SECURITYGROUP]
firewall_driver = hyperv.neutron.security_groups_driver.HyperVSecurityGroupsDriver
enable_security_group = true</screen>
      </step>
      <step>
        <para>Start the OpenStack Networking Hyper-V agent:</para>
        <screen language="console">&gt; C:\Python27\Scripts\neutron-hyperv-agent.exe --config-file
C:\etc\neutron-hyperv-agent.conf</screen>
      </step>
    </procedure>
  </section>
  <section>
    <title>Basic operations on agents</title>
    <para>This table shows examples of Networking commands that enable you to
                complete basic operations on agents.</para>
    <informaltable>
      <tgroup cols="2">
        <colspec colname="c1" colwidth="50.0*"/>
        <colspec colname="c2" colwidth="50.0*"/>
        <thead>
          <row>
            <entry>
              <para>Operation</para>
            </entry>
            <entry>
              <para>Command</para>
            </entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>
              <para>List all available agents.</para>
            </entry>
            <entry>
              <para>
                <literal>$ openstack network agent list</literal>
              </para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Show information of a given agent.</para>
            </entry>
            <entry>
              <para>
                <literal>$ openstack network agent show AGENT_ID</literal>
              </para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Update the admin status and description for a specified agent. The
                                    command can be used to enable and disable agents by using
                                    <literal>--admin-state-up</literal> parameter set to <literal>False</literal> or <literal>True</literal>.</para>
            </entry>
            <entry>
              <para>
                <literal>$ neutron agent-update --admin-state-up False AGENT_ID</literal>
              </para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Delete a given agent. Consider disabling the agent before deletion.</para>
            </entry>
            <entry>
              <para>
                <literal>$ openstack network agent delete AGENT_ID</literal>
              </para>
            </entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>
    <para>
      <emphasis role="bold">Basic operations on Networking agents</emphasis>
    </para>
    <para>See the <link xlink:href="https://docs.openstack.org/cli-reference/neutron.html">OpenStack Command-Line Interface
                    Reference</link>
                for more information on Networking commands.</para>
  </section>
</section>
