<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="telemetry-alarmdefinitions">
 <title>Telemetry Alarms</title>
 <para>
  These alarms show under the Telemetry section of the &productname; &opscon;.
 </para>
 <section>
  <title>SERVICE: TELEMETRY</title>
  <informaltable colsep="1" rowsep="1">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="30*"/>
    <colspec colname="c2" colnum="2" colwidth="70*"/>
    <thead>
     <row>
      <entry>Alarm Information</entry>
      <entry>Mitigation Tasks</entry>
     </row>
    </thead>
    <tbody valign="top">
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the
        <literal>ceilometer-agent-notification</literal> process is not
        running.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process has crashed.
       </para>
      </entry>
      <entry>
       <para>
        Review the logs on the alarming host in the following location for the
        cause:
       </para>
<screen>/var/log/ceilometer/ceilometer-agent-notification-json.log</screen>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Use the Ceilometer start playbook against the affected node:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ceilometer-start.yml \
--limit &lt;hostname&gt;</screen>
        </step>
       </procedure>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the
        <literal>ceilometer-polling</literal> process is not running.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process has crashed.
       </para>
      </entry>
      <entry>
       <para>
        Review the logs on the alarming host in the following location for the
        cause:
       </para>
<screen>/var/log/ceilometer/ceilometer-polling-json.log</screen>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Use the Ceilometer start playbook against the affected node:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ceilometer-start.yml \
--limit &lt;hostname&gt;</screen>
        </step>
       </procedure>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </section>
 <section>
  <title>SERVICE: METERING in Telemetry section</title>
  <informaltable colsep="1" rowsep="1">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="30*"/>
    <colspec colname="c2" colnum="2" colwidth="70*"/>
    <thead>
     <row>
      <entry>Alarm Information</entry>
      <entry>Mitigation Tasks</entry>
     </row>
    </thead>
    <tbody valign="top">
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Service Log Directory Size</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Service log directory
        consuming more disk than its quota.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> This could be due to a
        service set to <literal>DEBUG</literal> instead of
        <literal>INFO</literal> level. Another reason could be due to a
        repeating error message filling up the log files. Finally, it could be
        due to log rotate not configured properly so old log files are not
        being deleted properly.
       </para>
      </entry>
      <entry>Find the service that is consuming too much disk space. Look at
       the logs. If <literal>DEBUG</literal> log entries exist, set the logging
       level to <literal>INFO</literal>. If the logs are repeatedly logging an
       error message, do what is needed to resolve the error. If old log files
       exist, configure log rotate to remove them. You could also choose to
       remove old log files by hand after backing them up if needed.</entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </section>
 <section>
  <title>SERVICE: KAFKA in Telemetry section</title>
  <informaltable colsep="1" rowsep="1">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="30*"/>
    <colspec colname="c2" colnum="2" colwidth="70*"/>
    <thead>
     <row>
      <entry>Alarm Information</entry>
      <entry>Mitigation Tasks</entry>
     </row>
    </thead>
    <tbody valign="top">
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Kafka Persister Metric Consumer Lag</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the Persister
        consumer group is not keeping up with the incoming messages on the
        metric topic.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> There is a slow down in
        the system or heavy load.
       </para>
      </entry>
      <entry>
       <para>
        Verify that all of the monasca-persister services are up with these
        steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;
         </para>
        </step>
        <step>
         <para>
          Verify that all of the <literal>monasca-persister</literal> services
          are up with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-persister</screen>
        </step>
       </procedure>
       <para>
        Look for high load in the various systems. This alert can fire for
        multiple topics or on multiple hosts. Determining which alarms are
        firing can help diagnose likely causes. For example, if the alarm is
        alerting all on one machine it could be the machine. If one topic
        across multiple machines it is likely the consumers of that topic, etc.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Kafka Alarm Transition Consumer Lag</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        consumer group is not keeping up with the incoming messages on the
        alarm state transition topic.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> There is a slow down in
        the system or heavy load.
       </para>
      </entry>
      <entry>
       <para>
        Check that monasca-thresh and monasca-notification are up.
       </para>
       <para>
        Look for high load in the various systems. This alert can fire for
        multiple topics or on multiple hosts. Which alarms are firing can help
        diagnose likely causes. For example:
       </para>
       <itemizedlist>
        <listitem>
         <para>
          If all alarms are on the same machine, the machine could be at fault.
         </para>
        </listitem>
        <listitem>
         <para>
          If one topic is shared across multiple machines, the consumers of
          that topic are likely at fault.
         </para>
        </listitem>
       </itemizedlist>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Kafka Kronos Consumer Lag</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the Kronos
        consumer group is not keeping up with the incoming messages on the
        metric topic.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> There is a slow down in
        the system or heavy load.
       </para>
      </entry>
      <entry>
       <para>
        Look for high load in the various systems. This alert can fire for
        multiple topics or on multiple hosts. Which alarms are firing can help
        diagnose likely causes. For example:
       </para>
       <itemizedlist>
        <listitem>
         <para>
          If all alarms are on the same machine, the machine could be at fault.
         </para>
        </listitem>
        <listitem>
         <para>
          If one topic is shared across multiple machines, the consumers of
          that topic are likely at fault.
         </para>
        </listitem>
       </itemizedlist>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running:
       </para>
       <screen>process_name = kafka.Kafka               </screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Stop the kafka service with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags kafka</screen>
        </step>
        <step>
         <para>
          Start the kafka service back up with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags kafka</screen>
        </step>
       </procedure>
       <para>
        Review the logs in <filename>/var/log/kafka/server.log</filename>
       </para>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </section>
 <section>
  <title>SERVICE: LOGGING in Telemetry section</title>
  <informaltable colsep="1" rowsep="1">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="30*"/>
    <colspec colname="c2" colnum="2" colwidth="70*"/>
    <thead>
     <row>
      <entry>Alarm Information</entry>
      <entry>Mitigation Tasks</entry>
     </row>
    </thead>
    <tbody valign="top">
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Beaver Memory Usage</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Beaver is using more
        memory than expected. This may indicate that it cannot forward messages
        and its queue is filling up. If you continue to see this, see the
        troubleshooting guide.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Overloaded system or
        services with memory leaks.
       </para>
      </entry>
      <entry>Log on to the reporting host to investigate high memory users.</entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Audit Log Partition Low Watermark</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> The
        <literal>/var/audit</literal> disk space usage has crossed low
        watermark. If the high watermark is reached, logrotate will be run to
        free up disk space. If needed, adjust:
       </para>
       <screen>var_audit_low_watermark_percent         </screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> This could be due to a
        service set to DEBUG instead of INFO level. Another reason could be due
        to a repeating error message filling up the log files. Finally, it
        could be due to log rotate not configured properly so old log files are
        not being deleted properly.
       </para>
      </entry>
      <entry>Find the service that is consuming too much disk space. Look at
       the logs. If DEBUG log entries exist, set the logging level to INFO. If
       the logs are repeatedly logging an error message, do what is needed to
       resolve the error. If old log files exist, configure log rotate to
       remove them. You could also choose to remove old log files by hand after
       backing them up if needed.</entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Audit Log Partition High Watermark</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> The
        <literal>/var/audit</literal> volume is running low on disk space.
        Logrotate will be run now to free up space. If needed, adjust:
       </para>
       <screen>var_audit_high_watermark_percent        </screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> This could be due to a
        service set to DEBUG instead of INFO level. Another reason could be due
        to a repeating error message filling up the log files. Finally, it
        could be due to log rotate not configured properly so old log files are
        not being deleted properly.
       </para>
      </entry>
      <entry>Find the service that is consuming too much disk space. Look at
       the logs. If DEBUG log entries exist, set the logging level to INFO. If
       the logs are repeatedly logging an error message, do what is needed to
       resolve the error. If old log files exist, configure log rotate to
       remove them. You could also choose to remove old log files by hand after
       backing them up if needed.</entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: &elasticsearch; Unassigned Shards</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> component =
        elasticsearch; &elasticsearch; unassigned shards count is greater than
        0.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Environment could be
        misconfigured.
       </para>
      </entry>
      <entry>
       <para>
        To find the unassigned shards, run the following command on the &clm;
        from the <filename>~/scratch/ansible/next/ardana/ansible</filename>
        directory:
       </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible -i hosts/verb_hosts LOG-SVR[0] -m shell -a \
"curl localhost:9200/_cat/shards?pretty -s" | grep UNASSIGNED</screen>
       <para>
        This shows which shards are unassigned, like this:
       </para>
<screen>logstash-2015.10.21 4 p UNASSIGNED ... 10.240.75.10 NodeName</screen>
       <para>
        The last column shows the name that &elasticsearch; uses for the node
        that the unassigned shards are on. To find the actual host name, run:
       </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible -i hosts/verb_hosts LOG-SVR[0] -m shell -a \
"curl localhost:9200/_nodes/_all/name?pretty -s"</screen>
       <para>
        When you find the host name, take the following steps:
       </para>
       <procedure>
        <step>
         <para>
          Make sure the node is not out of disk space, and free up space if
          needed.
         </para>
        </step>
        <step>
         <para>
          Restart the node (use caution, as this may affect other services as
          well).
         </para>
        </step>
        <step>
         <para>
          Make sure all versions of &elasticsearch; are the same:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible -i hosts/verb_hosts LOG-SVR -m shell -a \
"curl localhost:9200/_nodes/_local/name?pretty -s" | grep version</screen>
        </step>
        <step>
         <para>
          Contact customer support.
         </para>
        </step>
       </procedure>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: &elasticsearch; Number of Log Entries</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> &elasticsearch; Number of
        Log Entries: <literal>component = elasticsearch;</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> The number of log
        entries may get too large.
       </para>
      </entry>
      <entry>Older versions of Kibana (version 3 and earlier) may hang if the
       number of log entries is too large (for example, above 40,000), and the
       page size would need to be small enough (about 20,000 results), because
       if it is larger (for example, 200,000), it may hang the browser, but
       Kibana 4 should not have this issue.</entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: &elasticsearch; Field Data Evictions</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> &elasticsearch; Field
        Data Evictions count is greater than 0: <literal>component =
        elasticsearch</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Field Data Evictions may
        be found even though it is nowhere near the limit set.
       </para>
      </entry>
      <entry>
       <para>
        The <literal>elasticsearch_indices_fielddata_cache_size</literal> is
        set to <literal>unbounded</literal> by default. If this is set by the
        user to a value that is insufficient, you may need to increase this
        configuration parameter or set it to <literal>unbounded</literal> and
        run a reconfigure using the steps below:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Edit the configuration file below and change the value for
          <literal>elasticsearch_indices_fielddata_cache_size</literal> to your
          desired value:
         </para>
<screen>~/openstack/my_cloud/config/logging/main.yml</screen>
        </step>
        <step>
         <para>
          Commit the changes to git:
         </para>
<screen>&prompt.ardana;git add -A
&prompt.ardana;git commit -a -m "&elasticsearch; fielddata cache size"</screen>
        </step>
        <step>
         <para>
          Run the configuration processor:
         </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost config-processor-run.yml</screen>
        </step>
        <step>
         <para>
          Update your deployment directory:
         </para>
<screen>&prompt.ardana;cd ~/openstack/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/localhost ready-deployment.yml</screen>
        </step>
        <step>
         <para>
          Run the Logging reconfigure playbook to deploy the change:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible/
&prompt.ardana;ansible-playbook -i hosts/verb_hosts kronos-reconfigure.yml</screen>
        </step>
       </procedure>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Service Log Directory Size</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Service log directory
        consuming more disk than its quota.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> This could be due to a
        service set to <literal>DEBUG</literal> instead of
        <literal>INFO</literal> level. Another reason could be due to a
        repeating error message filling up the log files. Finally, it could be
        due to log rotate not configured properly so old log files are not
        being deleted properly.
       </para>
      </entry>
      <entry>Find the service that is consuming too much disk space. Look at
       the logs. If <literal>DEBUG</literal> log entries exist, set the logging
       level to <literal>INFO</literal>. If the logs are repeatedly logging an
       error message, do what is needed to resolve the error. If old log files
       exist, configure log rotate to remove them. You could also choose to
       remove old log files by hand after backing them up if needed.</entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Separate alarms for each
        of these logging services, specified by the
        <literal>process_name</literal> dimension:
       </para>
       <itemizedlist>
        <listitem>
         <para>
          elasticsearch
         </para>
        </listitem>
        <listitem>
         <para>
          logstash
         </para>
        </listitem>
        <listitem>
         <para>
          beaver
         </para>
        </listitem>
        <listitem>
         <para>
          apache2
         </para>
        </listitem>
        <listitem>
         <para>
          kibana
         </para>
        </listitem>
       </itemizedlist>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process has crashed.
       </para>
      </entry>
      <entry>
       <para>
        On the affected node, attempt to restart the process.
       </para>
       <para>
        If the <command>elasticsearch</command> process has crashed, use:
       </para>
<screen>&prompt.ardana;sudo systemctl restart elasticsearch</screen>
       <para>
        If the logstash process has crashed, use:
       </para>
<screen>&prompt.ardana;sudo systemctl restart logstash</screen>
       <para>
        The rest of the processes can be restarted using similar commands,
        listed here:
       </para>
<screen>&prompt.ardana;sudo systemctl restart beaver
&prompt.ardana;sudo systemctl restart apache2
&prompt.ardana;sudo systemctl restart kibana</screen>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </section>
 <section>
  <title>SERVICE: MONASCA-TRANSFORM in Telemetry section</title>
  <informaltable colsep="1" rowsep="1">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="30*"/>
    <colspec colname="c2" colnum="2" colwidth="70*"/>
    <thead>
     <row>
      <entry>Alarm Information</entry>
      <entry>Mitigation Tasks</entry>
     </row>
    </thead>
    <tbody valign="top">
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> <literal>process_name =
        pyspark</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Service process has
        crashed.
       </para>
      </entry>
      <entry>
       <para>
        Restart process on affected node. Review logs.
       </para>
       <para>
        Child process of <literal>spark-worker</literal> but created once the
        <literal>monasca-transform</literal> process begins processing streams.
        If the process fails on one node only, along with the pyspark process,
        it is likely that the <literal>spark-worker</literal> has failed to
        connect to the elected leader of the <literal>spark-master</literal>
        service. In this case the <literal>spark-worker</literal> service
        should be started on the affected node. If on multiple nodes check the
        <literal>spark-worker</literal>, <literal>spark-master</literal> and
        <literal>monasca-transform</literal> services and logs. If the
        <literal>monasca-transform</literal> or <literal>spark</literal>
        services have been interrupted this process may not re-appear for up to
        ten minutes (the stream processing interval).
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis>
       </para>
       <screen>process_name =
org.apache.spark.executor.CoarseGrainedExecutorBackend</screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Service process has
        crashed.
       </para>
      </entry>
      <entry>
       <para>
        Restart process on affected node. Review logs.
       </para>
       <para>
        Child process of <literal>spark-worker</literal> but created once the
        <literal>monasca-transform</literal> process begins processing streams.
        If the process fails on one node only, along with the pyspark process,
        it is likely that the <literal>spark-worker</literal> has failed to
        connect to the elected leader of the <literal>spark-master</literal>
        service. In this case the <literal>spark-worker</literal> service
        should be started on the affected node. If on multiple nodes check the
        <literal>spark-worker</literal>, <literal>spark-master</literal> and
        <literal>monasca-transform</literal> services and logs. If the
        <literal>monasca-transform</literal> or <literal>spark</literal>
        services have been interrupted this process may not re-appear for up to
        ten minutes (the stream processing interval).
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> <literal>process_name =
        monasca-transform</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Service process has
        crashed.
       </para>
      </entry>
      <entry>Restart the service on affected node. Review logs.</entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </section>
 <section>
  <title>SERVICE: MONITORING in Telemetery section</title>
  <informaltable colsep="1" rowsep="1">
   <?dbhtml table-width="99%" ?>
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="30*"/>
    <colspec colname="c2" colnum="2" colwidth="70*"/>
    <thead>
     <row>
      <entry>Alarm Information</entry>
      <entry>Mitigation Tasks</entry>
     </row>
    </thead>
    <tbody valign="top">
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: HTTP Status</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Persister Health Check
        <literal>component = monasca-persister</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> The process has crashed
        or a dependency is out.
       </para>
      </entry>
      <entry>
       <para>
        If the process has crashed, restart it using the steps below. If a
        dependent service is down, address that issue.
       </para>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-api</literal> is running on all nodes with
          this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-persister</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags persister</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-persister</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: HTTP Status</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> API Health Check
        <literal>component = monasca-api</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> The process has crashed
        or a dependency is out.
       </para>
      </entry>
      <entry>
       <para>
        If the process has crashed, restart it using the steps below. If a
        dependent service is down, address that issue.
       </para>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-api</literal> is running on all nodes with
          this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-api</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags monasca-api</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-api</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: &o_monitor; Agent Collection Time</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the elapsed
        time the <literal>monasca-agent</literal> takes to collect metrics is
        high.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Heavy load on the box or
        a stuck agent plug-in.
       </para>
      </entry>
      <entry>
       <para>
        Address the load issue on the machine. If needed, restart the agent
        using the steps below:
       </para>
       <para>
        Restart the agent on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-agent</literal> is running on all nodes
          with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-agent-status.yml</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--limit &lt;hostname&gt;</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-agent-status.yml</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running: <literal>component = kafka</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if Kafka is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags kafka</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags kafka</screen>
        </step>
        <step>
         <para>
          Verify that Kafka is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags kafka</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running:
       </para>
       <screen>process_name = monasca-notification     </screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-api</literal> is running on all nodes with
          this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags notification</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags notification</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags notification</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running: <literal>process_name = monasca-agent</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Restart the agent on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-agent</literal> is running on all nodes
          with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-agent-status.yml</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--limit &lt;hostname&gt;</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-agent-status.yml</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running: <literal>process_name = monasca-api</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        >Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-api</literal> is running on all nodes with
          this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-api</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags monasca-api</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-api</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running: <literal>process_name =
        monasca-persister</literal>
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-api</literal> is running on all nodes with
          this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-persister</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags persister</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags monasca-persister</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running:
       </para>
       <screen>process_name = backtype.storm.daemon.nimbus
component = apache-storm</screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Review the logs in the <filename>/var/log/storm</filename> directory on
        all storm hosts to find the root cause.
       </para>
       <note>
        <para>
         The logs containing threshold engine logging are on the 2nd and 3rd
         controller nodes.
        </para>
       </note>
       <para>
        Restart <literal>monasca-thresh</literal>, if necessary, with these
        steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-thresh</literal> is running on all nodes
          with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags thresh</screen>
        </step>
       </procedure>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running:
       </para>
       <screen>process_name = backtype.storm.daemon.supervisor
component = apache-storm</screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Review the logs in the <literal>/var/log/storm</literal> directory on
        all storm hosts to find the root cause.
       </para>
       <note>
        <para>
         The logs containing threshold engine logging are on the 2nd and 3rd
         controller nodes.
        </para>
       </note>
       <para>
        Restart monasca-thresh with these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Stop the monasca-thresh service:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-stop.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Start the monasca-thresh service back up:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags thresh</screen>
        </step>
       </procedure>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running:
       </para>
       <screen>process_name = backtype.storm.daemon.worker
component = apache-storm</screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Review the logs in the <literal>/var/log/storm</literal> directory on
        all storm hosts to find the root cause.
       </para>
       <note>
        <para>
         The logs containing threshold engine logging are on the 2nd and 3rd
         controller nodes.
        </para>
       </note>
       <para>
        Restart <literal>monasca-thresh</literal> with these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Stop the <literal>monasca-thresh</literal> service:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-stop.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Start the <literal>monasca-thresh</literal> service back up:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags thresh</screen>
        </step>
       </procedure>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Process Check</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Alarms when the specified
        process is not running: <literal></literal>
       </para>
       <screen>process_name = monasca-thresh
component = apache-storm</screen>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> Process crashed.
       </para>
      </entry>
      <entry>
       <para>
        Restart the process on the affected node using these steps:
       </para>
       <procedure>
        <step>
         <para>
          Log in to the &clm;.
         </para>
        </step>
        <step>
         <para>
          Check if <literal>monasca-thresh</literal> is running on all nodes
          with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Use the &o_monitor; start playbook against the affected node to restart
          it:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-start.yml \
--tags thresh</screen>
        </step>
        <step>
         <para>
          Verify that it is running on all nodes with this playbook:
         </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts monasca-status.yml \
--tags thresh</screen>
        </step>
       </procedure>
       <para>
        Review the associated logs.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis role="bold">Name: Service Log Directory Size</emphasis>
       </para>
       <para>
        <emphasis role="bold">Description:</emphasis> Service log directory
        consuming more disk than its quota.
       </para>
       <para>
        <emphasis role="bold">Likely cause:</emphasis> The service log
        directory, as indicated by the <literal>path</literal> dimension, is
        over the 2.5 GB quota.
       </para>
      </entry>
      <entry>Find the service that is consuming too much disk space. Look at
       the logs. If <literal>DEBUG</literal> log entries exist, set the logging
       level to <literal>INFO</literal>. If the logs are repeatedly logging an
       error message, do what is needed to resolve the error. If old log files
       exist, configure log rotate to remove them. You could also choose to
       remove old log files by hand after backing them up if needed.</entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </section>
</section>
