<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<chapter xml:id="magnum-admin-guide" xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.1">
 <title>Magnum Administration Guide</title>
        <section xml:id="installation-operations">
          <title>Installation &amp; Operations</title>
          <para>If you are a system administrator running Magnum, this section contains
                information that should help you understand how to deploy, operate, and upgrade
                the services.</para>
          <section xml:id="using-proxies-in-magnum-if-running-under-firewall" xml:base="magnum-proxy">
            <title>Using Proxies in magnum if running under firewall</title>
            <para>If you are running magnum behind a firewall then you may need a proxy
            for using services like docker, kubernetes and mesos. Use these steps
            when your firewall will not allow you to use those services without a
            proxy.</para>
            <note>
              <para>This feature has only been tested with the supported cluster type
                    and associated image: Kubernetes and Swarm use the Fedora Atomic
                    image, and Mesos uses the Ubuntu image.</para>
            </note>
            <section xml:id="proxy-parameters-to-define-before-use">
              <title>Proxy Parameters to define before use</title>
              <procedure>
                <step>
                  <para><literal>http-proxy</literal></para>
                </step>
              </procedure>
              <para>Address of a proxy that will receive all HTTP requests and relay
                them. The format is a URL including a port number. For example:
                <link xlink:href="http://10.11.12.13:8000"/> or <link xlink:href="http://abcproxy.com:8000"/></para>
              <procedure>
                <step>
                  <para><literal>https-proxy</literal></para>
                </step>
              </procedure>
              <para>Address of a proxy that will receive all HTTPS requests and relay
                them. The format is a URL including a port number. For example:
                <link xlink:href="https://10.11.12.13:8000"/> or <link xlink:href="https://abcproxy.com:8000"/></para>
              <procedure>
                <step>
                  <para><literal>no-proxy</literal></para>
                </step>
              </procedure>
              <para>A comma separated list of IP addresses or hostnames that should bypass
                your proxy, and make connections directly.</para>
              <note>
                <para>You may not express networks or subnets. It only accepts names
                and IP addresses. An example of this would be: 192.168.0.0/28.</para>
              </note>
            </section>
            <section xml:id="steps-to-configure-proxies">
              <title>Steps to configure proxies</title>
              <para>You can specify all three proxy parameters while creating a <literal>ClusterTemplate</literal> of
                any container orchestration engines (COE) type. All of proxy parameters are optional.</para>
              <variablelist>
                <varlistentry>
                  <term>magnum cluster-template-create k8s-cluster-template </term>
                  <listitem>
                    <screen language="bash">–image fedora-atomic-latest –keypair testkey –external-network public –dns-nameserver 8.8.8.8 –flavor m1.small –coe kubernetes –http-proxy &lt;<link xlink:href="http://abc-proxy.com:8080"/>&gt; –https-proxy &lt;<link xlink:href="https://abc-proxy.com:8080"/>&gt; –no-proxy &lt;172.24.4.4,172.24.4.9,172.24.4.8&gt;</screen>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>magnum cluster-template-create swarm-cluster-template </term>
                  <listitem>
                    <screen language="bash">–image fedora-atomic-latest –keypair testkey –external-network public –dns-nameserver 8.8.8.8 –flavor m1.small –coe swarm –http-proxy &lt;<link xlink:href="http://abc-proxy.com:8080"/>&gt; –https-proxy &lt;<link xlink:href="https://abc-proxy.com:8080"/>&gt; –no-proxy &lt;172.24.4.4,172.24.4.9,172.24.4.8&gt;</screen>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>magnum cluster-template-create mesos-cluster-template </term>
                  <listitem>
                    <screen language="bash">–image ubuntu-mesos –keypair testkey –external-network public –dns-nameserver 8.8.8.8 –flavor m1.small –coe mesos –http-proxy &lt;<link xlink:href="http://abc-proxy.com:8080"/>&gt; –https-proxy &lt;<link xlink:href="https://abc-proxy.com:8080"/>&gt; –no-proxy &lt;172.24.4.4,172.24.4.9,172.24.4.8&gt;</screen>
                  </listitem>
                </varlistentry>
              </variablelist>
            </section>
          </section>
          <section xml:id="guru-meditation-reports" xml:base="gmr">
            <title>Guru Meditation Reports</title>
            <para>Magnum contains a mechanism whereby developers and system administrators can
            generate a report about the state of a running Magnum executable. This report
            is called a <emphasis>Guru Meditation Report</emphasis> (<emphasis>GMR</emphasis> for short).</para>
            <section xml:id="generating-a-gmr">
              <title>Generating a GMR</title>
              <para>A <emphasis>GMR</emphasis> can be generated by sending the <emphasis>USR2</emphasis> signal to any Magnum process
                with support (see below). The <emphasis>GMR</emphasis> will then be outputted as standard error
                for that particular process.</para>
              <para>For example, suppose that <literal>magnum-api</literal> has process id <literal>8675</literal>, and was run
                with <literal>2&gt;/var/log/magnum/magnum-api-err.log</literal>. Then, <literal>kill -USR2 8675</literal> will
                trigger the Guru Meditation report to be printed to
                <literal>/var/log/magnum/magnum-api-err.log</literal>.</para>
            </section>
            <section xml:id="structure-of-a-gmr">
              <title>Structure of a GMR</title>
              <para>The <emphasis>GMR</emphasis> is designed to be extensible and any particular executable may add its
                own sections. However, the base <emphasis>GMR</emphasis> consists of several sections:</para>
              <variablelist>
                <varlistentry>
                  <term>Package</term>
                  <listitem>
                    <para>Shows information about the package to which this process belongs, including
                            version information.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Threads</term>
                  <listitem>
                    <para>Shows stack traces and thread ids for each of the threads within this
                            process.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Green Threads</term>
                  <listitem>
                    <para>Shows stack traces for each of the green threads within this process (green
                            threads don’t have thread IDs).</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Configuration</term>
                  <listitem>
                    <para>Lists all the configuration options currently accessible via the CONF object
                            for the current process.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </section>
            <section xml:id="adding-support-for-gmrs-to-new-executables">
              <title>Adding support for GMRs to new executables</title>
              <para>Adding support for a <emphasis>GMR</emphasis> to a given executable is fairly easy.</para>
              <para>First import the module:</para>
              <screen language="python"><![CDATA[from oslo_reports import guru_meditation_report as gmr
from magnum import version]]></screen>
              <para>Then, register any additional sections (optional):</para>
              <screen language="python"><![CDATA[TextGuruMeditation.register_section('Some Special Section',
                                    some_section_generator)]]></screen>
              <para>Finally (under main), before running the “main loop” of the executable (usually
                <literal>service.server(server)</literal> or something similar), register the <emphasis>GMR</emphasis> hook:</para>
              <screen language="python"><![CDATA[TextGuruMeditation.setup_autorun(version)]]></screen>
            </section>
            <section xml:id="extending-the-gmr">
              <title>Extending the GMR</title>
              <para>As mentioned above, additional sections can be added to the GMR for a
                particular executable. For more information, see the inline documentation
                under <literal>oslo.reports</literal></para>
            </section>
          </section>
          <section xml:id="magnum-troubleshooting-guide" xml:base="troubleshooting-guide">
            <title>Troubleshooting magnum</title>
            <para>This guide is intended for users who use Magnum to deploy and manage
            clusters of hosts for a Container Orchestration Engine. It describes
            common failure conditions and techniques for troubleshooting. To help
            the users quickly identify the relevant information, the guide is
            organized as a list of failure symptoms: Each has some suggestions
            with pointers to the details for troubleshooting.</para>
            <para>A separate section <xref linkend="for-developers"/> describes useful techniques such as
            debugging unit tests and gate tests.</para>
            <section xml:id="failure-symptoms">
              <title>Failure symptoms</title>
              <variablelist>
                <varlistentry>
                  <term>My cluster-create takes a really long time</term>
                  <listitem>
                    <para>If you are using devstack on a small VM, cluster-create will take a long
                            time and may eventually fail because of insufficient resources.
                            Another possible reason is that a process on one of the nodes is hung
                            and heat is still waiting on the signal. In this case, it will eventually
                            fail with a timeout, but since heat has a long default timeout, you can
                            look at the <xref linkend="heat-stacks"/> and check the WaitConditionHandle resources.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>My <literal>cluster-create</literal> fails with error: <literal>Failed to create trustee XXX in domain XXX</literal></term>
                  <listitem>
                    <para>Check the <xref linkend="trustee-for-cluster"/></para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Kubernetes cluster-create fails</term>
                  <listitem>
                    <para>Check the <xref linkend="heat-stacks"/>, log into the master nodes and check the
                            Kubernetes service and <xref linkend="etcd-service"/>.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Swarm cluster-create fails</term>
                  <listitem>
                    <para>Check the <xref linkend="heat-stacks"/>, log into the master nodes and check the Swarm services and <xref linkend="etcd-service"/>.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Mesos cluster-create fails</term>
                  <listitem>
                    <para>Check the <xref linkend="heat-stacks"/>, log into the master nodes and check the Mesos services.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>I get the error <literal>Timed out waiting for a reply</literal> when deploying a pod</term>
                  <listitem>
                    <para>Verify the Kubernetes service and <xref linkend="etcd-service"/> are running on the
                            master nodes.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>I deploy pods on Kubernetes cluster but the status stays “Pending”</term>
                  <listitem>
                    <para>The pod status is <literal>Pending</literal> while the Docker image is being downloaded,
                            so if the status does not change for a long time, log into the minion
                            node and check for <xref linkend="cluster-internet-access"/>.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>I deploy pods and services on Kubernetes cluster but the app is not working</term>
                  <listitem>
                    <para>The pods and services are running and the status looks correct, but
                            if the app is performing communication between pods through services,
                            verify <xref linkend="kubernetes-networking"/>.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Swarm cluster is created successfully but I cannot deploy containers</term>
                  <listitem>
                    <para>Check the Swarm services and <xref linkend="etcd-service"/> on the master nodes.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>Mesos cluster is created successfully but I cannot deploy containers on Marathon</term>
                  <listitem>
                    <para>Check the Mesos services on the master node.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>I get a <literal>Protocol violation</literal> error when deploying a container</term>
                  <listitem>
                    <para>For Kubernetes, check the Kubernetes service to verify that
                            <literal>kube-apiserver</literal> is running to accept the request.
                            Check <xref linkend="tls"/> and Barbican service.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>My <literal>cluster-create</literal> fails with a resource error on <literal>docker_volume</literal></term>
                  <listitem>
                    <para>Check for available volume space on Cinder and the volume size in the heat template.
                            Run <literal>nova volume-list</literal> to check the volume status.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </section>
            <section xml:id="troubleshooting-details">
              <title>Troubleshooting details</title>
              <section xml:id="heat-stacks">
                <title>Heat stacks</title>
                <para>A cluster is deployed by a set of heat stacks: One top level stack and several
                    nested stack. The stack names are prefixed with the cluster name and the
                    nested stack names contain descriptive internal names like <emphasis>kube_masters</emphasis>,
                    <emphasis>kube_minions</emphasis>.</para>
                <para>List the status of all the stacks for a cluster by using the following command:</para>
                <screen language="bash">heat stack-list -n | grep <emphasis>cluster-name</emphasis></screen>
                <para>If the cluster has failed, then one or more of the heat stacks would have
                    failed. From the stack list above, look for the stacks that failed, then
                    look for the particular resource(s) that failed in the failed stack by using the following command:</para>
                <screen language="bash">heat resource-list <emphasis>failed-stack-name</emphasis> | grep “FAILED”</screen>
                <para>The <literal>resource_type</literal> of the failed resource should point to the OpenStack
                    service, for example: <literal>OS::Cinder::Volume</literal>. Check for more details on the failure by using the following command:</para>
                <screen language="bash">heat resource-show <emphasis>failed-stack-name</emphasis><emphasis>failed-resource-name</emphasis></screen>
                <para>The <literal>resource_status_reason</literal> may give an indication on the failure, although
                    in some cases it may only say <literal>Unknown</literal>.</para>
                <para>If the failed resource is <literal>OS::Heat::WaitConditionHandle</literal>, this indicates that
                    one of the services that are being started on the node is hung. Log into the
                    node where the failure occurred and check the respective Kubernetes, Swarm or Mesos serivces. If the failure is in
                    other scripts, look for them as Heat software resource scripts.</para>
              </section>
              <section xml:id="trustee-for-cluster">
                <title>Trustee for cluster</title>
                <para>When a user creates a cluster, Magnum dynamically creates a service account
                    for the cluster. The service account is used by the cluster to
                    access the OpenStack services (i.e. Neutron, Swift, etc.). A trust relationship
                    will be created between the user who created the cluster (the “trustor”) and
                    the service account created for the cluster (the “trustee”).</para>
                <para>If Magnum fails to create the trustee, check the magnum config file (usually
                    in <literal>/etc/magnum/magnum.conf</literal>). Make sure <literal>trustee_*</literal> and
                    <literal>auth_uri</literal> are set and their values are correct:</para>
                <screen language="bash">[keystone_authtoken] auth_uri = http://controller:5000/v3 …</screen>
                <screen language="bash">[trust]
                        trustee_domain_admin_password = XXX
                        trustee_domain_admin_id = XXX
                        trustee_domain_id = XXX</screen>
                <para>If the trust group is missing, you might need to create the trustee domain
                    and the domain admin:</para>
                <screen language="bash"><![CDATA[source /opt/stack/devstack/accrc/admin/admin
export OS_IDENTITY_API_VERSION=3
unset OS_AUTH_TYPE
openstack domain create magnum
openstack user create trustee_domain_admin --password=secret \
    --domain=magnum
openstack role add --user=trustee_domain_admin --user-domain magnum --domain=magnum admin

source /opt/stack/devstack/functions
export MAGNUM_CONF=/etc/magnum/magnum.conf
iniset $MAGNUM_CONF trust trustee_domain_id \
    $(openstack domain show magnum | awk '/ id /{print $4}')
iniset $MAGNUM_CONF trust trustee_domain_admin_id \
    $(openstack user show trustee_domain_admin | awk '/ id /{print $4}')
iniset $MAGNUM_CONF trust trustee_domain_admin_password secret]]></screen>
                <para>Then, restart <literal>magnum-api</literal> and <literal>magnum-cond</literal> to pick up the new configuration.
                    If the problem still exists, you might want to manually verify your domain
                    admin credential to ensure it has the right privilege. To do that, run the
                    script below with the credentials replaced (you must use the IDs where
                    specified). If it fails, that means the credential you provided is invalid.</para>
                <screen language="python"><![CDATA[from keystoneauth1.identity import v3 as ka_v3
from keystoneauth1 import session as ka_session
from keystoneclient.v3 import client as kc_v3

auth = ka_v3.Password(
    auth_url=YOUR_AUTH_URI,
    user_id=YOUR_TRUSTEE_DOMAIN_ADMIN_ID,
    domain_id=YOUR_TRUSTEE_DOMAIN_ID,
    password=YOUR_TRUSTEE_DOMAIN_ADMIN_PASSWORD)

session = ka_session.Session(auth=auth)
domain_admin_client = kc_v3.Client(session=session)
user = domain_admin_client.users.create(
    name='anyname',
    password='anypass')]]></screen>
              </section>
              <section xml:id="tls">
                <title>TLS</title>
                <para>In production deployments, operators run the OpenStack APIs using
                    ssl certificates and in private clouds it is common to use self-signed
                    or certificates signed from CAs that they are usually not included
                    in the systems’ default CA-bundles. Magnum clusters with TLS enabled
                    have their own CA but they need to make requests to the OpenStack
                    APIs for several reasons. For example, get the cluster CA and sign node
                    certificates (Keystone, Magnum), signal the Heat API for stack
                    completion, create resources (volumes, load balancers) or get
                    information for each node (Cinder, Neutron, Nova). In these cases,
                    the cluster nodes need the CA used for to run the APIs.</para>
                <para>To pass the OpenStack CA bundle to the nodes you can set the CA
                    using the <literal>openstack_ca_file</literal> option in the <literal>drivers</literal> section of
                    Magnum’s configuration file (usually <literal>/etc/magnum/magnum.conf</literal>).
                    The default drivers in magnum install this CA in the system and
                    set it in all the places it might be needed (eg when configuring
                    the Kubernetes cloud provider or for the heat-agents.)</para>
                <para>The cluster nodes validate the Certificate Authority by default
                    when making requests to the OpenStack APIs (Keystone, Magnum, Heat).
                    If you need to disable CA validation, the configuration parameter
                    <literal>verify_ca</literal> can be set to <literal>False</literal>.
                    For more information on <link xlink:href="https://bugs.launchpad.net/magnum/+bug/1663757">CA Validation</link>.</para>
              </section>
              <section xml:id="cluster-internet-access">
                <title>Cluster internet access</title>
                <para>The nodes for Kubernetes, Swarm and Mesos are connected to a private
                    Neutron network, so to provide access to the external internet, a router
                    connects the private network to a public network. With devstack, the
                    default public network is public, but this can be replaced by the
                    parameter <literal>external-network</literal> in the <literal>ClusterTemplate</literal>. The public
                    network with devstack is actually not a real external network, so it is in turn
                    routed to the network interface of the host for devstack. This is
                    configured in the file <literal>local.conf</literal> with the variable <literal>PUBLIC_INTERFACE</literal>,
                    for example:</para>
                <screen><![CDATA[PUBLIC_INTERFACE=eth1]]></screen>
                <para>If the route to the external internet is not set up properly, the ectd
                    discovery would fail (if using public discovery) and container images
                    cannot be downloaded, among other failures.</para>
                <para>First, check for connectivity to the external internet by pinging
                    an external IP (the IP shown here is an example, use an IP that
                    works in your case):</para>
                <screen><![CDATA[ping 8.8.8.8]]></screen>
                <para>If the ping fails, there is no route to the external internet.
                    Check the following:</para>
                <itemizedlist>
                  <listitem>
                    <para>Is <literal>PUBLIC_INTERFACE</literal> in <literal>devstack/local.conf</literal> the correct network
                            interface? Does this interface have a route to the external internet?</para>
                  </listitem>
                  <listitem>
                    <para>If <literal>external-network</literal> is specified in the <literal>ClusterTemplate</literal>, does this
                            network have a route to the external internet?</para>
                  </listitem>
                  <listitem>
                    <para>Is your devstack environment behind a firewall? This can be the case for some
                            enterprises or countries. In this case, consider using a <link xlink:href="https://docs.openstack.org/magnum/pike/admin/magnum-proxy.html">proxy server</link>.</para>
                  </listitem>
                  <listitem>
                    <para>Is the traffic blocked by the security group? Check the
                            <link xlink:href="https://docs.openstack.org/operations-guide/ops-user-facing-operations.html#security-groups">rules of security group</link>.</para>
                  </listitem>
                  <listitem>
                    <para>Is your host NAT’ing your internal network correctly? Check your host
                            <link xlink:href="https://docs.openstack.org/operations-guide/ops-network-troubleshooting.html#iptables">iptables</link>.</para>
                  </listitem>
                  <listitem>
                    <para>Use <emphasis>tcpdump</emphasis> for <link xlink:href="https://docs.openstack.org/operations-guide/ops-network-troubleshooting.html#tcpdump">networking troubleshooting</link>.
                            You can run <emphasis>tcpdump</emphasis> on the interface <emphasis>docker0, flannel0</emphasis> and <emphasis>eth0</emphasis> on the
                            node and then run <emphasis>ping</emphasis> to see the path of the message from the container.</para>
                  </listitem>
                </itemizedlist>
                <para>If ping is successful, check that DNS is working:</para>
                <screen><![CDATA[wget google.com]]></screen>
                <para>If DNS works, you should get back a few lines of HTML text.</para>
                <para>If the name lookup fails, check the following:</para>
                <itemizedlist>
                  <listitem>
                    <para>Is the DNS entry correct in the subnet? Try <literal>neutron subnet-show subnet-id</literal> for the private
                            subnet and check <literal>dns_nameservers</literal>.
                            The IP should be either the default public DNS 8.8.8.8 or the value
                            specified by <literal>dns-nameserver</literal> in the <literal>ClusterTemplate</literal>.</para>
                  </listitem>
                  <listitem>
                    <para>If you are using your own DNS server by specifying <literal>dns-nameserver</literal>
                            in the <literal>ClusterTemplate</literal>, is it reachable and working?</para>
                  </listitem>
                  <listitem>
                    <para>More help on <link xlink:href="https://docs.openstack.org/operations-guide/ops-network-troubleshooting.html#debugging-dns-issues">DNS troubleshooting</link>.</para>
                  </listitem>
                </itemizedlist>
              </section>
              <section xml:id="kubernetes-networking">
                <title>Kubernetes networking</title>
                <para>The networking between pods is different and separate from the neutron
                    network set up for the cluster.
                    Kubernetes presents a flat network space for the pods and services
                    and uses different network drivers to provide this network model.</para>
                <para>It is possible for the pods to come up correctly and be able to connect
                    to the external internet, but they cannot reach each other.
                    In this case, the app in the pods may not be working as expected.
                    For example, if you are trying the <link xlink:href="https://github.com/kubernetes/kubernetes/blob/release-1.1/examples/redis/README.md">redis example</link>,
                    the <literal>key:value</literal> may not be replicated correctly. In this case, use the
                    following steps to verify the inter-pods networking and pinpoint problems.</para>
                <para>Since the steps are specific to the network drivers, refer to the
                    particular driver being used for the cluster.</para>
                <section xml:id="using-flannel-as-network-driver">
                  <title>Using Flannel as network driver</title>
                  <para>Flannel is the default network driver for Kubernetes clusters. Flannel is
                        an overlay network that runs on top of the neutron network. It works by
                        encapsulating the messages between pods and forwarding them to the
                        correct node that hosts the target pod.</para>
                  <para>First check the connectivity at the node level. Log into two
                        different minion nodes, for example node A and node B, run a docker container
                        on each node, attach to the container and find the IP.</para>
                  <para>For example, on node A:</para>
                  <screen><![CDATA[sudo docker run -it alpine
# ip -f inet -o a | grep eth0 | awk '{print $4}'
10.100.54.2/24]]></screen>
                  <para>Similarly, on node B:</para>
                  <screen><![CDATA[sudo docker run -it alpine
# ip -f inet -o a | grep eth0 | awk '{print $4}'
10.100.49.3/24]]></screen>
                  <para>Check that the containers can see each other by pinging from one to another.</para>
                  <para>On node A:</para>
                  <screen><![CDATA[# ping 10.100.49.3
PING 10.100.49.3 (10.100.49.3): 56 data bytes
64 bytes from 10.100.49.3: seq=0 ttl=60 time=1.868 ms
64 bytes from 10.100.49.3: seq=1 ttl=60 time=1.108 ms]]></screen>
                  <para>Similarly, on node B:</para>
                  <screen><![CDATA[# ping 10.100.54.2
PING 10.100.54.2 (10.100.54.2): 56 data bytes
64 bytes from 10.100.54.2: seq=0 ttl=60 time=2.678 ms
64 bytes from 10.100.54.2: seq=1 ttl=60 time=1.240 ms]]></screen>
                  <para>If the ping is not successful, check the following:</para>
                  <itemizedlist>
                    <listitem>
                      <para>Is neutron working properly? Try pinging between the VMs.</para>
                    </listitem>
                    <listitem>
                      <para>Are the <literal>docker0</literal> and <literal>flannel0</literal> interfaces configured correctly on the
                                nodes? Log into each node and find the Flannel CIDR by:</para>
                      <screen><![CDATA[cat /run/flannel/subnet.env | grep FLANNEL_SUBNET
FLANNEL_SUBNET=10.100.54.1/24]]></screen>
                      <para>Then check the interfaces by:</para>
                      <screen><![CDATA[ifconfig flannel0
ifconfig docker0]]></screen>
                      <para>The correct configuration should assign flannel0 with the “0” address
                                in the subnet, like <emphasis>10.100.54.0</emphasis>, and docker0 with the “1” address, like
                                <emphasis>10.100.54.1</emphasis>.</para>
                    </listitem>
                    <listitem>
                      <para>Verify the IP’s assigned to the nodes as found above are in the correct
                                Flannel subnet. If this is not correct, the docker daemon is not configured
                                correctly with the parameter <emphasis>–bip</emphasis>. Check the systemd service for docker.</para>
                    </listitem>
                    <listitem>
                      <para>Is Flannel running properly? Check the <xref linkend="running-flannel"/>.</para>
                    </listitem>
                    <listitem>
                      <para>Ping and try <link xlink:href="https://docs.openstack.org/operations-guide/ops-network-troubleshooting.html#tcpdump">tcpdump</link>
                                on each network interface along the path between two nodes
                                to see how far the message is able to travel.
                                The message path should be as follows:</para>
                      <procedure>
                        <step>
                          <para>Source node: docker0</para>
                        </step>
                        <step>
                          <para>Source node: flannel0</para>
                        </step>
                        <step>
                          <para>Source node: eth0</para>
                        </step>
                        <step>
                          <para>Target node: eth0</para>
                        </step>
                        <step>
                          <para>Target node: flannel0</para>
                        </step>
                        <step>
                          <para>Target node: docker0</para>
                        </step>
                      </procedure>
                    </listitem>
                  </itemizedlist>
                  <para>If ping works, this means the flannel overlay network is functioning
                        correctly.</para>
                  <para>The containers created by Kubernetes for pods will be on the same IP
                        subnet as the containers created directly in Docker as above, so they
                        will have the same connectivity. However, the pods still may not be
                        able to reach each other because normally they connect through some
                        Kubernetes services rather than directly. The services are supported
                        by the <literal>kube-proxy</literal> and rules inserted into the iptables, therefore
                        their networking paths have some extra hops and there may be problems
                        here.</para>
                  <para>To check the connectivity at the Kubernetes pod level, log into the
                        master node and create two pods and a service for one of the pods.
                        You can use the examples provided in the directory
                        <emphasis>/etc/kubernetes/examples/</emphasis> for the first pod and service. This will
                        start up an nginx container and a Kubernetes service to expose the
                        endpoint. Create another manifest for a second pod to test the
                        endpoint:</para>
                  <screen><![CDATA[cat > alpine.yaml << END
apiVersion: v1
kind: Pod
metadata:
  name: alpine
spec:
  containers:
  - name: alpine
    image: alpine
    args:
    - sleep
    - "1000000"
END

kubectl create -f /etc/kubernetes/examples/pod-nginx-with-label.yaml
kubectl create -f /etc/kubernetes/examples/service.yaml
kubectl create -f alpine.yaml]]></screen>
                  <para>Get the endpoint for the <literal>nginx-service</literal>, which should route message to the pod
                        nginx:</para>
                  <screen><![CDATA[kubectl describe service nginx-service | grep -e IP: -e Port:
IP:                     10.254.21.158
Port:                   <unnamed>       8000/TCP]]></screen>
                  <para>Note the IP and port to use for checking below. Log into the node
                        where the <emphasis>alpine</emphasis> pod is running. You can find the hosting node by
                        running this command on the master node:</para>
                  <screen><![CDATA[kubectl get pods -o wide  | grep alpine | awk '{print $6}'
k8-gzvjwcooto-0-gsrxhmyjupbi-kube-minion-br73i6ans2b4]]></screen>
                  <para>To get the IP of the node, query nova on devstack:</para>
                  <screen><![CDATA[nova list]]></screen>
                  <para>On this hosting node, attach to the <emphasis>alpine</emphasis> container:</para>
                  <screen><![CDATA[export DOCKER_ID=`sudo docker ps | grep k8s_alpine | awk '{print $1}'`
sudo docker exec -it $DOCKER_ID sh]]></screen>
                  <para>From the <emphasis>alpine</emphasis> pod, you can try to reach the nginx pod through the nginx
                        service using the IP and Port found above:</para>
                  <screen><![CDATA[wget 10.254.21.158:8000]]></screen>
                  <para>If the connection is successful, you should receive the file <emphasis>index.html</emphasis> from
                        nginx.</para>
                  <para>If the connection is not successful, you will get an error message:</para>
                  <para>wget: can’t connect to remote host (10.100.54.9): No route to host</para>
                  <para>In this case, check the following:</para>
                  <itemizedlist>
                    <listitem>
                      <para>Is <literal>kube-proxy</literal> running on the nodes? It runs as a container on each node.
                                check by logging in the minion nodes and run:</para>
                      <screen><![CDATA[sudo docker ps | grep k8s_kube-proxy]]></screen>
                    </listitem>
                    <listitem>
                      <para>Check the log from <literal>kube-proxy</literal> by running on the minion nodes:</para>
                      <screen><![CDATA[export PROXY=`sudo docker ps | grep "hyperkube proxy" | awk '{print $1}'`
sudo docker logs $PROXY]]></screen>
                    </listitem>
                    <listitem>
                      <para>Try additional <link xlink:href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/user-guide/debugging-services.md">service debugging</link>.
                                To see what’s going during provisioning:</para>
                      <screen><![CDATA[kubectl get events]]></screen>
                      <para>To get information on a service in question:</para>
                      <screen><![CDATA[kubectl describe services <service_name>]]></screen>
                    </listitem>
                  </itemizedlist>
                </section>
              </section>
              <section xml:id="etcd-service">
                <title>etcd service</title>
                <para>The etcd service is used by many other components for key/value pair
                    management, therefore if it fails to start, these other components
                    will not be running correctly either.
                    Check that etcd is running on the master nodes by:</para>
                <screen><![CDATA[sudo service etcd status -l]]></screen>
                <para>If it is running correctly, you should see that the service is
                    successfully deployed:</para>
                <screen><![CDATA[Active: active (running) since ....]]></screen>
                <para>The log message should show the service being published:</para>
                <screen><![CDATA[etcdserver: published {Name:10.0.0.5 ClientURLs:[http://10.0.0.5:2379]} to cluster 3451e4c04ec92893]]></screen>
                <para>In some cases, the service may show as <emphasis>active</emphasis> but may still be stuck
                    in discovery mode and not fully operational. The log message may show
                    something like:</para>
                <screen><![CDATA[discovery: waiting for other nodes: error connecting to https://discovery.etcd.io, retrying in 8m32s]]></screen>
                <para>If this condition persists, check for <xref linkend="cluster-internet-access"/>.</para>
                <para>If the daemon is not running, the status will show the service as failed,
                    something like:</para>
                <screen><![CDATA[Active: failed (Result: timeout)]]></screen>
                <para>In this case, try restarting etcd by:</para>
                <screen><![CDATA[sudo service etcd start]]></screen>
                <para>If etcd continues to fail, check the following:</para>
                <itemizedlist>
                  <listitem>
                    <para>Check the log for etcd:</para>
                    <screen><![CDATA[sudo journalctl -u etcd]]></screen>
                  </listitem>
                  <listitem>
                    <para>etcd requires discovery, and the default discovery method is the
                            public discovery service provided by etcd.io; therefore, a common
                            cause of failure is that this public discovery service is not
                            reachable. Check by running on the master nodes:</para>
                    <screen><![CDATA[source /etc/sysconfig/heat-params
curl $ETCD_DISCOVERY_URL]]></screen>
                    <para>You should receive something like:</para>
                    <screen><![CDATA[{"action":"get",
 "node":{"key":"/_etcd/registry/00a6b00064174c92411b0f09ad5466c6",
         "dir":true,
         "nodes":[
           {"key":"/_etcd/registry/00a6b00064174c92411b0f09ad5466c6/7d8a68781a20c0a5",
            "value":"10.0.0.5=http://10.0.0.5:2380",
            "modifiedIndex":978239406,
            "createdIndex":978239406}],
         "modifiedIndex":978237118,
         "createdIndex":978237118}
}]]></screen>
                    <para>The list of master IP is provided by Magnum during cluster deployment,
                            therefore it should match the current IP of the master nodes.
                            If the public discovery service is not reachable, check the
                            <xref linkend="cluster-internet-access"/>.</para>
                  </listitem>
                </itemizedlist>
              </section>
              <section xml:id="running-flannel">
                <title>Running Flannel</title>
                <para>When deploying a COE, Flannel is available as a network driver for
                    certain COE type. Magnum currently supports Flannel for a Kubernetes
                    or Swarm cluster.</para>
                <para>Flannel provides a flat network space for the containers in the cluster:
                    they are allocated IP in this network space and they will have connectivity
                    to each other. Therefore, if Flannel fails, some containers will not
                    be able to access services from other containers in the cluster. This can be
                    confirmed by running <emphasis>ping</emphasis> or <emphasis>curl</emphasis> from one container to another.</para>
                <para>The Flannel daemon is run as a systemd service on each node of the cluster.
                    To check Flannel, run on each node:</para>
                <screen><![CDATA[sudo service flanneld status]]></screen>
                <para>If the daemon is running, you should see that the service is successfully
                    deployed:</para>
                <screen><![CDATA[Active: active (running) since ....]]></screen>
                <para>If the daemon is not running, the status will show the service as failed,
                    something like:</para>
                <screen><![CDATA[Active: failed (Result: timeout) ....]]></screen>
                <para>Or:</para>
                <screen><![CDATA[Active: inactive (dead) ....]]></screen>
                <para>Flannel daemon may also be running but not functioning correctly.
                    Check the following:</para>
                <itemizedlist>
                  <listitem>
                    <para>Check the log for Flannel:</para>
                    <screen><![CDATA[sudo journalctl -u flanneld]]></screen>
                  </listitem>
                  <listitem>
                    <para>Since Flannel relies on etcd, a common cause for failure is that the
                            etcd service is not running on the master nodes. Check the <xref linkend="etcd-service"/>.
                            If the etcd service failed, once it has been restored successfully, the
                            Flannel service can be restarted by:</para>
                    <screen><![CDATA[sudo service flanneld restart]]></screen>
                  </listitem>
                  <listitem>
                    <para>Magnum writes the configuration for Flannel in a local file on each master
                            node. Check for this file on the master nodes by:</para>
                    <screen><![CDATA[cat /etc/sysconfig/flannel-network.json]]></screen>
                    <para>The content should be something like:</para>
                    <screen><![CDATA[{
  "Network": "10.100.0.0/16",
  "Subnetlen": 24,
  "Backend": {
    "Type": "udp"
  }
}]]></screen>
                    <para>Where the values for the parameters must match the corresponding
                            parameters from the <literal>ClusterTemplate</literal>.</para>
                    <para>Magnum also loads this configuration into etcd, therefore, verify
                            the configuration in etcd by running <emphasis>etcdctl</emphasis> on the master nodes:</para>
                    <screen><![CDATA[. /etc/sysconfig/flanneld
etcdctl get $FLANNEL_ETCD_KEY/config]]></screen>
                  </listitem>
                  <listitem>
                    <para>Each node is allocated a segment of the network space. Check
                            for this segment on each node by:</para>
                    <screen><![CDATA[grep FLANNEL_SUBNET /run/flannel/subnet.env]]></screen>
                    <para>The containers on this node should be assigned an IP in this range.
                            The nodes negotiate for their segment through etcd, and you can use
                            <emphasis>etcdctl</emphasis> on the master node to query the network segment associated
                            with each node:</para>
                    <screen><![CDATA[. /etc/sysconfig/flanneld
for s in `etcdctl ls $FLANNEL_ETCD_KEY/subnets`
do
echo $s
etcdctl get $s
done

/atomic.io/network/subnets/10.100.14.0-24
{"PublicIP":"10.0.0.5"}
/atomic.io/network/subnets/10.100.61.0-24
{"PublicIP":"10.0.0.6"}
/atomic.io/network/subnets/10.100.92.0-24
{"PublicIP":"10.0.0.7"}]]></screen>
                    <para>Alternatively, you can read the full record in ectd by:</para>
                    <screen><![CDATA[curl http://<master_node_ip>:2379/v2/keys/coreos.com/network/subnets]]></screen>
                    <para>You should receive a JSON snippet that describes all the segments
                            allocated.</para>
                  </listitem>
                  <listitem>
                    <para>This network segment is passed to Docker via the parameter <emphasis>–bip</emphasis>.
                            If this is not configured correctly, Docker would not assign the correct
                            IP in the Flannel network segment to the container. Check by:</para>
                    <screen><![CDATA[cat /run/flannel/docker
ps -aux | grep docker]]></screen>
                  </listitem>
                  <listitem>
                    <para>Check the interface for Flannel:</para>
                    <screen><![CDATA[ifconfig flannel0]]></screen>
                    <para>The IP should be the first address in the Flannel subnet for this node.</para>
                  </listitem>
                  <listitem>
                    <para>Flannel has several different backend implementations and they have
                            specific requirements. The <emphasis>udp</emphasis> backend is the most general and have
                            no requirement on the network. The <emphasis>vxlan</emphasis> backend requires vxlan
                            support in the kernel, so ensure that the image used does provide
                            vxlan support. The <emphasis>host-gw</emphasis> backend requires that all the hosts are
                            on the same L2 network. This is currently met by the private neutron
                            subnet created by Magnum; however, if other network topology is used
                            instead, ensure that this requirement is met if <emphasis>host-gw</emphasis> is used.</para>
                  </listitem>
                </itemizedlist>
              </section>
            <section xml:id="for-developers">
              <title>For Developers</title>
              <para>This section is intended to help with issues that developers may
                run into in the course of their development adventures in Magnum.</para>
              <section xml:id="troubleshooting-in-gate">
                <title>Troubleshooting in Gate</title>
                <variablelist>
                  <varlistentry>
                    <term>Simulating gate tests</term>
                    <listitem>
                      <note>
                        <para>This is adapted from Devstack Gate’s <link xlink:href="https://github.com/openstack-infra/devstack-gate/blob/master/README.rst#simulating-devstack-gate-testsP">README</link> which
                                is worth a quick read to better understand the following.</para>
                      </note>
                      <procedure>
                        <step>
                          <para>Boot a VM like described in the Devstack Gate’s <link xlink:href="https://github.com/openstack-infra/devstack-gate/blob/master/README.rst#simulating-devstack-gate-testsP">README</link> .</para>
                        </step>
                        <step>
                          <para>Provision this VM like so:</para>
                          <screen><![CDATA[apt-get update \
&& apt-get upgrade -y \ # Kernel upgrade, as recommended by README, select to keep existing grub config
&& apt-get install -y git tmux vim \
&& git clone https://git.openstack.org/openstack-infra/system-config \
&& system-config/install_puppet.sh && system-config/install_modules.sh \
&& puppet apply \
--modulepath=/root/system-config/modules:/etc/puppet/modules \
-e "class { openstack_project::single_use_slave: install_users => false,
ssh_key => \"$( cat .ssh/authorized_keys | awk '{print $2}' )\" }" \
&& echo "jenkins ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers \
&& cat ~/.ssh/authorized_keys >> /home/jenkins/.ssh/authorized_keys]]></screen>
                        </step>
                        <step>
                          <para>Compare <literal>~/.ssh/authorized_keys</literal> and <literal>/home/jenkins/.ssh/authorized_keys</literal>.
                                Your original public SSH key should now be in <literal>/home/jenkins/.ssh/authorized_keys</literal>.
                                If it’s not, explicitly copy it (this can happen if you spin up a using
                                <literal>--key-name &lt;name&gt;</literal>, for example).</para>
                        </step>
                        <step>
                          <para>Assuming all is well up to this point, now it’s time to <literal>reboot</literal>
                                into the latest kernel</para>
                        </step>
                        <step>
                          <para>Once done booting into the new kernel, log back in as <literal>jenkins</literal>
                                user to continue with setting up the simulation.</para>
                        </step>
                        <step>
                          <para>Now it’s time to set up the workspace:</para>
                          <screen><![CDATA[export REPO_URL=https://git.openstack.org
export WORKSPACE=/home/jenkins/workspace/testing
export ZUUL_URL=/home/jenkins/workspace-cache2
export ZUUL_REF=HEAD
export ZUUL_BRANCH=master
export ZUUL_PROJECT=openstack/magnum
mkdir -p $WORKSPACE
git clone $REPO_URL/$ZUUL_PROJECT $ZUUL_URL/$ZUUL_PROJECT \
&& cd $ZUUL_URL/$ZUUL_PROJECT \
&& git checkout remotes/origin/$ZUUL_BRANCH]]></screen>
                        </step>
                        <step>
                          <para>At this point, you may be wanting to test a specific change. If so, you can pull down
                                the changes in <literal>$ZUUL_URL/$ZUUL_PROJECT</literal> directory:</para>
                          <screen><![CDATA[cd $ZUUL_URL/$ZUUL_PROJECT \
&& git fetch https://review.openstack.org/openstack/magnum refs/changes/83/247083/12 && git checkout FETCH_HEAD]]></screen>
                        </step>
                        <step>
                          <para>Now you’re ready to pull down the <literal>devstack-gate</literal> scripts that will let
                                you run the gate job on your own VM:</para>
                          <screen><![CDATA[cd $WORKSPACE \
&& git clone --depth 1 $REPO_URL/openstack-infra/devstack-gate]]></screen>
                        </step>
                        <step>
                          <para>And now you can kick off the job using the following script (the
                                <literal>devstack-gate</literal> documentation suggests just copying from the
                                job which can be found in the
                                <link xlink:href="https://github.com/openstack-infra/project-config">project-config</link> repository),
                                naturally it should be executable (<literal>chmod u+x &lt;filename&gt;</literal>):</para>
                          <screen><![CDATA[#!/bin/bash -xe
cat > clonemap.yaml << EOF
clonemap:
  - name: openstack-infra/devstack-gate
    dest: devstack-gate
EOF
/usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
    git://git.openstack.org \
    openstack-infra/devstack-gate
export PYTHONUNBUFFERED=true
export DEVSTACK_GATE_TIMEOUT=240 # bump this if you see timeout issues. Default is 120
export DEVSTACK_GATE_TEMPEST=0
export DEVSTACK_GATE_NEUTRON=1
# Enable tempest for tempest plugin
export ENABLED_SERVICES=tempest
export BRANCH_OVERRIDE="default"
if [ "$BRANCH_OVERRIDE" != "default" ] ; then
    export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
fi
export PROJECTS="openstack/magnum $PROJECTS"
export PROJECTS="openstack/python-magnumclient $PROJECTS"
export PROJECTS="openstack/barbican $PROJECTS"
export DEVSTACK_LOCAL_CONFIG="enable_plugin magnum git://git.openstack.org/openstack/magnum"
export DEVSTACK_LOCAL_CONFIG+=$'\n'"enable_plugin ceilometer git://git.openstack.org/openstack/ceilometer"
# Keep localrc to be able to set some vars in post_test_hook
export KEEP_LOCALRC=1
function gate_hook {
     cd /opt/stack/new/magnum/
    ./magnum/tests/contrib/gate_hook.sh api # change this to swarm to run swarm functional tests or k8s to run kubernetes functional tests
}
export -f gate_hook
function post_test_hook {
    source $BASE/new/devstack/accrc/admin/admin
    cd /opt/stack/new/magnum/
    ./magnum/tests/contrib/post_test_hook.sh api # change this to swarm to run swarm functional tests or k8s to run kubernetes functional tests
}
export -f post_test_hook
cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
./safe-devstack-vm-gate-wrap.sh]]></screen>
                        </step>
                      </procedure>
                    </listitem>
                  </varlistentry>
                  <varlistentry>
                    <term>Helpful nuances about the Devstack Gate:</term>
                    <listitem>
                      <itemizedlist>
                        <listitem>
                          <para>Main job is in <literal>project-config</literal>’s <link xlink:href="https://github.com/openstack-infra/project-config/blob/master/jenkins/jobs/magnum.yaml">magnum.yaml</link>.</para>
                          <itemizedlist>
                            <listitem>
                              <para>Must modify parameters passed in since those are escaped:</para>
                              <itemizedlist>
                                <listitem>
                                  <para>Anything with <literal>{}</literal> should be set as an environment variable</para>
                                </listitem>
                                <listitem>
                                  <para>Anything with <literal>{{ }}</literal> should have those brackets changed to
                                                        single brackets - <literal>{}</literal>.</para>
                                </listitem>
                                <listitem>
                                  <para>As with the documentation for Devstack Gate, you can just create
                                                        a new file for the job you want, paste in what you want, then
                                                        <literal>chmod u+x &lt;filename&gt;</literal> and run it.</para>
                                </listitem>
                              </itemizedlist>
                            </listitem>
                            <listitem>
                              <para>Parameters can be found in <link xlink:href="https://github.com/openstack-infra/project-config/blob/master/jenkins/jobs/projects.yaml">projects.yaml</link>.
                                    This file changes a lot, so it’s more reliable to say that you can
                                    search for the magnum jobs where you’ll see examples of what
                                    gets passed in.</para>
                            </listitem>
                          </itemizedlist>
                        </listitem>
                        <listitem>
                          <para>Three jobs are usually run as a part of Magnum gate, all of which are found
                                in <literal>project-config</literal>’s <link xlink:href="https://github.com/openstack-infra/project-config/blob/master/jenkins/jobs/macros.yaml">macros.yml</link>:</para>
                          <itemizedlist>
                            <listitem>
                              <para>link-logs</para>
                            </listitem>
                            <listitem>
                              <para>net-info</para>
                            </listitem>
                            <listitem>
                              <para>devstack-checkout</para>
                            </listitem>
                          </itemizedlist>
                        </listitem>
                        <listitem>
                          <para>After you run a job, it’s ideal to clean up and start over with a
                                fresh VM to best simulate the Devstack Gate environment.</para>
                        </listitem>
                      </itemizedlist>
                    </listitem>
                  </varlistentry>
                </variablelist>
              </section>
            </section>
          </section>
        </section>
        <section>
          <title>Configuration</title>
          <para>Following pages will be helpful in configuring specific aspects
                of Magnum that may or may not be suitable to every situation.</para>
            <section xml:id="magnum-config">
              <title>Magnum Config</title>
              <para>The magnum configuration file is called <literal>magnum.conf</literal>.</para>
            </section>
            <section xml:id="magnum-pipeline">
              <title>Magnum Pipeline</title>
              <para>The pipeline details are contained in <literal>api-paste.ini</literal>.</para>
              <section xml:id="healthcheck-middleware">
                <title>Healthcheck Middleware</title>
                <para>This piece of middleware creates an endpoint that allows a load balancer
                    to probe if the API endpoint should be available at the node or not.</para>
                <para>The healthcheck middleware should be placed early in the pipeline. Which
                    is located in your <literal>api-paste.ini</literal> under a section called
                    <literal>[filter:healthcheck]</literal>. It should look like this:</para>
                <screen><![CDATA[[filter:healthcheck]
paste.filter_factory = oslo_middleware:Healthcheck.factory
backends = disable_by_file
disable_by_file_path = /etc/magnum/healthcheck_disable]]></screen>
                <para>The main pipeline using this filter should look something like this also
                    defined in the <literal>api-paste.ini</literal>:</para>
                <screen><![CDATA[[pipeline:main]
pipeline = cors healthcheck request_id authtoken api_v1]]></screen>
                <para>If you wish to disable a middleware without taking it out of the
                    pipeline, you can create a file under the file path defined by
                    <literal>disable_by_file_path</literal> ie. <literal>/etc/magnum/healthcheck_disable</literal>.</para>
                <para>For more information see
                    <link xlink:href="http://docs.openstack.org/developer/oslo.middleware/api.html#oslo_middleware.Healthcheck">oslo.middleware</link>.</para>
              </section>
            </section>
          </section>
        </section>
    </chapter>
