<?xml version="1.0"?>
<!DOCTYPE section [
 <!ENTITY % entities SYSTEM "entity-decl.ent"> %entities;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
        xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="recoverrabbit">
 <title>Understanding and Recovering &rabbit; after Failure</title>
 <para>
  &rabbit; is the message queue service that runs on each of your controller
  nodes and brokers communication between multiple services in your
  &product; cloud environment. It is important for cloud operators to
  understand how different troubleshooting scenarios affect &rabbit; so they
  can minimize downtime in their environments. We are going to discuss multiple
  scenarios and how it affects &rabbit;. We will also explain how you can
  recover from them if there are issues.
 </para>

 <section xml:id="idg-all-operations-troubleshooting-recover-rabbit-xml-7">
  <title>How upgrades affect &rabbit;</title>
  <para>
   There are two types of upgrades within &productname; -- major and minor. The
   effect that the upgrade process has on &rabbit; depends on these types.
  </para>
  <para>
   A major upgrade is defined by an erlang change or major version upgrade of
   &rabbit;. A minor upgrade would be an upgrade where &rabbit; stays within
   the same version, such as v3.4.3 to v.3.4.6.
  </para>
  <para>
   During both types of upgrades there may be minor blips in the authentication
   process of client services as the accounts are recreated.
  </para>
  <para>
   <emphasis role="bold">&rabbit; during a major upgrade</emphasis>
  </para>
  <para>
   There will be a &rabbit; service outage while the upgrade is performed.
  </para>
  <para>
   During the upgrade, high availability consistency is compromised -- all but
   the primary node will go down and will be reset, meaning their database
   copies are deleted. The primary node is not taken down until the last step
   and then it is upgrade. The database of users and permissions is maintained
   during this process. Then the other nodes are brought back into the cluster
   and resynchronized.
  </para>
  <para>
   <emphasis role="bold">&rabbit; during a minor upgrade</emphasis>
  </para>
  <para>
   Minor upgrades are performed node by node. This "rolling" process means
   there should be no overall service outage because each node is taken out of
   its cluster in turn, its database is reset, and then it is added back to the
   cluster and resynchronized.
  </para>
 </section>
 <section xml:id="idg-all-operations-troubleshooting-recover-rabbit-xml-8">
  <title>How &rabbit; is affected by other operational processes</title>
  <para>
   There are operational tasks, such as <xref linkend="stop-restart"/>, where
   you use the <filename>ardana-stop.yml</filename> and
   <filename>ardana-start.yml</filename> playbooks to gracefully restart your cloud.
   If you use these playbooks, and there are no errors associated with them
   forcing you to troubleshoot further, then &rabbit; is brought down
   gracefully and brought back up. There is nothing special to note regarding
   &rabbit; in these normal operational processes.
  </para>
  <para>
   However, there are other scenarios where an understanding of &rabbit; is
   important when a graceful shutdown did not occur.
  </para>
  <para>
   These examples that follow assume you are using one of the entry-scale
   models where &rabbit; is hosted on your controller node cluster. If you are
   using a mid-scale model or have a dedicated cluster that &rabbit; lives on
   you may need to alter the steps accordingly. To determine which nodes
   &rabbit; is on you can use the <filename>rabbit-status.yml</filename> playbook
   from your &clm;.
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts rabbitmq-status.yml</screen>
  <para>
   <emphasis role="bold">Your entire control plane cluster goes down</emphasis>
  </para>
  <para>
   If you have a scenario where all of your controller nodes went down, either
   manually or via another process such as a power outage, then an
   understanding of how &rabbit; should be brought back up is important. Follow
   these steps to recover &rabbit; on your controller node cluster in these
   cases:
  </para>
  <procedure>
   <step>
    <para>
     The order in which the nodes went down is key here. Locate the last node
     to go down as this will be used as the primary node when bringing the
     &rabbit; cluster back up. You can review the timestamps in the
     <filename>/var/log/rabbitmq</filename> log file to determine what the last
     node was.
    </para>
    <note>
     <para>
      The <literal>primary</literal> status of a node is transient, it only applies for the
      duration that this process is running. There is no long-term distinction
      between any of the nodes in your cluster. The primary node is simply
      the one that owns the &rabbit; configuration database that will be
      synchronized across the cluster.
     </para>
    </note>
   </step>
   <step>
    <para>
     Run the <filename>ardana-start.yml</filename> playbook specifying the primary
     node (aka the last node down determined in the first step):
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-start.yml -e rabbit_primary_hostname=&lt;hostname&gt;</screen>
    <note>
     <para>
      The <literal>&lt;hostname&gt;</literal> value will be the "shortname" for
      your node, as found in the <filename>/etc/hosts</filename> file.
     </para>
    </note>
   </step>
  </procedure>
  <para>
   <emphasis role="bold">If one of your controller nodes goes down</emphasis>
  </para>
  <para>
   First step here is to determine whether the controller that went down is the
   primary &rabbit; host or not. The primary host is going to be the first host
   member in the <literal>FND-RMQ</literal> group in the file below on your
   &clm;:
  </para>
<screen>&prompt.ardana;~/scratch/ansible/next/ardana/ansible/hosts/verb_hosts</screen>
  <para>
   In this example below, <literal>ardana-cp1-c1-m1-mgmt</literal> would be the
   primary:
  </para>
<screen>[FND-RMQ-ccp-cluster1:children]
ardana-cp1-c1-m1-mgmt
ardana-cp1-c1-m2-mgmt
ardana-cp1-c1-m3-mgmt</screen>
  <para>
   If your primary &rabbit; controller node has gone down and you need to bring
   it back up, you can follow these steps. In this playbook you are using the
   <literal>rabbit_primary_hostname</literal> parameter to specify the hostname
   for one of the other controller nodes in your environment hosting &rabbit;,
   which will service as the primary node in the recovery. You will also use
   the <literal>--limit</literal> parameter to specify the controller node you
   are attempting to bring back up.
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-start.yml -e rabbit_primary_hostname=&lt;new_primary_hostname&gt; --limit &lt;hostname_of_node_you_are_bringing_up&gt;</screen>
  <para>
   If the node you need to bring back is <emphasis role="bold">not</emphasis>
   the primary &rabbit; node then you can just run the
   <filename>ardana-start.yml</filename> playbook with the
   <literal>--limit</literal> parameter and your node should recover:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-start.yml --limit &lt;hostname_of_node_you_are_bringing_up&gt;</screen>
  <para>
   <emphasis role="bold">If you are replacing one or more of your controller
   nodes</emphasis>
  </para>
  <para>
   The same general process noted above is used if you are removing or
   replacing one or more of your controller nodes.
  </para>
  <para>
   If your node needs minor hardware repairs, but does not need to be replaced
   with a new node, you should use the <filename>ardana-stop.yml</filename> playbook
   with the <literal>--limit</literal> parameter to stop services on that node
   prior to removing it from the cluster.
  </para>
  <procedure>
   <step>
    <para>
     Log into the &clm;.
    </para>
   </step>
   <step>
    <para>
     Run the <filename>rabbitmq-stop.yml</filename> playbook, specifying the
     hostname of the node you are removing, which will remove the node from the
     &rabbit; cluster:
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts rabbitmq-stop.yml --limit &lt;hostname_of_node_you_are_removing&gt;</screen>
   </step>
   <step>
    <para>
     Run the <filename>ardana-stop.yml</filename> playbook, again specifying the
     hostname of the node you are removing, which will stop the rest of the
     services and prepare it to be removed:
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-stop.yml --limit &lt;hostname_of_node_you_are_removing&gt;</screen>
   </step>
  </procedure>
  <para>
   If your node cannot be repaired and needs to be replaced with another
   baremetal node, any references to the replaced node must be removed from the
   &rabbit; cluster. This is because &rabbit; associates a cookie with each
   node in the cluster which is derived, in part, by the specific hardware.  So
   it is possible to replace a hard drive in a node. However changing a
   motherboard or replacing the node with another node entirely may cause
   &rabbit; to stop working. When this happens, the running &rabbit; cluster
   must be edited from a running &rabbit; node. The following steps show how to
   do this.
  </para>
  <para>
   In this example, controller 3 is the node being replaced with the following
   steps:
  </para>
  <procedure>
   <step>
    <screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible</screen>
   </step>
   <step>
    <para>
     SSH to a running &rabbit; cluster node.
    </para>
    <screen>&prompt.ardana;ssh cloud-cp1-rmq-mysql-m1-mgmt</screen>
   </step>
   <step>
    <para>
     Force the cluster to forget the node you are removing (in this example,
     the controller 3 node).
    </para>
    <screen>&prompt.ardana;sudo rabbitmqctl forget_cluster_node \
rabbit@cloud-cp1-rmq-mysql-m3-mgmt</screen>
   </step>
   <step>
    <para>
     Confirm that the node has been removed.
    </para>
    <screen>&prompt.ardana;sudo rabbitmqctl cluster_status</screen>
   </step>
   <step>
    <para>
     On the replacement node, information and services related to &rabbit; must be removed.
    </para>
    <screen>&prompt.ardana;sudo systemctl stop rabbitmq-server
&prompt.ardana;sudo systemctl stop epmd.socket></screen>
   </step>
   <step>
    <para>
     Verify that the epmd service has stopped (kill it if it is still running).
    </para>
    <screen>&prompt.ardana;ps -eaf | grep epmd.</screen>
   </step>
   <step>
    <para>
     Remove the Mnesia database directory.
    </para>
    <screen>&prompt.ardana;sudo rm -rf /var/lib/rabbitmq/mnesia</screen>
   </step>
   <step>
    <para>
     Restart the &rabbit; server.
    </para>
    <screen>&prompt.ardana;sudo systemctl start rabbitmq-server</screen>
   </step>
   <step>
    <para>
     On the &clm;, run the <filename>ardana-start.yml</filename> playbook.
    </para>
   </step>
  </procedure>
  <para>
   If the node you are removing/replacing is your primary host then when you
   are adding it to your cluster then you will want to ensure that you specify
   a new primary host when doing so, as follows:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-start.yml -e rabbit_primary_hostname=&lt;new_primary_hostname&gt; --limit &lt;hostname_of_node_you_are_adding&gt;</screen>
  <para>
   If the node you are removing/replacing is not your primary host then you can
   add it as follows:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-start.yml --limit &lt;hostname_of_node_you_are_adding&gt;</screen>
  <para>
   <emphasis role="bold">If one of your controller nodes has rebooted or
   temporarily lost power</emphasis>
  </para>
  <para>
   After a single reboot, &rabbit; will not automatically restart. This is by
   design to protect your &rabbit; cluster. To restart &rabbit;, you should
   follow the process below.
  </para>
  <para>
   If the rebooted node was your primary &rabbit; host, you will specify a
   different primary hostname using one of the other nodes in your cluster:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-start.yml -e rabbit_primary_hostname=&lt;new_primary_hostname&gt; --limit &lt;hostname_of_node_that_rebooted&gt;</screen>
  <para>
   If the rebooted node was not the primary &rabbit; host then you can just
   start it back up with this playbook:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-start.yml --limit &lt;hostname_of_node_that_rebooted&gt;</screen>
 </section>
 <section xml:id="recovery">
  <title>Recovering &rabbit;</title>
  <para>
   In this section we will show you how to check the status of &rabbit; and how
   to do a variety of disaster recovery procedures.
  </para>
  <para>
   <emphasis role="bold">Verifying the status of &rabbit;</emphasis>
  </para>
  <para>
   You can verify the status of &rabbit; on each of your controller nodes by
   using the following steps:
  </para>
  <procedure>
   <step>
    <para>
     Log in to the &clm;.
    </para>
   </step>
   <step>
    <para>
     Run the <filename>rabbitmq-status.yml</filename> playbook:
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts rabbitmq-status.yml</screen>
   </step>
   <step>
    <para>
     If all is well, you should see an output similar to the following:
    </para>
<screen>PLAY RECAP ********************************************************************
rabbitmq | status | Check RabbitMQ running hosts in cluster ------------- 2.12s
rabbitmq | status | Check RabbitMQ service running ---------------------- 1.69s
rabbitmq | status | Report status of RabbitMQ --------------------------- 0.32s
-------------------------------------------------------------------------------
Total: ------------------------------------------------------------------ 4.36s
ardana-cp1-c1-m1-mgmt  : ok=2    changed=0    unreachable=0    failed=0
ardana-cp1-c1-m2-mgmt  : ok=2    changed=0    unreachable=0    failed=0
ardana-cp1-c1-m3-mgmt  : ok=2    changed=0    unreachable=0    failed=0</screen>
   </step>
  </procedure>
  <para>
   If one or more of your controller nodes are having &rabbit; issues then
   continue reading, looking for the scenario that best matches yours.
  </para>
  <para>
   <emphasis role="bold">&rabbit; recovery after a small network
   outage</emphasis>
  </para>
  <para>
   In the case of a transient network outage, the version of &rabbit; included
   with &product; is likely to recover automatically without any further
   action needed. However, if yours does not and the
   <filename>rabbitmq-status.yml</filename> playbook is reporting an issue then
   use the scenarios below to resolve your issues.
  </para>
  <para>
   <emphasis role="bold">All of your controller nodes have gone down and using
   other methods have not brought RabbitMQ back up</emphasis>
  </para>
  <para>
   If your &rabbit; cluster is irrecoverable and you need rapid service
   recovery because other methods either cannot resolve the issue or you do not
   have time to investigate more nuanced approaches then we provide a disaster
   recovery playbook for you to use. This playbook will tear down and reset any
   &rabbit; services. This does have an extreme effect on your services. The
   process will ensure that the &rabbit; cluster is recreated.
  </para>
  <procedure>
   <step>
    <para>
     Log in to your &clm;.
    </para>
   </step>
   <step>
    <para>
     Run the &rabbit; disaster recovery playbook. This generally takes around
     two minutes.
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts rabbitmq-disaster-recovery.yml</screen>
   </step>
   <step>
    <para>
     Run the reconfigure playbooks for both cinder (Block Storage) and heat
     (Orchestration), if those services are present in your cloud. These
     services are affected when the fan-out queues are not recovered correctly.
     The reconfigure generally takes around five minutes.
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts cinder-reconfigure.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts heat-reconfigure.yml
&prompt.ardana;ansible-playbook -i hosts/verb_hosts kronos-server-configure.yml</screen>
   </step>
   <step>
    <para>
     If you need to do a safe recovery of all the services in your environment
     then you can use this playbook. This is a more lengthy process as all
     services are inspected.
    </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts ardana-reconfigure.yml</screen>
   </step>
  </procedure>
  <para>
   <emphasis role="bold">One of your controller nodes has gone down and using
   other methods have not brought &rabbit; back up</emphasis>
  </para>
  <para>
   This disaster recovery procedure has the same caveats as the preceding one,
   but the steps differ.
  </para>
  <para>
   If your primary &rabbit; controller node has gone down and you need to
   perform a disaster recovery, use this playbook from your &clm;:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts rabbitmq-disaster-recovery.yml -e rabbit_primary_hostname=&lt;new_primary_hostname&gt; --limit &lt;hostname_of_node_that_needs_recovered&gt;</screen>
  <para>
   If the controller node is not your primary, you can use this playbook:
  </para>
<screen>&prompt.ardana;cd ~/scratch/ansible/next/ardana/ansible
&prompt.ardana;ansible-playbook -i hosts/verb_hosts rabbitmq-disaster-recovery.yml --limit &lt;hostname_of_node_that_needs_recovered&gt;</screen>
  <para>
   No reconfigure playbooks are needed because all of the fan-out exchanges are
   maintained by the running members of your &rabbit; cluster.
  </para>
 </section>
</section>
