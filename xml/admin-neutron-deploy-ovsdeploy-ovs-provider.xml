<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.1" xml:id="deploy-ovs-provider">
  <title>Open vSwitch: Provider networks</title>
  <para>This architecture example provides layer-2 connectivity between instances
            and the physical network infrastructure using VLAN (802.1q) tagging. It
            supports one untagged (flat) network and up to 4095 tagged (VLAN) networks.
            The actual quantity of VLAN networks depends on the physical network
            infrastructure. For more information on provider networks, see
            <xref linkend="intro-os-networking-provider"/>.</para>
  <warning>
    <para>Linux distributions often package older releases of Open vSwitch that can
                introduce issues during operation with the Networking service. We recommend
                using at least the latest long-term stable (LTS) release of Open vSwitch
                for the best experience and support from Open vSwitch. See
                <link xlink:href="http://www.openvswitch.org"/> for available releases and the
                <link xlink:href="https://github.com/openvswitch/ovs/blob/master/INSTALL.md">installation instructions</link> for</para>
  </warning>
  <section>
    <title>Prerequisites</title>
    <para>One controller node with the following components:</para>
    <itemizedlist>
      <listitem>
        <para>Two network interfaces: management and provider.</para>
      </listitem>
      <listitem>
        <para>OpenStack Networking server service and ML2 plug-in.</para>
      </listitem>
    </itemizedlist>
    <para>Two compute nodes with the following components:</para>
    <itemizedlist>
      <listitem>
        <para>Two network interfaces: management and provider.</para>
      </listitem>
      <listitem>
        <para>OpenStack Networking Open vSwitch (OVS) layer-2 agent, DHCP agent, metadata
                        agent, and any dependencies including OVS.</para>
      </listitem>
    </itemizedlist>
    <note>
      <para>Larger deployments typically deploy the DHCP and metadata agents on a
                    subset of compute nodes to increase performance and redundancy. However,
                    too many agents can overwhelm the message bus. Also, to further simplify
                    any deployment, you can omit the metadata agent and use a configuration
                    drive to provide metadata to instances.</para>
    </note>
  </section>
  <section>
    <title>Architecture</title>
    <informalfigure>
      <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="deploy-ovs-provider-overview.png"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="deploy-ovs-provider-overview.png"/>
        </imageobject>
      </mediaobject>
    </informalfigure>
    <para>The following figure shows components and connectivity for one untagged
                (flat) network. In this particular case, the instance resides on the
                same compute node as the DHCP agent for the network. If the DHCP agent
                resides on another compute node, the latter only contains a DHCP namespace
                with a port on the OVS integration bridge.</para>
    <informalfigure>
      <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="deploy-ovs-provider-compconn1.png"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="deploy-ovs-provider-compconn1.png"/>
        </imageobject>
      </mediaobject>
    </informalfigure>
    <para>The following figure describes virtual connectivity among components for
                two tagged (VLAN) networks. Essentially, all networks use a single OVS
                integration bridge with different internal VLAN tags. The internal VLAN
                tags almost always differ from the network VLAN assignment in the Networking
                service. Similar to the untagged network case, the DHCP agent may reside on
                a different compute node.</para>
    <informalfigure>
      <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="deploy-ovs-provider-compconn2.png"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="deploy-ovs-provider-compconn2.png"/>
        </imageobject>
      </mediaobject>
    </informalfigure>
    <note>
      <para>These figures omit the controller node because it does not handle instance
                    network traffic.</para>
    </note>
  </section>
  <section>
    <title>Example configuration</title>
    <para>Use the following example configuration as a template to deploy provider
                networks in your environment.</para>
    <section>
      <title>Controller node</title>
      <procedure>
        <step>
          <para>Install the Networking service components that provide the
                            <literal>neutron-server</literal> service and ML2 plug-in.</para>
        </step>
        <step>
          <para>In the <literal>neutron.conf</literal> file:</para>
          <itemizedlist>
            <listitem>
              <para>Configure common options:</para>
              <screen language="ini">[DEFAULT]
core_plugin = ml2
auth_strategy = keystone

[database]
# ...

[keystone_authtoken]
# ...

[nova]
# ...

[agent]
# ...</screen>
              <para>See the <link xlink:href="https://docs.openstack.org">Installation Tutorials and Guides</link> and
                                    <link xlink:href="https://docs.openstack.org">Configuration Reference</link> for your OpenStack
                                    release to obtain the appropriate additional configuration for the
                                    <literal>[DEFAULT]</literal>, <literal>[database]</literal>, <literal>[keystone_authtoken]</literal>, <literal>[nova]</literal>, and
                                    <literal>[agent]</literal> sections.</para>
            </listitem>
            <listitem>
              <para>Disable service plug-ins because provider networks do not require
                                    any. However, this breaks portions of the dashboard that manage
                                    the Networking service. See the
                                    <link xlink:href="https://docs.openstack.org/project-install-guide/ocata">Ocata Install Tutorials and Guides</link> for more
                                    information.</para>
              <screen language="ini">[DEFAULT]
service_plugins =</screen>
            </listitem>
            <listitem>
              <para>Enable two DHCP agents per network so both compute nodes can
                                    provide DHCP service provider networks.</para>
              <screen language="ini">[DEFAULT]
dhcp_agents_per_network = 2</screen>
            </listitem>
            <listitem>
              <para>If necessary, <xref linkend="config-mtu"/>.</para>
            </listitem>
          </itemizedlist>
        </step>
        <step>
          <para>In the <literal>ml2_conf.ini</literal> file:</para>
          <itemizedlist>
            <listitem>
              <para>Configure drivers and network types:</para>
              <screen language="ini">[ml2]
type_drivers = flat,vlan
tenant_network_types =
mechanism_drivers = openvswitch
extension_drivers = port_security</screen>
            </listitem>
            <listitem>
              <para>Configure network mappings:</para>
              <screen language="ini">[ml2_type_flat]
flat_networks = provider

[ml2_type_vlan]
network_vlan_ranges = provider</screen>
              <note>
                <para>The <literal>tenant_network_types</literal> option contains no value because the
                                        architecture does not support self-service networks.</para>
              </note>
              <note>
                <para>The <literal>provider</literal> value in the <literal>network_vlan_ranges</literal> option lacks VLAN
                                        ID ranges to support use of arbitrary VLAN IDs.</para>
              </note>
            </listitem>
          </itemizedlist>
        </step>
        <step>
          <para>Populate the database.</para>
          <screen language="console"># su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf \
  --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron</screen>
        </step>
        <step>
          <para>Start the following services:</para>
          <itemizedlist>
            <listitem>
              <para>Server</para>
            </listitem>
          </itemizedlist>
        </step>
      </procedure>
    </section>
    <section>
      <title>Compute nodes</title>
      <procedure>
        <step>
          <para>Install the Networking service OVS layer-2 agent, DHCP agent, and
                            metadata agent.</para>
        </step>
        <step>
          <para>Install OVS.</para>
        </step>
        <step>
          <para>In the <literal>neutron.conf</literal> file, configure common options:</para>
          <screen language="ini">[DEFAULT]
core_plugin = ml2
auth_strategy = keystone

[database]
# ...

[keystone_authtoken]
# ...

[nova]
# ...

[agent]
# ...</screen>
          <para>See the <link xlink:href="https://docs.openstack.org">Installation Tutorials and Guides</link> and
                            <link xlink:href="https://docs.openstack.org">Configuration Reference</link> for your OpenStack
                            release to obtain the appropriate additional configuration for the
                            <literal>[DEFAULT]</literal>, <literal>[database]</literal>, <literal>[keystone_authtoken]</literal>, <literal>[nova]</literal>, and
                            <literal>[agent]</literal> sections.</para>
        </step>
        <step>
          <para>In the <literal>openvswitch_agent.ini</literal> file, configure the OVS agent:</para>
          <screen language="ini">[ovs]
bridge_mappings = provider:br-provider

[securitygroup]
firewall_driver = iptables_hybrid</screen>
        </step>
        <step>
          <para>In the <literal>dhcp_agent.ini</literal> file, configure the DHCP agent:</para>
          <screen language="ini">[DEFAULT]
interface_driver = openvswitch
enable_isolated_metadata = True
force_metadata = True</screen>
          <note>
            <para>The <literal>force_metadata</literal> option forces the DHCP agent to provide
                                a host route to the metadata service on <literal>169.254.169.254</literal>
                                regardless of whether the subnet contains an interface on a
                                router, thus maintaining similar and predictable metadata behavior
                                among subnets.</para>
          </note>
        </step>
        <step>
          <para>In the <literal>metadata_agent.ini</literal> file, configure the metadata agent:</para>
          <screen language="ini">[DEFAULT]
nova_metadata_host = controller
metadata_proxy_shared_secret = METADATA_SECRET</screen>
          <para>The value of <literal>METADATA_SECRET</literal> must match the value of the same option
                            in the <literal>[neutron]</literal> section of the <literal>nova.conf</literal> file.</para>
        </step>
        <step>
          <para>Start the following services:</para>
          <itemizedlist>
            <listitem>
              <para>OVS</para>
            </listitem>
          </itemizedlist>
        </step>
        <step>
          <para>Create the OVS provider bridge <literal>br-provider</literal>:</para>
          <screen language="console">$ ovs-vsctl add-br br-provider</screen>
        </step>
        <step>
          <para>Add the provider network interface as a port on the OVS provider
                            bridge <literal>br-provider</literal>:</para>
          <screen language="console">$ ovs-vsctl add-port br-provider PROVIDER_INTERFACE</screen>
          <para>Replace <literal>PROVIDER_INTERFACE</literal> with the name of the underlying interface
                            that handles provider networks. For example, <literal>eth1</literal>.</para>
        </step>
        <step>
          <para>Start the following services:</para>
          <itemizedlist>
            <listitem>
              <para>OVS agent</para>
            </listitem>
            <listitem>
              <para>DHCP agent</para>
            </listitem>
            <listitem>
              <para>Metadata agent</para>
            </listitem>
          </itemizedlist>
        </step>
      </procedure>
    </section>
    <section>
      <title>Verify service operation</title>
      <procedure>
        <step>
          <para>Source the administrative project credentials.</para>
        </step>
        <step>
          <para>Verify presence and operation of the agents:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack network agent list
+--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+
| ID                                   | Agent Type         | Host     | Availability Zone | Alive | State | Binary                    |
+--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+
| 1236bbcb-e0ba-48a9-80fc-81202ca4fa51 | Metadata agent     | compute2 |                   | True  | UP    | neutron-metadata-agent    |
| 457d6898-b373-4bb3-b41f-59345dcfb5c5 | Open vSwitch agent | compute2 |                   | True  | UP    | neutron-openvswitch-agent |
| 71f15e84-bc47-4c2a-b9fb-317840b2d753 | DHCP agent         | compute2 | nova              | True  | UP    | neutron-dhcp-agent        |
| a6c69690-e7f7-4e56-9831-1282753e5007 | Metadata agent     | compute1 |                   | True  | UP    | neutron-metadata-agent    |
| af11f22f-a9f4-404f-9fd8-cd7ad55c0f68 | DHCP agent         | compute1 | nova              | True  | UP    | neutron-dhcp-agent        |
| bcfc977b-ec0e-4ba9-be62-9489b4b0e6f1 | Open vSwitch agent | compute1 |                   | True  | UP    | neutron-openvswitch-agent |
+--------------------------------------+--------------------+----------+-------------------+-------+-------+---------------------------+</screen>
        </step>
      </procedure>
    </section>
    <section>
      <title>Create initial networks</title>
      <para>The configuration supports one flat or multiple VLAN provider networks. For
                    simplicity, the following procedure creates one flat provider network.</para>
      <procedure>
        <step>
          <para>Source the administrative project credentials.</para>
        </step>
        <step>
          <para>Create a flat network.</para>
          <screen language="console">$ openstack network create --share --provider-physical-network provider \
  --provider-network-type flat provider1
+---------------------------+-----------+-
| Field                     | Value     |
+---------------------------+-----------+
| admin_state_up            | UP        |
| mtu                       | 1500      |
| name                      | provider1 |
| port_security_enabled     | True      |
| provider:network_type     | flat      |
| provider:physical_network | provider  |
| provider:segmentation_id  | None      |
| router:external           | Internal  |
| shared                    | True      |
| status                    | ACTIVE    |
+---------------------------+-----------+</screen>
          <note>
            <para>The <literal>share</literal> option allows any project to use this network. To limit
                                access to provider networks, see <xref linkend="config-rbac"/>.</para>
          </note>
          <note>
            <para>To create a VLAN network instead of a flat network, change
                                <literal>--provider:network_type flat</literal> to <literal>--provider-network-type vlan</literal>
                                and add <literal>--provider-segment</literal> with a value referencing
                                the VLAN ID.</para>
          </note>
        </step>
        <step>
          <para>Create a IPv4 subnet on the provider network.</para>
          <screen language="console">$ openstack subnet create --subnet-range 203.0.113.0/24 --gateway 203.0.113.1 \
  --network provider1 --allocation-pool start=203.0.113.11,end=203.0.113.250 \
  --dns-nameserver 8.8.4.4 provider1-v4
+-------------------+----------------------------+
| Field             | Value                      |
+-------------------+----------------------------+
| allocation_pools  | 203.0.113.11-203.0.113.250 |
| cidr              | 203.0.113.0/24             |
| dns_nameservers   | 8.8.4.4                    |
| enable_dhcp       | True                       |
| gateway_ip        | 203.0.113.1                |
| ip_version        | 4                          |
| name              | provider1-v4               |
+-------------------+----------------------------+</screen>
          <important>
            <para>Enabling DHCP causes the Networking service to provide DHCP which can
                                interfere with existing DHCP services on the physical network
                                infrastructure. Use the <literal>--no-dhcp</literal> option to have the subnet managed
                                by existing DHCP services.</para>
          </important>
        </step>
        <step>
          <para>Create a IPv6 subnet on the provider network.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack subnet create --subnet-range fd00:203:0:113::/64 --gateway fd00:203:0:113::1 \
  --ip-version 6 --ipv6-address-mode slaac --network provider1 \
  --dns-nameserver 2001:4860:4860::8844 provider1-v6
+-------------------+------------------------------------------------------+
| Field             | Value                                                |
+-------------------+------------------------------------------------------+
| allocation_pools  | fd00:203:0:113::2-fd00:203:0:113:ffff:ffff:ffff:ffff |
| cidr              | fd00:203:0:113::/64                                  |
| dns_nameservers   | 2001:4860:4860::8844                                 |
| enable_dhcp       | True                                                 |
| gateway_ip        | fd00:203:0:113::1                                    |
| ip_version        | 6                                                    |
| ipv6_address_mode | slaac                                                |
| ipv6_ra_mode      | None                                                 |
| name              | provider1-v6                                         |
+-------------------+------------------------------------------------------+</screen>
          <note>
            <para>The Networking service uses the layer-3 agent to provide router
                                advertisement. Provider networks rely on physical network infrastructure
                                for layer-3 services rather than the layer-3 agent. Thus, the physical
                                network infrastructure must provide router advertisement on provider
                                networks for proper operation of IPv6.</para>
          </note>
        </step>
      </procedure>
    </section>
    <section>
      <title>Verify network operation</title>
      <procedure>
        <step>
          <para>On each compute node, verify creation of the <literal>qdhcp</literal> namespace.</para>
          <screen language="console"># ip netns
qdhcp-8b868082-e312-4110-8627-298109d4401c</screen>
        </step>
        <step>
          <para>Source a regular (non-administrative) project credentials.</para>
        </step>
        <step>
          <para>Create the appropriate security group rules to allow <literal>ping</literal> and SSH
                            access instances using the network.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule create --proto icmp default
+------------------+-----------+
| Field            | Value     |
+------------------+-----------+
| direction        | ingress   |
| ethertype        | IPv4      |
| protocol         | icmp      |
| remote_ip_prefix | 0.0.0.0/0 |
+------------------+-----------+

$ openstack security group rule create --ethertype IPv6 --proto ipv6-icmp default
+-----------+-----------+
| Field     | Value     |
+-----------+-----------+
| direction | ingress   |
| ethertype | IPv6      |
| protocol  | ipv6-icmp |
+-----------+-----------+

$ openstack security group rule create --proto tcp --dst-port 22 default
+------------------+-----------+
| Field            | Value     |
+------------------+-----------+
| direction        | ingress   |
| ethertype        | IPv4      |
| port_range_max   | 22        |
| port_range_min   | 22        |
| protocol         | tcp       |
| remote_ip_prefix | 0.0.0.0/0 |
+------------------+-----------+

$ openstack security group rule create --ethertype IPv6 --proto tcp --dst-port 22 default
+------------------+-----------+
| Field            | Value     |
+------------------+-----------+
| direction        | ingress   |
| ethertype        | IPv6      |
| port_range_max   | 22        |
| port_range_min   | 22        |
| protocol         | tcp       |
+------------------+-----------+</screen>
        </step>
        <step>
          <para>Launch an instance with an interface on the provider network. For example,
                            a CirrOS image using flavor ID 1.</para>
          <screen language="console">$ openstack server create --flavor 1 --image cirros \
  --nic net-id=NETWORK_ID provider-instance1</screen>
          <para>Replace <literal>NETWORK_ID</literal> with the ID of the provider network.</para>
        </step>
        <step>
          <para>Determine the IPv4 and IPv6 addresses of the instance.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack server list
+--------------------------------------+--------------------+--------+------------------------------------------------------------+------------+
| ID                                   | Name               | Status | Networks                                                   | Image Name |
+--------------------------------------+--------------------+--------+------------------------------------------------------------+------------+
| 018e0ae2-b43c-4271-a78d-62653dd03285 | provider-instance1 | ACTIVE | provider1=203.0.113.13, fd00:203:0:113:f816:3eff:fe58:be4e | cirros     |
+--------------------------------------+--------------------+--------+------------------------------------------------------------+------------+</screen>
        </step>
        <step>
          <para>On the controller node or any host with access to the provider network,
                            <literal>ping</literal> the IPv4 and IPv6 addresses of the instance.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ping -c 4 203.0.113.13
PING 203.0.113.13 (203.0.113.13) 56(84) bytes of data.
64 bytes from 203.0.113.13: icmp_req=1 ttl=63 time=3.18 ms
64 bytes from 203.0.113.13: icmp_req=2 ttl=63 time=0.981 ms
64 bytes from 203.0.113.13: icmp_req=3 ttl=63 time=1.06 ms
64 bytes from 203.0.113.13: icmp_req=4 ttl=63 time=0.929 ms

--- 203.0.113.13 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3002ms
rtt min/avg/max/mdev = 0.929/1.539/3.183/0.951 ms

$ ping6 -c 4 fd00:203:0:113:f816:3eff:fe58:be4e
PING fd00:203:0:113:f816:3eff:fe58:be4e(fd00:203:0:113:f816:3eff:fe58:be4e) 56 data bytes
64 bytes from fd00:203:0:113:f816:3eff:fe58:be4e icmp_seq=1 ttl=64 time=1.25 ms
64 bytes from fd00:203:0:113:f816:3eff:fe58:be4e icmp_seq=2 ttl=64 time=0.683 ms
64 bytes from fd00:203:0:113:f816:3eff:fe58:be4e icmp_seq=3 ttl=64 time=0.762 ms
64 bytes from fd00:203:0:113:f816:3eff:fe58:be4e icmp_seq=4 ttl=64 time=0.486 ms

--- fd00:203:0:113:f816:3eff:fe58:be4e ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 2999ms
rtt min/avg/max/mdev = 0.486/0.796/1.253/0.282 ms</screen>
        </step>
        <step>
          <para>Obtain access to the instance.</para>
        </step>
        <step>
          <para>Test IPv4 and IPv6 connectivity to the Internet or other external network.</para>
        </step>
      </procedure>
    </section>
  </section>
  <section>
    <title>Network traffic flow</title>
    <para>The following sections describe the flow of network traffic in several
                common scenarios. <emphasis>North-south</emphasis> network traffic travels between an instance
                and external network such as the Internet. <emphasis>East-west</emphasis> network traffic
                travels between instances on the same or different networks. In all scenarios,
                the physical network infrastructure handles switching and routing among
                provider networks and external networks such as the Internet. Each case
                references one or more of the following components:</para>
    <itemizedlist>
      <listitem>
        <para>Provider network 1 (VLAN)</para>
        <itemizedlist>
          <listitem>
            <para>VLAN ID 101 (tagged)</para>
          </listitem>
          <listitem>
            <para>IP address ranges 203.0.113.0/24 and fd00:203:0:113::/64</para>
          </listitem>
          <listitem>
            <para>Gateway (via physical network infrastructure)</para>
            <itemizedlist>
              <listitem>
                <para>IP addresses 203.0.113.1 and fd00:203:0:113:0::1</para>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
      </listitem>
      <listitem>
        <para>Provider network 2 (VLAN)</para>
        <itemizedlist>
          <listitem>
            <para>VLAN ID 102 (tagged)</para>
          </listitem>
          <listitem>
            <para>IP address range 192.0.2.0/24 and fd00:192:0:2::/64</para>
          </listitem>
          <listitem>
            <para>Gateway</para>
            <itemizedlist>
              <listitem>
                <para>IP addresses 192.0.2.1 and fd00:192:0:2::1</para>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
      </listitem>
      <listitem>
        <para>Instance 1</para>
        <itemizedlist>
          <listitem>
            <para>IP addresses 203.0.113.101 and fd00:203:0:113:0::101</para>
          </listitem>
        </itemizedlist>
      </listitem>
      <listitem>
        <para>Instance 2</para>
        <itemizedlist>
          <listitem>
            <para>IP addresses 192.0.2.101 and fd00:192:0:2:0::101</para>
          </listitem>
        </itemizedlist>
      </listitem>
    </itemizedlist>
    <section>
      <title>North-south</title>
      <itemizedlist>
        <listitem>
          <para>The instance resides on compute node 1 and uses provider network 1.</para>
        </listitem>
        <listitem>
          <para>The instance sends a packet to a host on the Internet.</para>
        </listitem>
      </itemizedlist>
      <para>The following steps involve compute node 1.</para>
      <procedure>
        <step>
          <para>The instance interface (1) forwards the packet to the security group
                            bridge instance port (2) via <literal>veth</literal> pair.</para>
        </step>
        <step>
          <para>Security group rules (3) on the security group bridge handle firewalling
                            and connection tracking for the packet.</para>
        </step>
        <step>
          <para>The security group bridge OVS port (4) forwards the packet to the OVS
                            integration bridge security group port (5) via <literal>veth</literal> pair.</para>
        </step>
        <step>
          <para>The OVS integration bridge adds an internal VLAN tag to the packet.</para>
        </step>
        <step>
          <para>The OVS integration bridge <literal>int-br-provider</literal> patch port (6) forwards
                            the packet to the OVS provider bridge <literal>phy-br-provider</literal> patch port (7).</para>
        </step>
        <step>
          <para>The OVS provider bridge swaps the internal VLAN tag with actual VLAN tag
                            101.</para>
        </step>
        <step>
          <para>The OVS provider bridge provider network port (8) forwards the packet to
                            the physical network interface (9).</para>
        </step>
        <step>
          <para>The physical network interface forwards the packet to the physical
                            network infrastructure switch (10).</para>
        </step>
      </procedure>
      <para>The following steps involve the physical network infrastructure:</para>
      <procedure>
        <step>
          <para>The switch removes VLAN tag 101 from the packet and forwards it to the
                            router (11).</para>
        </step>
        <step>
          <para>The router routes the packet from the provider network (12) to the
                            external network (13) and forwards the packet to the switch (14).</para>
        </step>
        <step>
          <para>The switch forwards the packet to the external network (15).</para>
        </step>
        <step>
          <para>The external network (16) receives the packet.</para>
        </step>
      </procedure>
      <informalfigure>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="deploy-ovs-provider-flowns1.png"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="deploy-ovs-provider-flowns1.png"/>
          </imageobject>
        </mediaobject>
      </informalfigure>
      <note>
        <para>Return traffic follows similar steps in reverse.</para>
      </note>
    </section>
    <section>
      <title>East-west scenario 1: Instances on the same network</title>
      <para>Instances on the same network communicate directly between compute nodes
                    containing those instances.</para>
      <itemizedlist>
        <listitem>
          <para>Instance 1 resides on compute node 1 and uses provider network 1.</para>
        </listitem>
        <listitem>
          <para>Instance 2 resides on compute node 2 and uses provider network 1.</para>
        </listitem>
        <listitem>
          <para>Instance 1 sends a packet to instance 2.</para>
        </listitem>
      </itemizedlist>
      <para>The following steps involve compute node 1:</para>
      <procedure>
        <step>
          <para>The instance 1 interface (1) forwards the packet to the security group
                            bridge instance port (2) via <literal>veth</literal> pair.</para>
        </step>
        <step>
          <para>Security group rules (3) on the security group bridge handle firewalling
                            and connection tracking for the packet.</para>
        </step>
        <step>
          <para>The security group bridge OVS port (4) forwards the packet to the OVS
                            integration bridge security group port (5) via <literal>veth</literal> pair.</para>
        </step>
        <step>
          <para>The OVS integration bridge adds an internal VLAN tag to the packet.</para>
        </step>
        <step>
          <para>The OVS integration bridge <literal>int-br-provider</literal> patch port (6) forwards
                            the packet to the OVS provider bridge <literal>phy-br-provider</literal> patch port (7).</para>
        </step>
        <step>
          <para>The OVS provider bridge swaps the internal VLAN tag with actual VLAN tag
                            101.</para>
        </step>
        <step>
          <para>The OVS provider bridge provider network port (8) forwards the packet to
                            the physical network interface (9).</para>
        </step>
        <step>
          <para>The physical network interface forwards the packet to the physical
                            network infrastructure switch (10).</para>
        </step>
      </procedure>
      <para>The following steps involve the physical network infrastructure:</para>
      <procedure>
        <step>
          <para>The switch forwards the packet from compute node 1 to compute node 2 (11).</para>
        </step>
      </procedure>
      <para>The following steps involve compute node 2:</para>
      <procedure>
        <step>
          <para>The physical network interface (12) forwards the packet to the OVS
                            provider bridge provider network port (13).</para>
        </step>
        <step>
          <para>The OVS provider bridge <literal>phy-br-provider</literal> patch port (14) forwards the
                            packet to the OVS integration bridge <literal>int-br-provider</literal> patch port (15).</para>
        </step>
        <step>
          <para>The OVS integration bridge swaps the actual VLAN tag 101 with the internal
                            VLAN tag.</para>
        </step>
        <step>
          <para>The OVS integration bridge security group port (16) forwards the packet
                            to the security group bridge OVS port (17).</para>
        </step>
        <step>
          <para>Security group rules (18) on the security group bridge handle firewalling
                            and connection tracking for the packet.</para>
        </step>
        <step>
          <para>The security group bridge instance port (19) forwards the packet to the
                            instance 2 interface (20) via <literal>veth</literal> pair.</para>
        </step>
      </procedure>
      <informalfigure>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="deploy-ovs-provider-flowew1.png"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="deploy-ovs-provider-flowew1.png"/>
          </imageobject>
        </mediaobject>
      </informalfigure>
      <note>
        <para>Return traffic follows similar steps in reverse.</para>
      </note>
    </section>
    <section>
      <title>East-west scenario 2: Instances on different networks</title>
      <para>Instances communicate via router on the physical network infrastructure.</para>
      <itemizedlist>
        <listitem>
          <para>Instance 1 resides on compute node 1 and uses provider network 1.</para>
        </listitem>
        <listitem>
          <para>Instance 2 resides on compute node 1 and uses provider network 2.</para>
        </listitem>
        <listitem>
          <para>Instance 1 sends a packet to instance 2.</para>
        </listitem>
      </itemizedlist>
      <note>
        <para>Both instances reside on the same compute node to illustrate how VLAN
                        tagging enables multiple logical layer-2 networks to use the same
                        physical layer-2 network.</para>
      </note>
      <para>The following steps involve the compute node:</para>
      <procedure>
        <step>
          <para>The instance 1 interface (1) forwards the packet to the security group
                            bridge instance port (2) via <literal>veth</literal> pair.</para>
        </step>
        <step>
          <para>Security group rules (3) on the security group bridge handle firewalling
                            and connection tracking for the packet.</para>
        </step>
        <step>
          <para>The security group bridge OVS port (4) forwards the packet to the OVS
                            integration bridge security group port (5) via <literal>veth</literal> pair.</para>
        </step>
        <step>
          <para>The OVS integration bridge adds an internal VLAN tag to the packet.</para>
        </step>
        <step>
          <para>The OVS integration bridge <literal>int-br-provider</literal> patch port (6) forwards
                            the packet to the OVS provider bridge <literal>phy-br-provider</literal> patch port (7).</para>
        </step>
        <step>
          <para>The OVS provider bridge swaps the internal VLAN tag with actual VLAN tag
                            101.</para>
        </step>
        <step>
          <para>The OVS provider bridge provider network port (8) forwards the packet to
                            the physical network interface (9).</para>
        </step>
        <step>
          <para>The physical network interface forwards the packet to the physical
                            network infrastructure switch (10).</para>
        </step>
      </procedure>
      <para>The following steps involve the physical network infrastructure:</para>
      <procedure>
        <step>
          <para>The switch removes VLAN tag 101 from the packet and forwards it to the
                            router (11).</para>
        </step>
        <step>
          <para>The router routes the packet from provider network 1 (12) to provider
                            network 2 (13).</para>
        </step>
        <step>
          <para>The router forwards the packet to the switch (14).</para>
        </step>
        <step>
          <para>The switch adds VLAN tag 102 to the packet and forwards it to compute
                            node 1 (15).</para>
        </step>
      </procedure>
      <para>The following steps involve the compute node:</para>
      <procedure>
        <step>
          <para>The physical network interface (16) forwards the packet to the OVS
                            provider bridge provider network port (17).</para>
        </step>
        <step>
          <para>The OVS provider bridge <literal>phy-br-provider</literal> patch port (18) forwards the
                            packet to the OVS integration bridge <literal>int-br-provider</literal> patch port (19).</para>
        </step>
        <step>
          <para>The OVS integration bridge swaps the actual VLAN tag 102 with the internal
                            VLAN tag.</para>
        </step>
        <step>
          <para>The OVS integration bridge security group port (20) removes the internal
                            VLAN tag and forwards the packet to the security group bridge OVS port
                            (21).</para>
        </step>
        <step>
          <para>Security group rules (22) on the security group bridge handle firewalling
                            and connection tracking for the packet.</para>
        </step>
        <step>
          <para>The security group bridge instance port (23) forwards the packet to the
                            instance 2 interface (24) via <literal>veth</literal> pair.</para>
        </step>
      </procedure>
      <informalfigure>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="deploy-ovs-provider-flowew2.png"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="deploy-ovs-provider-flowew2.png"/>
          </imageobject>
        </mediaobject>
      </informalfigure>
      <note>
        <para>Return traffic follows similar steps in reverse.</para>
      </note>
    </section>
  </section>
</section>
