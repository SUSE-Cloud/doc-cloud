<?xml version="1.0"?>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:lang="en">
  <title>OpenStack Administrator Guide</title>
  <info>
    <abstract>
      <title>Abstract</title>
      <para>OpenStack offers open source software for OpenStack administrators to
manage and troubleshoot an OpenStack cloud.</para>
      <para>This guide documents OpenStack Newton and Mitaka releases.</para>
    </abstract>
    <productname>SUSE OpenStack Cloud</productname>
    <productnumber>7</productnumber>
    <legalnotice role="cc-by">
 <para>Except where otherwise noted, this document is licensed under 
  <emphasis role="bold">Creative Commons Attribution 3.0 License </emphasis>: 
  <link xlink:href="http://creativecommons.org/licenses/by/3.0/legalcode"/>
 </para>
</legalnotice>
  </info>
  <chapter version="5.0">
<!-- No ID here! -->

 <title>Documentation Conventions</title>

 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:maintainer>taroth</dm:maintainer>
   <dm:status/>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>no</dm:translation>
   <dm:languages/>
  </dm:docmanager>
 </info>

 <para>
  The following notices and typographical conventions are used
  in this documentation:
 </para>

   <warning>
   <para>
    Vital information you must be aware of before proceeding. Warns you about
    security issues, potential loss of data, damage to hardware, or physical
    hazards.
   </para>
  </warning>
  <important>
   <para>
    Important information you should be aware of before proceeding.
   </para>
  </important>
  <note>
   <para>
    Additional information, for example about differences in software
    versions.
   </para>
  </note>
  <tip>
   <para>
    Helpful information, like a guideline or a piece of practical advice.
   </para>
  </tip>
<screen><prompt>tux &gt; </prompt><command>command</command></screen>
   <para>
    Commands than can be run by any user, including the <systemitem class="username">root</systemitem> user.
   </para>
<screen><prompt role="root">root # </prompt><command>command</command></screen>
   <para>
    Commands that must be run with <systemitem class="username">root</systemitem> privileges. In often you
    can also prefix these commands with the <command>sudo</command> command to
    run them.
   </para>
</chapter>
  <chapter>
    <title>Get started with OpenStack</title>
    <info/>
    <para>The OpenStack project is an open source cloud computing platform for all
types of clouds, which aims to be simple to implement, massively
scalable, and feature rich. Developers and cloud computing technologists
from around the world create the OpenStack project.</para>
    <para>OpenStack provides an <xref linkend="term-infrastructure-as-a-service-iaas"/> solution
through a set of interrelated services. Each service offers an
<xref linkend="term-application-programming-interface-api"/> that facilitates this
integration. Depending on your needs, you can install some or all
services.</para>
    <para>The following table describes the OpenStack services that make up the
OpenStack architecture:</para>
    <table>
      <title>OpenStack Services</title>
      <tgroup cols="3">
        <colspec colname="c1" colwidth="16.7*"/>
        <colspec colname="c2" colwidth="16.7*"/>
        <colspec colname="c3" colwidth="66.7*"/>
        <thead>
          <row>
            <entry>
              <para>Service</para>
            </entry>
            <entry>
              <para>Project name</para>
            </entry>
            <entry>
              <para>Description</para>
            </entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/horizon">Dashboard</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/horizon/">Horizon</link>
              </para>
            </entry>
            <entry>
              <para>Provides a web-based self-service portal to interact with underlying
OpenStack services, such as launching an instance, assigning IP
addresses and configuring access controls.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/nova">Compute</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/nova/">Nova</link>
              </para>
            </entry>
            <entry>
              <para>Manages the lifecycle of compute instances in an OpenStack environment.
Responsibilities include spawning, scheduling and decommissioning of
virtual machines on demand.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/neutron">Networking</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/neutron/">Neutron</link>
              </para>
            </entry>
            <entry>
              <para>Enables Network-Connectivity-as-a-Service for other OpenStack services,
such as OpenStack Compute. Provides an API for users to define networks
and the attachments into them. Has a pluggable architecture that
supports many popular networking vendors and technologies.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/swift">Object Storage</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/swift/">Swift</link>
              </para>
            </entry>
            <entry>
              <para>Stores and retrieves arbitrary unstructured data objects via a RESTful,
HTTP based API. It is highly fault tolerant with its data replication
and scale-out architecture. Its implementation is not like a file server
with mountable directories. In this case, it writes objects and files to
multiple drives, ensuring the data is replicated across a server
cluster.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/cinder">Block Storage</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/cinder/">Cinder</link>
              </para>
            </entry>
            <entry>
              <para>Provides persistent block storage to running instances. Its pluggable
driver architecture facilitates the creation and management of block
storage devices.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/keystone">Identity service</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/keystone/">Keystone</link>
              </para>
            </entry>
            <entry>
              <para>Provides an authentication and authorization service for other
OpenStack services. Provides a catalog of endpoints for all
OpenStack services.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/glance">Image service</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/glance/">Glance</link>
              </para>
            </entry>
            <entry>
              <para>Stores and retrieves virtual machine disk images. OpenStack Compute
makes use of this during instance provisioning.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/ceilometer">Telemetry</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/ceilometer/">Ceilometer</link>
              </para>
            </entry>
            <entry>
              <para>Monitors and meters the OpenStack cloud for billing, benchmarking,
scalability, and statistical purposes.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/heat">Orchestration</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/heat/">Heat</link>
              </para>
            </entry>
            <entry>
              <para>Orchestrates multiple composite cloud applications by using either the
native HOT template format or the AWS CloudFormation template format,
through both an OpenStack-native REST API and a
CloudFormation-compatible Query API.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/trove">Database service</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/trove/">Trove</link>
              </para>
            </entry>
            <entry>
              <para>Provides scalable and reliable Cloud Database-as-a-Service functionality
for both relational and non-relational database engines.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>
                <link xlink:href="http://www.openstack.org/software/releases/newton/components/sahara">Data processing service</link>
              </para>
            </entry>
            <entry>
              <para>
                <link xlink:href="http://docs.openstack.org/developer/sahara/">Sahara</link>
              </para>
            </entry>
            <entry>
              <para>Provides capabilities to provision and scale Hadoop clusters in OpenStack
by specifying parameters like Hadoop version, cluster topology and nodes
hardware details.</para>
            </entry>
          </row>
        </tbody>
      </tgroup>
    </table>
    <sect1 xml:id="get-started-conceptual-architecture">
      <title>Conceptual architecture</title>
      <para>The following diagram shows the relationships among the OpenStack
services:</para>
      <informalfigure>
        <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="openstack_kilo_conceptual_arch.png" width="99%"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="openstack_kilo_conceptual_arch.png" width="99%"/>
        </imageobject>
        </mediaobject>
      </informalfigure>
    </sect1>
    <sect1>
      <title>Logical architecture</title>
      <para>To design, deploy, and configure OpenStack, administrators must
understand the logical architecture.</para>
      <para>As shown in <xref linkend="get-started-conceptual-architecture"/>, OpenStack consists of
several independent parts, named the OpenStack services. All services
authenticate through a common Identity service. Individual services interact
with each other through public APIs, except where privileged administrator
commands are necessary.</para>
      <para>Internally, OpenStack services are composed of several processes. All
services have at least one API process, which listens for API requests,
preprocesses them and passes them on to other parts of the service. With
the exception of the Identity service, the actual work is done by
distinct processes.</para>
      <para>For communication between the processes of one service, an AMQP message
broker is used. The service's state is stored in a database. When
deploying and configuring your OpenStack cloud, you can choose among
several message broker and database solutions, such as RabbitMQ,
MySQL, MariaDB, and SQLite.</para>
      <para>Users can access OpenStack via the web-based user interface implemented
by <xref linkend="sec.dashboard"/>, via <link xlink:href="http://docs.openstack.org/cli-reference/">command-line
clients</link> and by
issuing API requests through tools like browser plug-ins or <command>curl</command>.
For applications, <link xlink:href="http://developer.openstack.org/#sdk">several SDKs</link>
are available. Ultimately, all these access methods issue REST API calls
to the various OpenStack services.</para>
      <para>The following diagram shows the most common, but not the only possible,
architecture for an OpenStack cloud:</para>
      <informalfigure>
        <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="openstack-arch-kilo-logical-v1.png" width="99%"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="openstack-arch-kilo-logical-v1.png" width="99%"/>
        </imageobject>
        </mediaobject>
      </informalfigure>
    </sect1>
    <sect1>
      <title>OpenStack services</title>
      <para>This section describes OpenStack services in detail.</para>
      <sect2>
        <title>Compute service overview</title>
        <para>Use OpenStack Compute to host and manage cloud computing systems.
OpenStack Compute is a major part of an <xref linkend="term-infrastructure-as-a-service-iaas"/> system. The main modules are implemented in Python.</para>
        <para>OpenStack Compute interacts with OpenStack Identity for authentication;
OpenStack Image service for disk and server images; and OpenStack
Dashboard for the user and administrative interface. Image access is
limited by projects, and by users; quotas are limited per project (the
number of instances, for example). OpenStack Compute can scale
horizontally on standard hardware, and download images to launch
instances.</para>
        <para>OpenStack Compute consists of the following areas and their components:</para>
        <variablelist>
          <varlistentry>
            <term><literal>nova-api</literal> service</term>
            <listitem>
              <para>Accepts and responds to end user compute API calls. The service
supports the OpenStack Compute API, the Amazon EC2 API, and a
special Admin API for privileged users to perform administrative
actions. It enforces some policies and initiates most orchestration
activities, such as running an instance.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-api-metadata</literal> service</term>
            <listitem>
              <para>Accepts metadata requests from instances. The <literal>nova-api-metadata</literal>
service is generally used when you run in multi-host mode with
<literal>nova-network</literal> installations. For details, see <link xlink:href="http://docs.openstack.org/admin-guide/compute-networking-nova.html#metadata-service">Metadata
service</link>
in the OpenStack Administrator Guide.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-compute</literal> service</term>
            <listitem>
              <para>A worker daemon that creates and terminates virtual machine
instances through hypervisor APIs. For example:</para>
              <itemizedlist>
                <listitem>
                  <para>XenAPI for XenServer/XCP</para>
                </listitem>
                <listitem>
                  <para>libvirt for KVM or QEMU</para>
                </listitem>
                <listitem>
                  <para>VMwareAPI for VMware</para>
                </listitem>
              </itemizedlist>
              <para>Processing is fairly complex. Basically, the daemon accepts actions
from the queue and performs a series of system commands such as
launching a KVM instance and updating its state in the database.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-scheduler</literal> service</term>
            <listitem>
              <para>Takes a virtual machine instance request from the queue and
determines on which compute server host it runs.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-conductor</literal> module</term>
            <listitem>
              <para>Mediates interactions between the <literal>nova-compute</literal> service and the
database. It eliminates direct accesses to the cloud database made
by the <literal>nova-compute</literal> service. The <literal>nova-conductor</literal> module scales
horizontally. However, do not deploy it on nodes where the
<literal>nova-compute</literal> service runs. For more information, see <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/conductor.html">Configuration
Reference Guide</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-cert</literal> module</term>
            <listitem>
              <para>A server daemon that serves the Nova Cert service for X509
certificates. Used to generate certificates for
<literal>euca-bundle-image</literal>. Only needed for the EC2 API.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-consoleauth</literal> daemon</term>
            <listitem>
              <para>Authorizes tokens for users that console proxies provide. See
<literal>nova-novncproxy</literal>.<!-- and <literal>nova-xvpvncproxy</literal>.--> This service must be running
for console proxies to work. You can run proxies of either type
against a single nova-consoleauth service in a cluster
configuration. For information, see <link xlink:href="http://docs.openstack.org/admin-guide/compute-remote-console-access.html#about-nova-consoleauth">About
nova-consoleauth</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-novncproxy</literal> daemon</term>
            <listitem>
              <para>Provides a proxy for accessing running instances through a VNC
connection. Supports browser-based novnc clients.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>nova-spicehtml5proxy</literal> daemon</term>
            <listitem>
              <para>Provides a proxy for accessing running instances through a SPICE
connection. Supports browser-based HTML5 client.</para>
            </listitem>
          </varlistentry>
          <!--<varlistentry>
            <term><literal>nova-xvpvncproxy</literal> daemon</term>
            <listitem>
              <para>Provides a proxy for accessing running instances through a VNC
connection. Supports an OpenStack-specific Java client.</para>
            </listitem>
          </varlistentry>-->
          <varlistentry>
            <term>The queue</term>
            <listitem>
              <para>A central hub for passing messages between daemons. Usually
implemented with <link xlink:href="http://www.rabbitmq.com/">RabbitMQ</link>, also can be
implemented with another AMQP message queue, such as <link xlink:href="http://www.zeromq.org/">ZeroMQ</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>SQL database</term>
            <listitem>
              <para>Stores most build-time and run-time states for a cloud
infrastructure, including:</para>
              <itemizedlist>
                <listitem>
                  <para>Available instance types</para>
                </listitem>
                <listitem>
                  <para>Instances in use</para>
                </listitem>
                <listitem>
                  <para>Available networks</para>
                </listitem>
                <listitem>
                  <para>Projects</para>
                </listitem>
              </itemizedlist>
              <para>Theoretically, OpenStack Compute can support any database that
SQLAlchemy supports. Common databases are SQLite3 for test and
development work, MySQL, MariaDB, and PostgreSQL.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Storage concepts</title>
        <para>The OpenStack stack uses the following storage types:</para>
        <table>
          <title>Storage types</title>
          <tgroup cols="4">
            <colspec colname="c1" colwidth="25.0*"/>
            <colspec colname="c2" colwidth="25.0*"/>
            <colspec colname="c3" colwidth="25.0*"/>
            <colspec colname="c4" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>On-instance / ephemeral</para>
                </entry>
                <entry>
                  <para>Block storage (cinder)</para>
                </entry>
                <entry>
                  <para>Object Storage (swift)</para>
                </entry>
                <entry>
                  <para>File Storage (manila)</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>Runs operating systems and provides scratch space</para>
                </entry>
                <entry>
                  <para>Used for adding additional persistent storage to a virtual machine (VM)</para>
                </entry>
                <entry>
                  <para>Used for storing virtual machine images and data</para>
                </entry>
                <entry>
                  <para>Used for providing file shares to a virtual machine</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Persists until VM is terminated</para>
                </entry>
                <entry>
                  <para>Persists until deleted</para>
                </entry>
                <entry>
                  <para>Persists until deleted</para>
                </entry>
                <entry>
                  <para>Persists until deleted</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Access associated with a VM</para>
                </entry>
                <entry>
                  <para>Access associated with a VM</para>
                </entry>
                <entry>
                  <para>Available from anywhere</para>
                </entry>
                <entry>
                  <para>Access can be provided to a VM</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Implemented as a filesystem underlying OpenStack Compute</para>
                </entry>
                <entry>
                  <para>Mounted via OpenStack Block Storage controlled protocol (for example, iSCSI)</para>
                </entry>
                <entry>
                  <para>REST API</para>
                </entry>
                <entry>
                  <para>Provides Shared File System service via nfs, cifs, glusterfs, or hdfs protocol</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Encryption is available</para>
                </entry>
                <entry>
                  <para>Encryption is available</para>
                </entry>
                <entry>
                  <para>Work in progress - expected for the Mitaka release</para>
                </entry>
                <entry>
                  <para>Encryption is not available yet</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Administrator configures size setting, based on flavors</para>
                </entry>
                <entry>
                  <para>Sizings based on need</para>
                </entry>
                <entry>
                  <para>Easily scalable for future growth</para>
                </entry>
                <entry>
                  <para>Sizing based on need</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Example: 10 GB first disk, 30 GB/core second disk</para>
                </entry>
                <entry>
                  <para>Example: 1 TB "extra hard drive"</para>
                </entry>
                <entry>
                  <para>Example: 10s of TBs of data set storage</para>
                </entry>
                <entry>
                  <para>Example: 1 TB of file share</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <note>
          <itemizedlist>
            <listitem>
              <para><emphasis>You cannot use OpenStack Object Storage like a traditional hard
drive.</emphasis> The Object Storage relaxes some of the constraints of a
POSIX-style file system to get other gains. You can access the
objects through an API which uses HTTP. Subsequently you don't have
to provide atomic operations (that is, relying on eventual
consistency), you can scale a storage system easily and avoid a
central point of failure.</para>
            </listitem>
            <listitem>
              <para><emphasis>The OpenStack Image service is used to manage the virtual machine
images in an OpenStack cluster, not store them.</emphasis> It provides an
abstraction to different methods for storage - a bridge to the
storage, not the storage itself.</para>
            </listitem>
            <listitem>
              <para><emphasis>The OpenStack Object Storage can function on its own.</emphasis> The Object
Storage (swift) product can be used independently of the Compute
(nova) product.</para>
            </listitem>
          </itemizedlist>
        </note>
      </sect2>
      <sect2>
        <title>Object Storage service overview</title>
        <para>The OpenStack Object Storage is a multi-tenant object storage system. It
is highly scalable and can manage large amounts of unstructured data at
low cost through a RESTful HTTP API.</para>
        <para>It includes the following components:</para>
        <variablelist>
          <varlistentry>
            <term>Proxy servers (swift-proxy-server)</term>
            <listitem>
              <para>Accepts OpenStack Object Storage API and raw HTTP requests to upload
files, modify metadata, and create containers. It also serves file
or container listings to web browsers. To improve performance, the
proxy server can use an optional cache that is usually deployed with
memcache.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Account servers (swift-account-server)</term>
            <listitem>
              <para>Manages accounts defined with Object Storage.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Container servers (swift-container-server)</term>
            <listitem>
              <para>Manages the mapping of containers or folders, within Object Storage.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Object servers (swift-object-server)</term>
            <listitem>
              <para>Manages actual objects, such as files, on the storage nodes.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Various periodic processes</term>
            <listitem>
              <para>Performs housekeeping tasks on the large data store. The replication
services ensure consistency and availability through the cluster.
Other periodic processes include auditors, updaters, and reapers.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>WSGI middleware</term>
            <listitem>
              <para>Handles authentication and is usually OpenStack Identity.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>swift client</term>
            <listitem>
              <para>Enables users to submit commands to the REST API through a
command-line client authorized as either a admin user, reseller
user, or swift user.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>swift-init</term>
            <listitem>
              <para>Script that initializes the building of the ring file, takes daemon
names as parameter and offers commands. Documented in
<link xlink:href="http://docs.openstack.org/developer/swift/admin_guide.html#managing-services">Managing Services</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>swift-recon</term>
            <listitem>
              <para>A cli tool used to retrieve various metrics and telemetry information
about a cluster that has been collected by the swift-recon middleware.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>swift-ring-builder</term>
            <listitem>
              <para>Storage ring build and rebalance utility. Documented in
<link xlink:href="http://docs.openstack.org/developer/swift/admin_guide.html#managing-the-rings">Managing the Rings</link>.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Block Storage service overview</title>
        <para>The OpenStack Block Storage service (cinder) adds persistent storage
to a virtual machine. Block Storage provides an infrastructure for managing
volumes, and interacts with OpenStack Compute to provide volumes for
instances. The service also enables management of volume snapshots, and
volume types.</para>
        <para>The Block Storage service consists of the following components:</para>
        <variablelist>
          <varlistentry>
            <term>cinder-api</term>
            <listitem>
              <para>Accepts API requests, and routes them to the <literal>cinder-volume</literal> for
action.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>cinder-volume</term>
            <listitem>
              <para>Interacts directly with the Block Storage service, and processes
such as the <literal>cinder-scheduler</literal>. It also interacts with these processes
through a message queue. The <literal>cinder-volume</literal> service responds to read
and write requests sent to the Block Storage service to maintain
state. It can interact with a variety of storage providers through a
driver architecture.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>cinder-scheduler daemon</term>
            <listitem>
              <para>Selects the optimal storage provider node on which to create the
volume. A similar component to the <literal>nova-scheduler</literal>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>cinder-backup daemon</term>
            <listitem>
              <para>The <literal>cinder-backup</literal> service provides backing up volumes of any type to
a backup storage provider. Like the <literal>cinder-volume</literal> service, it can
interact with a variety of storage providers through a driver
architecture.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Messaging queue</term>
            <listitem>
              <para>Routes information between the Block Storage processes.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Shared File Systems service overview</title>
        <para>The OpenStack Shared File Systems service (manila) provides file storage to a
virtual machine. The Shared File Systems service provides an infrastructure
for managing and provisioning of file shares. The service also enables
management of share types as well as share snapshots if a driver supports
them.</para>
        <para>The Shared File Systems service consists of the following components:</para>
        <variablelist>
          <varlistentry>
            <term>manila-api</term>
            <listitem>
              <para>A WSGI app that authenticates and routes requests throughout the Shared File
Systems service. It supports the OpenStack APIs.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>manila-data</term>
            <listitem>
              <para>A standalone service whose purpose is to receive requests, process data
operations such as copying, share migration or backup, and send back a
response after an operation has been completed.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>manila-scheduler</term>
            <listitem>
              <para>Schedules and routes requests to the appropriate share service. The
scheduler uses configurable filters and weighers to route requests. The
Filter Scheduler is the default and enables filters on things like Capacity,
Availability Zone, Share Types, and Capabilities as well as custom filters.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>manila-share</term>
            <listitem>
              <para>Manages back-end devices that provide shared file systems. A manila-share
process can run in one of two modes, with or without handling of share
servers. Share servers export file shares via share networks. When share
servers are not used, the networking requirements are handled outside of
Manila.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Messaging queue</term>
            <listitem>
              <para>Routes information between the Shared File Systems processes.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>For more information, see <link xlink:href="http://docs.openstack.org/newton/config-reference/shared-file-systems/overview.html">OpenStack Configuration Reference</link>.</para>
      </sect2>
      <sect2>
        <title>Networking service overview</title>
        <para>OpenStack Networking (neutron) allows you to create and attach interface
devices managed by other OpenStack services to networks. Plug-ins can be
implemented to accommodate different networking equipment and software,
providing flexibility to OpenStack architecture and deployment.</para>
        <para>It includes the following components:</para>
        <variablelist>
          <varlistentry>
            <term>neutron-server</term>
            <listitem>
              <para>Accepts and routes API requests to the appropriate OpenStack
Networking plug-in for action.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>OpenStack Networking plug-ins and agents</term>
            <listitem>
              <para>Plug and unplug ports, create networks or subnets, and provide
IP addressing. These plug-ins and agents differ depending on the
vendor and technologies used in the particular cloud. OpenStack
Networking ships with plug-ins and agents for Cisco virtual and
physical switches, NEC OpenFlow products, Open vSwitch, Linux
bridging, and the VMware NSX product.</para>
              <para>The common agents are L3 (layer 3), DHCP (dynamic host IP
addressing), and a plug-in agent.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Messaging queue</term>
            <listitem>
              <para>Used by most OpenStack Networking installations to route information
between the neutron-server and various agents. Also acts as a database
to store networking state for particular plug-ins.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>OpenStack Networking mainly interacts with OpenStack Compute to provide
networks and connectivity for its instances.</para>
      </sect2>
      <sect2 xml:id="sec.dashboard">
        <title>Dashboard overview</title>
        <para>The OpenStack Dashboard is a modular <link xlink:href="https://www.djangoproject.com/">Django web
application</link> that provides a
graphical interface to OpenStack services.</para>
        <informalfigure>
          <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="horizon-screenshot.png" width="99%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="horizon-screenshot.png" width="99%"/>
          </imageobject>
          </mediaobject>
        </informalfigure>
        <para>The dashboard is usually deployed through
<link xlink:href="http://code.google.com/p/modwsgi/">mod_wsgi</link> in Apache. You can
modify the dashboard code to make it suitable for different sites.</para>
        <para>From a network architecture point of view, this service must be
accessible to customers and the public API for each OpenStack service.
To use the administrator functionality for other services, it must also
connect to Admin API endpoints, which should not be accessible by
customers.</para>
      </sect2>
      <sect2>
        <title>Identity service overview</title>
        <para>The OpenStack <xref linkend="term-identity-service-keystone"/> provides
a single point of integration for managing authentication, authorization, and
a catalog of services.</para>
        <para>The Identity service is typically the first service a user interacts with. Once
authenticated, an end user can use their identity to access other OpenStack
services. Likewise, other OpenStack services leverage the Identity service to
ensure users are who they say they are and discover where other services are
within the deployment. The Identity service can also integrate with some
external user management systems (such as LDAP).</para>
        <para>Users and services can locate other services by using the service catalog,
which is managed by the Identity service. As the name implies, a service
catalog is a collection of available services in an OpenStack deployment. Each
service can have one or many endpoints and each endpoint can be one of three
types: admin, internal, or public. In a production environment, different
endpoint types might reside on separate networks exposed to different types of
users for security reasons. For instance, the public API network might be
visible from the Internet so customers can manage their clouds. The admin API
network might be restricted to operators within the organization that manages
cloud infrastructure. The internal API network might be restricted to the hosts
that contain OpenStack services. Also, OpenStack supports multiple regions for
scalability. For simplicity, this guide uses the management network for all
endpoint types and the default <literal>RegionOne</literal> region. Together, regions,
services, and endpoints created within the Identity service comprise the
service catalog for a deployment. Each OpenStack service in your deployment
needs a service entry with corresponding endpoints stored in the Identity
service. This can all be done after the Identity service has been installed and
configured.</para>
        <para>The Identity service contains these components:</para>
        <variablelist>
          <varlistentry>
            <term>Server</term>
            <listitem>
              <para>A centralized server provides authentication and authorization
services using a RESTful interface.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Drivers</term>
            <listitem>
              <para>Drivers or a service back end are integrated to the centralized
server. They are used for accessing identity information in
repositories external to OpenStack, and may already exist in
the infrastructure where OpenStack is deployed (for example, SQL
databases or LDAP servers).</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Modules</term>
            <listitem>
              <para>Middleware modules run in the address space of the OpenStack
component that is using the Identity service. These modules
intercept service requests, extract user credentials, and send them
to the centralized server for authorization. The integration between
the middleware modules and OpenStack components uses the Python Web
Server Gateway Interface.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Image service overview</title>
        <para>The OpenStack Image service is central to Infrastructure-as-a-Service
(IaaS) as shown in <xref linkend="get-started-conceptual-architecture"/>. It accepts API
requests for disk or server images, and metadata definitions from end users or
OpenStack Compute components. It also supports the storage of disk or server
images on various repository types, including OpenStack Object Storage.</para>
        <para>A number of periodic processes run on the OpenStack Image service to
support caching. Replication services ensure consistency and
availability through the cluster. Other periodic processes include
auditors, updaters, and reapers.</para>
        <para>The OpenStack Image service includes the following components:</para>
        <variablelist>
          <varlistentry>
            <term>glance-api</term>
            <listitem>
              <para>Accepts Image API calls for image discovery, retrieval, and storage.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>glance-registry</term>
            <listitem>
              <para>Stores, processes, and retrieves metadata about images. Metadata
includes items such as size and type.</para>
              <warning>
                <para>The registry is a private internal service meant for use by
OpenStack Image service. Do not expose this service to users.</para>
              </warning>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Database</term>
            <listitem>
              <para>Stores image metadata and you can choose your database depending on
your preference. Most deployments use MySQL or SQLite.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Storage repository for image files</term>
            <listitem>
              <para>Various repository types are supported including normal file
systems (or any filesystem mounted on the glance-api controller
node), Object Storage, RADOS block devices, VMware datastore,
and HTTP. Note that some repositories will only support read-only
usage.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Metadata definition service</term>
            <listitem>
              <para>A common API for vendors, admins, services, and users to meaningfully
define their own custom metadata. This metadata can be used on
different types of resources like images, artifacts, volumes,
flavors, and aggregates. A definition includes the new property's key,
description, constraints, and the resource types which it can be
associated with.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Telemetry service overview</title>
        <sect3>
          <title>Telemetry Data Collection service</title>
          <para>The Telemetry Data Collection services provide the following functions:</para>
          <itemizedlist>
            <listitem>
              <para>Efficiently polls metering data related to OpenStack services.</para>
            </listitem>
            <listitem>
              <para>Collects event and metering data by monitoring notifications sent
from services.</para>
            </listitem>
            <listitem>
              <para>Publishes collected data to various targets including data stores and
message queues.</para>
            </listitem>
          </itemizedlist>
          <para>The Telemetry service consists of the following components:</para>
          <variablelist>
            <varlistentry>
              <term>A compute agent (<literal>ceilometer-agent-compute</literal>)</term>
              <listitem>
                <para>Runs on each compute node and polls for resource utilization
statistics. There may be other types of agents in the future, but
for now our focus is creating the compute agent.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>A central agent (<literal>ceilometer-agent-central</literal>)</term>
              <listitem>
                <para>Runs on a central management server to poll for resource utilization
statistics for resources not tied to instances or compute nodes.
Multiple agents can be started to scale service horizontally.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>A notification agent (<literal>ceilometer-agent-notification</literal>)</term>
              <listitem>
                <para>Runs on a central management server(s) and consumes messages from
the message queue(s) to build event and metering data.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>A collector (<literal>ceilometer-collector</literal>)</term>
              <listitem>
                <para>Runs on central management server(s) and dispatches collected
telemetry data to a data store or external consumer without
modification.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>An API server (<literal>ceilometer-api</literal>)</term>
              <listitem>
                <para>Runs on one or more central management servers to provide data
access from the data store.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </sect3>
        <sect3>
          <title>Telemetry Alarming service</title>
          <para>The Telemetry Alarming services trigger alarms when the collected metering
or event data break the defined rules.</para>
          <para>The Telemetry Alarming service consists of the following components:</para>
          <variablelist>
            <varlistentry>
              <term>An API server (<literal>aodh-api</literal>)</term>
              <listitem>
                <para>Runs on one or more central management servers to provide access
to the alarm information stored in the data store.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>An alarm evaluator (<literal>aodh-evaluator</literal>)</term>
              <listitem>
                <para>Runs on one or more central management servers to determine when
alarms fire due to the associated statistic trend crossing a
threshold over a sliding time window.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>A notification listener (<literal>aodh-listener</literal>)</term>
              <listitem>
                <para>Runs on a central management server and determines when to fire alarms.
The alarms are generated based on defined rules against events, which are
captured by the Telemetry Data Collection service's notification agents.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>An alarm notifier (<literal>aodh-notifier</literal>)</term>
              <listitem>
                <para>Runs on one or more central management servers to allow alarms to be
set based on the threshold evaluation for a collection of samples.</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <para>These services communicate by using the OpenStack messaging bus. Only
the collector and API server have access to the data store.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Orchestration service overview</title>
        <para>The Orchestration service provides a template-based orchestration for
describing a cloud application by running OpenStack API calls to
generate running cloud applications. The software integrates other core
components of OpenStack into a one-file template system. The templates
allow you to create most OpenStack resource types such as instances,
floating IPs, volumes, security groups, and users. It also provides
advanced functionality such as instance high availability, instance
auto-scaling, and nested stacks. This enables OpenStack core projects to
receive a larger user base.</para>
        <para>The service enables deployers to integrate with the Orchestration service
directly or through custom plug-ins.</para>
        <para>The Orchestration service consists of the following components:</para>
        <variablelist>
          <varlistentry>
            <term><literal>heat</literal> command-line client</term>
            <listitem>
              <para>A CLI that communicates with the <literal>heat-api</literal> to run AWS
CloudFormation APIs. End developers can directly use the Orchestration
REST API.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>heat-api</literal> component</term>
            <listitem>
              <para>An OpenStack-native REST API that processes API requests by sending
them to the <literal>heat-engine</literal> over <xref linkend="term-remote-procedure-call-rpc"/>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>heat-api-cfn</literal> component</term>
            <listitem>
              <para>An AWS Query API that is compatible with AWS CloudFormation. It
processes API requests by sending them to the <literal>heat-engine</literal> over RPC.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>heat-engine</literal>
            </term>
            <listitem>
              <para>Orchestrates the launching of templates and provides events back to
the API consumer.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Database service overview</title>
        <para>The Database service provides scalable and reliable cloud provisioning
functionality for both relational and non-relational database engines.
Users can quickly and easily use database features without the burden of
handling complex administrative tasks. Cloud users and database
administrators can provision and manage multiple database instances as
needed.</para>
        <para>The Database service provides resource isolation at high performance
levels and automates complex administrative tasks such as deployment,
configuration, patching, backups, restores, and monitoring.</para>
        <para>
          <emphasis role="bold">Process flow example</emphasis>
        </para>
        <para>This example is a high-level process flow for using Database services:</para>
        <procedure>
          <step>
            <para>The OpenStack Administrator configures the basic infrastructure using
the following steps:</para>
            <substeps>
              <step>
                <para>Install the Database service.</para>
              </step>
              <step>
                <para>Create an image for each type of database. For example, one for MySQL
and one for MongoDB.</para>
              </step>
              <step>
                <para>Use the <command>trove-manage</command> command to import images and offer them
to tenants.</para>
              </step>
            </substeps>
          </step>
          <step>
            <para>The OpenStack end user deploys the Database service using the following
steps:</para>
            <substeps>
              <step>
                <para>Create a Database service instance using the <command>trove create</command>
command.</para>
              </step>
              <step>
                <para>Use the <command>trove list</command> command to get the ID of the instance,
followed by the <command>trove show</command> command to get the IP address of
it.</para>
              </step>
              <step>
                <para>Access the Database service instance using typical database access
commands. For example, with MySQL:</para>
                <screen language="console">$ mysql -u myuser -p -h TROVE_IP_ADDRESS mydb</screen>
              </step>
            </substeps>
          </step>
        </procedure>
        <para>
          <emphasis role="bold">Components</emphasis>
        </para>
        <para>The Database service includes the following components:</para>
        <variablelist>
          <varlistentry>
            <term><literal>python-troveclient</literal> command-line client</term>
            <listitem>
              <para>A CLI that communicates with the <literal>trove-api</literal> component.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>trove-api</literal> component</term>
            <listitem>
              <para>Provides an OpenStack-native RESTful API that supports JSON to
provision and manage Trove instances.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>trove-conductor</literal> service</term>
            <listitem>
              <para>Runs on the host, and receives messages from guest instances that
want to update information on the host.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>trove-taskmanager</literal> service</term>
            <listitem>
              <para>Instruments the complex system flows that support provisioning
instances, managing the lifecycle of instances, and performing
operations on instances.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><literal>trove-guestagent</literal> service</term>
            <listitem>
              <para>Runs within the guest instance. Manages and performs operations on
the database itself.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Data Processing service overview</title>
        <para>The Data processing service for OpenStack (sahara) aims to provide users
with a simple means to provision data processing (Hadoop, Spark)
clusters by specifying several parameters like Hadoop version, cluster
topology, node hardware details and a few more. After a user fills in
all the parameters, the Data processing service deploys the cluster in a
few minutes. Sahara also provides a means to scale already provisioned
clusters by adding or removing worker nodes on demand.</para>
        <para>The solution addresses the following use cases:</para>
        <itemizedlist>
          <listitem>
            <para>Fast provisioning of Hadoop clusters on OpenStack for development and
QA.</para>
          </listitem>
          <listitem>
            <para>Utilization of unused compute power from general purpose OpenStack
IaaS cloud.</para>
          </listitem>
          <listitem>
            <para>Analytics-as-a-Service for ad-hoc or bursty analytic workloads.</para>
          </listitem>
        </itemizedlist>
        <para>Key features are:</para>
        <itemizedlist>
          <listitem>
            <para>Designed as an OpenStack component.</para>
          </listitem>
          <listitem>
            <para>Managed through REST API with UI available as part of OpenStack
Dashboard.</para>
          </listitem>
          <listitem>
            <para>Support for different Hadoop distributions:</para>
            <itemizedlist>
              <listitem>
                <para>Pluggable system of Hadoop installation engines.</para>
              </listitem>
              <listitem>
                <para>Integration with vendor specific management tools, such as Apache
Ambari or Cloudera Management Console.</para>
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem>
            <para>Predefined templates of Hadoop configurations with the ability to
modify parameters.</para>
          </listitem>
          <listitem>
            <para>User-friendly UI for ad-hoc analytics queries based on Hive or Pig.</para>
          </listitem>
        </itemizedlist>
      </sect2>
    </sect1>
    <sect1>
      <title>Feedback</title>
      <para>To provide feedback on documentation, join and use the
<link xlink:href="mailto:openstack-docs@lists.openstack.org">openstack-docs@lists.openstack.org</link> mailing list at <link xlink:href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs">OpenStack
Documentation Mailing
List</link>,
or <link xlink:href="https://bugs.launchpad.net/openstack-manuals/+filebug">report a
bug</link>.</para>
    </sect1>
  </chapter>
  <chapter xml:id="cha.identity">
    <title>Identity management</title>
    <info/>
    <para>OpenStack Identity, code-named keystone, is the default Identity
management system for OpenStack. After you install Identity, you
configure it through the <literal>/etc/keystone/keystone.conf</literal>
configuration file and, possibly, a separate logging configuration
file. You initialize data into Identity by using the <literal>keystone</literal>
command-line client.</para>
    <sect1>
      <title>Identity concepts</title>
      <variablelist>
        <varlistentry>
          <term>Authentication</term>
          <listitem>
            <para>The process of confirming the identity of a user. To confirm an incoming
request, OpenStack Identity validates a set of credentials users
supply. Initially, these credentials are a user name and password, or a
user name and API key. When OpenStack Identity validates user credentials,
it issues an authentication token. Users provide the token in
subsequent requests.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Credentials</term>
          <listitem>
            <para>Data that confirms the identity of the user. For example, user
name and password, user name and API key, or an authentication
token that the Identity service provides.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Domain</term>
          <listitem>
            <para>An Identity service API v3 entity. Domains are a collection of
projects and users that define administrative boundaries for
managing Identity entities. Domains can represent an
individual, company, or operator-owned space. They expose
administrative activities directly to system users. Users can be
granted the administrator role for a domain. A domain
administrator can create projects, users, and groups in a domain
and assign roles to users and groups in a domain.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Endpoint</term>
          <listitem>
            <para>A network-accessible address, usually a URL, through which you can
access a service. If you are using an extension for templates, you
can create an endpoint template that represents the templates of
all consumable services that are available across the regions.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Group</term>
          <listitem>
            <para>An Identity service API v3 entity. Groups are a collection of
users owned by a domain. A group role, granted to a domain
or project, applies to all users in the group. Adding or removing
users to or from a group grants or revokes their role and
authentication to the associated domain or project.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>OpenStackClient</term>
          <listitem>
            <para>A command-line interface for several OpenStack services including
the Identity API. For example, a user can run the
<command>openstack service create</command> and
<command>openstack endpoint create</command> commands to register services
in their OpenStack installation.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Project</term>
          <listitem>
            <para>A container that groups or isolates resources or identity objects.
Depending on the service operator, a project might map to a
customer, account, organization, or tenant.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Region</term>
          <listitem>
            <para>An Identity service API v3 entity. Represents a general division
in an OpenStack deployment. You can associate zero or more
sub-regions with a region to make a tree-like structured hierarchy.
Although a region does not have a geographical connotation, a
deployment can use a geographical name for a region, such as <literal>us-east</literal>.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Role</term>
          <listitem>
            <para>A personality with a defined set of user rights and privileges to
perform a specific set of operations. The Identity service issues
a token to a user that includes a list of roles. When a user calls
a service, that service interprets the user role set, and
determines to which operations or resources each role grants
access.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Service</term>
          <listitem>
            <para>An OpenStack service, such as Compute (nova), Object Storage
(swift), or Image service (glance), that provides one or more
endpoints through which users can access resources and perform
operations.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Token</term>
          <listitem>
            <para>An alpha-numeric text string that enables access to OpenStack APIs
and resources. A token may be revoked at any time and is valid for
a finite duration. While OpenStack Identity supports token-based
authentication in this release, it intends to support additional
protocols in the future. OpenStack Identity is an integration
service that does not aspire to be a full-fledged identity store
and management solution.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>User</term>
          <listitem>
            <para>A digital representation of a person, system, or service that uses
OpenStack cloud services. The Identity service validates that
incoming requests are made by the user who claims to be making the
call. Users have a login and can access resources by using
assigned tokens. Users can be directly assigned to a particular
project and behave as if they are contained in that project.</para>
          </listitem>
        </varlistentry>
      </variablelist>
      <sect2>
        <title>User management</title>
        <para>Identity user management examples:</para>
        <itemizedlist>
          <listitem>
            <para>Create a user named <literal>alice</literal>:</para>
            <screen language="console">$ openstack user create --password-prompt --email alice@example.com alice</screen>
          </listitem>
          <listitem>
            <para>Create a project named <literal>acme</literal>:</para>
            <screen language="console">$ openstack project create acme --domain default</screen>
          </listitem>
          <listitem>
            <para>Create a domain named <literal>emea</literal>:</para>
            <screen language="console">$ openstack --os-identity-api-version=3 domain create emea</screen>
          </listitem>
          <listitem>
            <para>Create a role named <literal>compute-user</literal>:</para>
            <screen language="console">$ openstack role create compute-user</screen>
            <note>
              <para>Individual services assign meaning to roles, typically through
limiting or granting access to users with the role to the
operations that the service supports. Role access is typically
configured in the service's <literal>policy.json</literal> file. For example,
to limit Compute access to the <literal>compute-user</literal> role, edit the
Compute service's <literal>policy.json</literal> file to require this role for
Compute operations.</para>
            </note>
          </listitem>
        </itemizedlist>
        <para>The Identity service assigns a project and a role to a user. You might
assign the <literal>compute-user</literal> role to the <literal>alice</literal> user in the <literal>acme</literal>
project:</para>
        <screen language="console">$ openstack role add --project acme --user alice compute-user</screen>
        <para>A user can have different roles in different projects. For example, Alice
might also have the <literal>admin</literal> role in the <literal>Cyberdyne</literal> project. A user
can also have multiple roles in the same project.</para>
        <para>The <literal>/etc/[SERVICE_CODENAME]/policy.json</literal> file controls the
tasks that users can perform for a given service. For example, the
<literal>/etc/nova/policy.json</literal> file specifies the access policy for the
Compute service, the <literal>/etc/glance/policy.json</literal> file specifies
the access policy for the Image service, and the
<literal>/etc/keystone/policy.json</literal> file specifies the access policy for
the Identity service.</para>
        <para>The default <literal>policy.json</literal> files in the Compute, Identity, and
Image services recognize only the <literal>admin</literal> role. Any user with
any role in a project can access all operations that do not require the
<literal>admin</literal> role.</para>
        <para>To restrict users from performing operations in, for example, the
Compute service, you must create a role in the Identity service and
then modify the <literal>/etc/nova/policy.json</literal> file so that this role
is required for Compute operations.</para>
        <para>For example, the following line in the <literal>/etc/cinder/policy.json</literal>
file does not restrict which users can create volumes:</para>
        <screen language="json">"volume:create": "",</screen>
        <para>If the user has any role in a project, he can create volumes in that
project.</para>
        <para>To restrict the creation of volumes to users who have the
<literal>compute-user</literal> role in a particular project, you add <literal>"role:compute-user"</literal>:</para>
        <screen language="json">"volume:create": "role:compute-user",</screen>
        <para>To restrict all Compute service requests to require this role, the
resulting file looks like:</para>
        <screen language="json">{
   "admin_or_owner": "role:admin or project_id:%(project_id)s",
   "default": "rule:admin_or_owner",
   "compute:create": "role:compute-user",
   "compute:create:attach_network": "role:compute-user",
   "compute:create:attach_volume": "role:compute-user",
   "compute:get_all": "role:compute-user",
   "compute:unlock_override": "rule:admin_api",
   "admin_api": "role:admin",
   "compute_extension:accounts": "rule:admin_api",
   "compute_extension:admin_actions": "rule:admin_api",
   "compute_extension:admin_actions:pause": "rule:admin_or_owner",
   "compute_extension:admin_actions:unpause": "rule:admin_or_owner",
   "compute_extension:admin_actions:suspend": "rule:admin_or_owner",
   "compute_extension:admin_actions:resume": "rule:admin_or_owner",
   "compute_extension:admin_actions:lock": "rule:admin_or_owner",
   "compute_extension:admin_actions:unlock": "rule:admin_or_owner",
   "compute_extension:admin_actions:resetNetwork": "rule:admin_api",
   "compute_extension:admin_actions:injectNetworkInfo": "rule:admin_api",
   "compute_extension:admin_actions:createBackup": "rule:admin_or_owner",
   "compute_extension:admin_actions:migrateLive": "rule:admin_api",
   "compute_extension:admin_actions:migrate": "rule:admin_api",
   "compute_extension:aggregates": "rule:admin_api",
   "compute_extension:certificates": "role:compute-user",
   "compute_extension:cloudpipe": "rule:admin_api",
   "compute_extension:console_output": "role:compute-user",
   "compute_extension:consoles": "role:compute-user",
   "compute_extension:createserverext": "role:compute-user",
   "compute_extension:deferred_delete": "role:compute-user",
   "compute_extension:disk_config": "role:compute-user",
   "compute_extension:evacuate": "rule:admin_api",
   "compute_extension:extended_server_attributes": "rule:admin_api",
   "compute_extension:extended_status": "role:compute-user",
   "compute_extension:flavorextradata": "role:compute-user",
   "compute_extension:flavorextraspecs": "role:compute-user",
   "compute_extension:flavormanage": "rule:admin_api",
   "compute_extension:floating_ip_dns": "role:compute-user",
   "compute_extension:floating_ip_pools": "role:compute-user",
   "compute_extension:floating_ips": "role:compute-user",
   "compute_extension:hosts": "rule:admin_api",
   "compute_extension:keypairs": "role:compute-user",
   "compute_extension:multinic": "role:compute-user",
   "compute_extension:networks": "rule:admin_api",
   "compute_extension:quotas": "role:compute-user",
   "compute_extension:rescue": "role:compute-user",
   "compute_extension:security_groups": "role:compute-user",
   "compute_extension:server_action_list": "rule:admin_api",
   "compute_extension:server_diagnostics": "rule:admin_api",
   "compute_extension:simple_tenant_usage:show": "rule:admin_or_owner",
   "compute_extension:simple_tenant_usage:list": "rule:admin_api",
   "compute_extension:users": "rule:admin_api",
   "compute_extension:virtual_interfaces": "role:compute-user",
   "compute_extension:virtual_storage_arrays": "role:compute-user",
   "compute_extension:volumes": "role:compute-user",
   "compute_extension:volume_attachments:index": "role:compute-user",
   "compute_extension:volume_attachments:show": "role:compute-user",
   "compute_extension:volume_attachments:create": "role:compute-user",
   "compute_extension:volume_attachments:delete": "role:compute-user",
   "compute_extension:volumetypes": "role:compute-user",
   "volume:create": "role:compute-user",
   "volume:get_all": "role:compute-user",
   "volume:get_volume_metadata": "role:compute-user",
   "volume:get_snapshot": "role:compute-user",
   "volume:get_all_snapshots": "role:compute-user",
   "network:get_all_networks": "role:compute-user",
   "network:get_network": "role:compute-user",
   "network:delete_network": "role:compute-user",
   "network:disassociate_network": "role:compute-user",
   "network:get_vifs_by_instance": "role:compute-user",
   "network:allocate_for_instance": "role:compute-user",
   "network:deallocate_for_instance": "role:compute-user",
   "network:validate_networks": "role:compute-user",
   "network:get_instance_uuids_by_ip_filter": "role:compute-user",
   "network:get_floating_ip": "role:compute-user",
   "network:get_floating_ip_pools": "role:compute-user",
   "network:get_floating_ip_by_address": "role:compute-user",
   "network:get_floating_ips_by_project": "role:compute-user",
   "network:get_floating_ips_by_fixed_address": "role:compute-user",
   "network:allocate_floating_ip": "role:compute-user",
   "network:deallocate_floating_ip": "role:compute-user",
   "network:associate_floating_ip": "role:compute-user",
   "network:disassociate_floating_ip": "role:compute-user",
   "network:get_fixed_ip": "role:compute-user",
   "network:add_fixed_ip_to_instance": "role:compute-user",
   "network:remove_fixed_ip_from_instance": "role:compute-user",
   "network:add_network_to_project": "role:compute-user",
   "network:get_instance_nw_info": "role:compute-user",
   "network:get_dns_domains": "role:compute-user",
   "network:add_dns_entry": "role:compute-user",
   "network:modify_dns_entry": "role:compute-user",
   "network:delete_dns_entry": "role:compute-user",
   "network:get_dns_entries_by_address": "role:compute-user",
   "network:get_dns_entries_by_name": "role:compute-user",
   "network:create_private_dns_domain": "role:compute-user",
   "network:create_public_dns_domain": "role:compute-user",
   "network:delete_dns_domain": "role:compute-user"
}</screen>
      </sect2>
      <sect2>
        <title>Service management</title>
        <para>The Identity service provides identity, token, catalog, and policy
services. It consists of:</para>
        <itemizedlist>
          <listitem>
            <variablelist>
              <varlistentry>
                <term>keystone Web Server Gateway Interface (WSGI) service</term>
                <listitem>
                  <para>Can be run in a WSGI-capable web server such as Apache httpd to provide
the Identity service. The service and administrative APIs are run as
separate instances of the WSGI service.</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </listitem>
          <listitem>
            <variablelist>
              <varlistentry>
                <term>Identity service functions</term>
                <listitem>
                  <para>Each has a pluggable back end that allow different ways to use the
particular service. Most support standard back ends like LDAP or SQL.</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </listitem>
          <listitem>
            <variablelist>
              <varlistentry>
                <term>keystone-all</term>
                <listitem>
                  <para>Starts both the service and administrative APIs in a single process.
Using federation with keystone-all is not supported. keystone-all is
deprecated in favor of the WSGI service. Also, this will be removed
in Newton.</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </listitem>
        </itemizedlist>
        <para>The Identity service also maintains a user that corresponds to each
service, such as, a user named <literal>nova</literal> for the Compute service, and a
special service project called <literal>service</literal>.</para>
        <para>For information about how to create services and endpoints, see the
<link xlink:href="http://docs.openstack.org/admin-guide/cli-manage-services.html">OpenStack Administrator Guide</link>.</para>
      </sect2>
      <sect2>
        <title>Groups</title>
        <para>A group is a collection of users in a domain. Administrators can
create groups and add users to them. A role can then be assigned to
the group, rather than individual users. Groups were introduced with
the Identity API v3.</para>
        <para>Identity API V3 provides the following group-related operations:</para>
        <itemizedlist>
          <listitem>
            <para>Create a group</para>
          </listitem>
          <listitem>
            <para>Delete a group</para>
          </listitem>
          <listitem>
            <para>Update a group (change its name or description)</para>
          </listitem>
          <listitem>
            <para>Add a user to a group</para>
          </listitem>
          <listitem>
            <para>Remove a user from a group</para>
          </listitem>
          <listitem>
            <para>List group members</para>
          </listitem>
          <listitem>
            <para>List groups for a user</para>
          </listitem>
          <listitem>
            <para>Assign a role on a project to a group</para>
          </listitem>
          <listitem>
            <para>Assign a role on a domain to a group</para>
          </listitem>
          <listitem>
            <para>Query role assignments to groups</para>
          </listitem>
        </itemizedlist>
        <note>
          <para>The Identity service server might not allow all operations. For
example, if you use the Identity server with the LDAP Identity
back end and group updates are disabled, a request to create,
delete, or update a group fails.</para>
        </note>
        <para>Here are a couple of examples:</para>
        <itemizedlist>
          <listitem>
            <para>Group A is granted Role A on Project A. If User A is a member of Group
A, when User A gets a token scoped to Project A, the token also
includes Role A.</para>
          </listitem>
          <listitem>
            <para>Group B is granted Role B on Domain B. If User B is a member of
Group B, when User B gets a token scoped to Domain B, the token also
includes Role B.</para>
          </listitem>
        </itemizedlist>
      </sect2>
    </sect1>
    <sect1 xml:id="cha.certificates.pki">
      <title>Certificates for PKI</title>
      <para>PKI stands for Public Key Infrastructure. Tokens are documents,
cryptographically signed using the X509 standard. In order to work
correctly token generation requires a public/private key pair. The
public key must be signed in an X509 certificate, and the certificate
used to sign it must be available as a <xref linkend="term-certificate-authority-ca"/>
certificate. These files can be generated either using the
<command>keystone-manage</command> utility, or externally generated. The files need to
be in the locations specified by the top level Identity service
configuration file <literal>/etc/keystone/keystone.conf</literal> as specified in the
above section. Additionally, the private key should only be readable by
the system user that will run the Identity service.</para>
      <warning>
        <para>The certificates can be world readable, but the private key cannot
be. The private key should only be readable by the account that is
going to sign tokens. When generating files with the
<command>keystone-manage pki_setup</command> command, your best option is to run
as the pki user. If you run <command>keystone-manage</command> as root, you can
append <literal>--keystone-user</literal> and <literal>--keystone-group</literal> parameters
to set the user name and group keystone is going to run under.</para>
      </warning>
      <para>The values that specify where to read the certificates are under the
<literal>[signing]</literal> section of the configuration file. The configuration
values are:</para>
      <itemizedlist>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>certfile</literal>
              </term>
              <listitem>
                <para>Location of certificate used to verify tokens. Default is
<literal>/etc/keystone/ssl/certs/signing_cert.pem</literal>.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>keyfile</literal>
              </term>
              <listitem>
                <para>Location of private key used to sign tokens. Default is
<literal>/etc/keystone/ssl/private/signing_key.pem</literal>.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>ca_certs</literal>
              </term>
              <listitem>
                <para>Location of certificate for the authority that issued
the above certificate. Default is
<literal>/etc/keystone/ssl/certs/ca.pem</literal>.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>ca_key</literal>
              </term>
              <listitem>
                <para>Location of the private key used by the CA. Default is
<literal>/etc/keystone/ssl/private/cakey.pem</literal>.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>key_size</literal>
              </term>
              <listitem>
                <para>Default is <literal>2048</literal>.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>valid_days</literal>
              </term>
              <listitem>
                <para>Default is <literal>3650</literal>.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>cert_subject</literal>
              </term>
              <listitem>
                <para>Certificate subject (auto generated certificate) for token signing.
Default is <literal>/C=US/ST=Unset/L=Unset/O=Unset/CN=www.example.com</literal>.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
      </itemizedlist>
      <para>When generating certificates with the <command>keystone-manage pki_setup</command>
command, the <literal>ca_key</literal>, <literal>key_size</literal>, and <literal>valid_days</literal> configuration
options are used.</para>
      <para>If the <command>keystone-manage pki_setup</command> command is not used to generate
certificates, or you are providing your own certificates, these values
do not need to be set.</para>
      <para>If <literal>provider=keystone.token.providers.uuid.Provider</literal> in the
<literal>[token]</literal> section of the keystone configuration file, a typical token
looks like <literal>53f7f6ef0cc344b5be706bcc8b1479e1</literal>. If
<literal>provider=keystone.token.providers.pki.Provider</literal>, a typical token is a
much longer string, such as:</para>
      <screen><?dbsuse-fo font-size="8pt"?>MIIKtgYJKoZIhvcNAQcCoIIKpzCCCqMCAQExCTAHBgUrDgMCGjCCCY8GCSqGSIb3DQEHAaCCCYAEggl8eyJhY2Nlc3MiOiB7InRva2VuIjogeyJpc3N1ZWRfYXQiOiAiMjAxMy0wNS0z
MFQxNTo1MjowNi43MzMxOTgiLCAiZXhwaXJlcyI6ICIyMDEzLTA1LTMxVDE1OjUyOjA2WiIsICJpZCI6ICJwbGFjZWhvbGRlciIsICJ0ZW5hbnQiOiB7ImRlc2NyaXB0aW9uIjogbnVs
bCwgImVuYWJsZWQiOiB0cnVlLCAiaWQiOiAiYzJjNTliNGQzZDI4NGQ4ZmEwOWYxNjljYjE4MDBlMDYiLCAibmFtZSI6ICJkZW1vIn19LCAic2VydmljZUNhdGFsb2ciOiBbeyJlbmRw
b2ludHMiOiBbeyJhZG1pblVSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4xMDA6ODc3NC92Mi9jMmM1OWI0ZDNkMjg0ZDhmYTA5ZjE2OWNiMTgwMGUwNiIsICJyZWdpb24iOiAiUmVnaW9u
T25lIiwgImludGVybmFsVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4Nzc0L3YyL2MyYzU5YjRkM2QyODRkOGZhMDlmMTY5Y2IxODAwZTA2IiwgImlkIjogIjFmYjMzYmM5M2Y5
ODRhNGNhZTk3MmViNzcwOTgzZTJlIiwgInB1YmxpY1VSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4xMDA6ODc3NC92Mi9jMmM1OWI0ZDNkMjg0ZDhmYTA5ZjE2OWNiMTgwMGUwNiJ9XSwg
ImVuZHBvaW50c19saW5rcyI6IFtdLCAidHlwZSI6ICJjb21wdXRlIiwgIm5hbWUiOiAibm92YSJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3
LjEwMDozMzMzIiwgInJlZ2lvbiI6ICJSZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjMzMzMiLCAiaWQiOiAiN2JjMThjYzk1NWFiNDNkYjhm
MGU2YWNlNDU4NjZmMzAiLCAicHVibGljVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDozMzMzIn1dLCAiZW5kcG9pbnRzX2xpbmtzIjogW10sICJ0eXBlIjogInMzIiwgIm5hbWUi
OiAiczMifSwgeyJlbmRwb2ludHMiOiBbeyJhZG1pblVSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4xMDA6OTI5MiIsICJyZWdpb24iOiAiUmVnaW9uT25lIiwgImludGVybmFsVVJMIjog
Imh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo5MjkyIiwgImlkIjogIjczODQzNTJhNTQ0MjQ1NzVhM2NkOTVkN2E0YzNjZGY1IiwgInB1YmxpY1VSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4x
MDA6OTI5MiJ9XSwgImVuZHBvaW50c19saW5rcyI6IFtdLCAidHlwZSI6ICJpbWFnZSIsICJuYW1lIjogImdsYW5jZSJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6
Ly8xOTIuMTY4LjI3LjEwMDo4Nzc2L3YxL2MyYzU5YjRkM2QyODRkOGZhMDlmMTY5Y2IxODAwZTA2IiwgInJlZ2lvbiI6ICJSZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDov
LzE5Mi4xNjguMjcuMTAwOjg3NzYvdjEvYzJjNTliNGQzZDI4NGQ4ZmEwOWYxNjljYjE4MDBlMDYiLCAiaWQiOiAiMzQ3ZWQ2ZThjMjkxNGU1MGFlMmJiNjA2YWQxNDdjNTQiLCAicHVi
bGljVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4Nzc2L3YxL2MyYzU5YjRkM2QyODRkOGZhMDlmMTY5Y2IxODAwZTA2In1dLCAiZW5kcG9pbnRzX2xpbmtzIjogW10sICJ0eXBl
IjogInZvbHVtZSIsICJuYW1lIjogImNpbmRlciJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4NzczL3NlcnZpY2VzL0FkbWluIiwg
InJlZ2lvbiI6ICJSZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjg3NzMvc2VydmljZXMvQ2xvdWQiLCAiaWQiOiAiMmIwZGMyYjNlY2U4NGJj
YWE1NDAzMDMzNzI5YzY3MjIiLCAicHVibGljVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4NzczL3NlcnZpY2VzL0Nsb3VkIn1dLCAiZW5kcG9pbnRzX2xpbmtzIjogW10sICJ0
eXBlIjogImVjMiIsICJuYW1lIjogImVjMiJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDozNTM1Ny92Mi4wIiwgInJlZ2lvbiI6ICJS
ZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjUwMDAvdjIuMCIsICJpZCI6ICJiNTY2Y2JlZjA2NjQ0ZmY2OWMyOTMxNzY2Yjc5MTIyOSIsICJw
dWJsaWNVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjUwMDAvdjIuMCJ9XSwgImVuZHBvaW50c19saW5rcyI6IFtdLCAidHlwZSI6ICJpZGVudGl0eSIsICJuYW1lIjogImtleXN0
b25lIn1dLCAidXNlciI6IHsidXNlcm5hbWUiOiAiZGVtbyIsICJyb2xlc19saW5rcyI6IFtdLCAiaWQiOiAiZTVhMTM3NGE4YTRmNDI4NWIzYWQ3MzQ1MWU2MDY4YjEiLCAicm9sZXMi
OiBbeyJuYW1lIjogImFub3RoZXJyb2xlIn0sIHsibmFtZSI6ICJNZW1iZXIifV0sICJuYW1lIjogImRlbW8ifSwgIm1ldGFkYXRhIjogeyJpc19hZG1pbiI6IDAsICJyb2xlcyI6IFsi
YWRiODM3NDVkYzQzNGJhMzk5ODllNjBjOTIzYWZhMjgiLCAiMzM2ZTFiNjE1N2Y3NGFmZGJhNWUwYTYwMWUwNjM5MmYiXX19fTGB-zCB-AIBATBcMFcxCzAJBgNVBAYTAlVTMQ4wDAYD
VQQIEwVVbnNldDEOMAwGA1UEBxMFVW5zZXQxDjAMBgNVBAoTBVVuc2V0MRgwFgYDVQQDEw93d3cuZXhhbXBsZS5jb20CAQEwBwYFKw4DAhowDQYJKoZIhvcNAQEBBQAEgYCAHLpsEs2R
nouriuiCgFayIqCssK3SVdhOMINiuJtqv0sE-wBDFiEj-Prcudqlz-n+6q7VgV4mwMPszz39-rwp+P5l4AjrJasUm7FrO-4l02tPLaaZXU1gBQ1jUG5e5aL5jPDP08HbCWuX6wr-QQQB
SrWY8lF3HrTcJT23sZIleg==</screen>
      <sect2>
        <title>Sign certificate issued by external CA</title>
        <para>You can use a signing certificate issued by an external CA instead of
generated by <command>keystone-manage</command>. However, a certificate issued by an
external CA must satisfy the following conditions:</para>
        <itemizedlist>
          <listitem>
            <para>All certificate and key files must be in Privacy Enhanced Mail (PEM)
format</para>
          </listitem>
          <listitem>
            <para>Private key files must not be protected by a password</para>
          </listitem>
        </itemizedlist>
        <para>When using a signing certificate issued by an external CA, you do not
need to specify <literal>key_size</literal>, <literal>valid_days</literal>, and <literal>ca_password</literal> as
they will be ignored.</para>
        <para>The basic workflow for using a signing certificate issued by an external
CA involves:</para>
        <procedure>
          <step>
            <para>Request Signing Certificate from External CA</para>
          </step>
          <step>
            <para>Convert certificate and private key to PEM if needed</para>
          </step>
          <step>
            <para>Install External Signing Certificate</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Request a signing certificate from an external CA</title>
        <para>One way to request a signing certificate from an external CA is to first
generate a PKCS #10 Certificate Request Syntax (CRS) using OpenSSL CLI.</para>
        <para>Create a certificate request configuration file. For example, create the
<literal>cert_req.conf</literal> file, as follows:</para>
        <screen language="ini">[ req ]
default_bits            = 4096
default_keyfile         = keystonekey.pem
default_md              = sha256

prompt                  = no
distinguished_name      = distinguished_name

[ distinguished_name ]
countryName             = US
stateOrProvinceName     = CA
localityName            = Sunnyvale
organizationName        = OpenStack
organizationalUnitName  = Keystone
commonName              = Keystone Signing
emailAddress            = keystone@openstack.org</screen>
        <para>Then generate a CRS with OpenSSL CLI. <emphasis role="bold">Do not encrypt the generated
private key. You must use the -nodes option.</emphasis></para>
        <para>For example:</para>
        <screen language="console">$ openssl req -newkey rsa:1024 -keyout signing_key.pem -keyform PEM \
  -out signing_cert_req.pem -outform PEM -config cert_req.conf -nodes</screen>
        <para>If everything is successful, you should end up with
<literal>signing_cert_req.pem</literal> and <literal>signing_key.pem</literal>. Send
<literal>signing_cert_req.pem</literal> to your CA to request a token signing certificate
and make sure to ask the certificate to be in PEM format. Also, make sure your
trusted CA certificate chain is also in PEM format.</para>
      </sect2>
      <sect2>
        <title>Install an external signing certificate</title>
        <para>Assuming you have the following already:</para>
        <itemizedlist>
          <listitem>
            <variablelist>
              <varlistentry>
                <term>
                  <literal>signing_cert.pem</literal>
                </term>
                <listitem>
                  <para>(Keystone token) signing certificate in PEM format</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </listitem>
          <listitem>
            <variablelist>
              <varlistentry>
                <term>
                  <literal>signing_key.pem</literal>
                </term>
                <listitem>
                  <para>Corresponding (non-encrypted) private key in PEM format</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </listitem>
          <listitem>
            <variablelist>
              <varlistentry>
                <term>
                  <literal>cacert.pem</literal>
                </term>
                <listitem>
                  <para>Trust CA certificate chain in PEM format</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </listitem>
        </itemizedlist>
        <para>Copy the above to your certificate directory. For example:</para>
        <screen language="console"># mkdir -p /etc/keystone/ssl/certs
# cp signing_cert.pem /etc/keystone/ssl/certs/
# cp signing_key.pem /etc/keystone/ssl/certs/
# cp cacert.pem /etc/keystone/ssl/certs/
# chmod -R 700 /etc/keystone/ssl/certs</screen>
        <note>
          <para>Make sure the certificate directory is only accessible by root.</para>
        </note>
        <note>
          <para>The procedure of copying the key and cert files may be improved if
done after first running <command>keystone-manage pki_setup</command> since this
command also creates other needed files, such as the <literal>index.txt</literal>
and <literal>serial</literal> files.</para>
          <para>Also, when copying the necessary files to a different server for
replicating the functionality, the entire directory of files is
needed, not just the key and cert files.</para>
        </note>
        <para>If your certificate directory path is different from the default
<literal>/etc/keystone/ssl/certs</literal>, make sure it is reflected in the
<literal>[signing]</literal> section of the configuration file.</para>
      </sect2>
      <sect2>
        <title>Switching out expired signing certificates</title>
        <para>The following procedure details how to switch out expired signing
certificates with no cloud outages.</para>
        <procedure>
          <step>
            <para>Generate a new signing key.</para>
          </step>
          <step>
            <para>Generate a new certificate request.</para>
          </step>
          <step>
            <para>Sign the new certificate with the existing CA to generate a new
<literal>signing_cert</literal>.</para>
          </step>
          <step>
            <para>Append the new <literal>signing_cert</literal> to the old <literal>signing_cert</literal>. Ensure the
old certificate is in the file first.</para>
          </step>
          <step>
            <para>Remove all signing certificates from all your hosts to force OpenStack
Compute to download the new <literal>signing_cert</literal>.</para>
          </step>
          <step>
            <para>Replace the old signing key with the new signing key. Move the new
signing certificate above the old certificate in the <literal>signing_cert</literal>
file.</para>
          </step>
          <step>
            <para>After the old certificate reads as expired, you can safely remove the
old signing certificate from the file.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Domain-specific configuration</title>
      <para>The Identity service supports domain-specific Identity drivers.
The drivers allow a domain to have its own LDAP or SQL back end.
By default, domain-specific drivers are disabled.</para>
      <para>Domain-specific Identity configuration options can be stored in
domain-specific configuration files, or in the Identity SQL
database using API REST calls.</para>
      <note>
        <para>Storing and managing configuration options in an SQL database is
experimental in Kilo, and added to the Identity service in the
Liberty release.</para>
      </note>
      <sect2>
        <title>Enable drivers for domain-specific configuration files</title>
        <para>To enable domain-specific drivers, set these options in the
<literal>/etc/keystone/keystone.conf</literal> file:</para>
        <screen language="ini">[identity]
domain_specific_drivers_enabled = True
domain_config_dir = /etc/keystone/domains</screen>
        <para>When you enable domain-specific drivers, Identity looks in the
<literal>domain_config_dir</literal> directory for configuration files that are named as
<literal>keystone.DOMAIN_NAME.conf</literal>. A domain without a domain-specific
configuration file uses options in the primary configuration file.</para>
      </sect2>
      <sect2>
        <title>Enable drivers for storing configuration options in SQL database</title>
        <para>To enable domain-specific drivers, set these options in the
<literal>/etc/keystone/keystone.conf</literal> file:</para>
        <screen language="ini">[identity]
domain_specific_drivers_enabled = True
domain_configurations_from_database = True</screen>
        <para>Any domain-specific configuration options specified through the
Identity v3 API will override domain-specific configuration files in the
<literal>/etc/keystone/domains</literal> directory.</para>
      </sect2>
      <sect2>
        <title>Migrate domain-specific configuration files to the SQL database</title>
        <para>You can use the <literal>keystone-manage</literal> command to migrate configuration
options in domain-specific configuration files to the SQL database:</para>
        <screen language="console"># keystone-manage domain_config_upload --all</screen>
        <para>To upload options from a specific domain-configuration file, specify the
domain name:</para>
        <screen language="console"># keystone-manage domain_config_upload --domain-name DOMAIN_NAME</screen>
      </sect2>
    </sect1>
    <sect1>
      <title>External authentication with Identity</title>
      <para>When Identity runs in <literal>apache-httpd</literal>, you can use external
authentication methods that differ from the authentication provided by
the identity store back end. For example, you can use an SQL identity
back end together with X.509 authentication and Kerberos, instead of
using the user name and password combination.</para>
      <sect2>
        <title>Use HTTPD authentication</title>
        <para>Web servers, like Apache HTTP, support many methods of authentication.
Identity can allow the web server to perform the authentication. The web
server then passes the authenticated user to Identity by using the
<literal>REMOTE_USER</literal> environment variable. This user must already exist in
the Identity back end to get a token from the controller. To use this
method, Identity should run on <literal>apache-httpd</literal>.</para>
      </sect2>
      <sect2>
        <title>Use X.509</title>
        <para>The following Apache configuration snippet authenticates the user based
on a valid X.509 certificate from a known CA:</para>
        <screen language="apacheconf">&lt;VirtualHost _default_:5000&gt;
    SSLEngine on
    SSLCertificateFile    /etc/ssl/certs/ssl.cert
    SSLCertificateKeyFile /etc/ssl/private/ssl.key

    SSLCACertificatePath /etc/ssl/allowed_cas
    SSLCARevocationPath  /etc/ssl/allowed_cas
    SSLUserName          SSL_CLIENT_S_DN_CN
    SSLVerifyClient      require
    SSLVerifyDepth       10

    (...)
&lt;/VirtualHost&gt;</screen>
      </sect2>
    </sect1>
    <sect1>
      <title>Integrate Identity with LDAP</title>
      <para>The OpenStack Identity service supports integration with existing LDAP
directories for authentication and authorization services. LDAP back
ends require initialization before configuring the OpenStack Identity
service to work with it. For more information, see <link xlink:href="https://wiki.openstack.org/wiki/OpenLDAP">Setting up LDAP
for use with Keystone</link>.</para>
      <para>When the OpenStack Identity service is configured to use LDAP back ends,
you can split authentication (using the <emphasis>identity</emphasis> feature) and
authorization (using the <emphasis>assignment</emphasis> feature).</para>
      <para>The <emphasis>identity</emphasis> feature enables administrators to manage users and groups
by each domain or the OpenStack Identity service entirely.</para>
      <para>The <emphasis>assignment</emphasis> feature enables administrators to manage project role
authorization using the OpenStack Identity service SQL database, while
providing user authentication through the LDAP directory.</para>
      <sect2 xml:id="identity-ldap-server-setup">
        <title>Identity LDAP server set up</title>
        <important>
          <para>For the OpenStack Identity service to access LDAP servers, you must
enable the <literal>authlogin_nsswitch_use_ldap</literal> boolean value for SELinux
on the server running the OpenStack Identity service. To enable and
make the option persistent across reboots, set the following boolean
value as the root user:</para>
          <screen language="console"># setsebool -P authlogin_nsswitch_use_ldap on</screen>
        </important>
        <para>The Identity configuration is split into two separate back ends; identity
(back end for users and groups), and assignments (back end for domains,
projects, roles, role assignments). To configure Identity, set options
in the <literal>/etc/keystone/keystone.conf</literal> file. See
<xref linkend="integrate-identity-backend-ldap"/> for Identity back end configuration
examples. Modify these examples as needed.</para>
        <para>
          <emphasis role="bold">To define the destination LDAP server</emphasis>
        </para>
        <procedure>
          <step>
            <para>Define the destination LDAP server in the
<literal>/etc/keystone/keystone.conf</literal> file:</para>
            <screen language="ini">[ldap]
url = ldap://localhost
user = dc=Manager,dc=example,dc=org
password = samplepassword
suffix = dc=example,dc=org</screen>
          </step>
        </procedure>
        <para>
          <emphasis role="bold">Additional LDAP integration settings</emphasis>
        </para>
        <para>Set these options in the <literal>/etc/keystone/keystone.conf</literal> file for a
single LDAP server, or <literal>/etc/keystone/domains/keystone.DOMAIN_NAME.conf</literal>
files for multiple back ends. Example configurations appear below each
setting summary:</para>
        <para>
          <emphasis role="bold">Query option</emphasis>
        </para>
        <itemizedlist>
          <listitem>
            <para>Use <literal>query_scope</literal> to control the scope level of data presented
(search only the first level or search an entire sub-tree)
through LDAP.</para>
          </listitem>
          <listitem>
            <para>Use <literal>page_size</literal> to control the maximum results per page. A value
of zero disables paging.</para>
          </listitem>
          <listitem>
            <para>Use <literal>alias_dereferencing</literal> to control the LDAP dereferencing
option for queries.</para>
          </listitem>
        </itemizedlist>
        <screen language="ini">[ldap]
query_scope = sub
page_size = 0
alias_dereferencing = default
chase_referrals =</screen>
        <para>
          <emphasis role="bold">Debug</emphasis>
        </para>
        <para>Use <literal>debug_level</literal> to set the LDAP debugging level for LDAP calls.
A value of zero means that debugging is not enabled.</para>
        <screen language="ini">[ldap]
debug_level = 0</screen>
        <warning>
          <para>This value is a bitmask, consult your LDAP documentation for
possible values.</para>
        </warning>
        <para>
          <emphasis role="bold">Connection pooling</emphasis>
        </para>
        <para>Use <literal>use_pool</literal> to enable LDAP connection pooling. Configure the
connection pool size, maximum retry, reconnect trials, timeout (-1
indicates indefinite wait) and lifetime in seconds.</para>
        <screen language="ini">[ldap]
use_pool = true
pool_size = 10
pool_retry_max = 3
pool_retry_delay = 0.1
pool_connection_timeout = -1
pool_connection_lifetime = 600</screen>
        <para>
          <emphasis role="bold">Connection pooling for end user authentication</emphasis>
        </para>
        <para>Use <literal>use_auth_pool</literal> to enable LDAP connection pooling for end user
authentication. Configure the connection pool size and lifetime in
seconds.</para>
        <screen language="ini">[ldap]
use_auth_pool = false
auth_pool_size = 100
auth_pool_connection_lifetime = 60</screen>
        <para>When you have finished the configuration, restart the OpenStack Identity
service.</para>
        <warning>
          <para>During the service restart, authentication and authorization are
unavailable.</para>
        </warning>
      </sect2>
      <sect2 xml:id="integrate-identity-backend-ldap">
        <title>Integrate Identity back end with LDAP</title>
        <para>The Identity back end contains information for users, groups, and group
member lists. Integrating the Identity back end with LDAP allows
administrators to use users and groups in LDAP.</para>
        <important>
          <para>For OpenStack Identity service to access LDAP servers, you must
define the destination LDAP server in the
<literal>/etc/keystone/keystone.conf</literal> file. For more information,
see <xref linkend="identity-ldap-server-setup"/>.</para>
        </important>
        <para>
          <emphasis role="bold">To integrate one Identity back end with LDAP</emphasis>
        </para>
        <procedure>
          <step>
            <para>Enable the LDAP Identity driver in the <literal>/etc/keystone/keystone.conf</literal>
file. This allows LDAP as an identity back end:</para>
            <screen language="ini">[identity]
#driver = sql
driver = ldap</screen>
          </step>
          <step>
            <para>Create the organizational units (OU) in the LDAP directory, and define
the corresponding location in the <literal>/etc/keystone/keystone.conf</literal>
file:</para>
            <screen language="ini">[ldap]
user_tree_dn = ou=Users,dc=example,dc=org
user_objectclass = inetOrgPerson

group_tree_dn = ou=Groups,dc=example,dc=org
group_objectclass = groupOfNames</screen>
            <note>
              <para>These schema attributes are extensible for compatibility with
various schemas. For example, this entry maps to the person
attribute in Active Directory:</para>
              <screen language="ini">user_objectclass = person</screen>
            </note>
          </step>
          <step>
            <para>A read-only implementation is recommended for LDAP integration. These
permissions are applied to object types in the
<literal>/etc/keystone/keystone.conf</literal> file:</para>
            <screen language="ini">[ldap]
user_allow_create = False
user_allow_update = False
user_allow_delete = False

group_allow_create = False
group_allow_update = False
group_allow_delete = False</screen>
            <para>Restart the OpenStack Identity service.</para>
            <warning>
              <para>During service restart, authentication and authorization are
unavailable.</para>
            </warning>
          </step>
        </procedure>
        <para>
          <emphasis role="bold">To integrate multiple Identity back ends with LDAP</emphasis>
        </para>
        <procedure>
          <step>
            <para>Set the following options in the <literal>/etc/keystone/keystone.conf</literal>
file:</para>
            <substeps>
              <step>
                <para>Enable the LDAP driver:</para>
                <screen language="ini">[identity]
#driver = sql
driver = ldap</screen>
              </step>
              <step>
                <para>Enable domain-specific drivers:</para>
                <screen language="ini">[identity]
domain_specific_drivers_enabled = True
domain_config_dir = /etc/keystone/domains</screen>
              </step>
            </substeps>
          </step>
          <step>
            <para>Restart the OpenStack Identity service.</para>
            <warning>
              <para>During service restart, authentication and authorization are
unavailable.</para>
            </warning>
          </step>
          <step>
            <para>List the domains using the dashboard, or the OpenStackClient CLI. Refer
to the <link xlink:href="http://docs.openstack.org/developer/python-openstackclient/command-list.html">Command List</link>
for a list of OpenStackClient commands.</para>
          </step>
          <step>
            <para>Create domains using OpenStack dashboard, or the OpenStackClient CLI.</para>
          </step>
          <step>
            <para>For each domain, create a domain-specific configuration file in the
<literal>/etc/keystone/domains</literal> directory. Use the file naming convention
<literal>keystone.DOMAIN_NAME.conf</literal>, where DOMAIN_NAME is the domain name
assigned in the previous step.</para>
            <note>
              <para>The options set in the
<literal>/etc/keystone/domains/keystone.DOMAIN_NAME.conf</literal> file will
override options in the <literal>/etc/keystone/keystone.conf</literal> file.</para>
            </note>
          </step>
          <step>
            <para>Define the destination LDAP server in the
<literal>/etc/keystone/domains/keystone.DOMAIN_NAME.conf</literal> file. For example:</para>
            <screen language="ini">[ldap]
url = ldap://localhost
user = dc=Manager,dc=example,dc=org
password = samplepassword
suffix = dc=example,dc=org</screen>
          </step>
          <step>
            <para>Create the organizational units (OU) in the LDAP directories, and define
their corresponding locations in the
<literal>/etc/keystone/domains/keystone.DOMAIN_NAME.conf</literal> file. For example:</para>
            <screen language="ini">[ldap]
user_tree_dn = ou=Users,dc=example,dc=org
user_objectclass = inetOrgPerson

group_tree_dn = ou=Groups,dc=example,dc=org
group_objectclass = groupOfNames</screen>
            <note>
              <para>These schema attributes are extensible for compatibility with
various schemas. For example, this entry maps to the person
attribute in Active Directory:</para>
              <screen language="ini">user_objectclass = person</screen>
            </note>
          </step>
          <step>
            <para>A read-only implementation is recommended for LDAP integration. These
permissions are applied to object types in the
<literal>/etc/keystone/domains/keystone.DOMAIN_NAME.conf</literal> file:</para>
            <screen language="ini">[ldap]
user_allow_create = False
user_allow_update = False
user_allow_delete = False

group_allow_create = False
group_allow_update = False
group_allow_delete = False</screen>
          </step>
          <step>
            <para>Restart the OpenStack Identity service.</para>
            <warning>
              <para>During service restart, authentication and authorization are
unavailable.</para>
            </warning>
          </step>
        </procedure>
        <para>
          <emphasis role="bold">Additional LDAP integration settings</emphasis>
        </para>
        <para>Set these options in the <literal>/etc/keystone/keystone.conf</literal> file for a
single LDAP server, or <literal>/etc/keystone/domains/keystone.DOMAIN_NAME.conf</literal>
files for multiple back ends. Example configurations appear below each
setting summary:</para>
        <variablelist>
          <varlistentry>
            <term>Filters</term>
            <listitem>
              <para>Use filters to control the scope of data presented through LDAP.</para>
              <screen language="ini">[ldap]
user_filter = (memberof=cn=openstack-users,ou=workgroups,dc=example,dc=org)
group_filter =</screen>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Identity attribute mapping</term>
            <listitem>
              <para>Mask account status values (include any additional attribute
mappings) for compatibility with various directory services.
Superfluous accounts are filtered with <literal>user_filter</literal>.</para>
              <para>Setting attribute ignore to list of attributes stripped off on
update.</para>
              <para>For example, you can mask Active Directory account status attributes
in the <literal>/etc/keystone/keystone.conf</literal> file:</para>
              <screen language="ini">[ldap]
user_id_attribute      = cn
user_name_attribute    = sn
user_mail_attribute    = mail
user_pass_attribute    = userPassword
user_enabled_attribute = userAccountControl
user_enabled_mask      = 2
user_enabled_invert    = false
user_enabled_default   = 512
user_default_project_id_attribute =
user_additional_attribute_mapping =

group_id_attribute     = cn
group_name_attribute   = ou
group_member_attribute = member
group_desc_attribute   = description
group_additional_attribute_mapping =</screen>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Enabled emulation</term>
            <listitem>
              <para>An alternative method to determine if a user is enabled or not is by
checking if that user is a member of the emulation group.</para>
              <para>Use DN of the group entry to hold enabled user when using enabled
emulation.</para>
              <screen language="ini">[ldap]
user_enabled_emulation = false
user_enabled_emulation_dn = false</screen>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>When you have finished configuration, restart the OpenStack Identity
service.</para>
        <warning>
          <para>During service restart, authentication and authorization are
unavailable.</para>
        </warning>
      </sect2>
      <sect2>
        <title>Secure the OpenStack Identity service connection to an LDAP back end</title>
        <para>The Identity service supports the use of TLS to encrypt LDAP traffic.
Before configuring this, you must first verify where your certificate
authority file is located. For more information, see the
<link xlink:href="http://docs.openstack.org/security-guide/secure-communication/introduction-to-ssl-and-tls.html">OpenStack Security Guide SSL introduction</link>.</para>
        <para>Once you verify the location of your certificate authority file:</para>
        <para>
          <emphasis role="bold">To configure TLS encryption on LDAP traffic</emphasis>
        </para>
        <procedure>
          <step>
            <para>Open the <literal>/etc/keystone/keystone.conf</literal> configuration file.</para>
          </step>
          <step>
            <para>Find the <literal>[ldap]</literal> section.</para>
          </step>
          <step>
            <para>In the <literal>[ldap]</literal> section, set the <literal>use_tls</literal> configuration key to
<literal>True</literal>. Doing so will enable TLS.</para>
          </step>
          <step>
            <para>Configure the Identity service to use your certificate authorities file.
To do so, set the <literal>tls_cacertfile</literal> configuration key in the <literal>ldap</literal>
section to the certificate authorities file's path.</para>
            <note>
              <para>You can also set the <literal>tls_cacertdir</literal> (also in the <literal>ldap</literal>
section) to the directory where all certificate authorities files
are kept. If both <literal>tls_cacertfile</literal> and <literal>tls_cacertdir</literal> are set,
then the latter will be ignored.</para>
            </note>
          </step>
          <step>
            <para>Specify what client certificate checks to perform on incoming TLS
sessions from the LDAP server. To do so, set the <literal>tls_req_cert</literal>
configuration key in the <literal>[ldap]</literal> section to <literal>demand</literal>, <literal>allow</literal>, or
<literal>never</literal>:</para>
            <itemizedlist>
              <listitem>
                <para><literal>demand</literal> - The LDAP server always receives certificate
requests. The session terminates if no certificate
is provided, or if the certificate provided cannot be verified
against the existing certificate authorities file.</para>
              </listitem>
              <listitem>
                <para><literal>allow</literal> - The LDAP server always receives certificate
requests. The session will proceed as normal even if a certificate
is not provided. If a certificate is provided but it cannot be
verified against the existing certificate authorities file, the
certificate will be ignored and the session will proceed as
normal.</para>
              </listitem>
              <listitem>
                <para><literal>never</literal> - A certificate will never be requested.</para>
              </listitem>
            </itemizedlist>
          </step>
        </procedure>
        <para>On distributions that include openstack-config, you can configure TLS
encryption on LDAP traffic by running the following commands instead.</para>
        <screen language="console"># openstack-config --set /etc/keystone/keystone.conf \
  ldap use_tls True
# openstack-config --set /etc/keystone/keystone.conf \
  ldap tls_cacertfile ``CA_FILE``
# openstack-config --set /etc/keystone/keystone.conf \
  ldap tls_req_cert ``CERT_BEHAVIOR``</screen>
        <para>Where:</para>
        <itemizedlist>
          <listitem>
            <para><literal>CA_FILE</literal> is the absolute path to the certificate authorities file
that should be used to encrypt LDAP traffic.</para>
          </listitem>
          <listitem>
            <para><literal>CERT_BEHAVIOR</literal> specifies what client certificate checks to perform
on an incoming TLS session from the LDAP server (<literal>demand</literal>,
<literal>allow</literal>, or <literal>never</literal>).</para>
          </listitem>
        </itemizedlist>
      </sect2>
    </sect1>
    <sect1>
      <title>Keystone tokens</title>
      <para>Tokens are used to authenticate and authorize your interactions with the
various OpenStack APIs. Tokens come in many flavors, representing various
authorization scopes and sources of identity. There are also several different
"token providers", each with their own user experience, performance, and
deployment characteristics.</para>
      <sect2>
        <title>Authorization scopes</title>
        <para>Tokens can express your authorization in different scopes. You likely have
different sets of roles, in different projects, and in different domains.
While tokens always express your identity, they may only ever express one set
of roles in one authorization scope at a time.</para>
        <para>Each level of authorization scope is useful for certain types of operations in
certain OpenStack services, and are not interchangeable.</para>
        <sect3>
          <title>Unscoped tokens</title>
          <para>An unscoped token contains neither a service catalog, any roles, a project
scope, nor a domain scope. Their primary use case is simply to prove your
identity to keystone at a later time (usually to generate scoped tokens),
without repeatedly presenting your original credentials.</para>
          <para>The following conditions must be met to receive an unscoped token:</para>
          <itemizedlist>
            <listitem>
              <para>You must not specify an authorization scope in your authentication request
(for example, on the command line with arguments such as
<literal>--os-project-name</literal> or <literal>--os-domain-id</literal>),</para>
            </listitem>
            <listitem>
              <para>Your identity must not have a "default project" associated with it that you
also have role assignments, and thus authorization, upon.</para>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Project-scoped tokens</title>
          <para>Project-scoped tokens are the bread and butter of OpenStack. They express your
authorization to operate in a specific tenancy of the cloud and are useful to
authenticate yourself when working with most other services.</para>
          <para>They contain a service catalog, a set of roles, and details of the project upon
which you have authorization.</para>
        </sect3>
        <sect3>
          <title>Domain-scoped tokens</title>
          <para>Domain-scoped tokens also have limited use cases in OpenStack. They express
your authorization to operate a domain-level, above that of the user and
projects contained therein (typically as a domain-level administrator).
Depending on Keystone's configuration, they are useful for working with a
single domain in Keystone.</para>
          <para>They contain a limited service catalog (only those services which do not
explicitly require per-project endpoints), a set of roles, and details of the
project upon which you have authorization.</para>
          <para>They can also be used to work with domain-level concerns in other services,
such as to configure domain-wide quotas that apply to all users or projects in
a specific domain.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Token providers</title>
        <para>The token type issued by keystone is configurable through the
<literal>/etc/keystone/keystone.conf</literal> file. Currently, there are four supported
token types and they include <literal>UUID</literal>, <literal>fernet</literal>, <literal>PKI</literal>, and <literal>PKIZ</literal>.</para>
        <sect3>
          <title>UUID tokens</title>
          <para>UUID was the first token type supported and is currently the default token
provider. UUID tokens are 32 bytes in length and must be persisted in a back
end. Clients must pass their UUID token to the Identity service in order to
validate it.</para>
        </sect3>
        <sect3>
          <title>Fernet tokens</title>
          <para>The fernet token format was introduced in the OpenStack Kilo release. Unlike
the other token types mentioned in this document, fernet tokens do not need to
be persisted in a back end. <literal>AES256</literal> encryption is used to protect the
information stored in the token and integrity is verified with a <literal>SHA256
HMAC</literal> signature. Only the Identity service should have access to the keys used
to encrypt and decrypt fernet tokens. Like UUID tokens, fernet tokens must be
passed back to the Identity service in order to validate them. For more
information on the fernet token type, see the <xref linkend="cha.fernet.faq"/>.</para>
        </sect3>
        <sect3>
          <title>PKI and PKIZ tokens</title>
          <para>PKI tokens are signed documents that contain the authentication context, as
well as the service catalog. Depending on the size of the OpenStack deployment,
these tokens can be very long. The Identity service uses public/private key
pairs and certificates in order to create and validate PKI tokens.</para>
          <para>The same concepts from PKI tokens apply to PKIZ tokens. The only difference
between the two is PKIZ tokens are compressed to help mitigate the size issues
of PKI. For more information on the certificate setup for PKI and PKIZ tokens,
see the <xref linkend="cha.certificates.pki"/>.</para>
          <!--<note>
            <para>PKI and PKIZ tokens are deprecated and not supported in Ocata.</para>
          </note>-->
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Configure Identity service for token binding</title>
      <para>Token binding embeds information from an external authentication
mechanism, such as a Kerberos server or X.509 certificate, inside a
token. By using token binding, a client can enforce the use of a
specified external authentication mechanism with the token. This
additional security mechanism ensures that if a token is stolen, for
example, it is not usable without external authentication.</para>
      <para>You configure the authentication types for a token binding in the
<literal>/etc/keystone/keystone.conf</literal> file:</para>
      <screen language="ini">[token]
bind = kerberos</screen>
      <para>or</para>
      <screen language="ini">[token]
bind = x509</screen>
      <para>Currently <literal>kerberos</literal> and <literal>x509</literal> are supported.</para>
      <para>To enforce checking of token binding, set the <literal>enforce_token_bind</literal>
option to one of these modes:</para>
      <itemizedlist>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>disabled</literal>
              </term>
              <listitem>
                <para>Disables token bind checking.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>permissive</literal>
              </term>
              <listitem>
                <para>Enables bind checking. If a token is bound to an unknown
authentication mechanism, the server ignores it. The default is this
mode.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>strict</literal>
              </term>
              <listitem>
                <para>Enables bind checking. If a token is bound to an unknown
authentication mechanism, the server rejects it.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>required</literal>
              </term>
              <listitem>
                <para>Enables bind checking. Requires use of at least authentication
mechanism for tokens.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>kerberos</literal>
              </term>
              <listitem>
                <para>Enables bind checking. Requires use of kerberos as the authentication
mechanism for tokens:</para>
                <screen language="ini">[token]
enforce_token_bind = kerberos</screen>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>
                <literal>x509</literal>
              </term>
              <listitem>
                <para>Enables bind checking. Requires use of X.509 as the authentication
mechanism for tokens:</para>
                <screen language="ini">[token]
enforce_token_bind = x509</screen>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
      </itemizedlist>
    </sect1>
    <sect1 xml:id="cha.fernet.faq">
      <title>Fernet - Frequently Asked Questions</title>
      <para>The following questions have been asked periodically since the initial release
of the fernet token format in Kilo.</para>
      <sect2>
        <title>What are the different types of keys?</title>
        <para>A key repository is required by keystone in order to create fernet tokens.
These keys are used to encrypt and decrypt the information that makes up the
payload of the token. Each key in the repository can have one of three states.
The state of the key determines how keystone uses a key with fernet tokens. The
different types are as follows:</para>
        <variablelist>
          <varlistentry>
            <term>Primary key:</term>
            <listitem>
              <para>There is only ever one primary key in a key repository. The primary key is
allowed to encrypt and decrypt tokens. This key is always named as the
highest index in the repository.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Secondary key:</term>
            <listitem>
              <para>A secondary key was at one point a primary key, but has been demoted in place
of another primary key. It is only allowed to decrypt tokens. Since it was
the primary at some point in time, its existence in the key repository is
justified. Keystone needs to be able to decrypt tokens that were created with
old primary keys.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Staged key:</term>
            <listitem>
              <para>The staged key is a special key that shares some similarities with secondary
keys. There can only ever be one staged key in a repository and it must
exist. Just like secondary keys, staged keys have the ability to decrypt
tokens. Unlike secondary keys, staged keys have never been a primary key. In
fact, they are opposites since the staged key will always be the next primary
key. This helps clarify the name because they are the next key staged to be
the primary key. This key is always named as <literal>0</literal> in the key repository.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>So, how does a staged key help me and why do I care about it?</title>
        <para>The fernet keys have a natural lifecycle. Each key starts as a staged key, is
promoted to be the primary key, and then demoted to be a secondary key. New
tokens can only be encrypted with a primary key. Secondary and staged keys are
never used to encrypt token. The staged key is a special key given the order of
events and the attributes of each type of key. The staged key is the only key
in the repository that has not had a chance to encrypt any tokens yet, but it
is still allowed to decrypt tokens. As an operator, this gives you the chance
to perform a key rotation on one keystone node, and distribute the new key set
over a span of time. This does not require the distribution to take place in an
ultra short period of time. Tokens encrypted with a primary key can be
decrypted, and validated, on other nodes where that key is still staged.</para>
      </sect2>
      <sect2>
        <title>Where do I put my key repository?</title>
        <para>The key repository is specified using the <literal>key_repository</literal> option in the
keystone configuration file. The keystone process should be able to read and
write to this location but it should be kept secret otherwise. Currently,
keystone only supports file-backed key repositories.</para>
        <screen language="ini">[fernet_tokens]
key_repository = /etc/keystone/fernet-keys/</screen>
      </sect2>
      <sect2>
        <title>What is the recommended way to rotate and distribute keys?</title>
        <para>The <command>keystone-manage</command> command line utility includes a key rotation
mechanism. This mechanism will initialize and rotate keys but does not make
an effort to distribute keys across keystone nodes. The distribution of keys
across a keystone deployment is best handled through configuration management
tooling. Use <command>keystone-manage fernet_rotate</command> to rotate the key
repository.</para>
      </sect2>
      <sect2>
        <title>Do fernet tokens still expire?</title>
        <para>Yes, fernet tokens can expire just like any other keystone token formats.</para>
      </sect2>
      <sect2>
        <title>Why should I choose fernet tokens over UUID tokens?</title>
        <para>Even though fernet tokens operate very similarly to UUID tokens, they do not
require persistence. The keystone token database no longer suffers bloat as a
side effect of authentication. Pruning expired tokens from the token database
is no longer required when using fernet tokens. Because fernet tokens do not
require persistence, they do not have to be replicated. As long as each
keystone node shares the same key repository, fernet tokens can be created and
validated instantly across nodes.</para>
      </sect2>
      <sect2>
        <title>Why should I choose fernet tokens over PKI or PKIZ tokens?</title>
        <para>The arguments for using fernet over PKI and PKIZ remain the same as UUID, in
addition to the fact that fernet tokens are much smaller than PKI and PKIZ
tokens. PKI and PKIZ tokens still require persistent storage and can sometimes
cause issues due to their size. This issue is mitigated when switching to
fernet because fernet tokens are kept under a 250 byte limit. PKI and PKIZ
tokens typically exceed 1600 bytes in length. The length of a PKI or PKIZ token
is dependent on the size of the deployment. Bigger service catalogs will result
in longer token lengths. This pattern does not exist with fernet tokens because
the contents of the encrypted payload is kept to a minimum.</para>
      </sect2>
      <sect2>
        <title>Should I rotate and distribute keys from the same keystone node every rotation?</title>
        <para>No, but the relationship between rotation and distribution should be lock-step.
Once you rotate keys on one keystone node, the key repository from that node
should be distributed to the rest of the cluster. Once you confirm that each
node has the same key repository state, you could rotate and distribute from
any other node in the cluster.</para>
        <para>If the rotation and distribution are not lock-step, a single keystone node in
the deployment will create tokens with a primary key that no other node has as
a staged key. This will cause tokens generated from one keystone node to fail
validation on other keystone nodes.</para>
      </sect2>
      <sect2>
        <title>How do I add new keystone nodes to a deployment?</title>
        <para>The keys used to create fernet tokens should be treated like super secret
configuration files, similar to an SSL secret key. Before a node is allowed to
join an existing cluster, issuing and validating tokens, it should have the
same key repository as the rest of the nodes in the cluster.</para>
      </sect2>
      <sect2>
        <title>How should I approach key distribution?</title>
        <para>Remember that key distribution is only required in multi-node keystone
deployments. If you only have one keystone node serving requests in your
deployment, key distribution is unnecessary.</para>
        <para>Key distribution is a problem best approached from the deployment's current
configuration management system. Since not all deployments use the same
configuration management systems, it makes sense to explore options around what
is already available for managing keys, while keeping the secrecy of the keys
in mind. Many configuration management tools can leverage something like
<literal>rsync</literal> to manage key distribution.</para>
        <para>Key rotation is a single operation that promotes the current staged key to
primary, creates a new staged key, and prunes old secondary keys. It is easiest
to do this on a single node and verify the rotation took place properly before
distributing the key repository to the rest of the cluster. The concept behind
the staged key breaks the expectation that key rotation and key distribution
have to be done in a single step. With the staged key, we have time to inspect
the new key repository before syncing state with the rest of the cluster. Key
distribution should be an operation that can run in succession until it
succeeds. The following might help illustrate the isolation between key
rotation and key distribution.</para>
        <procedure>
          <step>
            <para>Ensure all keystone nodes in the deployment have the same key repository.</para>
          </step>
          <step>
            <para>Pick a keystone node in the cluster to rotate from.</para>
          </step>
          <step>
            <para>Rotate keys.</para>
            <substeps>
              <step>
                <para>Was it successful?</para>
                <substeps>
                  <step>
                    <para>If no, investigate issues with the particular keystone node you
rotated keys on. Fernet keys are small and the operation for
rotation is trivial. There should not be much room for error in key
rotation. It is possible that the user does not have the ability to
write new keys to the key repository. Log output from
<literal>keystone-manage fernet_rotate</literal> should give more information into
specific failures.</para>
                  </step>
                  <step>
                    <para>If yes, you should see a new staged key. The old staged key should
be the new primary. Depending on the <literal>max_active_keys</literal> limit you
might have secondary keys that were pruned. At this point, the node
that you rotated on will be creating fernet tokens with a primary
key that all other nodes should have as the staged key. This is why
we checked the state of all key repositories in Step one. All other
nodes in the cluster should be able to decrypt tokens created with
the new primary key. At this point, we are ready to distribute the
new key set.</para>
                  </step>
                </substeps>
              </step>
            </substeps>
          </step>
          <step>
            <para>Distribute the new key repository.</para>
            <substeps>
              <step>
                <para>Was it successful?</para>
                <substeps>
                  <step>
                    <para>If yes, you should be able to confirm that all nodes in the cluster
have the same key repository that was introduced in Step 3.  All
nodes in the cluster will be creating tokens with the primary key
that was promoted in Step 3. No further action is required until the
next schedule key rotation.</para>
                  </step>
                  <step>
                    <para>If no, try distributing again. Remember that we already rotated the
repository and performing another rotation at this point will
result in tokens that cannot be validated across certain hosts.
Specifically, the hosts that did not get the latest key set. You
should be able to distribute keys until it is successful. If certain
nodes have issues syncing, it could be permission or network issues
and those should be resolved before subsequent rotations.</para>
                  </step>
                </substeps>
              </step>
            </substeps>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>How long should I keep my keys around?</title>
        <para>The fernet tokens that keystone creates are only secure as the keys creating
them. With staged keys the penalty of key rotation is low, allowing you to err
on the side of security and rotate weekly, daily, or even hourly.  Ultimately,
this should be less time than it takes an attacker to break a <literal>AES256</literal> key
and a <literal>SHA256 HMAC</literal>.</para>
      </sect2>
      <sect2>
        <title>Is a fernet token still a bearer token?</title>
        <para>Yes, and they follow exactly the same validation path as UUID tokens, with the
exception of being written to, and read from, a back end. If someone
compromises your fernet token, they have the power to do all the operations you
are allowed to do.</para>
      </sect2>
      <sect2>
        <title>What if I need to revoke all my tokens?</title>
        <para>To invalidate every token issued from keystone and start fresh, remove the
current key repository, create a new key set, and redistribute it to all nodes
in the cluster. This will render every token issued from keystone as invalid
regardless if the token has actually expired. When a client goes to
re-authenticate, the new token will have been created with a new fernet key.</para>
      </sect2>
      <sect2>
        <title>What can an attacker do if they compromise a fernet key in my deployment?</title>
        <para>If any key used in the key repository is compromised, an attacker will be able
to build their own tokens. If they know the ID of an administrator on a
project, they could generate administrator tokens for the project. They will be
able to generate their own tokens until the compromised key has been removed
from from the repository.</para>
      </sect2>
      <sect2>
        <title>I rotated keys and now tokens are invalidating early, what did I do?</title>
        <para>Using fernet tokens requires some awareness around token expiration and the key
lifecycle. You do not want to rotate so often that secondary keys are removed
that might still be needed to decrypt unexpired tokens. If this happens, you
will not be able to decrypt the token because the key the was used to encrypt
it is now gone. Only remove keys that you know are not being used to encrypt or
decrypt tokens.</para>
        <para>For example, your token is valid for 24 hours and we want to rotate keys every
six hours. We will need to make sure tokens that were created at 08:00 AM on
Monday are still valid at 07:00 AM on Tuesday, assuming they were not
prematurely revoked. To accomplish this, we will want to make sure we set
<literal>max_active_keys=6</literal> in our keystone configuration file. This will allow us to
hold all keys that might still be required to validate a previous token, but
keeps the key repository limited to only the keys that are needed.</para>
        <para>The number of <literal>max_active_keys</literal> for a deployment can be determined by
dividing the token lifetime, in hours, by the frequency of rotation in hours
and adding two. Better illustrated as:</para>
        <screen>token_expiration = 24
rotation_frequency = 6
max_active_keys = (token_expiration / rotation_frequency) + 2</screen>
        <para>The reason for adding two additional keys to the count is to include the staged
key and a buffer key. This can be shown based on the previous example. We
initially setup the key repository at 6:00 AM on Monday, and the initial state
looks like:</para>
        <screen language="console">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (primary key)</screen>
        <para>All tokens created after 6:00 AM are encrypted with key <literal>1</literal>. At 12:00 PM we
will rotate keys again, resulting in,</para>
        <screen language="console">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (primary key)</screen>
        <para>We are still able to validate tokens created between 6:00 - 11:59 AM because
the <literal>1</literal> key still exists as a secondary key. All tokens issued after 12:00 PM
will be encrypted with key <literal>2</literal>. At 6:00 PM we do our next rotation, resulting
in:</para>
        <screen language="console">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (primary key)</screen>
        <para>It is still possible to validate tokens issued from 6:00 AM - 5:59 PM because
keys <literal>1</literal> and <literal>2</literal> exist as secondary keys. Every token issued until 11:59 PM
will be encrypted with key <literal>3</literal>, and at 12:00 AM we do our next rotation:</para>
        <screen language="console">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (secondary key)
-rw------- 1 keystone keystone   44 4    (primary key)</screen>
        <para>Just like before, we can still validate tokens issued from 6:00 AM the previous
day until 5:59 AM today because keys <literal>1</literal> - <literal>4</literal> are present. At 6:00 AM,
tokens issued from the previous day will start to expire and we do our next
scheduled rotation:</para>
        <screen language="console">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (secondary key)
-rw------- 1 keystone keystone   44 4    (secondary key)
-rw------- 1 keystone keystone   44 5    (primary key)</screen>
        <para>Tokens will naturally expire after 6:00 AM, but we will not be able to remove
key <literal>1</literal> until the next rotation because it encrypted all tokens from 6:00 AM
to 12:00 PM the day before. Once we do our next rotation, which is at 12:00 PM,
the <literal>1</literal> key will be pruned from the repository:</para>
        <screen language="console">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (secondary key)
-rw------- 1 keystone keystone   44 4    (secondary key)
-rw------- 1 keystone keystone   44 5    (secondary key)
-rw------- 1 keystone keystone   44 6    (primary key)</screen>
        <para>If keystone were to receive a token that was created between 6:00 AM and 12:00
PM the day before, encrypted with the <literal>1</literal> key, it would not be valid because
it was already expired. This makes it possible for us to remove the <literal>1</literal> key
from the repository without negative validation side-effects.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Use trusts</title>
      <para>OpenStack Identity manages authentication and authorization. A trust is
an OpenStack Identity extension that enables delegation and, optionally,
impersonation through <literal>keystone</literal>. A trust extension defines a
relationship between:</para>
      <variablelist>
        <varlistentry>
          <term>
            <emphasis role="bold">Trustor</emphasis>
          </term>
          <listitem>
            <para>The user delegating a limited set of their own rights to another user.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <emphasis role="bold">Trustee</emphasis>
          </term>
          <listitem>
            <para>The user trust is being delegated to, for a limited time.</para>
            <para>The trust can eventually allow the trustee to impersonate the trustor.
For security reasons, some safeties are added. For example, if a trustor
loses a given role, any trusts the user issued with that role, and the
related tokens, are automatically revoked.</para>
          </listitem>
        </varlistentry>
      </variablelist>
      <para>The delegation parameters are:</para>
      <variablelist>
        <varlistentry>
          <term>
            <emphasis role="bold">User ID</emphasis>
          </term>
          <listitem>
            <para>The user IDs for the trustor and trustee.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <emphasis role="bold">Privileges</emphasis>
          </term>
          <listitem>
            <para>The delegated privileges are a combination of a project ID and a
number of roles that must be a subset of the roles assigned to the
trustor.</para>
            <para>If you omit all privileges, nothing is delegated. You cannot
delegate everything.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <emphasis role="bold">Delegation depth</emphasis>
          </term>
          <listitem>
            <para>Defines whether or not the delegation is recursive. If it is
recursive, defines the delegation chain length.</para>
            <para>Specify one of the following values:</para>
            <itemizedlist>
              <listitem>
                <para><literal>0</literal>. The delegate cannot delegate these permissions further.</para>
              </listitem>
              <listitem>
                <para><literal>1</literal>. The delegate can delegate the permissions to any set of
delegates but the latter cannot delegate further.</para>
              </listitem>
              <listitem>
                <para><literal>inf</literal>. The delegation is infinitely recursive.</para>
              </listitem>
            </itemizedlist>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <emphasis role="bold">Endpoints</emphasis>
          </term>
          <listitem>
            <para>A list of endpoints associated with the delegation.</para>
            <para>This parameter further restricts the delegation to the specified
endpoints only. If you omit the endpoints, the delegation is
useless. A special value of <literal>all_endpoints</literal> allows the trust to be
used by all endpoints associated with the delegated project.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <emphasis role="bold">Duration</emphasis>
          </term>
          <listitem>
            <para>(Optional) Comprised of the start time and end time for the trust.</para>
          </listitem>
        </varlistentry>
      </variablelist>
    </sect1>
    <sect1>
      <title>Caching layer</title>
      <para>OpenStack Identity supports a caching layer that is above the
configurable subsystems (for example, token). OpenStack Identity uses the
<link xlink:href="http://docs.openstack.org/developer/oslo.cache/">oslo.cache</link>
library which allows flexible cache back ends. The majority of the
caching configuration options are set in the <literal>[cache]</literal> section of the
<literal>/etc/keystone/keystone.conf</literal> file. However, each section that has
the capability to be cached usually has a caching boolean value that
toggles caching.</para>
      <para>So to enable only the token back end caching, set the values as follows:</para>
      <screen language="ini">[cache]
enabled=true

[catalog]
caching=false

[domain_config]
caching=false

[federation]
caching=false

[resource]
caching=false

[revoke]
caching=false

[role]
caching=false

[token]
caching=true</screen>
      <note>
        <para>Since the Newton release, the default setting is enabled for subsystem
caching and the global toggle. As a result, all subsystems that support
caching are doing this by default.</para>
      </note>
      <sect2>
        <title>Caching for tokens and tokens validation</title>
        <para>The token system has a separate <literal>cache_time</literal> configuration option,
that can be set to a value above or below the global <literal>expiration_time</literal>
default, allowing for different caching behavior from the other systems
in OpenStack Identity. This option is set in the <literal>[token]</literal> section of
the configuration file. Fernet tokens do not need to be persisted in a
back end and therefore must not be cached.</para>
        <para>The token revocation list cache time is handled by the configuration
option <literal>revocation_cache_time</literal> in the <literal>[token]</literal> section. The
revocation list is refreshed whenever a token is revoked. It typically
sees significantly more requests than specific token retrievals or token
validation calls.</para>
        <para>Here is a list of actions that are affected by the cached time: getting
a new token, revoking tokens, validating tokens, checking v2 tokens, and
checking v3 tokens.</para>
        <para>The delete token API calls invalidate the cache for the tokens being
acted upon, as well as invalidating the cache for the revoked token list
and the validate/check token calls.</para>
        <para>Token caching is configurable independently of the <literal>revocation_list</literal>
caching. Lifted expiration checks from the token drivers to the token
manager. This ensures that cached tokens will still raise a
<literal>TokenNotFound</literal> flag when expired.</para>
        <para>For cache consistency, all token IDs are transformed into the short
token hash at the provider and token driver level. Some methods have
access to the full ID (PKI Tokens), and some methods do not. Cache
invalidation is inconsistent without token ID normalization.</para>
      </sect2>
      <sect2>
        <title>Caching for non-token resources</title>
        <para>Various other keystone components have a separate <literal>cache_time</literal> configuration
option, that can be set to a value above or below the global
<literal>expiration_time</literal> default, allowing for different caching behavior
from the other systems in Identity service. This option can be set in various
sections (for example, <literal>[role]</literal> and <literal>[resource]</literal>) of the configuration
file.
The create, update, and delete actions for domains, projects and roles
will perform proper invalidations of the cached methods listed above.</para>
        <para>For more information about the different back ends (and configuration
options), see:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="http://dogpilecache.readthedocs.io/en/latest/api.html#memory-backend">dogpile.cache.memory</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://dogpilecache.readthedocs.io/en/latest/api.html#memcached-backends">dogpile.cache.memcached</link>
            </para>
            <note>
              <para>The memory back end is not suitable for use in a production
environment.</para>
            </note>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://dogpilecache.readthedocs.io/en/latest/api.html#redis-backends">dogpile.cache.redis</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://dogpilecache.readthedocs.io/en/latest/api.html#file-backends">dogpile.cache.dbm</link>
            </para>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>Configure the Memcached back end example</title>
        <para>The following example shows how to configure the memcached back end:</para>
        <screen language="ini">[cache]

enabled = true
backend = dogpile.cache.memcached
backend_argument = url:127.0.0.1:11211</screen>
        <para>You need to specify the URL to reach the <literal>memcached</literal> instance with the
<literal>backend_argument</literal> parameter.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Security compliance and PCI-DSS</title>
      <para>As of the Newton release, the Identity service contains additional security
compliance features, specifically to satisfy Payment Card Industry -
Data Security Standard (PCI-DSS) v3.1 requirements. See
<link xlink:href="http://specs.openstack.org/openstack/keystone-specs/specs/keystone/newton/pci-dss.html">Security Hardening PCI-DSS</link> for more information on PCI-DSS.</para>
      <para>Security compliance features are disabled by default and most of the features
only apply to the SQL backend for the identity driver. Other identity backends,
such as LDAP, should implement their own security controls.</para>
      <para>Enable these features by changing the configuration settings under the
<literal>[security_compliance]</literal> section in <literal>keystone.conf</literal>.</para>
      <sect2>
        <title>Setting the account lockout threshold</title>
        <para>The account lockout feature limits the number of incorrect password attempts.
If a user fails to authenticate after the maximum number of attempts, the
service disables the user. Re-enable the user by explicitly setting the
enable user attribute with the update user API call, either
<link xlink:href="http://developer.openstack.org/api-ref/identity/v2-admin/index.html?expanded=update-user-admin-endpoint-detail#update-user-admin-endpoint">v2.0</link> or <link xlink:href="http://developer.openstack.org/api-ref/identity/v3/index.html#update-user">v3</link>.</para>
        <para>You set the maximum number of failed authentication attempts by setting
the <literal>lockout_failure_attempts</literal>:</para>
        <screen language="ini">[security_compliance]
lockout_failure_attempts = 6</screen>
        <para>You set the number of minutes a user would be locked out by setting
the <literal>lockout_duration</literal> in seconds:</para>
        <screen language="ini">[security_compliance]
lockout_duration = 1800</screen>
        <para>If you do not set the <literal>lockout_duration</literal>, users may be locked out
indefinitely until the user is explicitly enabled via the API.</para>
      </sect2>
      <sect2>
        <title>Disabling inactive users</title>
        <para>PCI-DSS 8.1.4 requires that inactive user accounts be removed or disabled
within 90 days. You can achieve this by setting the
<literal>disable_user_account_days_inactive</literal>:</para>
        <screen language="ini">[security_compliance]
disable_user_account_days_inactive = 90</screen>
        <para>This above example means that users that have not authenticated (inactive) for
the past 90 days are automatically disabled. Users can be re-enabled by
explicitly setting the enable user attribute via the API.</para>
      </sect2>
      <sect2>
        <title>Configuring password expiration</title>
        <para>Passwords can be configured to expire within a certain number of days by
setting the <literal>password_expires_days</literal>:</para>
        <screen language="ini">[security_compliance]
password_expires_days = 90</screen>
        <para>Once set, any new password changes have an expiration date based on the
date/time of the password change plus the number of days defined here. Existing
passwords will not be impacted. If you want existing passwords to have an
expiration date, you would need to run a SQL script against the password table
in the database to update the expires_at column.</para>
        <para>In addition, you can set it so that passwords never expire for some users by
adding their user ID to <literal>password_expires_ignore_user_ids</literal> list:</para>
        <screen language="ini">[security_compliance]
password_expires_ignore_user_ids = [3a54353c9dcc44f690975ea768512f6a]</screen>
        <para>In this example, the password for user ID <literal>3a54353c9dcc44f690975ea768512f6a</literal>
would never expire.</para>
      </sect2>
      <sect2>
        <title>Indicating password strength requirements</title>
        <para>You set password strength requirements, such as requiring numbers in passwords
or setting a minimum password length, by adding a regular expression to the
<literal>password_regex</literal>:</para>
        <screen language="ini">[security_compliance]
password_regex = ^(?=.*\d)(?=.*[a-zA-Z]).{7,}$</screen>
        <para>The above example is a regular expression that requires a password to have
one letter, one digit, and a minimum length of seven characters.</para>
        <para>If you do set the <literal>password_regex</literal>, you should provide text that
describes your password strength requirements. You can do this by setting the
<literal>password_regex_description</literal>:</para>
        <screen language="ini">[security_compliance]
password_regex_description = Passwords must contain at least 1 letter, 1
                             digit, and be a minimum length of 7
                             characters.</screen>
        <para>The service returns that description to users to explain why their requested
password did not meet requirements.</para>
        <note>
          <para>You must ensure the <literal>password_regex_description</literal> accurately and
completely describes the <literal>password_regex</literal>. If the two options are out of
sync, the help text could inaccurately describe the password requirements
being applied to the password. This would lead to poor user experience.</para>
        </note>
      </sect2>
      <sect2>
        <title>Requiring a unique password history</title>
        <para>The password history requirements controls the number of passwords for a user
that must be unique before an old password can be reused. You can enforce this
by setting the <literal>unique_last_password_count</literal>:</para>
        <screen language="ini">[security_compliance]
unique_last_password_count= 5</screen>
        <para>The above example does not allow a user to create a new password that is the
same as any of their last four previous passwords.</para>
        <para>Similarly, you can set the number of days that a password must be used before
the user can change it by setting the <literal>minimum_password_age</literal>:</para>
        <screen language="ini">[security_compliance]
minimum_password_age = 1</screen>
        <para>In the above example, once a user changes their password, they would not be
able to change it again for one day. This prevents users from changing their
passwords immediately in order to wipe out their password history and reuse an
old password.</para>
        <note>
          <para>When you set <literal>password_expires_days</literal>, the value for the
<literal>minimum_password_age</literal> should be less than the <literal>password_expires_days</literal>.
Otherwise, users would not be able to change their passwords before they
expire.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>Example usage and Identity features</title>
      <para>The <literal>openstack</literal> CLI is used to interact with the Identity service.
It is set up to expect commands in the general
form of <literal>openstack command argument</literal>, followed by flag-like keyword
arguments to provide additional (often optional) information. For
example, the <command>user list</command> and <command>project create</command>
commands can be invoked as follows:</para>
      <screen language="bash"><?dbsuse-fo font-size="8pt"?># Using token auth env variables
export OS_SERVICE_ENDPOINT=http://127.0.0.1:5000/v2.0/
export OS_SERVICE_TOKEN=secrete_token
openstack user list
openstack project create demo --domain default

# Using token auth flags
openstack --os-token secrete --os-endpoint http://127.0.0.1:5000/v2.0/ user list
openstack --os-token secrete --os-endpoint http://127.0.0.1:5000/v2.0/ project create demo

# Using user + password + project_name env variables
export OS_USERNAME=admin
export OS_PASSWORD=secrete
export OS_PROJECT_NAME=admin
openstack user list
openstack project create demo --domain default

# Using user + password + project-name flags
openstack --os-username admin --os-password secrete --os-project-name admin user list
openstack --os-username admin --os-password secrete --os-project-name admin project create demo</screen>
      <sect2>
        <title>Logging</title>
        <para>You configure logging externally to the rest of Identity. The name of
the file specifying the logging configuration is set using the
<literal>log_config</literal> option in the <literal>[DEFAULT]</literal> section of the
<literal>/etc/keystone/keystone.conf</literal> file. To route logging through syslog,
set <literal>use_syslog=true</literal> in the <literal>[DEFAULT]</literal> section.</para>
        <para>A sample logging configuration file is available with the project in
<literal>etc/logging.conf.sample</literal>. Like other OpenStack projects, Identity
uses the Python logging module, which provides extensive configuration
options that let you define the output levels and formats.</para>
      </sect2>
      <sect2>
        <title>User CRUD</title>
        <para>Identity provides a user CRUD (Create, Read, Update, and Delete) filter that
Administrators can add to the <literal>public_api</literal> pipeline. The user CRUD filter
enables users to use a HTTP PATCH to change their own password. To enable
this extension you should define a <literal>user_crud_extension</literal> filter, insert
it after the <literal>*_body</literal> middleware and before the <literal>public_service</literal>
application in the <literal>public_api</literal> WSGI pipeline in
<literal>keystone-paste.ini</literal>. For example:</para>
        <screen language="ini"><?dbsuse-fo font-size="8pt"?>[filter:user_crud_extension]
paste.filter_factory = keystone.contrib.user_crud:CrudExtension.factory

[pipeline:public_api]
pipeline = sizelimit url_normalize request_id build_auth_context token_auth admin_token_auth json_body ec2_extension user_crud_extension public_service</screen>
        <para>Each user can then change their own password with a HTTP PATCH.</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ curl -X PATCH http://localhost:5000/v2.0/OS-KSCRUD/users/USERID -H "Content-type: application/json"  \
  -H "X_Auth_Token: AUTHTOKENID" -d '{"user": {"password": "ABCD", "original_password": "DCBA"}}'</screen>
        <para>In addition to changing their password, all current tokens for the user
are invalidated.</para>
        <note>
          <para>Only use a KVS back end for tokens when testing.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>Authentication middleware with user name and password</title>
      <para>You can also configure Identity authentication middleware using the
<literal>admin_user</literal> and <literal>admin_password</literal> options.</para>
      <note>
        <para>The <literal>admin_token</literal> option is deprecated and no longer used for
configuring auth_token middleware.</para>
      </note>
      <para>For services that have a separate paste-deploy <literal>.ini</literal> file, you can
configure the authentication middleware in the <literal>[keystone_authtoken]</literal>
section of the main configuration file, such as <literal>nova.conf</literal>. In
Compute, for example, you can remove the middleware parameters from
<literal>api-paste.ini</literal>, as follows:</para>
      <screen language="ini">[filter:authtoken]
paste.filter_factory = keystonemiddleware.auth_token:filter_factory</screen>
      <para>And set the following values in <literal>nova.conf</literal> as follows:</para>
      <screen language="ini">[DEFAULT]
...
auth_strategy=keystone

[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_user = admin
admin_password = SuperSekretPassword
admin_tenant_name = service</screen>
      <note>
        <para>The middleware parameters in the paste config take priority. You
must remove them to use the values in the <literal>[keystone_authtoken]</literal>
section.</para>
      </note>
      <note>
        <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and
<literal>auth_protocol</literal> options because the <literal>identity_uri</literal> option
replaces them.</para>
      </note>
      <para>This sample paste config filter makes use of the <literal>admin_user</literal> and
<literal>admin_password</literal> options:</para>
      <screen language="ini">[filter:authtoken]
paste.filter_factory = keystonemiddleware.auth_token:filter_factory
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
auth_token = 012345SECRET99TOKEN012345
admin_user = admin
admin_password = keystone123</screen>
      <note>
        <para>Using this option requires an admin project/role relationship. The
admin user is granted access to the admin role on the admin project.</para>
      </note>
      <note>
        <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and
<literal>auth_protocol</literal> options because the <literal>identity_uri</literal> option
replaces them.</para>
      </note>
    </sect1>
    <sect1>
      <title>Identity API protection with role-based access control (RBAC)</title>
      <para>Like most OpenStack projects, Identity supports the protection of its
APIs by defining policy rules based on an RBAC approach. Identity stores
a reference to a policy JSON file in the main Identity configuration
file, <literal>/etc/keystone/keystone.conf</literal>. Typically this file is named
<literal>policy.json</literal>, and contains the rules for which roles have access to
certain actions in defined services.</para>
      <para>Each Identity API v3 call has a line in the policy file that dictates
which level of governance of access applies.</para>
      <screen language="ini">API_NAME: RULE_STATEMENT or MATCH_STATEMENT</screen>
      <para>Where:</para>
      <para><literal>RULE_STATEMENT</literal> can contain <literal>RULE_STATEMENT</literal> or
<literal>MATCH_STATEMENT</literal>.</para>
      <para><literal>MATCH_STATEMENT</literal> is a set of identifiers that must match between the
token provided by the caller of the API and the parameters or target
entities of the API call in question. For example:</para>
      <screen language="ini">"identity:create_user": "role:admin and domain_id:%(user.domain_id)s"</screen>
      <para>Indicates that to create a user, you must have the admin role in your
token. The <literal>domain_id</literal> in your token must match the
<literal>domain_id</literal> in the user object that you are trying
to create, which implies this must be a domain-scoped token.
In other words, you must have the admin role on the domain
in which you are creating the user, and the token that you use
must be scoped to that domain.</para>
      <para>Each component of a match statement uses this format:</para>
      <screen language="ini">ATTRIB_FROM_TOKEN:CONSTANT or ATTRIB_RELATED_TO_API_CALL</screen>
      <para>The Identity service expects these attributes:</para>
      <para>Attributes from token:</para>
      <itemizedlist>
        <listitem>
          <para>
            <literal>user_id</literal>
          </para>
        </listitem>
        <listitem>
          <para>
            <literal>domain_id</literal>
          </para>
        </listitem>
        <listitem>
          <para>
            <literal>project_id</literal>
          </para>
        </listitem>
      </itemizedlist>
      <para>The <literal>project_id</literal> attribute requirement depends on the scope, and the
list of roles you have within that scope.</para>
      <para>Attributes related to API call:</para>
      <itemizedlist>
        <listitem>
          <para>
            <literal>user.domain_id</literal>
          </para>
        </listitem>
        <listitem>
          <para>Any parameters passed into the API call</para>
        </listitem>
        <listitem>
          <para>Any filters specified in the query string</para>
        </listitem>
      </itemizedlist>
      <para>You reference attributes of objects passed with an object.attribute
syntax (such as, <literal>user.domain_id</literal>). The target objects of an API are
also available using a target.object.attribute syntax. For instance:</para>
      <screen language="ini">"identity:delete_user": "role:admin and domain_id:%(target.user.domain_id)s"</screen>
      <para>would ensure that Identity only deletes the user object in the same
domain as the provided token.</para>
      <para>Every target object has an <literal>id</literal> and a <literal>name</literal> available as
<literal>target.OBJECT.id</literal> and <literal>target.OBJECT.name</literal>. Identity retrieves
other attributes from the database, and the attributes vary between
object types. The Identity service filters out some database fields,
such as user passwords.</para>
      <para>List of object attributes:</para>
      <screen language="ini">role:
     target.role.id
     target.role.name

user:
     target.user.default_project_id
     target.user.description
     target.user.domain_id
     target.user.enabled
     target.user.id
     target.user.name

group:
     target.group.description
     target.group.domain_id
     target.group.id
     target.group.name

domain:
     target.domain.enabled
     target.domain.id
     target.domain.name

project:
     target.project.description
     target.project.domain_id
     target.project.enabled
     target.project.id
     target.project.name</screen>
      <para>The default <literal>policy.json</literal> file supplied provides a somewhat
basic example of API protection, and does not assume any particular
use of domains. Refer to <literal>policy.v3cloudsample.json</literal> as an
example of multi-domain configuration installations where a cloud
provider wants to delegate administration of the contents of a domain
to a particular <literal>admin domain</literal>. This example policy file also
shows the use of an <literal>admin_domain</literal> to allow a cloud provider to
enable administrators to have wider access across the APIs.</para>
      <para>A clean installation could start with the standard policy file, to
allow creation of the <literal>admin_domain</literal> with the first users within
it. You could then obtain the <literal>domain_id</literal> of the admin domain,
paste the ID into a modified version of
<literal>policy.v3cloudsample.json</literal>, and then enable it as the main
<literal>policy file</literal>.</para>
    </sect1>
    <sect1>
      <title>Troubleshoot the Identity service</title>
      <para>To troubleshoot the Identity service, review the logs in the
<literal>/var/log/keystone/keystone.log</literal> file.</para>
      <para>Use the <literal>/etc/keystone/logging.conf</literal> file to configure the
location of log files.</para>
      <note>
        <para>The <literal>insecure_debug</literal> flag is unique to the Identity service.
If you enable <literal>insecure_debug</literal>, error messages from the API change
to return security-sensitive information. For example, the error message
on failed authentication includes information on why your authentication
failed.</para>
      </note>
      <para>The logs show the components that have come in to the WSGI request, and
ideally show an error that explains why an authorization request failed.
If you do not see the request in the logs, run keystone with the
<literal>--debug</literal> parameter. Pass the <literal>--debug</literal> parameter before the
command parameters.</para>
      <sect2>
        <title>Debug PKI middleware</title>
        <sect3>
          <title>Problem</title>
          <para>If you receive an <literal>Invalid OpenStack Identity Credentials</literal> message when
you accessing and reaching an OpenStack service, it might be caused by
the changeover from UUID tokens to PKI tokens in the Grizzly release.</para>
          <para>The PKI-based token validation scheme relies on certificates from
Identity that are fetched through HTTP and stored in a local directory.
The location for this directory is specified by the <literal>signing_dir</literal>
configuration option.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>In your services configuration file, look for a section like this:</para>
          <screen language="ini">[keystone_authtoken]
signing_dir = /var/cache/glance/api
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = glance</screen>
          <para>The first thing to check is that the <literal>signing_dir</literal> does, in fact,
exist. If it does, check for certificate files:</para>
          <screen language="console">$ ls -la /var/cache/glance/api/

total 24
drwx------. 2 ayoung root 4096 Jul 22 10:58 .
drwxr-xr-x. 4 root root 4096 Nov 7 2012 ..
-rw-r-----. 1 ayoung ayoung 1424 Jul 22 10:58 cacert.pem
-rw-r-----. 1 ayoung ayoung 15 Jul 22 10:58 revoked.pem
-rw-r-----. 1 ayoung ayoung 4518 Jul 22 10:58 signing_cert.pem</screen>
          <para>This directory contains two certificates and the token revocation list.
If these files are not present, your service cannot fetch them from
Identity. To troubleshoot, try to talk to Identity to make sure it
correctly serves files, as follows:</para>
          <screen language="console">$ curl http://localhost:35357/v2.0/certificates/signing</screen>
          <para>This command fetches the signing certificate:</para>
          <screen language="yaml">Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 1 (0x1)
    Signature Algorithm: sha1WithRSAEncryption
        Issuer: C=US, ST=Unset, L=Unset, O=Unset, CN=www.example.com
        Validity
            Not Before: Jul 22 14:57:31 2013 GMT
            Not After : Jul 20 14:57:31 2023 GMT
        Subject: C=US, ST=Unset, O=Unset, CN=www.example.com</screen>
          <para>Note the expiration dates of the certificate:</para>
          <screen language="console">Not Before: Jul 22 14:57:31 2013 GMT
Not After : Jul 20 14:57:31 2023 GMT</screen>
          <para>The token revocation list is updated once a minute, but the certificates
are not. One possible problem is that the certificates are the wrong
files or garbage. You can remove these files and run another command
against your server; they are fetched on demand.</para>
          <para>The Identity service log should show the access of the certificate files. You
might have to turn up your logging levels. Set <literal>debug = True</literal> in your
Identity configuration file and restart the Identity server.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>(keystone.common.wsgi): 2013-07-24 12:18:11,461 DEBUG wsgi __call__
arg_dict: {}
(access): 2013-07-24 12:18:11,462 INFO core __call__ 127.0.0.1 - - [24/Jul/2013:16:18:11 +0000]
"GET http://localhost:35357/v2.0/certificates/signing HTTP/1.0" 200 4518</screen>
          <para>If the files do not appear in your directory after this, it is likely
one of the following issues:</para>
          <itemizedlist>
            <listitem>
              <para>Your service is configured incorrectly and cannot talk to Identity.
Check the <literal>auth_port</literal> and <literal>auth_host</literal> values and make sure that
you can talk to that service through cURL, as shown previously.</para>
            </listitem>
            <listitem>
              <para>Your signing directory is not writable. Use the <literal>chmod</literal> command to
change its permissions so that the service (POSIX) user can write to
it. Verify the change through <literal>su</literal> and <literal>touch</literal> commands.</para>
            </listitem>
            <listitem>
              <para>The SELinux policy is denying access to the directory.</para>
            </listitem>
          </itemizedlist>
          <para>SELinux troubles often occur when you use Fedora or RHEL-based packages and
you choose configuration options that do not match the standard policy.
Run the <literal>setenforce permissive</literal> command. If that makes a difference,
you should relabel the directory. If you are using a sub-directory of
the <literal>/var/cache/</literal> directory, run the following command:</para>
          <screen language="console"># restorecon /var/cache/</screen>
          <para>If you are not using a <literal>/var/cache</literal> sub-directory, you should. Modify
the <literal>signing_dir</literal> configuration option for your service and restart.</para>
          <para>Set back to <literal>setenforce enforcing</literal> to confirm that your changes solve
the problem.</para>
          <para>If your certificates are fetched on demand, the PKI validation is
working properly. Most likely, the token from Identity is not valid for
the operation you are attempting to perform, and your user needs a
different role for the operation.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Debug signing key file errors</title>
        <sect3>
          <title>Problem</title>
          <para>If an error occurs when the signing key file opens, it is possible that
the person who ran the <command>keystone-manage pki_setup</command> command to
generate certificates and keys did not use the correct user.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>When you run the <command>keystone-manage pki_setup</command> command, Identity
generates a set of certificates and keys in <literal>/etc/keystone/ssl*</literal>, which
is owned by <literal>root:root</literal>. This can present a problem when you run the
Identity daemon under the keystone user account (nologin) when you try
to run PKI. Unless you run the <command>chown</command> command against the
files <literal>keystone:keystone</literal>, or run the <command>keystone-manage pki_setup</command>
command with the <literal>--keystone-user</literal> and
<literal>--keystone-group</literal> parameters, you will get an error.
For example:</para>
          <screen language="console">2012-07-31 11:10:53 ERROR [keystone.common.cms] Error opening signing key file
/etc/keystone/ssl/private/signing_key.pem
140380567730016:error:0200100D:system library:fopen:Permission
denied:bss_file.c:398:fopen('/etc/keystone/ssl/private/signing_key.pem','r')
140380567730016:error:20074002:BIO routines:FILE_CTRL:system lib:bss_file.c:400:
unable to load signing key file</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Flush expired tokens from the token database table</title>
        <sect3>
          <title>Problem</title>
          <para>As you generate tokens, the token database table on the Identity server
grows.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To clear the token table, an administrative user must run the
<command>keystone-manage token_flush</command> command to flush the tokens. When you
flush tokens, expired tokens are deleted and traceability is eliminated.</para>
          <para>Use <literal>cron</literal> to schedule this command to run frequently based on your
workload. For large workloads, running it every minute is recommended.</para>
        </sect3>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Dashboard</title>
    <info/>
    <para>The OpenStack Dashboard is a web-based interface that allows you to
manage OpenStack resources and services. The Dashboard allows you to
interact with the OpenStack Compute cloud controller using the OpenStack
APIs. For more information about installing and configuring the
Dashboard, see the <link xlink:href="http://docs.openstack.org/project-install-guide/newton/">Installation Tutorials and Guides</link>
for your operating system.</para>
     <itemizedlist>
      <listitem>
        <para>To deploy the dashboard, see the <link xlink:href="http://docs.openstack.org/developer/horizon/topics/deployment.html">OpenStack dashboard documentation</link>.</para>
      </listitem>
      <listitem>
        <para>To launch instances with the dashboard as an end user, see the
          <link xlink:href="http://docs.openstack.org/user-guide/dashboard-launch-instances.html">Launch and manage instances</link>.
          in the OpenStack End User Guide.</para>
      </listitem>
      <listitem>
        <para>To create and manage ports, see the <link xlink:href="http://docs.openstack.org/user-guide/dashboard-create-networks.html#create-a-port">Create and manage networks</link>
          section of the OpenStack End User Guide.</para>
      </listitem>
    </itemizedlist>
    <sect1>
      <title>Customize and configure the Dashboard</title>
      <para>Once you have the Dashboard installed, you can customize the way
it looks and feels to suit the needs of your environment, your
project, or your business.</para>
      <para>You can also configure the Dashboard for a secure HTTPS deployment, or
an HTTP deployment. The standard OpenStack installation uses a non-encrypted
HTTP channel, but you can enable SSL support for the Dashboard.</para>
      <para>For information on configuring HTTPS or HTTP, see <xref linkend="configure-dashboard"/>.</para>
      <sect2>
        <title>Customize the Dashboard</title>
        <para>The OpenStack Dashboard on Ubuntu installs the
<literal>openstack-dashboard-ubuntu-theme</literal> package by default. If you do not
want to use this theme, remove it and its dependencies:</para>
        <screen language="console"># apt-get remove --auto-remove openstack-dashboard-ubuntu-theme</screen>
        <note>
          <para>This guide focuses on the <literal>local_settings.py</literal> file.</para>
        </note>
        <para>The following Dashboard content can be customized to suit your needs:</para>
        <itemizedlist>
          <listitem>
            <para>Logo</para>
          </listitem>
          <listitem>
            <para>Site colors</para>
          </listitem>
          <listitem>
            <para>HTML title</para>
          </listitem>
          <listitem>
            <para>Logo link</para>
          </listitem>
          <listitem>
            <para>Help URL</para>
          </listitem>
        </itemizedlist>
        <sect3>
          <title>Logo and site colors</title>
          <procedure>
            <step>
              <para>Create two PNG logo files with transparent backgrounds using
the following sizes:</para>
              <itemizedlist>
                <listitem>
                  <para>Login screen: 365 x 50</para>
                </listitem>
                <listitem>
                  <para>Logged in banner: 216 x 35</para>
                </listitem>
              </itemizedlist>
            </step>
            <step>
              <para>Upload your new images to
<literal>/usr/share/openstack-dashboard/openstack_dashboard/static/dashboard/img/</literal>.</para>
            </step>
            <step>
              <para>Create a CSS style sheet in
<literal>/usr/share/openstack-dashboard/openstack_dashboard/static/dashboard/scss/</literal>.</para>
            </step>
            <step>
              <para>Change the colors and image file names as appropriate. Ensure the
relative directory paths are the same. The following example file
shows you how to customize your CSS file:</para>
              <screen language="css">/*
* New theme colors for dashboard that override the defaults:
*  dark blue: #355796 / rgb(53, 87, 150)
*  light blue: #BAD3E1 / rgb(186, 211, 225)
*
* By Preston Lee &lt;plee@tgen.org&gt;
*/
h1.brand {
background: #355796 repeat-x top left;
border-bottom: 2px solid #BAD3E1;
}
h1.brand a {
background: url(../img/my_cloud_logo_small.png) top left no-repeat;
}
#splash .login {
background: #355796 url(../img/my_cloud_logo_medium.png) no-repeat center 35px;
}
#splash .login .modal-header {
border-top: 1px solid #BAD3E1;
}
.btn-primary {
background-image: none !important;
background-color: #355796 !important;
border: none !important;
box-shadow: none;
}
.btn-primary:hover,
.btn-primary:active {
border: none;
box-shadow: none;
background-color: #BAD3E1 !important;
text-decoration: none;
}</screen>
            </step>
            <step>
              <para>Open the following HTML template in an editor of your choice:</para>
              <screen language="console">/usr/share/openstack-dashboard/openstack_dashboard/templates/_stylesheets.html</screen>
            </step>
            <step>
              <para>Add a line to include your newly created style sheet. For example,
<literal>custom.css</literal> file:</para>
              <screen language="html"><?dbsuse-fo font-size="8pt"?>&lt;link href='{{ STATIC_URL }}bootstrap/css/bootstrap.min.css' media='screen' rel='stylesheet' /&gt;
&lt;link href='{{ STATIC_URL }}dashboard/css/{% choose_css %}' media='screen' rel='stylesheet' /&gt;
&lt;link href='{{ STATIC_URL }}dashboard/css/custom.css' media='screen' rel='stylesheet' /&gt;</screen>
            </step>
            <step>
              <para>Restart the Apache service.</para>
            </step>
            <step>
              <para>To view your changes, reload your Dashboard. If necessary, go back
and modify your CSS file as appropriate.</para>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>HTML title</title>
          <procedure>
            <step>
              <para>Set the HTML title, which appears at the top of the browser window, by
adding the following line to <literal>local_settings.py</literal>:</para>
              <screen language="python">SITE_BRANDING = "Example, Inc. Cloud"</screen>
            </step>
            <step>
              <para>Restart Apache for this change to take effect.</para>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Logo link</title>
          <procedure>
            <step>
              <para>The logo also acts as a hyperlink. The default behavior is to redirect
to <literal>horizon:user_home</literal>. To change this, add the following attribute to
<literal>local_settings.py</literal>:</para>
              <screen language="python">SITE_BRANDING_LINK = "http://example.com"</screen>
            </step>
            <step>
              <para>Restart Apache for this change to take effect.</para>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Help URL</title>
          <procedure>
            <step>
              <para>By default, the help URL points to <link xlink:href="http://docs.openstack.org">http://docs.openstack.org</link>. To change
this, edit the following attribute in <literal>local_settings.py</literal>:</para>
              <screen language="python">HORIZON_CONFIG["help_url"] = "http://openstack.mycompany.org"</screen>
            </step>
            <step>
              <para>Restart Apache for this change to take effect.</para>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2 xml:id="configure-dashboard">
        <title>Configure the Dashboard</title>
        <para>The following section on configuring the Dashboard for a
secure HTTPS deployment, or a HTTP deployment, uses concrete
examples to ensure the procedure is clear. The file path varies
by distribution, however. If needed, you can also configure
the VNC window size in the Dashboard.</para>
        <sect3>
          <title>Configure the Dashboard for HTTP</title>
          <para>You can configure the Dashboard for a simple HTTP deployment.
The standard installation uses a non-encrypted HTTP channel.</para>
          <procedure>
            <step>
              <para>Specify the host for your Identity service endpoint in the
<literal>local_settings.py</literal> file with the <literal>OPENSTACK_HOST</literal> setting.</para>
              <para>The following example shows this setting:</para>
              <screen language="python">import os

from django.utils.translation import ugettext_lazy as _

DEBUG = False
TEMPLATE_DEBUG = DEBUG
PROD = True
USE_SSL = False

SITE_BRANDING = 'OpenStack Dashboard'

# Ubuntu-specific: Enables an extra panel in the 'Settings' section
# that easily generates a Juju environments.yaml for download,
# preconfigured with endpoints and credentials required for bootstrap
# and service deployment.
ENABLE_JUJU_PANEL = True

# Note: You should change this value
SECRET_KEY = 'elj1IWiLoWHgryYxFT6j7cM5fGOOxWY0'

# Specify a regular expression to validate user passwords.
# HORIZON_CONFIG = {
#     "password_validator": {
#         "regex": '.*',
#         "help_text": _("Your password does not meet the requirements.")
#     }
# }

LOCAL_PATH = os.path.dirname(os.path.abspath(__file__))

CACHES = {
    'default': {
        'BACKEND' : 'django.core.cache.backends.memcached.MemcachedCache',
        'LOCATION' : '127.0.0.1:11211'
    }
}

# Send email to the console by default
EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'
# Or send them to /dev/null
#EMAIL_BACKEND = 'django.core.mail.backends.dummy.EmailBackend'

# Configure these for your outgoing email host
# EMAIL_HOST = 'smtp.my-company.com'
# EMAIL_PORT = 25
# EMAIL_HOST_USER = 'djangomail'
# EMAIL_HOST_PASSWORD = 'top-secret!'

# For multiple regions uncomment this configuration, and add (endpoint, title).
# AVAILABLE_REGIONS = [
#     ('http://cluster1.example.com:5000/v2.0', 'cluster1'),
#     ('http://cluster2.example.com:5000/v2.0', 'cluster2'),
# ]

OPENSTACK_HOST = "127.0.0.1"
OPENSTACK_KEYSTONE_URL = "http://%s:5000/v2.0" % OPENSTACK_HOST
OPENSTACK_KEYSTONE_DEFAULT_ROLE = "Member"

# The OPENSTACK_KEYSTONE_BACKEND settings can be used to identify the
# capabilities of the auth backend for Keystone.
# If Keystone has been configured to use LDAP as the auth backend then set
# can_edit_user to False and name to 'ldap'.
#
# TODO(tres): Remove these once Keystone has an API to identify auth backend.
OPENSTACK_KEYSTONE_BACKEND = {
    'name': 'native',
    'can_edit_user': True
}

# OPENSTACK_ENDPOINT_TYPE specifies the endpoint type to use for the endpoints
# in the Keystone service catalog. Use this setting when Horizon is running
# external to the OpenStack environment. The default is 'internalURL'.
#OPENSTACK_ENDPOINT_TYPE = "publicURL"

# The number of Swift containers and objects to display on a single page before
# providing a paging element (a "more" link) to paginate results.
API_RESULT_LIMIT = 1000

# If you have external monitoring links, eg:
# EXTERNAL_MONITORING = [
#     ['Nagios','http://foo.com'],
#     ['Ganglia','http://bar.com'],
# ]

LOGGING = {
        'version': 1,
        # When set to True this will disable all logging except
        # for loggers specified in this configuration dictionary. Note that
        # if nothing is specified here and disable_existing_loggers is True,
        # django.db.backends will still log unless it is disabled explicitly.
        'disable_existing_loggers': False,
        'handlers': {
            'null': {
                'level': 'DEBUG',
                'class': 'django.utils.log.NullHandler',
                },
            'console': {
                # Set the level to "DEBUG" for verbose output logging.
                'level': 'INFO',
                'class': 'logging.StreamHandler',
                },
            },
        'loggers': {
            # Logging from django.db.backends is VERY verbose, send to null
            # by default.
            'django.db.backends': {
                'handlers': ['null'],
                'propagate': False,
                },
            'horizon': {
                'handlers': ['console'],
                'propagate': False,
            },
            'novaclient': {
                'handlers': ['console'],
                'propagate': False,
            },
            'keystoneclient': {
                'handlers': ['console'],
                'propagate': False,
            },
            'nose.plugins.manager': {
                'handlers': ['console'],
                'propagate': False,
            }
        }
}</screen>
              <para>The service catalog configuration in the Identity service determines
whether a service appears in the Dashboard.
For the full listing, see <link xlink:href="http://docs.openstack.org/developer/horizon/topics/settings.html">Horizon Settings and Configuration</link>.</para>
            </step>
            <step>
              <para>Restart the Apache HTTP Server.</para>
            </step>
            <step>
              <para>Restart <literal>memcached</literal>.</para>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Configure the Dashboard for HTTPS</title>
          <para>You can configure the Dashboard for a secured HTTPS deployment.
While the standard installation uses a non-encrypted HTTP channel,
you can enable SSL support for the Dashboard.</para>
          <para>This example uses the <literal>http://openstack.example.com</literal> domain.
Use a domain that fits your current setup.</para>
          <procedure>
            <step>
              <para>In the <literal>local_settings.py</literal> file, update the following options:</para>
              <screen language="python">USE_SSL = True
CSRF_COOKIE_SECURE = True
SESSION_COOKIE_SECURE = True
SESSION_COOKIE_HTTPONLY = True</screen>
              <para>To enable HTTPS, the <literal>USE_SSL = True</literal> option is required.</para>
              <para>The other options require that HTTPS is enabled;
these options defend against cross-site scripting.</para>
            </step>
            <step>
              <para>Edit the <literal>openstack-dashboard.conf</literal> file as shown in the
<emphasis role="bold">Example After</emphasis>:</para>
              <para>
                <emphasis role="bold">Example Before</emphasis>
              </para>
              <screen language="apacheconf"><?dbsuse-fo font-size="8pt"?>WSGIScriptAlias / /usr/share/openstack-dashboard/openstack_dashboard/wsgi/django.wsgi
WSGIDaemonProcess horizon user=www-data group=www-data processes=3 threads=10
Alias /static /usr/share/openstack-dashboard/openstack_dashboard/static/
&lt;Directory /usr/share/openstack-dashboard/openstack_dashboard/wsgi&gt;
# For Apache http server 2.2 and earlier:
Order allow,deny
Allow from all

# For Apache http server 2.4 and later:
# Require all granted
&lt;/Directory&gt;</screen>
              <para>
                <emphasis role="bold">Example After</emphasis>
              </para>
              <screen language="apacheconf"><?dbsuse-fo font-size="8pt"?>&lt;VirtualHost *:80&gt;
ServerName openstack.example.com
&lt;IfModule mod_rewrite.c&gt;
RewriteEngine On
RewriteCond %{HTTPS} off
RewriteRule (.*) https://%{HTTP_HOST}%{REQUEST_URI}
&lt;/IfModule&gt;
&lt;IfModule !mod_rewrite.c&gt;
RedirectPermanent / https://openstack.example.com
&lt;/IfModule&gt;
&lt;/VirtualHost&gt;
&lt;VirtualHost *:443&gt;
ServerName openstack.example.com

SSLEngine On
# Remember to replace certificates and keys with valid paths in your environment
SSLCertificateFile /etc/apache2/SSL/openstack.example.com.crt
SSLCACertificateFile /etc/apache2/SSL/openstack.example.com.crt
SSLCertificateKeyFile /etc/apache2/SSL/openstack.example.com.key
SetEnvIf User-Agent ".*MSIE.*" nokeepalive ssl-unclean-shutdown

# HTTP Strict Transport Security (HSTS) enforces that all communications
# with a server go over SSL. This mitigates the threat from attacks such
# as SSL-Strip which replaces links on the wire, stripping away https prefixes
# and potentially allowing an attacker to view confidential information on the
# wire
Header add Strict-Transport-Security "max-age=15768000"

WSGIScriptAlias / /usr/share/openstack-dashboard/openstack_dashboard/wsgi/django.wsgi
WSGIDaemonProcess horizon user=www-data group=www-data processes=3 threads=10
Alias /static /usr/share/openstack-dashboard/openstack_dashboard/static/
&lt;Directory /usr/share/openstack-dashboard/openstack_dashboard/wsgi&gt;
# For Apache http server 2.2 and earlier:
    &lt;ifVersion &lt;2.4&gt;
        Order allow,deny
        Allow from all
    &lt;/ifVersion&gt;
# For Apache http server 2.4 and later:
    &lt;ifVersion &gt;=2.4&gt;
#The following two lines have been added by bms for error "AH01630: client denied
#by server configuration:
#/usr/share/openstack-dashboard/openstack_dashboard/static/dashboard/cssa"
        Options All
        AllowOverride All
        Require all granted
    &lt;/ifVersion&gt;
&lt;/Directory&gt;
&lt;Directory /usr/share/openstack-dashboard/static&gt;
    &lt;ifVersion &gt;=2.4&gt;
        Options All
        AllowOverride All
        Require all granted
    &lt;/ifVersion&gt;
&lt;/Directory&gt;
&lt;/VirtualHost&gt;</screen>
              <para>In this configuration, the Apache HTTP Server listens on port 443 and
redirects all non-secure requests to the HTTPS protocol. The secured
section defines the private key, public key, and certificate to use.</para>
            </step>
            <step>
              <para>Restart the Apache HTTP Server.</para>
            </step>
            <step>
              <para>Restart <literal>memcached</literal>.</para>
              <para>If you try to access the Dashboard through HTTP, the browser redirects
you to the HTTPS page.</para>
              <note>
                <para>Configuring the Dashboard for HTTPS also requires enabling SSL for
the noVNC proxy service. On the controller node, add the following
additional options to the <literal>[DEFAULT]</literal> section of the
<literal>/etc/nova/nova.conf</literal> file:</para>
                <screen language="ini">[DEFAULT]
...
ssl_only = true
cert = /etc/apache2/SSL/openstack.example.com.crt
key = /etc/apache2/SSL/openstack.example.com.key</screen>
                <para>On the compute nodes, ensure the <literal>nonvncproxy_base_url</literal> option
points to a URL with an HTTPS scheme:</para>
                <screen language="ini">[DEFAULT]
...
novncproxy_base_url = https://controller:6080/vnc_auto.html</screen>
              </note>
            </step>
          </procedure>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Set up session storage for the Dashboard</title>
      <para>The Dashboard uses <link xlink:href="https://docs.djangoproject.com/en/dev/topics/http/sessions/">Django sessions
framework</link>
to handle user session data. However, you can use any available session
back end. You customize the session back end through the
<literal>SESSION_ENGINE</literal> setting in your <literal>local_settings.py</literal> file.</para>
      <para>After architecting and implementing the core OpenStack
services and other required services, combined with the Dashboard
service steps below, users and administrators can use
the OpenStack dashboard. Refer to the <link xlink:href="http://docs.openstack.org/user-guide/dashboard.html">OpenStack Dashboard</link>
chapter of the OpenStack End User Guide for
further instructions on logging in to the Dashboard.</para>
      <para>The following sections describe the pros and cons of each option as it
pertains to deploying the Dashboard.</para>
      <sect2>
        <title>Local memory cache</title>
        <para>Local memory storage is the quickest and easiest session back end to set
up, as it has no external dependencies whatsoever. It has the following
significant drawbacks:</para>
        <itemizedlist>
          <listitem>
            <para>No shared storage across processes or workers.</para>
          </listitem>
          <listitem>
            <para>No persistence after a process terminates.</para>
          </listitem>
        </itemizedlist>
        <para>The local memory back end is enabled as the default for Horizon solely
because it has no dependencies. It is not recommended for production
use, or even for serious development work.</para>
        <screen language="python">SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
  'default' : {
    'BACKEND': 'django.core.cache.backends.locmem.LocMemCache'
  }
}</screen>
        <para>You can use applications such as <literal>Memcached</literal> or <literal>Redis</literal> for external
caching. These applications offer persistence and shared storage and are
useful for small-scale deployments and development.</para>
        <sect3>
          <title>Memcached</title>
          <para>Memcached is a high-performance and distributed memory object caching
system providing in-memory key-value store for small chunks of arbitrary
data.</para>
          <para>Requirements:</para>
          <itemizedlist>
            <listitem>
              <para>Memcached service running and accessible.</para>
            </listitem>
            <listitem>
              <para>Python module <literal>python-memcached</literal> installed.</para>
            </listitem>
          </itemizedlist>
          <screen language="python">SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
  'default': {
    'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
    'LOCATION': 'my_memcached_host:11211',
  }
}</screen>
        </sect3>
        <sect3>
          <title>Redis</title>
          <para>Redis is an open source, BSD licensed, advanced key-value store. It is
often referred to as a data structure server.</para>
          <para>Requirements:</para>
          <itemizedlist>
            <listitem>
              <para>Redis service running and accessible.</para>
            </listitem>
            <listitem>
              <para>Python modules <literal>redis</literal> and <literal>django-redis</literal> installed.</para>
            </listitem>
          </itemizedlist>
          <screen language="python">SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
    "default": {
        "BACKEND": "redis_cache.cache.RedisCache",
        "LOCATION": "127.0.0.1:6379:1",
        "OPTIONS": {
            "CLIENT_CLASS": "redis_cache.client.DefaultClient",
        }
    }
}</screen>
        </sect3>
        <sect3>
          <title>Initialize and configure the database</title>
          <para>Database-backed sessions are scalable, persistent, and can be made
high-concurrency and highly available.</para>
          <para>However, database-backed sessions are one of the slower session storages
and incur a high overhead under heavy usage. Proper configuration of
your database deployment can also be a substantial undertaking and is
far beyond the scope of this documentation.</para>
          <procedure>
            <step>
              <para>Start the MySQL command-line client.</para>
              <screen language="console">$ mysql -u root -p</screen>
            </step>
            <step>
              <para>Enter the MySQL root user's password when prompted.</para>
            </step>
            <step>
              <para>To configure the MySQL database, create the dash database.</para>
              <screen language="console">mysql&gt; CREATE DATABASE dash;</screen>
            </step>
            <step>
              <para>Create a MySQL user for the newly created dash database that has full
control of the database. Replace DASH_DBPASS with a password for the
new user.</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>mysql&gt; GRANT ALL PRIVILEGES ON dash.* TO 'dash'@'%' IDENTIFIED BY 'DASH_DBPASS';
mysql&gt; GRANT ALL PRIVILEGES ON dash.* TO 'dash'@'localhost' IDENTIFIED BY 'DASH_DBPASS';</screen>
            </step>
            <step>
              <para>Enter <literal>quit</literal> at the <literal>mysql&gt;</literal> prompt to exit MySQL.</para>
            </step>
            <step>
              <para>In the <literal>local_settings.py</literal> file, change these options:</para>
              <screen language="python">SESSION_ENGINE = 'django.contrib.sessions.backends.db'
DATABASES = {
    'default': {
        # Database configuration here
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'dash',
        'USER': 'dash',
        'PASSWORD': 'DASH_DBPASS',
        'HOST': 'localhost',
        'default-character-set': 'utf8'
    }
}</screen>
            </step>
            <step>
              <para>After configuring the <literal>local_settings.py</literal> file as shown, you can run the
<command>manage.py syncdb</command> command to populate this newly created
database.</para>
              <screen language="console"># /usr/share/openstack-dashboard/manage.py syncdb</screen>
            </step>
            <step>
              <para>The following output is returned:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>Installing custom SQL ...
Installing indexes ...
DEBUG:django.db.backends:(0.008) CREATE INDEX `django_session_c25c2c28` ON `django_session` (`expire_date`);; args=()
No fixtures found.</screen>
            </step>
            <step>
              <para>To avoid a warning when you restart Apache on Ubuntu, create a
<literal>blackhole</literal> directory in the Dashboard directory, as follows.</para>
              <screen language="console"># mkdir -p /var/lib/dash/.blackhole</screen>
            </step>
            <step>
              <para>Restart the Apache service.</para>
            </step>
            <step>
              <para>On Ubuntu, restart the <literal>nova-api</literal> service to ensure that the API server
can connect to the Dashboard without error.</para>
              <screen language="console"># service nova-api restart</screen>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2>
        <title>Cached database</title>
        <para>To mitigate the performance issues of database queries, you can use the
Django <literal>cached_db</literal> session back end, which utilizes both your database
and caching infrastructure to perform write-through caching and
efficient retrieval.</para>
        <para>Enable this hybrid setting by configuring both your database and cache,
as discussed previously. Then, set the following value:</para>
        <screen language="python">SESSION_ENGINE = "django.contrib.sessions.backends.cached_db"</screen>
      </sect2>
      <sect2>
        <title>Cookies</title>
        <para>If you use Django 1.4 or later, the <literal>signed_cookies</literal> back end avoids
server load and scaling problems.</para>
        <para>This back end stores session data in a cookie, which is stored by the
user's browser. The back end uses a cryptographic signing technique to
ensure session data is not tampered with during transport. This is not
the same as encryption; session data is still readable by an attacker.</para>
        <para>The pros of this engine are that it requires no additional dependencies
or infrastructure overhead, and it scales indefinitely as long as the
quantity of session data being stored fits into a normal cookie.</para>
        <para>The biggest downside is that it places session data into storage on the
user's machine and transports it over the wire. It also limits the
quantity of session data that can be stored.</para>
        <para>See the Django <link xlink:href="https://docs.djangoproject.com/en/dev/topics/http/sessions/#using-cookie-based-sessions">cookie-based
sessions</link>
documentation.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Create and manage images</title>
      <para>As an administrative user, you can create and manage images
for the projects to which you belong. You can also create
and manage images for users in all projects to which you have
access.</para>
      <para>To create and manage images in specified projects as an end
user, see the <link xlink:href="http://docs.openstack.org/user-guide/dashboard-manage-images.html">upload and manage images with Dashboard in
OpenStack End User Guide</link>
and <link xlink:href="http://docs.openstack.org/user-guide/common/cli-manage-images.html">manage images with CLI in OpenStack End User Guide</link>.</para>
      <para>To create and manage images as an administrator for other
users, use the following procedures.</para>
      <sect2>
        <title>Create images</title>
        <para>For details about image creation, see the <link xlink:href="http://docs.openstack.org/image-guide/">Virtual Machine Image
Guide</link>.</para>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Images</guimenu> category. The images that you
can administer for cloud users appear on this page.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Image</guimenu>, which opens the
<guimenu>Create An Image</guimenu> window.</para>
            <figure>
              <title>Figure Dashboard — Create Image</title>
              <mediaobject>
                <imageobject role="fo">
                  <imagedata fileref="create_image.png" width="99%"/>
                </imageobject>
                <imageobject role="html">
                  <imagedata fileref="create_image.png" width="99%"/>
                </imageobject>
              </mediaobject>
            </figure>
          </step>
          <step>
            <para>In the <guimenu>Create An Image</guimenu> window, enter or select the
following values:</para>
            <informaltable>
              <tgroup cols="2">
                <colspec colname="c1" colwidth="48.4*"/>
                <colspec colname="c2" colwidth="51.6*"/>
                <tbody>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Name</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter a name for the image.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Description</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter a brief description of
the image.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Image Source</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Choose the image source from
the dropdown list. Your choices
are <guimenu>Image Location</guimenu>
and <guimenu>Image File</guimenu>.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para><guimenu>Image File</guimenu> or
<guimenu>Image Location</guimenu></para>
                    </entry>
                    <entry>
                      <para>Based on your selection, there
is an <guimenu>Image File</guimenu> or
<guimenu>Image Location</guimenu>
field. You can include the
location URL or browse for the
image file on your file system
and add it.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Format</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Select the image format.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Architecture</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Specify the architecture. For
example, <literal>i386</literal> for a 32-bit
architecture or <literal>x86_64</literal> for
a 64-bit architecture.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Minimum Disk (GB)</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Leave this field empty.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Minimum RAM (MB)</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Leave this field empty.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Copy Data</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Specify this option to copy
image data to the Image service.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Public</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Select this option to make the
image public to all users.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <guimenu>Protected</guimenu>
                      </para>
                    </entry>
                    <entry>
                      <para>Select this option to ensure
that only users with
permissions can delete it.</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </informaltable>
          </step>
          <step>
            <para>Click <guimenu>Create Image</guimenu>.</para>
            <para>The image is queued to be uploaded. It might take several minutes
before the status changes from <literal>Queued</literal> to <literal>Active</literal>.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Update images</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Images</guimenu> category.</para>
          </step>
          <step>
            <para>Select the images that you want to edit. Click <guimenu>Edit Image</guimenu>.</para>
          </step>
          <step>
            <para>In the <guimenu>Edit Image</guimenu> window, you can change the image name.</para>
            <para>Select the <guimenu>Public</guimenu> check box to make the image public.
Clear this check box to make the image private. You cannot change
the <guimenu>Kernel ID</guimenu>, <guimenu>Ramdisk ID</guimenu>, or
<guimenu>Architecture</guimenu> attributes for an image.</para>
          </step>
          <step>
            <para>Click <guimenu>Edit Image</guimenu>.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Delete images</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin tab</guimenu>, open the <guimenu>System</guimenu> tab
and click the <guimenu>Images</guimenu> category.</para>
          </step>
          <step>
            <para>Select the images that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Images</guimenu>.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Images</guimenu> window, click <guimenu>Delete
Images</guimenu> to confirm the deletion.</para>
            <para>You cannot undo this action.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Create and manage roles</title>
      <para>A role is a personality that a user assumes to perform a specific set
of operations. A role includes a set of rights and privileges. A user
assumes that role inherits those rights and privileges.</para>
      <note>
        <para>OpenStack Identity service defines a user's role on a
project, but it is completely up to the individual service
to define what that role means. This is referred to as the
service's policy. To get details about what the privileges
for each role are, refer to the <literal>policy.json</literal> file
available for each service in the
<literal>/etc/SERVICE/policy.json</literal> file. For example, the
policy defined for OpenStack Identity service is defined
in the <literal>/etc/keystone/policy.json</literal> file.</para>
      </note>
      <sect2>
        <title>Create a role</title>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>admin</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Identity</guimenu> tab, click the <guimenu>Roles</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Create Role</guimenu> button.</para>
            <para>In the <guimenu>Create Role</guimenu> window, enter a name for the role.</para>
          </step>
          <step>
            <para>Click the <guimenu>Create Role</guimenu> button to confirm your changes.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Edit a role</title>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>Identity</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Identity</guimenu> tab, click the <guimenu>Roles</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Edit</guimenu> button.</para>
            <para>In the <guimenu>Update Role</guimenu> window, enter a new name for the role.</para>
          </step>
          <step>
            <para>Click the <guimenu>Update Role</guimenu> button to confirm your changes.</para>
          </step>
        </procedure>
        <note>
          <para>Using the dashboard, you can edit only the name assigned to
a role.</para>
        </note>
      </sect2>
      <sect2>
        <title>Delete a role</title>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>Identity</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Identity</guimenu> tab, click the <guimenu>Roles</guimenu> category.</para>
          </step>
          <step>
            <para>Select the role you want to delete and click the <guimenu>Delete
Roles</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Roles</guimenu> window, click <guimenu>Delete
Roles</guimenu> to confirm the deletion.</para>
            <para>You cannot undo this action.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage instances</title>
      <para>As an administrative user, you can manage instances for users in various
projects. You can view, terminate, edit, perform a soft or hard reboot,
create a snapshot from, and migrate instances. You can also view the
logs for instances or launch a VNC console for an instance.</para>
      <para>For information about using the Dashboard to launch instances as an end
user, see the <link xlink:href="http://docs.openstack.org/user-guide/dashboard-launch-instances.html">OpenStack End User Guide</link>.</para>
      <sect2>
        <title>Create instance snapshots</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Instances</guimenu> category.</para>
          </step>
          <step>
            <para>Select an instance to create a snapshot from it. From the
Actions drop-down list, select <guimenu>Create Snapshot</guimenu>.</para>
          </step>
          <step>
            <para>In the <guimenu>Create Snapshot</guimenu> window, enter a name for the snapshot.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Snapshot</guimenu>. The Dashboard shows the instance snapshot
in the <guimenu>Images</guimenu> category.</para>
          </step>
          <step>
            <para>To launch an instance from the snapshot, select the snapshot and
click <guimenu>Launch</guimenu>. For information about launching
instances, see the
<link xlink:href="http://docs.openstack.org/user-guide/dashboard-launch-instances.html">OpenStack End User Guide</link>.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Control the state of an instance</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Instances</guimenu> category.</para>
          </step>
          <step>
            <para>Select the instance for which you want to change the state.</para>
          </step>
          <step>
            <para>From the drop-down list in the Actions column,
select the state.</para>
            <para>Depending on the current state of the instance, you can perform various
actions on the instance. For example, pause, un-pause, suspend, resume,
soft or hard reboot, or terminate (actions in red are dangerous).</para>
          </step>
        </procedure>
        <figure>
          <title>Figure Dashboard — Instance Actions</title>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="change_instance_state.jpg" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="change_instance_state.jpg" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
      </sect2>
      <sect2>
        <title>Track usage</title>
        <para>Use the <guimenu>Overview</guimenu> category to track usage of instances
for each project.</para>
        <para>You can track costs per month by showing meters like number of VCPUs,
disks, RAM, and uptime of all your instances.</para>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project from the
drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Overview</guimenu> category.</para>
          </step>
          <step>
            <para>Select a month and click <guimenu>Submit</guimenu> to query the instance usage for
that month.</para>
          </step>
          <step>
            <para>Click <guimenu>Download CSV Summary</guimenu> to download a CSV summary.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage flavors</title>
      <para>In OpenStack, a flavor defines the compute, memory, and storage
capacity of a virtual server, also known as an instance. As an
administrative user, you can create, edit, and delete flavors.</para>
      <para>As of Newton, there are no default flavors.  The following table
lists the default flavors for Mitaka and earlier.</para>
      <informaltable>
        <tgroup cols="4">
          <colspec colname="c1" colwidth="24.5*"/>
          <colspec colname="c2" colwidth="18.4*"/>
          <colspec colname="c3" colwidth="30.6*"/>
          <colspec colname="c4" colwidth="26.5*"/>
          <thead>
            <row>
              <entry>
                <para>Flavor</para>
              </entry>
              <entry>
                <para>VCPUs</para>
              </entry>
              <entry>
                <para>Disk (in GB)</para>
              </entry>
              <entry>
                <para>RAM (in MB)</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>m1.tiny</para>
              </entry>
              <entry>
                <para>1</para>
              </entry>
              <entry>
                <para>1</para>
              </entry>
              <entry>
                <para>512</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.small</para>
              </entry>
              <entry>
                <para>1</para>
              </entry>
              <entry>
                <para>20</para>
              </entry>
              <entry>
                <para>2048</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.medium</para>
              </entry>
              <entry>
                <para>2</para>
              </entry>
              <entry>
                <para>40</para>
              </entry>
              <entry>
                <para>4096</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.large</para>
              </entry>
              <entry>
                <para>4</para>
              </entry>
              <entry>
                <para>80</para>
              </entry>
              <entry>
                <para>8192</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.xlarge</para>
              </entry>
              <entry>
                <para>8</para>
              </entry>
              <entry>
                <para>160</para>
              </entry>
              <entry>
                <para>16384</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
      <sect2>
        <title>Create flavors</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>In the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu>
tab and click the <guimenu>Flavors</guimenu> category.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Flavor</guimenu>.</para>
          </step>
          <step>
            <para>In the <guimenu>Create Flavor</guimenu> window, enter or select the
parameters for the flavor in the <guimenu>Flavor Information</guimenu> tab.</para>
            <figure>
              <title>Dashboard — Create Flavor</title>
              <mediaobject>
                <imageobject role="fo">
                  <imagedata fileref="create_flavor.jpg" width="99%"/>
                </imageobject>
                <imageobject role="html">
                  <imagedata fileref="create_flavor.jpg" width="99%"/>
                </imageobject>
              </mediaobject>
            </figure>
            <informaltable>
              <tgroup cols="2">
                <colspec colname="c1" colwidth="39.1*"/>
                <colspec colname="c2" colwidth="60.9*"/>
                <tbody>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">Name</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter the flavor name.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">ID</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Unique ID (integer or UUID) for the
new flavor. If specifying 'auto', a
UUID will be automatically generated.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">VCPUs</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter the number of virtual CPUs to
use.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">RAM (MB)</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter the amount of RAM to use, in
megabytes.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">Root Disk (GB)</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter the amount of disk space in
gigabytes to use for the root (/)
partition.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">Ephemeral Disk (GB)</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter the amount of disk space in
gigabytes to use for the ephemeral
partition. If unspecified, the value
is 0 by default.</para>
                      <para>Ephemeral disks offer machine local
disk storage linked to the lifecycle
of a VM instance. When a VM is
terminated, all data on the ephemeral
disk is lost. Ephemeral disks are not
included in any snapshots.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">Swap Disk (MB)</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Enter the amount of swap space (in
megabytes) to use. If unspecified,
the default is 0.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">RX/TX Factor</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>Optional property allows servers with
a different bandwidth to be created
with the RX/TX Factor. The default
value is 1. That is, the new bandwidth
is the same as that of the attached
network.</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </informaltable>
          </step>
          <step>
            <para>In the <guimenu>Flavor Access</guimenu> tab, you can control access to
the flavor by moving projects from the <guimenu>All Projects</guimenu>
column to the <guimenu>Selected Projects</guimenu> column.</para>
            <para>Only projects in the <guimenu>Selected Projects</guimenu> column can
use the flavor. If there are no projects in the right column,
all projects can use the flavor.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Flavor</guimenu>.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Update flavors</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>In the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Flavors</guimenu> category.</para>
          </step>
          <step>
            <para>Select the flavor that you want to edit. Click <guimenu>Edit
Flavor</guimenu>.</para>
          </step>
          <step>
            <para>In the <guimenu>Edit Flavor</guimenu> window, you can change the flavor
name, VCPUs, RAM, root disk, ephemeral disk, and swap disk values.</para>
          </step>
          <step>
            <para>Click <guimenu>Save</guimenu>.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Update Metadata</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>In the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Flavors</guimenu> category.</para>
          </step>
          <step>
            <para>Select the flavor that you want to update. In the drop-down
list, click <guimenu>Update Metadata</guimenu> or click <guimenu>No</guimenu> or
<guimenu>Yes</guimenu> in the <guimenu>Metadata</guimenu> column.</para>
          </step>
          <step>
            <para>In the <guimenu>Update Flavor Metadata</guimenu> window, you can customize
some metadata keys, then add it to this flavor and set them values.</para>
          </step>
          <step>
            <para>Click <guimenu>Save</guimenu>.</para>
            <para>
              <emphasis role="bold">Optional metadata keys</emphasis>
            </para>
            <informaltable>
              <tgroup cols="2">
                <colspec colname="c1" colwidth="50.0*"/>
                <colspec colname="c2" colwidth="50.0*"/>
                <tbody>
                  <row>
                    <entry morerows="4">
                      <para>
                        <emphasis role="bold">CPU limits</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>quota:cpu_shares</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:cpu_period</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:cpu_limit</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:cpu_reservation</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:cpu_quota</para>
                    </entry>
                  </row>
                  <row>
                    <entry morerows="5">
                      <para>
                        <emphasis role="bold">Disk tuning</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>quota:disk_read_bytes_sec</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:disk_read_iops_sec</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:disk_write_bytes_sec</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:disk_write_iops_sec</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:disk_total_bytes_sec</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:disk_total_iops_sec</para>
                    </entry>
                  </row>
                  <row>
                    <entry morerows="5">
                      <para>
                        <emphasis role="bold">Bandwidth I/O</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>quota:vif_inbound_average</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:vif_inbound_burst</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:vif_inbound_peak</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:vif_outbound_average</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:vif_outbound_burst</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>quota:vif_outbound_peak</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">Watchdog behavior</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>hw:watchdog_action</para>
                    </entry>
                  </row>
                  <row>
                    <entry morerows="2">
                      <para>
                        <emphasis role="bold">Random-number generator</emphasis>
                      </para>
                    </entry>
                    <entry>
                      <para>hw_rng:allowed</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>hw_rng:rate_bytes</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>hw_rng:rate_period</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </informaltable>
            <para>For information about supporting metadata keys, see the
<xref linkend="compute-flavors"/>.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Delete flavors</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>In the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Flavors</guimenu> category.</para>
          </step>
          <step>
            <para>Select the flavors that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Flavors</guimenu>.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Flavors</guimenu> window, click
<guimenu>Delete Flavors</guimenu> to confirm the deletion. You cannot
undo this action.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage volumes and volume types</title>
      <para>Volumes are the Block Storage devices that you attach to instances to enable
persistent storage. Users can attach a volume to a running instance or detach
a volume and attach it to another instance at any time. For information about
using the dashboard to create and manage volumes as an end user, see the
<link xlink:href="http://docs.openstack.org/user-guide/dashboard-manage-volumes.html">OpenStack End User Guide</link>.</para>
      <para>As an administrative user, you can manage volumes and volume types for users
in various projects. You can create and delete volume types, and you can view
and delete volumes. Note that a volume can be encrypted by using the steps
outlined below.</para>
      <sect2 xml:id="create-a-volume-type">
        <title>Create a volume type</title>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>admin</guimenu>
project from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Volumes</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Volume Types</guimenu> tab, and click
<guimenu>Create Volume Type</guimenu> button. In the
<guimenu>Create Volume Type</guimenu> window, enter a name for the volume type.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Volume Type</guimenu> button to confirm your changes.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
      <sect2>
        <title>Create an encrypted volume type</title>
        <procedure>
          <step>
            <para>Create a volume type using the steps above for <xref linkend="create-a-volume-type"/>.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Encryption</guimenu> in the Actions column of the newly
created volume type.</para>
          </step>
          <step>
            <para>Configure the encrypted volume by setting the parameters below from
available options (see table):</para>
            <variablelist>
              <varlistentry>
                <term>Provider</term>
                <listitem>
                  <para>Specifies the class responsible for configuring the encryption.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Control Location</term>
                <listitem>
                  <para>Specifies whether the encryption is from the front end (nova) or the
back end (cinder).</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Cipher</term>
                <listitem>
                  <para>Specifies the encryption algorithm.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Key Size (bits)</term>
                <listitem>
                  <para>Specifies the encryption key size.</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </step>
          <step>
            <para>Click <guimenu>Create Volume Type Encryption</guimenu>.</para>
          </step>
        </procedure>
        <figure>
          <title>Encryption Options</title>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="create_volume_type_encryption.jpg" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="create_volume_type_encryption.jpg" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>The table below provides a few alternatives available for creating encrypted
volumes.</para>
        <informaltable>
          <tgroup cols="3">
            <colspec colname="c1" colwidth="28.2*"/>
            <colspec colname="c2" colwidth="32.4*"/>
            <colspec colname="c3" colwidth="39.4*"/>
            <thead>
              <row>
                <entry>
                  <para>Encryption
parameters</para>
                </entry>
                <entry>
                  <para>Parameter
options</para>
                </entry>
                <entry>
                  <para>Comments</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry morerows="1">
                  <para>Provider</para>
                </entry>
                <entry>
                  <para>nova.volume.encryptors.
luks.LuksEncryptor
(Recommended)</para>
                </entry>
                <entry>
                  <para>Allows easier import and
migration of imported
encrypted volumes, and
allows access key to be
changed without
re-encrypting the volume</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>nova.volume.encryptors.
cryptsetup.
CryptsetupEncryptor</para>
                </entry>
                <entry>
                  <para>Less disk overhead than
LUKS</para>
                </entry>
              </row>
              <row>
                <entry morerows="1">
                  <para>Control Location</para>
                </entry>
                <entry>
                  <para>front-end
(Recommended)</para>
                </entry>
                <entry>
                  <para>The encryption occurs within
nova so that the data
transmitted over the network
is encrypted</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>back-end</para>
                </entry>
                <entry>
                  <para>This could be selected if a
cinder plug-in supporting
an encrypted back-end block
storage device becomes
available in the future.
TLS or other network
encryption would also be
needed to protect data as it
traverses the network</para>
                </entry>
              </row>
              <row>
                <entry morerows="1">
                  <para>Cipher</para>
                </entry>
                <entry>
                  <para>aes-xts-plain64
(Recommended)</para>
                </entry>
                <entry>
                  <para>See NIST reference below
to see advantages*</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>aes-cbc-essiv</para>
                </entry>
                <entry>
                  <para>Note: On the command line,
type 'cryptsetup benchmark'
for additional options</para>
                </entry>
              </row>
              <row>
                <entry morerows="1">
                  <para>Key Size (bits)</para>
                </entry>
                <entry>
                  <para>512 (Recommended for
aes-xts-plain64. 256
should be used for
aes-cbc-essiv)</para>
                </entry>
                <entry>
                  <para>Using this selection for
aes-xts, the underlying key
size would only be 256-bits*</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>256</para>
                </entry>
                <entry>
                  <para>Using this selection for
aes-xts, the underlying key
size would only be 128-bits*</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para><literal>*</literal> Source <link xlink:href="http://csrc.nist.gov/publications/nistpubs/800-38E/nist-sp-800-38E.pdf">NIST SP 800-38E</link></para>
      </sect2>
      <sect2>
        <title>Delete volume types</title>
        <para>When you delete a volume type, volumes of that type are not deleted.</para>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>admin</guimenu> project from
the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Volumes</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Volume Types</guimenu> tab, select the volume type
or types that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Volume Types</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Volume Types</guimenu> window, click the
<guimenu>Delete Volume Types</guimenu> button to confirm the action.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
      <sect2>
        <title>Delete volumes</title>
        <para>When you delete an instance, the data of its attached volumes is not
destroyed.</para>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Volumes</guimenu> category.</para>
          </step>
          <step>
            <para>Select the volume or volumes that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Volumes</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Volumes</guimenu> window, click the
<guimenu>Delete Volumes</guimenu> button to confirm the action.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage shares and share types</title>
      <para>Shares are file storage that instances can access. Users can
allow or deny a running instance to have access to a share at any time.
For information about using the Dashboard to create and manage shares as
an end user, see the
<link xlink:href="http://docs.openstack.org/user-guide/dashboard-manage-shares.html">OpenStack End User Guide</link>.</para>
      <para>As an administrative user, you can manage shares and share types for users
in various projects. You can create and delete share types, and view
or delete shares.</para>
      <sect2>
        <title>Create a share type</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and choose the <guimenu>admin</guimenu>
project from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Shares</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Share Types</guimenu> tab, and click
<guimenu>Create Share Type</guimenu> button. In the
<guimenu>Create Share Type</guimenu> window, enter or select the
following values.</para>
            <para><guimenu>Name</guimenu>: Enter a name for the share type.</para>
            <para><guimenu>Driver handles share servers</guimenu>: Choose True or False</para>
            <para><guimenu>Extra specs</guimenu>: To add extra specs, use key=value.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Share Type</guimenu> button to confirm your changes.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
      <sect2>
        <title>Update share type</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and choose the <guimenu>admin</guimenu> project from
the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Shares</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Share Types</guimenu> tab, select the share type
that you want to update.</para>
          </step>
          <step>
            <para>Select <guimenu>Update Share Type</guimenu> from Actions.</para>
          </step>
          <step>
            <para>In the <guimenu>Update Share Type</guimenu> window, update extra specs.</para>
            <para><guimenu>Extra specs</guimenu>: To add extra specs, use key=value.
To unset extra specs, use key.</para>
          </step>
          <step>
            <para>Click <guimenu>Update Share Type</guimenu> button to confirm your changes.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
      <sect2>
        <title>Delete share types</title>
        <para>When you delete a share type, shares of that type are not deleted.</para>
        <procedure>
          <step>
            <para>Log in to the Dashboard and choose the <guimenu>admin</guimenu> project from
the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Shares</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Share Types</guimenu> tab, select the share type
or types that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Share Types</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Share Types</guimenu> window, click the
<guimenu>Delete Share Types</guimenu> button to confirm the action.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
      <sect2>
        <title>Delete shares</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and choose the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Shares</guimenu> category.</para>
          </step>
          <step>
            <para>Select the share or shares that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Shares</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Shares</guimenu> window, click the
<guimenu>Delete Shares</guimenu> button to confirm the action.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
      <sect2>
        <title>Delete share server</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and choose the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Share Servers</guimenu> category.</para>
          </step>
          <step>
            <para>Select the share that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Share Server</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Share Server</guimenu> window, click the
<guimenu>Delete Share Server</guimenu> button to confirm the action.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
      <sect2>
        <title>Delete share networks</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and choose the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Share Networks</guimenu> category.</para>
          </step>
          <step>
            <para>Select the share network or share networks that you want to delete.</para>
          </step>
          <step>
            <para>Click <guimenu>Delete Share Networks</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Confirm Delete Share Networks</guimenu> window, click the
<guimenu>Delete Share Networks</guimenu> button to confirm the action.</para>
          </step>
        </procedure>
        <note>
          <para>A message indicates whether the action succeeded.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>View and manage quotas</title>
      <para>To prevent system capacities from being exhausted without notification,
you can set up quotas. Quotas are operational limits. For example, the
number of gigabytes allowed for each project can be controlled so that
cloud resources are optimized. Quotas can be enforced at both the project
and the project-user level.</para>
      <para>Typically, you change quotas when a project needs more than ten
volumes or 1 TB on a compute node.</para>
      <para>Using the Dashboard, you can view default Compute and Block Storage
quotas for new projects, as well as update quotas for existing projects.</para>
      <note>
        <para>Using the command-line interface, you can manage quotas for the
OpenStack Compute service, the OpenStack Block Storage service, and
the OpenStack Networking service (see <link xlink:href="http://docs.openstack.org/admin-guide/cli-set-quotas.html">OpenStack Administrator Guide</link>).
Additionally, you can update Compute service quotas for
project users.</para>
      </note>
      <para>The following table describes the Compute and Block Storage service quotas:</para>
      <para>
        <emphasis role="bold">Quota Descriptions</emphasis>
      </para>
      <informaltable>
        <tgroup cols="3">
          <colspec colname="c1" colwidth="28.2*"/>
          <colspec colname="c2" colwidth="50.7*"/>
          <colspec colname="c3" colwidth="21.1*"/>
          <thead>
            <row>
              <entry>
                <para>Quota Name</para>
              </entry>
              <entry>
                <para>Defines the number of</para>
              </entry>
              <entry>
                <para>Service</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>Gigabytes</para>
              </entry>
              <entry>
                <para>Volume gigabytes allowed for
each project.</para>
              </entry>
              <entry>
                <para>Block Storage</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Instances</para>
              </entry>
              <entry>
                <para>Instances allowed for each
project.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Injected Files</para>
              </entry>
              <entry>
                <para>Injected files allowed for each
project.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Injected File
Content Bytes</para>
              </entry>
              <entry>
                <para>Content bytes allowed for each
injected file.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Keypairs</para>
              </entry>
              <entry>
                <para>Number of keypairs.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Metadata Items</para>
              </entry>
              <entry>
                <para>Metadata items allowed for each
instance.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>RAM (MB)</para>
              </entry>
              <entry>
                <para>RAM megabytes allowed for
each instance.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Security Groups</para>
              </entry>
              <entry>
                <para>Security groups allowed for each
project.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Security Group
Rules</para>
              </entry>
              <entry>
                <para>Rules allowed for each security
group.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Snapshots</para>
              </entry>
              <entry>
                <para>Volume snapshots allowed for
each project.</para>
              </entry>
              <entry>
                <para>Block Storage</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>VCPUs</para>
              </entry>
              <entry>
                <para>Instance cores allowed for each
project.</para>
              </entry>
              <entry>
                <para>Compute</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Volumes</para>
              </entry>
              <entry>
                <para>Volumes allowed for each
project.</para>
              </entry>
              <entry>
                <para>Block Storage</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
      <sect2>
        <title>View default project quotas</title>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Defaults</guimenu> category.</para>
          </step>
          <step>
            <para>The default quota values are displayed.</para>
          </step>
        </procedure>
        <note>
          <para>You can sort the table by clicking on either the
<guimenu>Quota Name</guimenu> or <guimenu>Limit</guimenu> column headers.</para>
        </note>
      </sect2>
      <sect2>
        <title>Update project quotas</title>
        <procedure>
          <step>
            <para>Log in to the dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>Defaults</guimenu> category.</para>
          </step>
          <step>
            <para>Click the <guimenu>Update Defaults</guimenu> button.</para>
          </step>
          <step>
            <para>In the <guimenu>Update Default Quotas</guimenu> window,
you can edit the default quota values.</para>
          </step>
          <step>
            <para>Click the <guimenu>Update Defaults</guimenu> button.</para>
          </step>
        </procedure>
        <note>
          <para>The dashboard does not show all possible project quotas.
To view and update the quotas for a service, use its
command-line client. See <link xlink:href="http://docs.openstack.org/admin-guide/cli-set-quotas.html">OpenStack Administrator Guide</link>.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>View cloud resources</title>
      <sect2>
        <title>View services information</title>
        <para>As an administrative user, you can view information for OpenStack services.</para>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the
<guimenu>admin</guimenu> project from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab
and click the <guimenu>System Information</guimenu> category.</para>
            <para>View the following information on these tabs:</para>
            <itemizedlist>
              <listitem>
                <para><guimenu>Services</guimenu>:
Displays the internal name and the public OpenStack name
for each service, the host on which the service runs,
and whether or not the service is enabled.</para>
              </listitem>
              <listitem>
                <para><guimenu>Compute Services</guimenu>:
Displays information specific to the Compute service. Both host
and zone are listed for each service, as well as its
activation status.</para>
              </listitem>
              <listitem>
                <para><guimenu>Block Storage Services</guimenu>:
Displays information specific to the Block Storage service. Both host
and zone are listed for each service, as well as its
activation status.</para>
              </listitem>
              <listitem>
                <para><guimenu>Network Agents</guimenu>:
Displays the network agents active within the cluster, such as L3 and
DHCP agents, and the status of each agent.</para>
              </listitem>
              <listitem>
                <para><guimenu>Orchestration Services</guimenu>:
Displays information specific to the Orchestration service. Name,
engine id, host and topic are listed for each service, as well as its
activation status.</para>
              </listitem>
            </itemizedlist>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>View cloud usage statistics</title>
        <para>The Telemetry service provides user-level usage data for
OpenStack-based clouds, which can be used for customer billing, system
monitoring, or alerts. Data can be collected by notifications sent by
existing OpenStack components (for example, usage events emitted from
Compute) or by polling the infrastructure (for example, libvirt).</para>
        <note>
          <para>You can only view metering statistics on the dashboard (available
only to administrators).
The Telemetry service must be set up and administered through the
<command>ceilometer</command> command-line interface (CLI).</para>
          <para>For basic administration information, refer to the <link xlink:href="http://docs.openstack.org/user-guide/cli-ceilometer.html">Measure Cloud
Resources</link>
chapter in the OpenStack End User Guide.</para>
        </note>
        <sect3>
          <title>View resource statistics</title>
          <procedure>
            <step>
              <para>Log in to the dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
            </step>
            <step>
              <para>On the <guimenu>Admin</guimenu> tab, click the <guimenu>Resource Usage</guimenu> category.</para>
            </step>
            <step>
              <para>Click the:</para>
              <itemizedlist>
                <listitem>
                  <para><guimenu>Usage Report</guimenu> tab to view a usage report per project
by specifying the time period (or even use a calendar to define
a date range).</para>
                </listitem>
                <listitem>
                  <para><guimenu>Stats</guimenu> tab to view a multi-series line chart with
user-defined meters. You group by project, define the value type
(min, max, avg, or sum), and specify the time period (or even use
a calendar to define a date range).</para>
                </listitem>
              </itemizedlist>
            </step>
          </procedure>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Create and manage host aggregates</title>
      <para>Host aggregates enable administrative users to assign key-value pairs to
groups of machines.</para>
      <para>Each node can have multiple aggregates and each aggregate can have
multiple key-value pairs. You can assign the same key-value pair to
multiple aggregates.</para>
      <para>The scheduler uses this information to make scheduling decisions.
For information, see
<link xlink:href="http://docs.openstack.org/newton/config-reference/compute/scheduler.html">Scheduling</link>.</para>
      <sect2>
        <title>To create a host aggregate</title>
        <procedure>
          <step>
            <para>Log in to the Dashboard and select the <guimenu>admin</guimenu> project
from the drop-down list.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab and click
the <guimenu>Host Aggregates</guimenu> category.</para>
          </step>
          <step>
            <para>Click <guimenu>Create Host Aggregate</guimenu>.</para>
          </step>
          <step>
            <para>In the <guimenu>Create Host Aggregate</guimenu> dialog box, enter or select the
following values on the <guimenu>Host Aggregate Information</guimenu> tab:</para>
            <itemizedlist>
              <listitem>
                <para><guimenu>Name</guimenu>: The host aggregate name.</para>
              </listitem>
              <listitem>
                <para><guimenu>Availability Zone</guimenu>: The cloud provider defines the default
availability zone, such as <literal>us-west</literal>, <literal>apac-south</literal>, or
<literal>nova</literal>. You can target the host aggregate, as follows:</para>
                <itemizedlist>
                  <listitem>
                    <para>When the host aggregate is exposed as an availability zone,
select the availability zone when you launch an instance.</para>
                  </listitem>
                  <listitem>
                    <para>When the host aggregate is not exposed as an availability zone,
select a flavor and its extra specs to target the host
aggregate.</para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>Assign hosts to the aggregate using the <guimenu>Manage Hosts within
Aggregate</guimenu> tab in the same dialog box.</para>
            <para>To assign a host to the aggregate, click <emphasis role="bold">+</emphasis> for the host. The host
moves from the <guimenu>All available hosts</guimenu> list to the
<guimenu>Selected hosts</guimenu> list.</para>
          </step>
        </procedure>
        <para>You can add one host to one or more aggregates. To add a host to an
existing aggregate, edit the aggregate.</para>
      </sect2>
      <sect2>
        <title>To manage host aggregates</title>
        <procedure>
          <step>
            <para>Select the <guimenu>admin</guimenu> project from the drop-down list at the top
of the page.</para>
          </step>
          <step>
            <para>On the <guimenu>Admin</guimenu> tab, open the <guimenu>System</guimenu> tab and click
the <guimenu>Host Aggregates</guimenu> category.</para>
            <itemizedlist>
              <listitem>
                <para>To edit host aggregates, select the host aggregate that you want
to edit. Click <guimenu>Edit Host Aggregate</guimenu>.</para>
                <para>In the <guimenu>Edit Host Aggregate</guimenu> dialog box, you can change the
name and availability zone for the aggregate.</para>
              </listitem>
              <listitem>
                <para>To manage hosts, locate the host aggregate that you want to edit
in the table. Click <guimenu>More</guimenu> and select <guimenu>Manage Hosts</guimenu>.</para>
                <para>In the <guimenu>Add/Remove Hosts to Aggregate</guimenu> dialog box,
click <emphasis role="bold">+</emphasis> to assign a host to an aggregate. Click <emphasis role="bold">-</emphasis> to
remove a host that is assigned to an aggregate.</para>
              </listitem>
              <listitem>
                <para>To delete host aggregates, locate the host aggregate that you want
to edit in the table. Click <guimenu>More</guimenu> and select
<guimenu>Delete Host Aggregate</guimenu>.</para>
              </listitem>
            </itemizedlist>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Launch and manage stacks using the Dashboard</title>
      <para>The Orchestration service provides a template-based
orchestration engine for the OpenStack cloud. Orchestration
services create and manage cloud infrastructure
resources such as storage, networking, instances, and
applications as a repeatable running environment.</para>
      <para>Administrators use templates to create stacks, which are
collections of resources. For example, a stack might
include instances, floating IPs, volumes,
security groups, or users. The Orchestration service
offers access to all OpenStack
core services via a single modular template, with additional
orchestration capabilities such as auto-scaling and basic
high availability.</para>
      <para>For information about:</para>
      <itemizedlist>
        <listitem>
          <para>administrative tasks on the command-line, see
the <link xlink:href="http://docs.openstack.org/admin-guide/cli-admin-manage-stacks.html">OpenStack Administrator Guide</link>.</para>
          <note>
            <para>There are no administration-specific tasks that can be done through
the Dashboard.</para>
          </note>
        </listitem>
        <listitem>
          <para>the basic creation and deletion of Orchestration stacks, refer to
the <link xlink:href="http://docs.openstack.org/user-guide/dashboard-stacks.html">OpenStack End User Guide</link>.</para>
        </listitem>
      </itemizedlist>
    </sect1>
  </chapter>
  <chapter>
    <title>Compute</title>
    <info/>
    <para>The OpenStack Compute service allows you to control an
<xref linkend="term-infrastructure-as-a-service-iaas"/> cloud computing platform.
It gives you control over instances and networks, and allows you to manage
access to the cloud through users and projects.</para>
    <para>Compute does not include virtualization software. Instead, it defines
drivers that interact with underlying virtualization mechanisms that run
on your host operating system, and exposes functionality over a
web-based API.</para>
    <sect1>
      <title>System architecture</title>
      <para>OpenStack Compute contains several main components.</para>
      <itemizedlist>
        <listitem>
          <para>The <xref linkend="term-cloud-controller"/> represents the global state and interacts with
the other components. The <literal>API server</literal> acts as the web services
front end for the cloud controller. The <literal>compute controller</literal>
provides compute server resources and usually also contains the
Compute service.</para>
        </listitem>
        <listitem>
          <para>The <literal>object store</literal> is an optional component that provides storage
services; you can also use OpenStack Object Storage instead.</para>
        </listitem>
        <listitem>
          <para>An <literal>auth manager</literal> provides authentication and authorization
services when used with the Compute system; you can also use
OpenStack Identity as a separate authentication service instead.</para>
        </listitem>
        <listitem>
          <para>A <literal>volume controller</literal> provides fast and permanent block-level
storage for the compute servers.</para>
        </listitem>
        <listitem>
          <para>The <literal>network controller</literal> provides virtual networks to enable
compute servers to interact with each other and with the public
network. You can also use OpenStack Networking instead.</para>
        </listitem>
        <listitem>
          <para>The <literal>scheduler</literal> is used to select the most suitable compute
controller to host an instance.</para>
        </listitem>
      </itemizedlist>
      <para>Compute uses a messaging-based, <literal>shared nothing</literal> architecture. All
major components exist on multiple servers, including the compute,
volume, and network controllers, and the Object Storage or Image service.
The state of the entire system is stored in a database. The cloud
controller communicates with the internal object store using HTTP, but
it communicates with the scheduler, network controller, and volume
controller using Advanced Message Queuing Protocol (AMQP). To avoid
blocking a component while waiting for a response, Compute uses
asynchronous calls, with a callback that is triggered when a response is
received.</para>
      <sect2>
        <title>Hypervisors</title>
        <para>Compute controls hypervisors through an API server. Selecting the best
hypervisor to use can be difficult, and you must take budget, resource
constraints, supported features, and required technical specifications
into account. However, the majority of OpenStack development is done on
systems using KVM and Xen-based hypervisors. For a detailed list of
features and support across different hypervisors, see the
<link xlink:href="http://docs.openstack.org/developer/nova/support-matrix.html">Feature Support Matrix</link>.</para>
        <para>You can also orchestrate clouds using multiple hypervisors in different
availability zones. Compute supports the following hypervisors:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="https://wiki.openstack.org/wiki/Ironic">Baremetal</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://linuxcontainers.org/">Linux Containers (LXC)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://wiki.qemu.org/Manual">Quick Emulator (QEMU)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://user-mode-linux.sourceforge.net/">User Mode Linux (UML)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://www.vmware.com/products/vsphere-hypervisor/support.html">VMware
vSphere</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://www.xen.org/support/documentation.html">Xen</link>
            </para>
          </listitem>
        </itemizedlist>
        <para>For more information about hypervisors, see the
<link xlink:href="http://docs.openstack.org/newton/config-reference/compute/hypervisors.html">Hypervisors</link>
section in the OpenStack Configuration Reference.</para>
      </sect2>
      <sect2>
        <title>Projects, users, and roles</title>
        <para>The Compute system is designed to be used by different consumers in the
form of projects on a shared system, and role-based access assignments.
Roles control the actions that a user is allowed to perform.</para>
        <para>Projects are isolated resource containers that form the principal
organizational structure within the Compute service. They consist of an
individual VLAN, and volumes, instances, images, keys, and users. A user
can specify the project by appending <literal>project_id</literal> to their access key.
If no project is specified in the API request, Compute attempts to use a
project with the same ID as the user.</para>
        <para>For projects, you can use quota controls to limit the:</para>
        <itemizedlist>
          <listitem>
            <para>Number of volumes that can be launched.</para>
          </listitem>
          <listitem>
            <para>Number of processor cores and the amount of RAM that can be
allocated.</para>
          </listitem>
          <listitem>
            <para>Floating IP addresses assigned to any instance when it launches. This
allows instances to have the same publicly accessible IP addresses.</para>
          </listitem>
          <listitem>
            <para>Fixed IP addresses assigned to the same instance when it launches.
This allows instances to have the same publicly or privately
accessible IP addresses.</para>
          </listitem>
        </itemizedlist>
        <para>Roles control the actions a user is allowed to perform. By default, most
actions do not require a particular role, but you can configure them by
editing the <literal>policy.json</literal> file for user roles. For example, a rule can
be defined so that a user must have the <literal>admin</literal> role in order to be
able to allocate a public IP address.</para>
        <para>A project limits users' access to particular images. Each user is
assigned a user name and password. Keypairs granting access to an
instance are enabled for each user, but quotas are set, so that each
project can control resource consumption across available hardware
resources.</para>
        <note>
          <para>Earlier versions of OpenStack used the term <literal>tenant</literal> instead of
<literal>project</literal>. Because of this legacy terminology, some command-line tools
use <literal>--tenant_id</literal> where you would normally expect to enter a
project ID.</para>
        </note>
      </sect2>
      <sect2>
        <title>Block storage</title>
        <para>OpenStack provides two classes of block storage: ephemeral storage
and persistent volume.</para>
        <para>
          <emphasis role="bold">Ephemeral storage</emphasis>
        </para>
        <para>Ephemeral storage includes a root ephemeral volume and an additional
ephemeral volume.</para>
        <para>The root disk is associated with an instance, and exists only for the
life of this very instance. Generally, it is used to store an
instance's root file system, persists across the guest operating system
reboots, and is removed on an instance deletion. The amount of the root
ephemeral volume is defined by the flavor of an instance.</para>
        <para>In addition to the ephemeral root volume, all default types of flavors,
except <literal>m1.tiny</literal>, which is the smallest one, provide an additional
ephemeral block device sized between 20 and 160 GB (a configurable value
to suit an environment). It is represented as a raw block device with no
partition table or file system. A cloud-aware operating system can
discover, format, and mount such a storage device. OpenStack Compute
defines the default file system for different operating systems as Ext4
for Linux distributions, VFAT for non-Linux and non-Windows operating
systems, and NTFS for Windows. However, it is possible to specify any
other filesystem type by using <literal>virt_mkfs</literal> or
<literal>default_ephemeral_format</literal> configuration options.</para>
        <note>
          <para>For example, the <literal>cloud-init</literal> package included into an Ubuntu's stock
cloud image, by default, formats this space as an Ext4 file system
and mounts it on <literal>/mnt</literal>. This is a cloud-init feature, and is not
an OpenStack mechanism. OpenStack only provisions the raw storage.</para>
        </note>
        <para>
          <emphasis role="bold">Persistent volume</emphasis>
        </para>
        <para>A persistent volume is represented by a persistent virtualized block
device independent of any particular instance, and provided by OpenStack
Block Storage.</para>
        <para>Only a single configured instance can access a persistent volume.
Multiple instances cannot access a persistent volume. This type of
configuration requires a traditional network file system to allow
multiple instances accessing the persistent volume. It also requires a
traditional network file system like NFS, CIFS, or a cluster file system
such as GlusterFS. These systems can be built within an OpenStack
cluster, or provisioned outside of it, but OpenStack software does not
provide these features.</para>
        <para>You can configure a persistent volume as bootable and use it to provide
a persistent virtual instance similar to the traditional non-cloud-based
virtualization system. It is still possible for the resulting instance
to keep ephemeral storage, depending on the flavor selected. In this
case, the root file system can be on the persistent volume, and its
state is maintained, even if the instance is shut down. For more
information about this type of configuration, see <link xlink:href="http://docs.openstack.org/newton/config-reference/block-storage/block-storage-overview.html">Introduction to the
Block Storage service</link>
in the OpenStack Configuration Reference.</para>
        <note>
          <para>A persistent volume does not provide concurrent access from multiple
instances. That type of configuration requires a traditional network
file system like NFS, or CIFS, or a cluster file system such as
GlusterFS. These systems can be built within an OpenStack cluster,
or provisioned outside of it, but OpenStack software does not
provide these features.</para>
        </note>
      </sect2>
      <sect2>
        <title>EC2 compatibility API</title>
        <para>In addition to the native compute API, OpenStack provides an
EC2-compatible API. This API allows EC2 legacy workflows built for EC2
to work with OpenStack.</para>
        <warning>
          <para>Nova in tree EC2-compatible API is deprecated.
The <link xlink:href="http://git.openstack.org/cgit/openstack/ec2-api/">ec2-api project</link>
is working to implement the EC2 API.</para>
        </warning>
        <para>You can use numerous third-party tools and language-specific SDKs to
interact with OpenStack clouds. You can use both native and
compatibility APIs. Some of the more popular third-party tools are:</para>
        <variablelist>
          <varlistentry>
            <term>Euca2ools</term>
            <listitem>
              <para>A popular open source command-line tool for interacting with the EC2
API. This is convenient for multi-cloud environments where EC2 is
the common API, or for transitioning from EC2-based clouds to
OpenStack. For more information, see the <link xlink:href="http://docs.hpcloud.com/eucalyptus">Eucalyptus
Documentation</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Hybridfox</term>
            <listitem>
              <para>A Firefox browser add-on that provides a graphical interface to many
popular public and private cloud technologies, including OpenStack.
For more information, see the <link xlink:href="http://code.google.com/p/hybridfox/">hybridfox
site</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>boto</term>
            <listitem>
              <para>Python library for interacting with Amazon Web Services. You can use
this library to access OpenStack through the EC2 compatibility API.
For more     information, see the <link xlink:href="https://github.com/boto/boto">boto project page on
GitHub</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>fog</term>
            <listitem>
              <para>A Ruby cloud services library. It provides methods to interact
with a large number of cloud and virtualization platforms, including
OpenStack. For more information, see the <link xlink:href="https://rubygems.org/gems/fog">fog
site</link>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>php-opencloud</term>
            <listitem>
              <para>A PHP SDK designed to work with most OpenStack-based cloud
deployments, as well as Rackspace public cloud. For more
information, see the <link xlink:href="http://www.php-opencloud.com">php-opencloud
site</link>.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Building blocks</title>
        <para>In OpenStack the base operating system is usually copied from an image
stored in the OpenStack Image service. This is the most common case and
results in an ephemeral instance that starts from a known template state
and loses all accumulated states on virtual machine deletion. It is also
possible to put an operating system on a persistent volume in the
OpenStack Block Storage volume system. This gives a more traditional
persistent system that accumulates states which are preserved on the
OpenStack Block Storage volume across the deletion and re-creation of
the virtual machine. To get a list of available images on your system,
run:</para>
        <screen language="console">$ openstack image list
+--------------------------------------+-----------------------------+--------+
| ID                                   | Name                        | Status |
+--------------------------------------+-----------------------------+--------+
| aee1d242-730f-431f-88c1-87630c0f07ba | Ubuntu 14.04 cloudimg amd64 | active |
| 0b27baa1-0ca6-49a7-b3f4-48388e440245 | Ubuntu 14.10 cloudimg amd64 | active |
| df8d56fc-9cea-4dfd-a8d3-28764de3cb08 | jenkins                     | active |
+--------------------------------------+-----------------------------+--------+</screen>
        <para>The displayed image attributes are:</para>
        <variablelist>
          <varlistentry>
            <term>
              <literal>ID</literal>
            </term>
            <listitem>
              <para>Automatically generated UUID of the image</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>Name</literal>
            </term>
            <listitem>
              <para>Free form, human-readable name for image</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>Status</literal>
            </term>
            <listitem>
              <para>The status of the image. Images marked <literal>ACTIVE</literal> are available for
use.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>Server</literal>
            </term>
            <listitem>
              <para>For images that are created as snapshots of running instances, this
is the UUID of the instance the snapshot derives from. For uploaded
images, this field is blank.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>Virtual hardware templates are called <literal>flavors</literal>. The default
installation provides five flavors. By default, these are configurable
by admin users, however that behavior can be changed by redefining the
access controls for <literal>compute_extension:flavormanage</literal> in
<literal>/etc/nova/policy.json</literal> on the <literal>compute-api</literal> server.</para>
        <para>For a list of flavors that are available on your system:</para>
        <screen language="console">$ openstack flavor list
+-----+-----------+-------+------+-----------+-------+-----------+
| ID  | Name      |   RAM | Disk | Ephemeral | VCPUs | Is_Public |
+-----+-----------+-------+------+-----------+-------+-----------+
| 1   | m1.tiny   |   512 |    1 |         0 |     1 | True      |
| 2   | m1.small  |  2048 |   20 |         0 |     1 | True      |
| 3   | m1.medium |  4096 |   40 |         0 |     2 | True      |
| 4   | m1.large  |  8192 |   80 |         0 |     4 | True      |
| 5   | m1.xlarge | 16384 |  160 |         0 |     8 | True      |
+-----+-----------+-------+------+-----------+-------+-----------+</screen>
      </sect2>
      <sect2>
        <title>Compute service architecture</title>
        <para>These basic categories describe the service architecture and information
about the cloud controller.</para>
        <para>
          <emphasis role="bold">API server</emphasis>
        </para>
        <para>At the heart of the cloud framework is an API server, which makes
command and control of the hypervisor, storage, and networking
programmatically available to users.</para>
        <para>The API endpoints are basic HTTP web services which handle
authentication, authorization, and basic command and control functions
using various API interfaces under the Amazon, Rackspace, and related
models. This enables API compatibility with multiple existing tool sets
created for interaction with offerings from other vendors. This broad
compatibility prevents vendor lock-in.</para>
        <para>
          <emphasis role="bold">Message queue</emphasis>
        </para>
        <para>A messaging queue brokers the interaction between compute nodes
(processing), the networking controllers (software which controls
network infrastructure), API endpoints, the scheduler (determines which
physical hardware to allocate to a virtual resource), and similar
components. Communication to and from the cloud controller is handled by
HTTP requests through multiple API endpoints.</para>
        <para>A typical message passing event begins with the API server receiving a
request from a user. The API server authenticates the user and ensures
that they are permitted to issue the subject command. The availability
of objects implicated in the request is evaluated and, if available, the
request is routed to the queuing engine for the relevant workers.
Workers continually listen to the queue based on their role, and
occasionally their type host name. When an applicable work request
arrives on the queue, the worker takes assignment of the task and begins
executing it. Upon completion, a response is dispatched to the queue
which is received by the API server and relayed to the originating user.
Database entries are queried, added, or removed as necessary during the
process.</para>
        <para>
          <emphasis role="bold">Compute worker</emphasis>
        </para>
        <para>Compute workers manage computing instances on host machines. The API
dispatches commands to compute workers to complete these tasks:</para>
        <itemizedlist>
          <listitem>
            <para>Run instances</para>
          </listitem>
          <listitem>
            <para>Delete instances (Terminate instances)</para>
          </listitem>
          <listitem>
            <para>Reboot instances</para>
          </listitem>
          <listitem>
            <para>Attach volumes</para>
          </listitem>
          <listitem>
            <para>Detach volumes</para>
          </listitem>
          <listitem>
            <para>Get console output</para>
          </listitem>
        </itemizedlist>
        <para>
          <emphasis role="bold">Network Controller</emphasis>
        </para>
        <para>The Network Controller manages the networking resources on host
machines. The API server dispatches commands through the message queue,
which are subsequently processed by Network Controllers. Specific
operations include:</para>
        <itemizedlist>
          <listitem>
            <para>Allocating fixed IP addresses</para>
          </listitem>
          <listitem>
            <para>Configuring VLANs for projects</para>
          </listitem>
          <listitem>
            <para>Configuring networks for compute nodes</para>
          </listitem>
        </itemizedlist>
      </sect2>
    </sect1>
    <sect1>
      <title>Images and instances</title>
      <para>Virtual machine images contain a virtual disk that holds a
bootable operating system on it. Disk images provide templates for
virtual machine file systems. The Image service controls image storage
and management.</para>
      <para>Instances are the individual virtual machines that run on physical
compute nodes inside the cloud. Users can launch any number of instances
from the same image. Each launched instance runs from a copy of the
base image. Any changes made to the instance do not affect
the base image. Snapshots capture the state of an instances
running disk. Users can create a snapshot, and build a new image based
on these snapshots. The Compute service controls instance, image, and
snapshot storage and management.</para>
      <para>When you launch an instance, you must choose a <literal>flavor</literal>, which
represents a set of virtual resources. Flavors define virtual
CPU number, RAM amount available, and ephemeral disks size. Users
must select from the set of available flavors
defined on their cloud. OpenStack provides a number of predefined
flavors that you can edit or add to.</para>
      <note>
        <itemizedlist>
          <listitem>
            <para>For more information about creating and troubleshooting images,
see the <link xlink:href="http://docs.openstack.org/image-guide/">OpenStack Virtual Machine Image
Guide</link>.</para>
          </listitem>
          <listitem>
            <para>For more information about image configuration options, see the
<link xlink:href="http://docs.openstack.org/newton/config-reference/image.html">Image services</link>
section of the OpenStack Configuration Reference.</para>
          </listitem>
          <listitem>
            <para>For more information about flavors, see <xref linkend="compute-flavors"/>.</para>
          </listitem>
        </itemizedlist>
      </note>
      <para>You can add and remove additional resources from running instances, such
as persistent volume storage, or public IP addresses. The example used
in this chapter is of a typical virtual system within an OpenStack
cloud. It uses the <literal>cinder-volume</literal> service, which provides persistent
block storage, instead of the ephemeral storage provided by the selected
instance flavor.</para>
      <para>This diagram shows the system state prior to launching an instance. The
image store has a number of predefined images, supported by the Image
service. Inside the cloud, a compute node contains the
available vCPU, memory, and local disk resources. Additionally, the
<literal>cinder-volume</literal> service stores predefined volumes.</para>
      <para>
        <emphasis role="bold">The base image state with no running instances</emphasis>
      </para>
      <figure>
        <title/>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="instance-life-1.png" width="99%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="instance-life-1.png" width="99%"/>
          </imageobject>
        </mediaobject>
      </figure>
      <sect2>
        <title>Instance Launch</title>
        <para>To launch an instance, select an image, flavor, and any optional
attributes. The selected flavor provides a root volume, labeled <literal>vda</literal>
in this diagram, and additional ephemeral storage, labeled <literal>vdb</literal>. In
this example, the <literal>cinder-volume</literal> store is mapped to the third virtual
disk on this instance, <literal>vdc</literal>.</para>
        <para>
          <emphasis role="bold">Instance creation from an image</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="instance-life-2.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="instance-life-2.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>The Image service copies the base image from the image store to the
local disk. The local disk is the first disk that the instance
accesses, which is the root volume labeled <literal>vda</literal>. Smaller
instances start faster. Less data needs to be copied across
the network.</para>
        <para>The new empty ephemeral disk is also created, labeled <literal>vdb</literal>.
This disk is deleted when you delete the instance.</para>
        <para>The compute node connects to the attached <literal>cinder-volume</literal> using iSCSI. The
<literal>cinder-volume</literal> is mapped to the third disk, labeled <literal>vdc</literal> in this
diagram. After the compute node provisions the vCPU and memory
resources, the instance boots up from root volume <literal>vda</literal>. The instance
runs and changes data on the disks (highlighted in red on the diagram).
If the volume store is located on a separate network, the
<literal>my_block_storage_ip</literal> option specified in the storage node
configuration file directs image traffic to the compute node.</para>
        <note>
          <para>Some details in this example scenario might be different in your
environment. For example, you might use a different type of back-end
storage, or different network protocols. One common variant is that
the ephemeral storage used for volumes <literal>vda</literal> and <literal>vdb</literal> could be
backed by network storage rather than a local disk.</para>
        </note>
        <para>When you delete an instance, the state is reclaimed with the exception
of the persistent volume. The ephemeral storage, whether encrypted or not,
is purged. Memory and vCPU resources are released. The image remains
unchanged throughout this process.</para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="instance-life-3.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="instance-life-3.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
      </sect2>
      <sect2>
        <title>Image properties and property protection</title>
        <para>An image property is a key and value pair that the administrator
or the image owner attaches to an OpenStack Image service image, as
follows:</para>
        <itemizedlist>
          <listitem>
            <para>The administrator defines core properties, such as the image
name.</para>
          </listitem>
          <listitem>
            <para>The administrator and the image owner can define additional
properties, such as licensing and billing information.</para>
          </listitem>
        </itemizedlist>
        <para>The administrator can configure any property as protected, which
limits which policies or user roles can perform CRUD operations on that
property. Protected properties are generally additional properties to
which only administrators have access.</para>
        <para>For unprotected image properties, the administrator can manage
core properties and the image owner can manage additional properties.</para>
        <para>
          <emphasis role="bold">To configure property protection</emphasis>
        </para>
        <para>To configure property protection, edit the <literal>policy.json</literal> file. This file
can also be used to set policies for Image service actions.</para>
        <procedure>
          <step>
            <para>Define roles or policies in the <literal>policy.json</literal> file:</para>
            <screen language="json">{
    "context_is_admin":  "role:admin",
    "default": "",

    "add_image": "",
    "delete_image": "",
    "get_image": "",
    "get_images": "",
    "modify_image": "",
    "publicize_image": "role:admin",
    "copy_from": "",

    "download_image": "",
    "upload_image": "",

    "delete_image_location": "",
    "get_image_location": "",
    "set_image_location": "",

    "add_member": "",
    "delete_member": "",
    "get_member": "",
    "get_members": "",
    "modify_member": "",

    "manage_image_cache": "role:admin",

    "get_task": "",
    "get_tasks": "",
    "add_task": "",
    "modify_task": "",

    "deactivate": "",
    "reactivate": "",

    "get_metadef_namespace": "",
    "get_metadef_namespaces":"",
    "modify_metadef_namespace":"",
    "add_metadef_namespace":"",
    "delete_metadef_namespace":"",

    "get_metadef_object":"",
    "get_metadef_objects":"",
    "modify_metadef_object":"",
    "add_metadef_object":"",

    "list_metadef_resource_types":"",
    "get_metadef_resource_type":"",
    "add_metadef_resource_type_association":"",

    "get_metadef_property":"",
    "get_metadef_properties":"",
    "modify_metadef_property":"",
    "add_metadef_property":"",

    "get_metadef_tag":"",
    "get_metadef_tags":"",
    "modify_metadef_tag":"",
    "add_metadef_tag":"",
    "add_metadef_tags":""
 }</screen>
            <para>For each parameter, use <literal>"rule:restricted"</literal> to restrict access to all
users or <literal>"role:admin"</literal> to limit access to administrator roles.
For example:</para>
            <screen language="json">"download_image":
"upload_image":</screen>
          </step>
          <step>
            <para>Define which roles or policies can manage which properties in a property
protections configuration file. For example:</para>
            <screen language="ini">[x_none_read]
create = context_is_admin
read = !
update = !
delete = !

[x_none_update]
create = context_is_admin
read = context_is_admin
update = !
delete = context_is_admin

[x_none_delete]
create = context_is_admin
read = context_is_admin
update = context_is_admin
delete = !</screen>
            <itemizedlist>
              <listitem>
                <para>A value of <literal>@</literal> allows the corresponding operation for a property.</para>
              </listitem>
              <listitem>
                <para>A value of <literal>!</literal> disallows the corresponding operation for a
property.</para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>In the <literal>glance-api.conf</literal> file, define the location of a property
protections configuration file.</para>
            <screen language="ini">property_protection_file = {file_name}</screen>
            <para>This file contains the rules for property protections and the roles and
policies associated with it.</para>
            <para>By default, property protections are not enforced.</para>
            <para>If you specify a file name value and the file is not found, the
<literal>glance-api</literal> service does not start.</para>
            <para>To view a sample configuration file, see
<link xlink:href="http://docs.openstack.org/newton/config-reference/image/glance-api.conf.html">glance-api.conf</link>.</para>
          </step>
          <step>
            <para>Optionally, in the <literal>glance-api.conf</literal> file, specify whether roles or
policies are used in the property protections configuration file</para>
            <screen language="ini">property_protection_rule_format = roles</screen>
            <para>The default is <literal>roles</literal>.</para>
            <para>To view a sample configuration file, see
<link xlink:href="http://docs.openstack.org/newton/config-reference/image/glance-api.conf.html">glance-api.conf</link>.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Image download: how it works</title>
        <para>Prior to starting a virtual machine, transfer the virtual machine image
to the compute node from the Image service. How this
works can change depending on the settings chosen for the compute node
and the Image service.</para>
        <para>Typically, the Compute service will use the image identifier passed to
it by the scheduler service and request the image from the Image API.
Though images are not stored in glance—rather in a back end, which could
be Object Storage, a filesystem or any other supported method—the
connection is made from the compute node to the Image service and the
image is transferred over this connection. The Image service streams the
image from the back end to the compute node.</para>
        <para>It is possible to set up the Object Storage node on a separate network,
and still allow image traffic to flow between the compute and object
storage nodes. Configure the <literal>my_block_storage_ip</literal> option in the
storage node configuration file to allow block storage traffic to reach
the compute node.</para>
        <para>Certain back ends support a more direct method, where on request the
Image service will return a URL that links directly to the back-end store.
You can download the image using this approach. Currently, the only store
to support the direct download approach is the filesystem store.
Configured the approach using the <literal>filesystems</literal> option in
the <literal>image_file_url</literal> section of the <literal>nova.conf</literal> file on
compute nodes.</para>
        <para>Compute nodes also implement caching of images, meaning that if an image
has been used before it won't necessarily be downloaded every time.
Information on the configuration options for caching on compute nodes
can be found in the <link xlink:href="http://docs.openstack.org/newton/config-reference/">Configuration
Reference</link>.</para>
      </sect2>
      <sect2>
        <title>Instance building blocks</title>
        <para>In OpenStack, the base operating system is usually copied from an image
stored in the OpenStack Image service. This results in an ephemeral
instance that starts from a known template state and loses all
accumulated states on shutdown.</para>
        <para>You can also put an operating system on a persistent volume in Compute
or the Block Storage volume system. This gives a more traditional,
persistent system that accumulates states that are preserved across
restarts. To get a list of available images on your system, run:</para>
        <screen language="console">$ openstack image list
+--------------------------------------+-----------------------------+--------+
| ID                                   | Name                        | Status |
+--------------------------------------+-----------------------------+--------+
| aee1d242-730f-431f-88c1-87630c0f07ba | Ubuntu 14.04 cloudimg amd64 | active |
+--------------------------------------+-----------------------------+--------+
| 0b27baa1-0ca6-49a7-b3f4-48388e440245 | Ubuntu 14.10 cloudimg amd64 | active |
+--------------------------------------+-----------------------------+--------+
| df8d56fc-9cea-4dfd-a8d3-28764de3cb08 | jenkins                     | active |
+--------------------------------------+-----------------------------+--------+</screen>
        <para>The displayed image attributes are:</para>
        <variablelist>
          <varlistentry>
            <term>
              <literal>ID</literal>
            </term>
            <listitem>
              <para>Automatically generated UUID of the image.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>Name</literal>
            </term>
            <listitem>
              <para>Free form, human-readable name for the image.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>Status</literal>
            </term>
            <listitem>
              <para>The status of the image. Images marked <literal>ACTIVE</literal> are available for
use.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>Server</literal>
            </term>
            <listitem>
              <para>For images that are created as snapshots of running instances, this
is the UUID of the instance the snapshot derives from. For uploaded
images, this field is blank.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>Virtual hardware templates are called <literal>flavors</literal>. The default
installation provides five predefined flavors.</para>
        <para>For a list of flavors that are available on your system, run:</para>
        <screen language="console">$ openstack flavor list
+-----+-----------+-------+------+-----------+-------+-----------+
| ID  | Name      |   RAM | Disk | Ephemeral | VCPUs | Is_Public |
+-----+-----------+-------+------+-----------+-------+-----------+
| 1   | m1.tiny   |   512 |    1 |         0 |     1 | True      |
| 2   | m1.small  |  2048 |   20 |         0 |     1 | True      |
| 3   | m1.medium |  4096 |   40 |         0 |     2 | True      |
| 4   | m1.large  |  8192 |   80 |         0 |     4 | True      |
| 5   | m1.xlarge | 16384 |  160 |         0 |     8 | True      |
+-----+-----------+-------+------+-----------+-------+-----------+</screen>
        <para>By default, administrative users can configure the flavors. You can
change this behavior by redefining the access controls for
<literal>compute_extension:flavormanage</literal> in <literal>/etc/nova/policy.json</literal> on the
<literal>compute-api</literal> server.</para>
      </sect2>
      <sect2>
        <title>Instance management tools</title>
        <para>OpenStack provides command-line, web interface, and API-based instance
management tools. Third-party management tools are also available, using
either the native API or the provided EC2-compatible API.</para>
        <para>The OpenStack python-novaclient package provides a basic command-line
utility, which uses the <command>nova</command> command. This is available as a native
package for most Linux distributions, or you can install the latest
version using the pip python package installer:</para>
        <screen language="console"># pip install python-novaclient</screen>
        <para>For more information about python-novaclient and other command-line
tools, see the <link xlink:href="http://docs.openstack.org/user-guide/cli.html">OpenStack End User
Guide</link>.</para>
      </sect2>
      <sect2>
        <title>Control where instances run</title>
        <para>The <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/scheduler.html">Scheduling section</link>
of OpenStack Configuration Reference
provides detailed information on controlling where your instances run,
including ensuring a set of instances run on different compute nodes for
service resiliency or on the same node for high performance
inter-instance communications.</para>
        <para>Administrative users can specify which compute node their instances
run on. To do this, specify the <literal>--availability-zone
AVAILABILITY_ZONE:COMPUTE_HOST</literal> parameter.</para>
      </sect2>
      <sect2>
        <title>Launch instances with UEFI</title>
        <para>Unified Extensible Firmware Interface (UEFI) is a standard firmware
designed to replace legacy BIOS. There is a slow but steady trend
for operating systems to move to the UEFI format and, in some cases,
make it their only format.</para>
        <para>
          <emphasis role="bold">To configure UEFI environment</emphasis>
        </para>
        <para>To successfully launch an instance from an UEFI image in QEMU/KVM
environment, the administrator has to install the following
packages on compute node:</para>
        <itemizedlist>
          <listitem>
            <para>OVMF, a port of Intel's tianocore firmware to QEMU virtual machine.</para>
          </listitem>
          <listitem>
            <para>libvirt, which has been supporting UEFI boot since version 1.2.9.</para>
          </listitem>
        </itemizedlist>
        <para>Because default UEFI loader path is <literal>/usr/share/OVMF/OVMF_CODE.fd</literal>, the
administrator must create one link to this location after UEFI package
is installed.</para>
        <para>
          <emphasis role="bold">To upload UEFI images</emphasis>
        </para>
        <para>To launch instances from a UEFI image, the administrator first has to
upload one UEFI image. To do so, <literal>hw_firmware_type</literal> property must
be set to <literal>uefi</literal> when the image is created. For example:</para>
        <screen language="console">$ openstack image create --container-format bare --disk-format qcow2 \
  --property hw_firmware_type=uefi --file /tmp/cloud-uefi.qcow --name uefi</screen>
        <para>After that, you can launch instances from this UEFI image.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Networking with nova-network</title>
      <para>Understanding the networking configuration options helps you design the
best configuration for your Compute instances.</para>
      <para>You can choose to either install and configure <literal>nova-network</literal> or use the
OpenStack Networking service (neutron). This section contains a brief
overview of <literal>nova-network</literal>. For more information about OpenStack
Networking, see <xref linkend="networking"/>.</para>
      <sect2>
        <title>Networking concepts</title>
        <para>Compute assigns a private IP address to each VM instance. Compute makes
a distinction between fixed IPs and floating IP. Fixed IPs are IP
addresses that are assigned to an instance on creation and stay the same
until the instance is explicitly terminated. Floating IPs are addresses
that can be dynamically associated with an instance. A floating IP
address can be disassociated and associated with another instance at any
time. A user can reserve a floating IP for their project.</para>
        <note>
          <para>Currently, Compute with <literal>nova-network</literal> only supports Linux bridge
networking that allows virtual interfaces to connect to the outside
network through the physical interface.</para>
        </note>
        <para>The network controller with <literal>nova-network</literal> provides virtual networks to
enable compute servers to interact with each other and with the public
network. Compute with <literal>nova-network</literal> supports the following network modes,
which are implemented as Network Manager types:</para>
        <variablelist>
          <varlistentry>
            <term>Flat Network Manager</term>
            <listitem>
              <para>In this mode, a network administrator specifies a subnet. IP
addresses for VM instances are assigned from the subnet, and then
injected into the image on launch. Each instance receives a fixed IP
address from the pool of available addresses. A system administrator
must create the Linux networking bridge (typically named <literal>br100</literal>,
although this is configurable) on the systems running the
<literal>nova-network</literal> service. All instances of the system are attached to
the same bridge, which is configured manually by the network
administrator.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <note>
          <para>Configuration injection currently only works on Linux-style
systems that keep networking configuration in
<literal>/etc/network/interfaces</literal>.</para>
        </note>
        <variablelist>
          <varlistentry>
            <term>Flat DHCP Network Manager</term>
            <listitem>
              <para>In this mode, OpenStack starts a DHCP server (dnsmasq) to allocate
IP addresses to VM instances from the specified subnet, in addition
to manually configuring the networking bridge. IP addresses for VM
instances are assigned from a subnet specified by the network
administrator.</para>
              <para>Like flat mode, all instances are attached to a single bridge on the
compute node. Additionally, a DHCP server configures instances
depending on single-/multi-host mode, alongside each <literal>nova-network</literal>.
In this mode, Compute does a bit more configuration. It attempts to
bridge into an Ethernet device (<literal>flat_interface</literal>, eth0 by
default). For every instance, Compute allocates a fixed IP address
and configures dnsmasq with the MAC ID and IP address for the VM.
Dnsmasq does not take part in the IP address allocation process, it
only hands out IPs according to the mapping done by Compute.
Instances receive their fixed IPs with the <command>dhcpdiscover</command> command.
These IPs are not assigned to any of the host's network interfaces,
only to the guest-side interface for the VM.</para>
              <para>In any setup with flat networking, the hosts providing the
<literal>nova-network</literal> service are responsible for forwarding traffic from the
private network. They also run and configure dnsmasq as a DHCP
server listening on this bridge, usually on IP address 10.0.0.1 (see
<xref linkend="compute-dnsmasq"/>). Compute can determine
the NAT entries for each network, although sometimes NAT is not
used, such as when the network has been configured with all public
IPs, or if a hardware router is used (which is a high availability
option). In this case, hosts need to have <literal>br100</literal> configured and
physically connected to any other nodes that are hosting VMs. You
must set the <literal>flat_network_bridge</literal> option or create networks with
the bridge parameter in order to avoid raising an error. Compute
nodes have iptables or ebtables entries created for each project and
instance to protect against MAC ID or IP address spoofing and ARP
poisoning.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <note>
          <para>In single-host Flat DHCP mode you will be able to ping VMs
through their fixed IP from the <literal>nova-network</literal> node, but you
cannot ping them from the compute nodes. This is expected
behavior.</para>
        </note>
        <variablelist>
          <varlistentry>
            <term>VLAN Network Manager</term>
            <listitem>
              <para>This is the default mode for OpenStack Compute. In this mode,
Compute creates a VLAN and bridge for each project. For
multiple-machine installations, the VLAN Network Mode requires a
switch that supports VLAN tagging (IEEE 802.1Q). The project gets a
range of private IPs that are only accessible from inside the VLAN.
In order for a user to access the instances in their project, a
special VPN instance (code named <literal>cloudpipe</literal>) needs to be created.
Compute generates a certificate and key for the user to access the
VPN and starts the VPN automatically. It provides a private network
segment for each project's instances that can be accessed through a
dedicated VPN connection from the internet. In this mode, each
project gets its own VLAN, Linux networking bridge, and subnet.</para>
              <para>The subnets are specified by the network administrator, and are
assigned dynamically to a project when required. A DHCP server is
started for each VLAN to pass out IP addresses to VM instances from
the subnet assigned to the project. All instances belonging to one
project are bridged into the same VLAN for that project. OpenStack
Compute creates the Linux networking bridges and VLANs when
required.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>These network managers can co-exist in a cloud system. However, because
you cannot select the type of network for a given project, you cannot
configure multiple network types in a single Compute installation.</para>
        <para>All network managers configure the network using network drivers. For
example, the Linux L3 driver (<literal>l3.py</literal> and <literal>linux_net.py</literal>), which
makes use of <literal>iptables</literal>, <literal>route</literal> and other network management
facilities, and the libvirt <link xlink:href="http://libvirt.org/formatnwfilter.html">network filtering
facilities</link>. The driver is
not tied to any particular network manager; all network managers use the
same driver. The driver usually initializes only when the first VM lands
on this host node.</para>
        <para>All network managers operate in either single-host or multi-host mode.
This choice greatly influences the network configuration. In single-host
mode, a single <literal>nova-network</literal> service provides a default gateway for VMs
and hosts a single DHCP server (dnsmasq). In multi-host mode, each
compute node runs its own <literal>nova-network</literal> service. In both cases, all
traffic between VMs and the internet flows through <literal>nova-network</literal>. Each
mode has benefits and drawbacks. For more on this, see the Network
Topology section in the <link xlink:href="http://docs.openstack.org/ops-guide/arch-network-design.html#network-topology">OpenStack Operations Guide</link>.</para>
        <para>All networking options require network connectivity to be already set up
between OpenStack physical nodes. OpenStack does not configure any
physical network interfaces. All network managers automatically create
VM virtual interfaces. Some network managers can also create network
bridges such as <literal>br100</literal>.</para>
        <para>The internal network interface is used for communication with VMs. The
interface should not have an IP address attached to it before OpenStack
installation, it serves only as a fabric where the actual endpoints are
VMs and dnsmasq. Additionally, the internal network interface must be in
<literal>promiscuous</literal> mode, so that it can receive packets whose target MAC
address is the guest VM, not the host.</para>
        <para>All machines must have a public and internal network interface
(controlled by these options: <literal>public_interface</literal> for the public
interface, and <literal>flat_interface</literal> and <literal>vlan_interface</literal> for the
internal interface with flat or VLAN managers). This guide refers to the
public network as the external network and the private network as the
internal or project network.</para>
        <para>For flat and flat DHCP modes, use the <command>nova network-create</command> command
to create a network:</para>
        <screen language="console">$ nova network-create vmnet \
  --fixed-range-v4 10.0.0.0/16 --fixed-cidr 10.0.20.0/24 --bridge br100</screen>
        <variablelist>
          <varlistentry>
            <term>This example uses the following parameters:</term>
            <listitem>
              <variablelist>
                <varlistentry>
                  <term>
                    <option>--fixed-range-v4</option>
                  </term>
                  <listitem>
                    <para>specifies the network subnet.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>
                    <option>--fixed-cidr</option>
                  </term>
                  <listitem>
                    <para>specifies a range of fixed IP addresses to allocate,
and can be a subset of the <literal>--fixed-range-v4</literal>
argument.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>
                    <option>--bridge</option>
                  </term>
                  <listitem>
                    <para>specifies the bridge device to which this network is
connected on every compute node.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2 xml:id="compute-dnsmasq">
        <title>DHCP server: dnsmasq</title>
        <para>The Compute service uses
<link xlink:href="http://www.thekelleys.org.uk/dnsmasq/doc.html">dnsmasq</link> as the DHCP
server when using either Flat DHCP Network Manager or VLAN Network
Manager. For Compute to operate in IPv4/IPv6 dual-stack mode, use at
least dnsmasq v2.63. The <literal>nova-network</literal> service is responsible for
starting dnsmasq processes.</para>
        <para>The behavior of dnsmasq can be customized by creating a dnsmasq
configuration file. Specify the configuration file using the
<literal>dnsmasq_config_file</literal> configuration option:</para>
        <screen language="ini">dnsmasq_config_file=/etc/dnsmasq-nova.conf</screen>
        <para>For more information about creating a dnsmasq configuration file, see
the <link xlink:href="http://docs.openstack.org/newton/config-reference/">OpenStack Configuration
Reference</link>,
and <link xlink:href="http://www.thekelleys.org.uk/dnsmasq/docs/dnsmasq.conf.example">the dnsmasq
documentation</link>.</para>
        <para>Dnsmasq also acts as a caching DNS server for instances. You can specify
the DNS server that dnsmasq uses by setting the <literal>dns_server</literal>
configuration option in <literal>/etc/nova/nova.conf</literal>. This example configures
dnsmasq to use Google's public DNS server:</para>
        <screen language="ini">dns_server=8.8.8.8</screen>
        <para>Dnsmasq logs to syslog (typically <literal>/var/log/syslog</literal> or
<literal>/var/log/messages</literal>, depending on Linux distribution). Logs can be
useful for troubleshooting, especially in a situation where VM instances
boot successfully but are not reachable over the network.</para>
        <para>Administrators can specify the starting point IP address to reserve with
the DHCP server (in the format n.n.n.n) with this command:</para>
        <screen language="console">$ nova-manage fixed reserve --address IP_ADDRESS</screen>
        <para>This reservation only affects which IP address the VMs start at, not the
fixed IP addresses that <literal>nova-network</literal> places on the bridges.</para>
      </sect2>
      <sect2>
        <title>Configure Compute to use IPv6 addresses</title>
        <para>If you are using OpenStack Compute with <literal>nova-network</literal>, you can put
Compute into dual-stack mode, so that it uses both IPv4 and IPv6
addresses for communication. In dual-stack mode, instances can acquire
their IPv6 global unicast addresses by using a stateless address
auto-configuration mechanism [RFC 4862/2462]. IPv4/IPv6 dual-stack mode
works with both <literal>VlanManager</literal> and <literal>FlatDHCPManager</literal> networking
modes.</para>
        <para>In <literal>VlanManager</literal> networking mode, each project uses a different 64-bit
global routing prefix. In <literal>FlatDHCPManager</literal> mode, all instances use
one 64-bit global routing prefix.</para>
        <para>This configuration was tested with virtual machine images that have an
IPv6 stateless address auto-configuration capability. This capability is
required for any VM to run with an IPv6 address. You must use an EUI-64
address for stateless address auto-configuration. Each node that
executes a <literal>nova-*</literal> service must have <literal>python-netaddr</literal> and <literal>radvd</literal>
installed.</para>
        <para>
          <emphasis role="bold">Switch into IPv4/IPv6 dual-stack mode</emphasis>
        </para>
        <procedure>
          <step>
            <para>For every node running a <literal>nova-*</literal> service, install python-netaddr:</para>
            <screen language="console"># apt-get install python-netaddr</screen>
          </step>
          <step>
            <para>For every node running <literal>nova-network</literal>, install <literal>radvd</literal> and configure
IPv6 networking:</para>
            <screen language="console"># apt-get install radvd
# echo 1 &gt; /proc/sys/net/ipv6/conf/all/forwarding
# echo 0 &gt; /proc/sys/net/ipv6/conf/all/accept_ra</screen>
          </step>
          <step>
            <para>On all nodes, edit the <literal>nova.conf</literal> file and specify
<literal>use_ipv6 = True</literal>.</para>
          </step>
          <step>
            <para>Restart all <literal>nova-*</literal> services.</para>
          </step>
        </procedure>
        <para>
          <emphasis role="bold">IPv6 configuration options</emphasis>
        </para>
        <para>You can use the following options with the <command>nova network-create</command>
command:</para>
        <itemizedlist>
          <listitem>
            <para>Add a fixed range for IPv6 addresses to the <command>nova network-create</command>
command. Specify <literal>public</literal> or <literal>private</literal> after the <literal>network-create</literal>
parameter.</para>
            <screen language="console">$ nova network-create public --fixed-range-v4 FIXED_RANGE_V4 \
  --vlan VLAN_ID --vpn VPN_START --fixed-range-v6 FIXED_RANGE_V6</screen>
          </listitem>
          <listitem>
            <para>Set the IPv6 global routing prefix by using the
<literal>--fixed_range_v6</literal> parameter. The default value for the parameter
is <literal>fd00::/48</literal>.</para>
            <para>When you use <literal>FlatDHCPManager</literal>, the command uses the original
<literal>--fixed_range_v6</literal> value. For example:</para>
            <screen language="console">$ nova network-create public  --fixed-range-v4 10.0.2.0/24 \
  --fixed-range-v6 fd00:1::/48</screen>
          </listitem>
          <listitem>
            <para>When you use <literal>VlanManager</literal>, the command increments the subnet ID
to create subnet prefixes. Guest VMs use this prefix to generate
their IPv6 global unicast addresses. For example:</para>
            <screen language="console">$ nova network-create public --fixed-range-v4 10.0.1.0/24 --vlan 100 \
  --vpn 1000 --fixed-range-v6 fd00:1::/48</screen>
          </listitem>
        </itemizedlist>
        <table>
          <title>Description of IPv6 configuration options</title>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="50.0*"/>
            <colspec colname="c2" colwidth="50.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Configuration option = Default value</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>[DEFAULT]</para>
                </entry>
                <entry/>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>fixed_range_v6 = fd00::/48</para>
                </entry>
                <entry>
                  <para>(StrOpt) Fixed IPv6 address block</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>gateway_v6 = None</para>
                </entry>
                <entry>
                  <para>(StrOpt) Default IPv6 gateway</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>ipv6_backend = rfc2462</para>
                </entry>
                <entry>
                  <para>(StrOpt) Backend to use for IPv6 generation</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>use_ipv6 = False</para>
                </entry>
                <entry>
                  <para>(BoolOpt) Use IPv6</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </sect2>
      <sect2>
        <title>Metadata service</title>
        <para>Compute uses a metadata service for virtual machine instances to
retrieve instance-specific data. Instances access the metadata service
at <literal>http://169.254.169.254</literal>. The metadata service supports two sets of
APIs: an OpenStack metadata API and an EC2-compatible API. Both APIs are
versioned by date.</para>
        <para>To retrieve a list of supported versions for the OpenStack metadata API,
make a GET request to <literal>http://169.254.169.254/openstack</literal>:</para>
        <screen language="console">$ curl http://169.254.169.254/openstack
2012-08-10
2013-04-04
2013-10-17
latest</screen>
        <para>To list supported versions for the EC2-compatible metadata API, make a
GET request to <literal>http://169.254.169.254</literal>:</para>
        <screen language="console">$ curl http://169.254.169.254
1.0
2007-01-19
2007-03-01
2007-08-29
2007-10-10
2007-12-15
2008-02-01
2008-09-01
2009-04-04
latest</screen>
        <para>If you write a consumer for one of these APIs, always attempt to access
the most recent API version supported by your consumer first, then fall
back to an earlier version if the most recent one is not available.</para>
        <para>Metadata from the OpenStack API is distributed in JSON format. To
retrieve the metadata, make a GET request to
<literal>http://169.254.169.254/openstack/2012-08-10/meta_data.json</literal>:</para>
        <screen language="console">$ curl http://169.254.169.254/openstack/2012-08-10/meta_data.json</screen>
        <screen language="json">{
   "uuid": "d8e02d56-2648-49a3-bf97-6be8f1204f38",
   "availability_zone": "nova",
   "hostname": "test.novalocal",
   "launch_index": 0,
   "meta": {
      "priority": "low",
      "role": "webserver"
   },
   "project_id": "f7ac731cc11f40efbc03a9f9e1d1d21f",
   "public_keys": {
       "mykey": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDYVEprvtYJXVOBN0XNKV\
                 VRNCRX6BlnNbI+USLGais1sUWPwtSg7z9K9vhbYAPUZcq8c/s5S9dg5vTH\
                 bsiyPCIDOKyeHba4MUJq8Oh5b2i71/3BISpyxTBH/uZDHdslW2a+SrPDCe\
                 uMMoss9NFhBdKtDkdG9zyi0ibmCP6yMdEX8Q== Generated by Nova\n"
   },
   "name": "test"
}</screen>
        <para>Instances also retrieve user data (passed as the <literal>user_data</literal> parameter
in the API call or by the <literal>--user_data</literal> flag in the
<command>openstack server create</command> command) through the metadata service, by making a
GET request to <literal>http://169.254.169.254/openstack/2012-08-10/user_data</literal>:</para>
        <screen language="console">$ curl http://169.254.169.254/openstack/2012-08-10/user_data
#!/bin/bash
echo 'Extra user data here'</screen>
        <para>The metadata service has an API that is compatible with version
2009-04-04 of the <link xlink:href="http://docs.amazonwebservices.com/AWSEC2/2009-04-04/UserGuide/AESDG-chapter-instancedata.html">Amazon EC2 metadata
service</link>.
This means that virtual machine images designed for EC2 will work
properly with OpenStack.</para>
        <para>The EC2 API exposes a separate URL for each metadata element. Retrieve a
listing of these elements by making a GET query to
<literal>http://169.254.169.254/2009-04-04/meta-data/</literal>:</para>
        <screen language="console">$ curl http://169.254.169.254/2009-04-04/meta-data/
ami-id
ami-launch-index
ami-manifest-path
block-device-mapping/
hostname
instance-action
instance-id
instance-type
kernel-id
local-hostname
local-ipv4
placement/
public-hostname
public-ipv4
public-keys/
ramdisk-id
reservation-id
security-groups</screen>
        <screen language="console">$ curl http://169.254.169.254/2009-04-04/meta-data/block-device-mapping/
ami</screen>
        <screen language="console">$ curl http://169.254.169.254/2009-04-04/meta-data/placement/
availability-zone</screen>
        <screen language="console">$ curl http://169.254.169.254/2009-04-04/meta-data/public-keys/
0=mykey</screen>
        <para>Instances can retrieve the public SSH key (identified by keypair name
when a user requests a new instance) by making a GET request to
<literal>http://169.254.169.254/2009-04-04/meta-data/public-keys/0/openssh-key</literal>:</para>
        <screen language="console">$ curl http://169.254.169.254/2009-04-04/meta-data/public-keys/0/openssh-key
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDYVEprvtYJXVOBN0XNKVVRNCRX6BlnNbI+US\
LGais1sUWPwtSg7z9K9vhbYAPUZcq8c/s5S9dg5vTHbsiyPCIDOKyeHba4MUJq8Oh5b2i71/3B\
ISpyxTBH/uZDHdslW2a+SrPDCeuMMoss9NFhBdKtDkdG9zyi0ibmCP6yMdEX8Q== Generated\
by Nova</screen>
        <para>Instances can retrieve user data by making a GET request to
<literal>http://169.254.169.254/2009-04-04/user-data</literal>:</para>
        <screen language="console">$ curl http://169.254.169.254/2009-04-04/user-data
#!/bin/bash
echo 'Extra user data here'</screen>
        <para>The metadata service is implemented by either the <literal>nova-api</literal> service or
the <literal>nova-api-metadata</literal> service. Note that the <literal>nova-api-metadata</literal> service
is generally only used when running in multi-host mode, as it retrieves
instance-specific metadata. If you are running the <literal>nova-api</literal> service, you
must have <literal>metadata</literal> as one of the elements listed in the
<literal>enabled_apis</literal> configuration option in <literal>/etc/nova/nova.conf</literal>. The
default <literal>enabled_apis</literal> configuration setting includes the metadata
service, so you do not need to modify it.</para>
        <para>Hosts access the service at <literal>169.254.169.254:80</literal>, and this is
translated to <literal>metadata_host:metadata_port</literal> by an iptables rule
established by the <literal>nova-network</literal> service. In multi-host mode, you can set
<literal>metadata_host</literal> to <literal>127.0.0.1</literal>.</para>
        <para>For instances to reach the metadata service, the <literal>nova-network</literal> service
must configure iptables to NAT port <literal>80</literal> of the <literal>169.254.169.254</literal>
address to the IP address specified in <literal>metadata_host</literal> (this defaults
to <literal>$my_ip</literal>, which is the IP address of the <literal>nova-network</literal> service) and
port specified in <literal>metadata_port</literal> (which defaults to <literal>8775</literal>) in
<literal>/etc/nova/nova.conf</literal>.</para>
        <note>
          <para>The <literal>metadata_host</literal> configuration option must be an IP address,
not a host name.</para>
        </note>
        <para>The default Compute service settings assume that <literal>nova-network</literal> and
<literal>nova-api</literal> are running on the same host. If this is not the case, in the
<literal>/etc/nova/nova.conf</literal> file on the host running <literal>nova-network</literal>, set the
<literal>metadata_host</literal> configuration option to the IP address of the host
where <literal>nova-api</literal> is running.</para>
        <table>
          <title>Description of metadata configuration options</title>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="50.0*"/>
            <colspec colname="c2" colwidth="50.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Configuration option = Default value</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>[DEFAULT]</para>
                </entry>
                <entry/>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>metadata_cache_expiration = 15</para>
                </entry>
                <entry>
                  <para>(IntOpt) Time in seconds to cache metadata; 0 to disable metadata
caching entirely (not recommended). Increasing this should improve
response times of the metadata API when under heavy load. Higher values
may increase memory usage and result in longer times for host metadata
changes to take effect.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>metadata_host = $my_ip</para>
                </entry>
                <entry>
                  <para>(StrOpt) The IP address for the metadata API server</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>metadata_listen = 0.0.0.0</para>
                </entry>
                <entry>
                  <para>(StrOpt) The IP address on which the metadata API will listen.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>metadata_listen_port = 8775</para>
                </entry>
                <entry>
                  <para>(IntOpt) The port on which the metadata API will listen.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>metadata_manager = nova.api.manager.MetadataManager</para>
                </entry>
                <entry>
                  <para>(StrOpt) OpenStack metadata service manager</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>metadata_port = 8775</para>
                </entry>
                <entry>
                  <para>(IntOpt) The port for the metadata API port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>metadata_workers = None</para>
                </entry>
                <entry>
                  <para>(IntOpt) Number of workers for metadata service. The default will be the number of CPUs available.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>vendordata_driver = nova.api.metadata.vendordata_json.JsonFileVendorData</para>
                </entry>
                <entry>
                  <para>(StrOpt) Driver to use for vendor data</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>vendordata_jsonfile_path = None</para>
                </entry>
                <entry>
                  <para>(StrOpt) File to load JSON formatted vendor data from</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </sect2>
      <sect2>
        <title>Enable ping and SSH on VMs</title>
        <para>You need to enable <literal>ping</literal> and <literal>ssh</literal> on your VMs for network access.
This can be done with either the <command>nova</command> or <command>euca2ools</command>
commands.</para>
        <note>
          <para>Run these commands as root only if the credentials used to interact
with <literal>nova-api</literal> are in <literal>/root/.bashrc</literal>. If the EC2 credentials in
the <literal>.bashrc</literal> file are for an unprivileged user, you must run
these commands as that user instead.</para>
        </note>
        <para>Enable ping and SSH with <command>openstack security group rule create</command>
commands:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule create default --protocol icmp --dst-port -1:-1 --remote-ip 0.0.0.0/0
$ openstack security group rule create default --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0</screen>
        <para>Enable ping and SSH with <literal>euca2ools</literal>:</para>
        <screen language="console">$ euca-authorize -P icmp -t -1:-1 -s 0.0.0.0/0 default
$ euca-authorize -P tcp -p 22 -s 0.0.0.0/0 default</screen>
        <para>If you have run these commands and still cannot ping or SSH your
instances, check the number of running <literal>dnsmasq</literal> processes, there
should be two. If not, kill the processes and restart the service with
these commands:</para>
        <screen language="console"># killall dnsmasq
# service nova-network restart</screen>
      </sect2>
      <sect2>
        <title>Configure public (floating) IP addresses</title>
        <para>This section describes how to configure floating IP addresses with
<literal>nova-network</literal>. For information about doing this with OpenStack
Networking, see <xref linkend="l3-routing-and-nat"/>.</para>
        <sect3>
          <title>Private and public IP addresses</title>
          <para>In this section, the term floating IP address is used to refer to an IP
address, usually public, that you can dynamically add to a running
virtual instance.</para>
          <para>Every virtual instance is automatically assigned a private IP address.
You can choose to assign a public (or floating) IP address instead.
OpenStack Compute uses network address translation (NAT) to assign
floating IPs to virtual instances.</para>
          <para>To be able to assign a floating IP address, edit the
<literal>/etc/nova/nova.conf</literal> file to specify which interface the
<literal>nova-network</literal> service should bind public IP addresses to:</para>
          <screen language="ini">public_interface=VLAN100</screen>
          <para>If you make changes to the <literal>/etc/nova/nova.conf</literal> file while the
<literal>nova-network</literal> service is running, you will need to restart the service to
pick up the changes.</para>
          <note>
            <para>Floating IPs are implemented by using a source NAT (SNAT rule in
iptables), so security groups can sometimes display inconsistent
behavior if VMs use their floating IP to communicate with other VMs,
particularly on the same physical host. Traffic from VM to VM across
the fixed network does not have this issue, and so this is the
recommended setup. To ensure that traffic does not get SNATed to the
floating range, explicitly set:</para>
            <screen language="ini">dmz_cidr=x.x.x.x/y</screen>
            <para>The <literal>x.x.x.x/y</literal> value specifies the range of floating IPs for each
pool of floating IPs that you define. This configuration is also
required if the VMs in the source group have floating IPs.</para>
          </note>
        </sect3>
        <sect3>
          <title>Enable IP forwarding</title>
          <para>IP forwarding is disabled by default on most Linux distributions. You
will need to enable it in order to use floating IPs.</para>
          <note>
            <para>IP forwarding only needs to be enabled on the nodes that run
<literal>nova-network</literal>. However, you will need to enable it on all compute
nodes if you use <literal>multi_host</literal> mode.</para>
          </note>
          <para>To check if IP forwarding is enabled, run:</para>
          <screen language="console">$ cat /proc/sys/net/ipv4/ip_forward
0</screen>
          <para>Alternatively, run:</para>
          <screen language="console">$ sysctl net.ipv4.ip_forward
net.ipv4.ip_forward = 0</screen>
          <para>In these examples, IP forwarding is disabled.</para>
          <para>To enable IP forwarding dynamically, run:</para>
          <screen language="console"># sysctl -w net.ipv4.ip_forward=1</screen>
          <para>Alternatively, run:</para>
          <screen language="console"># echo 1 &gt; /proc/sys/net/ipv4/ip_forward</screen>
          <para>To make the changes permanent, edit the <literal>/etc/sysctl.conf</literal> file and
update the IP forwarding setting:</para>
          <screen language="ini">net.ipv4.ip_forward = 1</screen>
          <para>Save the file and run this command to apply the changes:</para>
          <screen language="console"># sysctl -p</screen>
          <para>You can also apply the changes by restarting the network service:</para>
          <itemizedlist>
            <listitem>
              <para>on Ubuntu, Debian:</para>
              <screen language="console"># /etc/init.d/networking restart</screen>
            </listitem>
            <listitem>
              <para>on RHEL, Fedora, CentOS, openSUSE and SLES:</para>
              <screen language="console"># service network restart</screen>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Create a list of available floating IP addresses</title>
          <para>Compute maintains a list of floating IP addresses that are available for
assigning to instances. Use the <command>nova-manage floating</command> commands
to perform floating IP operations:</para>
          <itemizedlist>
            <listitem>
              <para>Add entries to the list:</para>
              <screen language="console"># nova-manage floating create --pool nova --ip_range 68.99.26.170/31</screen>
            </listitem>
            <listitem>
              <para>List the floating IP addresses in the pool:</para>
              <screen language="console"># openstack floating ip list</screen>
            </listitem>
            <listitem>
              <para>Create specific floating IPs for either a single address or a
subnet:</para>
              <screen language="console"># nova-manage floating create --pool POOL_NAME --ip_range CIDR</screen>
            </listitem>
            <listitem>
              <para>Remove floating IP addresses using the same parameters as the create
command:</para>
              <screen language="console"># openstack floating ip delete CIDR</screen>
            </listitem>
          </itemizedlist>
          <para>For more information about how administrators can associate floating IPs
with instances, see <link xlink:href="http://docs.openstack.org/admin-guide/cli-admin-manage-ip-addresses.html">Manage IP
addresses</link>
in the OpenStack Administrator Guide.</para>
        </sect3>
        <sect3>
          <title>Automatically add floating IPs</title>
          <para>You can configure <literal>nova-network</literal> to automatically allocate and assign a
floating IP address to virtual instances when they are launched. Add
this line to the <literal>/etc/nova/nova.conf</literal> file:</para>
          <screen language="ini">auto_assign_floating_ip=True</screen>
          <para>Save the file, and restart <literal>nova-network</literal></para>
          <note>
            <para>If this option is enabled, but all floating IP addresses have
already been allocated, the <command>openstack server create</command>
command will fail.</para>
          </note>
        </sect3>
      </sect2>
      <sect2>
        <title>Remove a network from a project</title>
        <para>You cannot delete a network that has been associated to a project. This
section describes the procedure for dissociating it so that it can be
deleted.</para>
        <para>In order to disassociate the network, you will need the ID of the
project it has been associated to. To get the project ID, you will need
to be an administrator.</para>
        <para>Disassociate the network from the project using the
<command>nova-manage project scrub</command> command,
with the project ID as the final parameter:</para>
        <screen language="console"># nova-manage project scrub --project ID</screen>
      </sect2>
      <sect2>
        <title>Multiple interfaces for instances (multinic)</title>
        <para>The multinic feature allows you to use more than one interface with your
instances. This is useful in several scenarios:</para>
        <itemizedlist>
          <listitem>
            <para>SSL Configurations (VIPs)</para>
          </listitem>
          <listitem>
            <para>Services failover/HA</para>
          </listitem>
          <listitem>
            <para>Bandwidth Allocation</para>
          </listitem>
          <listitem>
            <para>Administrative/Public access to your instances</para>
          </listitem>
        </itemizedlist>
        <para>Each VIP represents a separate network with its own IP block. Every
network mode has its own set of changes regarding multinic usage:</para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-manager.jpg" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-manager.jpg" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-DHCP-manager.jpg" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-DHCP-manager.jpg" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="SCH_5007_V00_NUAC-multi_nic_OpenStack-VLAN-manager.jpg" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="SCH_5007_V00_NUAC-multi_nic_OpenStack-VLAN-manager.jpg" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <sect3>
          <title>Using multinic</title>
          <para>In order to use multinic, create two networks, and attach them to the
project (named <literal>project</literal> on the command line):</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ nova network-create first-net --fixed-range-v4 20.20.0.0/24 --project-id $your-project
$ nova network-create second-net --fixed-range-v4 20.20.10.0/24 --project-id $your-project</screen>
          <para>Each new instance will now receive two IP addresses from their
respective DHCP servers:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack server list
+---------+----------+--------+-----------------------------------------+------------+
|ID       | Name     | Status | Networks                                | Image Name |
+---------+----------+--------+-----------------------------------------+------------+
| 1234... | MyServer | ACTIVE | network2=20.20.0.3; private=20.20.10.14 | cirros     |
+---------+----------+--------+-----------------------------------------+------------+</screen>
          <note>
            <para>Make sure you start the second interface on the instance, or it
won't be reachable through the second IP.</para>
          </note>
          <para>This example demonstrates how to set up the interfaces within the
instance. This is the configuration that needs to be applied inside the
image.</para>
          <para>Edit the <literal>/etc/network/interfaces</literal> file:</para>
          <screen language="bash"># The loopback network interface
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet dhcp

auto eth1
iface eth1 inet dhcp</screen>
          <para>If the Virtual Network Service Neutron is installed, you can specify the
networks to attach to the interfaces by using the <literal>--nic</literal> flag with
the <command>openstack server create</command> command:</para>
          <screen language="console">$ openstack server create --image ed8b2a37-5535-4a5f-a615-443513036d71 \
  --flavor 1 --nic net-id=NETWORK1_ID --nic net-id=NETWORK2_ID test-vm1</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Troubleshooting Networking</title>
        <sect3>
          <title>Cannot reach floating IPs</title>
          <para/>
          <bridgehead renderas="sect4">Problem</bridgehead>
          <para>You cannot reach your instances through the floating IP address.</para>
          <bridgehead renderas="sect4">Solution</bridgehead>
          <itemizedlist>
            <listitem>
              <para>Check that the default security group allows ICMP (ping) and SSH
(port 22), so that you can reach the instances:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule list default
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| ID                                   | IP Protocol | IP Range  | Port Range      | Remote Security Group |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| 63536865-e5b6-4df1-bac5-ca6d97d8f54d | tcp         | 0.0.0.0/0 | 22:22           | None                  |
| e9d3200f-647a-4293-a9fc-e65ceee189ae | icmp        | 0.0.0.0/0 | type=1:code=-1  | None                  |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+</screen>
            </listitem>
            <listitem>
              <para>Check the NAT rules have been added to iptables on the node that is
running <literal>nova-network</literal>:</para>
              <screen language="console"># iptables -L -nv -t nat
-A nova-network-PREROUTING -d 68.99.26.170/32 -j DNAT --to-destination 10.0.0.3
-A nova-network-floating-snat -s 10.0.0.3/32 -j SNAT --to-source 68.99.26.170</screen>
            </listitem>
            <listitem>
              <para>Check that the public address (<literal>68.99.26.170</literal> in
this example), has been added to your public interface. You should
see the address in the listing when you use the <command>ip addr</command> command:</para>
              <screen language="console">$ ip addr
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000
link/ether xx:xx:xx:17:4b:c2 brd ff:ff:ff:ff:ff:ff
inet 13.22.194.80/24 brd 13.22.194.255 scope global eth0
inet 68.99.26.170/32 scope global eth0
inet6 fe80::82b:2bf:fe1:4b2/64 scope link
valid_lft forever preferred_lft forever</screen>
              <note>
                <para>You cannot use <literal>SSH</literal> to access an instance with a public IP from within
the same server because the routing configuration does not allow
it.</para>
              </note>
            </listitem>
            <listitem>
              <para>Use <literal>tcpdump</literal> to identify if packets are being routed to the
inbound interface on the compute host. If the packets are reaching
the compute hosts but the connection is failing, the issue may be
that the packet is being dropped by reverse path filtering. Try
disabling reverse-path filtering on the inbound interface. For
example, if the inbound interface is <literal>eth2</literal>, run:</para>
              <screen language="console"># sysctl -w net.ipv4.conf.ETH2.rp_filter=0</screen>
              <para>If this solves the problem, add the following line to
<literal>/etc/sysctl.conf</literal> so that the reverse-path filter is persistent:</para>
              <screen language="ini">net.ipv4.conf.rp_filter=0</screen>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Temporarily disable firewall</title>
          <para/>
          <bridgehead renderas="sect4">Problem</bridgehead>
          <para>Networking issues prevent administrators accessing or reaching VM's
through various pathways.</para>
          <bridgehead renderas="sect4">Solution</bridgehead>
          <para>You can disable the firewall by setting this option
in <literal>/etc/nova/nova.conf</literal>:</para>
          <screen language="ini">firewall_driver=nova.virt.firewall.NoopFirewallDriver</screen>
        </sect3>
        <sect3>
          <title>Packet loss from instances to nova-network server (VLANManager mode)</title>
          <para/>
          <bridgehead renderas="sect4">Problem</bridgehead>
          <para>If you can access your instances with <literal>SSH</literal> but the network to your instance
is slow, or if you find that running certain operations are slower than
they should be (for example, <literal>sudo</literal>), packet loss could be occurring
on the connection to the instance.</para>
          <para>Packet loss can be caused by Linux networking configuration settings
related to bridges. Certain settings can cause packets to be dropped
between the VLAN interface (for example, <literal>vlan100</literal>) and the associated
bridge interface (for example, <literal>br100</literal>) on the host running
<literal>nova-network</literal>.</para>
          <bridgehead renderas="sect4">Solution</bridgehead>
          <para>One way to check whether this is the problem is to open three terminals
and run the following commands:</para>
          <procedure>
            <step>
              <para>In the first terminal, on the host running <literal>nova-network</literal>, use
<literal>tcpdump</literal> on the VLAN interface to monitor DNS-related traffic
(UDP, port 53). As root, run:</para>
              <screen language="console"># tcpdump -K -p -i vlan100 -v -vv udp port 53</screen>
            </step>
            <step>
              <para>In the second terminal, also on the host running <literal>nova-network</literal>, use
<literal>tcpdump</literal> to monitor DNS-related traffic on the bridge interface.
As root, run:</para>
              <screen language="console"># tcpdump -K -p -i br100 -v -vv udp port 53</screen>
            </step>
            <step>
              <para>In the third terminal, use <literal>SSH</literal> to access the instance and generate DNS
requests by using the <command>nslookup</command> command:</para>
              <screen language="console">$ nslookup www.google.com</screen>
              <para>The symptoms may be intermittent, so try running <command>nslookup</command>
multiple times. If the network configuration is correct, the command
should return immediately each time. If it is not correct, the
command hangs for several seconds before returning.</para>
            </step>
            <step>
              <para>If the <command>nslookup</command> command sometimes hangs, and there are packets
that appear in the first terminal but not the second, then the
problem may be due to filtering done on the bridges. Try disabling
filtering, and running these commands as root:</para>
              <screen language="console"># sysctl -w net.bridge.bridge-nf-call-arptables=0
# sysctl -w net.bridge.bridge-nf-call-iptables=0
# sysctl -w net.bridge.bridge-nf-call-ip6tables=0</screen>
              <para>If this solves your issue, add the following line to
<literal>/etc/sysctl.conf</literal> so that the changes are persistent:</para>
              <screen language="ini">net.bridge.bridge-nf-call-arptables=0
net.bridge.bridge-nf-call-iptables=0
net.bridge.bridge-nf-call-ip6tables=0</screen>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>KVM: Network connectivity works initially, then fails</title>
          <para/>
          <bridgehead renderas="sect4">Problem</bridgehead>
          <para>With KVM hypervisors, instances running Ubuntu 12.04 sometimes lose
network connectivity after functioning properly for a period of time.</para>
          <bridgehead renderas="sect4">Solution</bridgehead>
          <para>Try loading the <literal>vhost_net</literal> kernel module as a workaround for this
issue (see <link xlink:href="https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/997978/">bug
#997978</link>)
. This kernel module may also <link xlink:href="http://www.linux-kvm.org/page/VhostNet">improve network
performance</link> on KVM. To load
the kernel module:</para>
          <screen language="console"># modprobe vhost_net</screen>
          <note>
            <para>Loading the module has no effect on running instances.</para>
          </note>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>System administration</title>
      <para>To effectively administer compute, you must understand how the different
        installed nodes interact with each other. Compute can be installed in
        many different ways using multiple servers, but generally multiple
        compute nodes control the virtual servers and a cloud controller node
        contains the remaining Compute services.</para>
      <para>The Compute cloud works using a series of daemon processes named <literal>nova-*</literal>
        that exist persistently on the host machine. These binaries can all run
        on the same machine or be spread out on multiple boxes in a large
        deployment. The responsibilities of services and drivers are:</para>
      <para>
        <emphasis role="bold">Services</emphasis>
      </para>
      <variablelist>
        <varlistentry>
          <term>
            <literal>nova-api</literal>
          </term>
          <listitem>
            <para>receives XML requests and sends them to the rest of the
              system. A WSGI app routes and authenticates requests. Supports the
              EC2 and OpenStack APIs. A <literal>nova.conf</literal> configuration file is created
              when Compute is installed.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-cert</literal>
          </term>
          <listitem>
            <para>manages certificates.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-compute</literal>
          </term>
          <listitem>
            <para>manages virtual machines. Loads a Service object, and
              exposes the public methods on ComputeManager through a Remote
              Procedure Call (RPC).</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-conductor</literal>
          </term>
          <listitem>
            <para>provides database-access support for compute nodes
              (thereby reducing security risks).</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-consoleauth</literal>
          </term>
          <listitem>
            <para>manages console authentication.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-objectstore</literal>
          </term>
          <listitem>
            <para>a simple file-based storage system for images that
              replicates most of the S3 API. It can be replaced with OpenStack
              Image service and either a simple image manager or OpenStack Object
              Storage as the virtual machine image storage facility. It must exist
              on the same node as <literal>nova-compute</literal>.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-network</literal>
          </term>
          <listitem>
            <para>manages floating and fixed IPs, DHCP, bridging and
              VLANs. Loads a Service object which exposes the public methods on one
              of the subclasses of NetworkManager. Different networking strategies
              are available by changing the <literal>network_manager</literal> configuration
              option to <literal>FlatManager</literal>, <literal>FlatDHCPManager</literal>, or <literal>VLANManager</literal>
              (defaults to <literal>VLANManager</literal> if nothing is specified).</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-scheduler</literal>
          </term>
          <listitem>
            <para>dispatches requests for new virtual machines to the
              correct node.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <literal>nova-novncproxy</literal>
          </term>
          <listitem>
            <para>provides a VNC proxy for browsers, allowing VNC
              consoles to access virtual machines.</para>
          </listitem>
        </varlistentry>
      </variablelist>
      <note>
        <para>Some services have drivers that change how the service implements
          its core functionality. For example, the <literal>nova-compute</literal> service
          supports drivers that let you choose which hypervisor type it can
          use. <literal>nova-network</literal> and <literal>nova-scheduler</literal> also have drivers.</para>
      </note>
      <sect2>
        <title>Manage Compute users</title>
        <para>Access to the Euca2ools (ec2) API is controlled by an access key and a
secret key. The user's access key needs to be included in the request,
and the request must be signed with the secret key. Upon receipt of API
requests, Compute verifies the signature and runs commands on behalf of
the user.</para>
        <para>To begin using Compute, you must create a user with the Identity
service.</para>
      </sect2>
      <sect2>
        <title>Manage volumes</title>
        <para>Depending on the setup of your cloud provider, they may give you an
endpoint to use to manage volumes, or there may be an extension under
the covers. In either case, you can use the <literal>openstack</literal> CLI to manage
volumes.</para>
        <table>
          <title>openstack volume commands</title>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="50.0*"/>
            <colspec colname="c2" colwidth="50.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Command</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>server add volume</para>
                </entry>
                <entry>
                  <para>Attach a volume to a server.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume create</para>
                </entry>
                <entry>
                  <para>Add a new volume.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume delete</para>
                </entry>
                <entry>
                  <para>Remove or delete a volume.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>server remove volume</para>
                </entry>
                <entry>
                  <para>Detach or remove a volume from a server.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume list</para>
                </entry>
                <entry>
                  <para>List all the volumes.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume show</para>
                </entry>
                <entry>
                  <para>Show details about a volume.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot create</para>
                </entry>
                <entry>
                  <para>Add a new snapshot.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot delete</para>
                </entry>
                <entry>
                  <para>Remove a snapshot.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot list</para>
                </entry>
                <entry>
                  <para>List all the snapshots.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot show</para>
                </entry>
                <entry>
                  <para>Show details about a snapshot.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume type create</para>
                </entry>
                <entry>
                  <para>Create a new volume type.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume type delete</para>
                </entry>
                <entry>
                  <para>Delete a specific flavor</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume type list</para>
                </entry>
                <entry>
                  <para>Print a list of available 'volume types'.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <para>For example, to list IDs and names of volumes, run:</para>
        <screen language="console">$ openstack volume list
+--------+--------------+-----------+------+-------------+
| ID     | Display Name | Status    | Size | Attached to |
+--------+--------------+-----------+------+-------------+
| 86e6cb | testnfs      | available |    1 |             |
| e389f7 | demo         | available |    1 |             |
+--------+--------------+-----------+------+-------------+</screen>
      </sect2>
      <sect2 xml:id="compute-flavors">
        <title>Flavors</title>
        <para>Admin users can use the <command>openstack flavor</command> command to customize and
manage flavors. To see information for this command, run:</para>
        <screen language="console">$ openstack flavor --help
Command "flavor" matches:
  flavor create
  flavor delete
  flavor list
  flavor set
  flavor show
  flavor unset</screen>
        <note>
          <itemizedlist>
            <listitem>
              <para>Configuration rights can be delegated to additional users by
redefining the access controls for
<literal>compute_extension:flavormanage</literal> in <literal>/etc/nova/policy.json</literal>
on the <literal>nova-api</literal> server.</para>
            </listitem>
            <listitem>
              <para>The Dashboard simulates the ability to modify a flavor
by deleting an existing flavor and creating a new one with the same name.</para>
            </listitem>
          </itemizedlist>
        </note>
        <para>Flavors define these elements:</para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="17.1*"/>
            <colspec colname="c2" colwidth="82.9*"/>
            <thead>
              <row>
                <entry>
                  <para>Element</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>A descriptive name. XX.SIZE_NAME is typically not required,
though some third party tools may rely on it.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Memory MB</para>
                </entry>
                <entry>
                  <para>Instance memory in megabytes.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Disk</para>
                </entry>
                <entry>
                  <para>Virtual root disk size in gigabytes. This is an ephemeral disk that the base image is copied into. When booting from a persistent volume it is not used. The "0" size is a special case which uses the native base image size as the size of the
ephemeral root volume.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Ephemeral</para>
                </entry>
                <entry>
                  <para>Specifies the size of a secondary ephemeral data disk. This
is an empty, unformatted disk and exists only for the life of the instance. Default value is <literal>0</literal>.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Swap</para>
                </entry>
                <entry>
                  <para>Optional swap space allocation for the instance. Default
value is <literal>0</literal>.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>VCPUs</para>
                </entry>
                <entry>
                  <para>Number of virtual CPUs presented to the instance.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>RXTX Factor</para>
                </entry>
                <entry>
                  <para>Optional property allows created servers to have a different
bandwidth cap than that defined in the network they are attached to. This factor is multiplied by the rxtx_base property of the network. Default value is <literal>1.0</literal>. That is, the same
as attached network. This parameter is only available for Xen
or NSX based systems.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Is Public</para>
                </entry>
                <entry>
                  <para>Boolean value, whether flavor is available to all users or private to the project it was created in. Defaults to <literal>True</literal>.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Extra Specs</para>
                </entry>
                <entry>
                  <para>Key and value pairs that define on which compute nodes a flavor can run. These pairs must match corresponding pairs on the compute nodes. Use to implement special resources, such as flavors that run on only compute nodes with GPU hardware.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <para>Flavor customization can be limited by the hypervisor in use. For
example the libvirt driver enables quotas on CPUs available to a VM,
disk tuning, bandwidth I/O, watchdog behavior, random number generator
device control, and instance VIF traffic control.</para>
        </note>
        <sect3>
          <title>Is Public</title>
          <para>Flavors can be assigned to particular projects. By default, a flavor is public
and available to all projects. Private flavors are only accessible to those on
the access list and are invisible to other projects. To create and assign a
private flavor to a project, run this command:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack flavor create --private p1.medium --id auto --ram 512 --disk 40 --vcpus 4</screen>
        </sect3>
        <sect3>
          <title>Extra Specs</title>
          <variablelist>
            <varlistentry>
              <term>CPU limits</term>
              <listitem>
                <para>You can configure the CPU limits with control parameters with the
<literal>nova</literal> client. For example, to configure the I/O limit, use:</para>
                <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property quota:read_bytes_sec=10240000 \
    --property quota:write_bytes_sec=10240000</screen>
                <para>Use these optional parameters to control weight shares, enforcement
intervals for runtime quotas, and a quota for maximum allowed
bandwidth:</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>cpu_shares</literal>: Specifies the proportional weighted share for the
domain. If this element is omitted, the service defaults to the
OS provided defaults. There is no unit for the value; it is a
relative measure based on the setting of other VMs. For example,
a VM configured with value 2048 gets twice as much CPU time as a
VM configured with value 1024.</para>
                  </listitem>
                  <listitem>
                    <para><literal>cpu_shares_level</literal>: On VMware, specifies the allocation level. Can
be <literal>custom</literal>, <literal>high</literal>, <literal>normal</literal>, or <literal>low</literal>. If you choose
<literal>custom</literal>, set the number of shares using <literal>cpu_shares_share</literal>.</para>
                  </listitem>
                  <listitem>
                    <para><literal>cpu_period</literal>: Specifies the enforcement interval (unit:
microseconds) for QEMU and LXC hypervisors. Within a period, each
VCPU of the domain is not allowed to consume more than the quota
worth of runtime. The value should be in range <literal>[1000, 1000000]</literal>.
A period with value 0 means no value.</para>
                  </listitem>
                  <listitem>
                    <para><literal>cpu_limit</literal>: Specifies the upper limit for VMware machine CPU
allocation in MHz. This parameter ensures that a machine never
uses more than the defined amount of CPU time. It can be used to
enforce a limit on the machine's CPU performance.</para>
                  </listitem>
                  <listitem>
                    <para><literal>cpu_reservation</literal>: Specifies the guaranteed minimum CPU
reservation in MHz for VMware. This means that if needed, the
machine will definitely get allocated the reserved amount of CPU
cycles.</para>
                  </listitem>
                  <listitem>
                    <para><literal>cpu_quota</literal>: Specifies the maximum allowed bandwidth (unit:
microseconds). A domain with a negative-value quota indicates
that the domain has infinite bandwidth, which means that it is
not bandwidth controlled. The value should be in range <literal>[1000,
18446744073709551]</literal> or less than 0. A quota with value 0 means no
value. You can use this feature to ensure that all vCPUs run at the
same speed. For example:</para>
                    <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property quota:cpu_quota=10000 \
    --property quota:cpu_period=20000</screen>
                    <para>In this example, an instance of <literal>FLAVOR-NAME</literal> can only consume
a maximum of 50% CPU of a physical CPU computing capability.</para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>Memory limits</term>
              <listitem>
                <para>For VMware, you can configure the memory limits with control parameters.</para>
                <para>Use these optional parameters to limit the memory allocation,
guarantee minimum memory reservation, and to specify shares
used in case of resource contention:</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>memory_limit</literal>: Specifies the upper limit for VMware machine
memory allocation in MB. The utilization of a virtual machine will
not exceed this limit, even if there are available resources. This
is typically used to ensure a consistent performance of
virtual machines independent of available resources.</para>
                  </listitem>
                  <listitem>
                    <para><literal>memory_reservation</literal>: Specifies the guaranteed minimum memory
reservation in MB for VMware. This means the specified amount of
memory will definitely be allocated to the machine.</para>
                  </listitem>
                  <listitem>
                    <para><literal>memory_shares_level</literal>: On VMware, specifies the allocation level.
This can be <literal>custom</literal>, <literal>high</literal>, <literal>normal</literal> or <literal>low</literal>. If you choose
<literal>custom</literal>, set the number of shares using <literal>memory_shares_share</literal>.</para>
                  </listitem>
                  <listitem>
                    <para><literal>memory_shares_share</literal>: Specifies the number of shares allocated
in the event that <literal>custom</literal> is used. There is no unit for this
value. It is a relative measure based on the settings for other VMs.
For example:</para>
                    <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property quota:memory_shares_level=custom \
    --property quota:memory_shares_share=15</screen>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>Disk I/O limits</term>
              <listitem>
                <para>For VMware, you can configure the resource limits for disk
with control parameters.</para>
                <para>Use these optional parameters to limit the disk utilization,
guarantee disk allocation, and to specify shares
used in case of resource contention. This allows the VMware
driver to enable disk allocations for the running instance.</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>disk_io_limit</literal>: Specifies the upper limit for disk
utilization in I/O per second. The utilization of a
virtual machine will not exceed this limit, even
if there are available resources. The default value
is -1 which indicates unlimited usage.</para>
                  </listitem>
                  <listitem>
                    <para><literal>disk_io_reservation</literal>: Specifies the guaranteed minimum disk
allocation in terms of <xref linkend="term-input-output-operations-per-second-iops"/>.</para>
                  </listitem>
                  <listitem>
                    <para><literal>disk_io_shares_level</literal>: Specifies the allocation
level. This can be <literal>custom</literal>, <literal>high</literal>, <literal>normal</literal> or <literal>low</literal>.
If you choose custom, set the number of shares
using <literal>disk_io_shares_share</literal>.</para>
                  </listitem>
                  <listitem>
                    <para><literal>disk_io_shares_share</literal>: Specifies the number of shares
allocated in the event that <literal>custom</literal> is used.
When there is resource contention, this value is used
to determine the resource allocation.</para>
                    <para>The example below sets the <literal>disk_io_reservation</literal> to 2000 IOPS.</para>
                    <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property quota:disk_io_reservation=2000</screen>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>Disk tuning</term>
              <listitem>
                <para>Using disk I/O quotas, you can set maximum disk write to 10 MB per
second for a VM user. For example:</para>
                <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property quota:disk_write_bytes_sec=10485760</screen>
                <para>The disk I/O options are:</para>
                <itemizedlist>
                  <listitem>
                    <para>
                      <literal>disk_read_bytes_sec</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>disk_read_iops_sec</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>disk_write_bytes_sec</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>disk_write_iops_sec</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>disk_total_bytes_sec</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>disk_total_iops_sec</literal>
                    </para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>Bandwidth I/O</term>
              <listitem>
                <para>The vif I/O options are:</para>
                <itemizedlist>
                  <listitem>
                    <para>
                      <literal>vif_inbound_average</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>vif_inbound_burst</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>vif_inbound_peak</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>vif_outbound_average</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>vif_outbound_burst</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>vif_outbound_peak</literal>
                    </para>
                  </listitem>
                </itemizedlist>
                <para>Incoming and outgoing traffic can be shaped independently. The
bandwidth element can have at most, one inbound and at most, one
outbound child element. If you leave any of these child elements
out, no <xref linkend="term-quality-of-service-qos"/> is applied on that traffic
direction. So, if you want to shape only the network's incoming
traffic, use inbound only (and vice versa). Each element has one
mandatory attribute average, which specifies the average bit rate on
the interface being shaped.</para>
                <para>There are also two optional attributes (integer): <literal>peak</literal>, which
specifies the maximum rate at which a bridge can send data
(kilobytes/second), and <literal>burst</literal>, the amount of bytes that can be
burst at peak speed (kilobytes). The rate is shared equally within
domains connected to the network.</para>
                <para>The example below sets network traffic bandwidth limits for existing
flavor as follows:</para>
                <itemizedlist>
                  <listitem>
                    <para>Outbound traffic:</para>
                    <itemizedlist>
                      <listitem>
                        <para>average: 262 Mbps (32768 kilobytes/second)</para>
                      </listitem>
                      <listitem>
                        <para>peak: 524 Mbps (65536 kilobytes/second)</para>
                      </listitem>
                      <listitem>
                        <para>burst: 65536 kilobytes</para>
                      </listitem>
                    </itemizedlist>
                  </listitem>
                  <listitem>
                    <para>Inbound traffic:</para>
                    <itemizedlist>
                      <listitem>
                        <para>average: 262 Mbps (32768 kilobytes/second)</para>
                      </listitem>
                      <listitem>
                        <para>peak: 524 Mbps (65536 kilobytes/second)</para>
                      </listitem>
                      <listitem>
                        <para>burst: 65536 kilobytes</para>
                      </listitem>
                    </itemizedlist>
                  </listitem>
                </itemizedlist>
                <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property quota:vif_outbound_average=32768 \
    --property quota:vif_outbound_peak=65536 \
    --property quota:vif_outbound_burst=65536 \
    --property quota:vif_inbound_average=32768 \
    --property quota:vif_inbound_peak=65536 \
    --property quota:vif_inbound_burst=65536</screen>
                <note>
                  <para>All the speed limit values in above example are specified in
kilobytes/second. And burst values are in kilobytes. Values
were converted using 'Data rate units on
Wikipedia &lt;<link xlink:href="https://en.wikipedia.org/wiki/Data_rate_units">https://en.wikipedia.org/wiki/Data_rate_units</link>&gt;`_.</para>
                </note>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>Watchdog behavior</term>
              <listitem>
                <para>For the libvirt driver, you can enable and set the behavior of a
virtual hardware watchdog device for each flavor. Watchdog devices
keep an eye on the guest server, and carry out the configured
action, if the server hangs. The watchdog uses the i6300esb device
(emulating a PCI Intel 6300ESB). If <literal>hw:watchdog_action</literal> is not
specified, the watchdog is disabled.</para>
                <para>To set the behavior, use:</para>
                <screen language="console">$ openstack flavor set FLAVOR-NAME --property hw:watchdog_action=ACTION</screen>
                <para>Valid ACTION values are:</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>disabled</literal>: (default) The device is not attached.</para>
                  </listitem>
                  <listitem>
                    <para><literal>reset</literal>: Forcefully reset the guest.</para>
                  </listitem>
                  <listitem>
                    <para><literal>poweroff</literal>: Forcefully power off the guest.</para>
                  </listitem>
                  <listitem>
                    <para><literal>pause</literal>: Pause the guest.</para>
                  </listitem>
                  <listitem>
                    <para><literal>none</literal>: Only enable the watchdog; do nothing if the server hangs.</para>
                  </listitem>
                </itemizedlist>
                <note>
                  <para>Watchdog behavior set using a specific image's properties will
override behavior set using flavors.</para>
                </note>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>Random-number generator</term>
              <listitem>
                <para>If a random-number generator device has been added to the instance
through its image properties, the device can be enabled and
configured using:</para>
                <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property hw_rng:allowed=True \
    --property hw_rng:rate_bytes=RATE-BYTES \
    --property hw_rng:rate_period=RATE-PERIOD</screen>
                <para>Where:</para>
                <itemizedlist>
                  <listitem>
                    <para>RATE-BYTES: (integer) Allowed amount of bytes that the guest can
read from the host's entropy per period.</para>
                  </listitem>
                  <listitem>
                    <para>RATE-PERIOD: (integer) Duration of the read period in seconds.</para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>CPU topology</term>
              <listitem>
                <para>For the libvirt driver, you can define the topology of the processors
in the virtual machine using properties. The properties with <literal>max</literal>
limit the number that can be selected by the user with image properties.</para>
                <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property hw:cpu_sockets=FLAVOR-SOCKETS \
    --property hw:cpu_cores=FLAVOR-CORES \
    --property hw:cpu_threads=FLAVOR-THREADS \
    --property hw:cpu_max_sockets=FLAVOR-SOCKETS \
    --property hw:cpu_max_cores=FLAVOR-CORES \
    --property hw:cpu_max_threads=FLAVOR-THREADS</screen>
                <para>Where:</para>
                <itemizedlist>
                  <listitem>
                    <para>FLAVOR-SOCKETS: (integer) The number of sockets for the guest VM. By
default, this is set to the number of vCPUs requested.</para>
                  </listitem>
                  <listitem>
                    <para>FLAVOR-CORES: (integer) The number of cores per socket for the guest
VM. By default, this is set to <literal>1</literal>.</para>
                  </listitem>
                  <listitem>
                    <para>FLAVOR-THREADS: (integer) The number of threads per core for the guest
VM. By default, this is set to <literal>1</literal>.</para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>CPU pinning policy</term>
              <listitem>
                <para>For the libvirt driver, you can pin the virtual CPUs (vCPUs) of instances
to the host's physical CPU cores (pCPUs) using properties. You can further
refine this by stating how hardware CPU threads in a simultaneous
multithreading-based (SMT) architecture be used. These configurations will
result in improved per-instance determinism and performance.</para>
                <note>
                  <para>SMT-based architectures include Intel processors with Hyper-Threading
technology. In these architectures, processor cores share a number of
components with one or more other cores. Cores in such architectures
are commonly referred to as hardware threads, while the cores that a
given core share components with are known as thread siblings.</para>
                </note>
                <note>
                  <para>Host aggregates should be used to separate these pinned instances
from unpinned instances as the latter will not respect the resourcing
requirements of the former.</para>
                </note>
                <screen>$ openstack flavor set FLAVOR-NAME \
    --property hw:cpu_policy=CPU-POLICY \
    --property hw:cpu_thread_policy=CPU-THREAD-POLICY</screen>
                <para>Valid CPU-POLICY values are:</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>shared</literal>: (default) The guest vCPUs will be allowed to freely float
across host pCPUs, albeit potentially constrained by NUMA policy.</para>
                  </listitem>
                  <listitem>
                    <para><literal>dedicated</literal>: The guest vCPUs will be strictly pinned to a set of host
pCPUs. In the absence of an explicit vCPU topology request, the drivers
typically expose all vCPUs as sockets with one core and one thread.
When strict CPU pinning is in effect the guest CPU topology will be
setup to match the topology of the CPUs to which it is pinned. This
option implies an overcommit ratio of 1.0. For example, if a two vCPU
guest is pinned to a single host core with two threads, then the guest
will get a topology of one socket, one core, two threads.</para>
                  </listitem>
                </itemizedlist>
                <para>Valid CPU-THREAD-POLICY values are:</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>prefer</literal>: (default) The host may or may not have an SMT architecture.
Where an SMT architecture is present, thread siblings are preferred.</para>
                  </listitem>
                  <listitem>
                    <para><literal>isolate</literal>: The host must not have an SMT architecture or must emulate
a non-SMT architecture. If the host does not have an SMT architecture,
each vCPU is placed on a different core as expected. If the host does
have an SMT architecture - that is, one or more cores have thread
siblings - then each vCPU is placed on a different physical core. No
vCPUs from other guests are placed on the same core. All but one thread
sibling on each utilized core is therefore guaranteed to be unusable.</para>
                  </listitem>
                  <listitem>
                    <para><literal>require</literal>: The host must have an SMT architecture. Each vCPU is
allocated on thread siblings. If the host does not have an SMT
architecture, then it is not used. If the host has an SMT architecture,
but not enough cores with free thread siblings are available, then
scheduling fails.</para>
                  </listitem>
                </itemizedlist>
                <note>
                  <para>The <literal>hw:cpu_thread_policy</literal> option is only valid if <literal>hw:cpu_policy</literal>
is set to <literal>dedicated</literal>.</para>
                </note>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>NUMA topology</term>
              <listitem>
                <para>For the libvirt driver, you can define the host NUMA placement for the
instance vCPU threads as well as the allocation of instance vCPUs and
memory from the host NUMA nodes. For flavors whose memory and vCPU
allocations are larger than the size of NUMA nodes in the compute hosts,
the definition of a NUMA topology allows hosts to better utilize NUMA
and improve performance of the instance OS.</para>
                <screen language="console">$ openstack flavor set FLAVOR-NAME \
    --property hw:numa_nodes=FLAVOR-NODES \
    --property hw:numa_cpus.N=FLAVOR-CORES \
    --property hw:numa_mem.N=FLAVOR-MEMORY</screen>
                <para>Where:</para>
                <itemizedlist>
                  <listitem>
                    <para>FLAVOR-NODES: (integer) The number of host NUMA nodes to restrict
execution of instance vCPU threads to. If not specified, the vCPU
threads can run on any number of the host NUMA nodes available.</para>
                  </listitem>
                  <listitem>
                    <para>N: (integer) The instance NUMA node to apply a given CPU or memory
configuration to, where N is in the range <literal>0</literal> to <literal>FLAVOR-NODES</literal>
- <literal>1</literal>.</para>
                  </listitem>
                  <listitem>
                    <para>FLAVOR-CORES: (comma-separated list of integers) A list of instance
vCPUs to map to instance NUMA node N. If not specified, vCPUs are evenly
divided among available NUMA nodes.</para>
                  </listitem>
                  <listitem>
                    <para>FLAVOR-MEMORY: (integer) The number of MB of instance memory to map to
instance NUMA node N. If not specified, memory is evenly divided
among available NUMA nodes.</para>
                  </listitem>
                </itemizedlist>
                <note>
                  <para><literal>hw:numa_cpus.N</literal> and <literal>hw:numa_mem.N</literal> are only valid if
<literal>hw:numa_nodes</literal> is set. Additionally, they are only required if the
instance's NUMA nodes have an asymmetrical allocation of CPUs and RAM
(important for some NFV workloads).</para>
                </note>
                <note>
                  <para>The <literal>N</literal> parameter is an index of <emphasis>guest</emphasis> NUMA nodes and may not
correspond to <emphasis>host</emphasis> NUMA nodes. For example, on a platform with two
NUMA nodes, the scheduler may opt to place guest NUMA node 0, as
referenced in <literal>hw:numa_mem.0</literal> on host NUMA node 1 and vice versa.
Similarly, the integers used for <literal>FLAVOR-CORES</literal> are indexes of
<emphasis>guest</emphasis> vCPUs and may not correspond to <emphasis>host</emphasis> CPUs. As such, this
feature cannot be used to constrain instances to specific host CPUs or
NUMA nodes.</para>
                </note>
                <warning>
                  <para>If the combined values of <literal>hw:numa_cpus.N</literal> or <literal>hw:numa_mem.N</literal>
are greater than the available number of CPUs or memory respectively,
an exception is raised.</para>
                </warning>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>Large pages allocation</term>
              <listitem>
                <para>You can configure the size of large pages used to back the VMs.</para>
                <screen>$ openstack flavor set FLAVOR-NAME \
    --property hw:mem_page_size=PAGE_SIZE</screen>
                <para>Valid <literal>PAGE_SIZE</literal> values are:</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>small</literal>: (default) The smallest page size is used.
Example: 4 KB on x86.</para>
                  </listitem>
                  <listitem>
                    <para><literal>large</literal>: Only use larger page sizes for guest RAM.
Example: either 2 MB or 1 GB on x86.</para>
                  </listitem>
                  <listitem>
                    <para><literal>any</literal>: It is left up to the compute driver to decide. In this case,
the libvirt driver might try to find large pages, but fall back to small
pages. Other drivers may choose alternate policies for <literal>any</literal>.</para>
                  </listitem>
                  <listitem>
                    <para>pagesize: (string) An explicit page size can be set if the workload has
specific requirements. This value can be an integer value for the page
size in KB, or can use any standard suffix.
Example: <literal>4KB</literal>, <literal>2MB</literal>, <literal>2048</literal>, <literal>1GB</literal>.</para>
                  </listitem>
                </itemizedlist>
                <note>
                  <para>Large pages can be enabled for guest RAM without any regard to whether
the guest OS will use them or not. If the guest OS chooses not to
use huge pages, it will merely see small pages as before. Conversely,
if a guest OS does intend to use huge pages, it is very important that
the guest RAM be backed by huge pages. Otherwise, the guest OS will not
be getting the performance benefit it is expecting.</para>
                </note>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>PCI passthrough</term>
              <listitem>
                <para>You can assign PCI devices to a guest by specifying them in the flavor.</para>
                <screen>$ openstack flavor set FLAVOR-NAME \
    --property pci_passthrough:alias=ALIAS:COUNT</screen>
                <para>Where:</para>
                <itemizedlist>
                  <listitem>
                    <para>ALIAS: (string) The alias which correspond to a particular PCI device
class as configured in the nova configuration file (see <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/config-options.html">nova.conf
configuration options</link>).</para>
                  </listitem>
                  <listitem>
                    <para>COUNT: (integer) The amount of PCI devices of type ALIAS to be assigned
to a guest.</para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
           </variablelist>
        </sect3>
      </sect2>
      <sect2>
        <title>Compute service node firewall requirements</title>
        <para>Console connections for virtual machines, whether direct or through a
proxy, are received on ports <literal>5900</literal> to <literal>5999</literal>. The firewall on each
Compute service node must allow network traffic on these ports.</para>
        <para>This procedure modifies the iptables firewall to allow incoming
connections to the Compute services.</para>
        <para>
          <emphasis role="bold">Configuring the service-node firewall</emphasis>
        </para>
        <procedure>
          <step>
            <para>Log in to the server that hosts the Compute service, as root.</para>
          </step>
          <step>
            <para>Edit the <literal>/etc/sysconfig/iptables</literal> file, to add an INPUT rule that
allows TCP traffic on ports from <literal>5900</literal> to <literal>5999</literal>. Make sure the new
rule appears before any INPUT rules that REJECT traffic:</para>
            <screen language="console">-A INPUT -p tcp -m multiport --dports 5900:5999 -j ACCEPT</screen>
          </step>
          <step>
            <para>Save the changes to the <literal>/etc/sysconfig/iptables</literal> file, and restart the
<literal>iptables</literal> service to pick up the changes:</para>
            <screen language="console">$ service iptables restart</screen>
          </step>
          <step>
            <para>Repeat this process for each Compute service node.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Injecting the administrator password</title>
        <para>Compute can generate a random administrator (root) password and inject
that password into an instance. If this feature is enabled, users can
run <command>ssh</command> to an instance without an <command>ssh</command> keypair.
The random password appears in the output of the
<command>openstack server create</command> command.
You can also view and set the admin password from the dashboard.</para>
        <para>
          <emphasis role="bold">Password injection using the dashboard</emphasis>
        </para>
        <para>By default, the dashboard will display the <literal>admin</literal> password and allow
the user to modify it.</para>
        <para>If you do not want to support password injection, disable the password
fields by editing the dashboard's <literal>local_settings.py</literal> file.</para>
        <screen language="none">OPENSTACK_HYPERVISOR_FEATURES = {
...
    'can_set_password': False,
}</screen>
        <para>
          <emphasis role="bold">Password injection on libvirt-based hypervisors</emphasis>
        </para>
        <para>For hypervisors that use the libvirt back end (such as KVM, QEMU, and
LXC), admin password injection is disabled by default. To enable it, set
this option in <literal>/etc/nova/nova.conf</literal>:</para>
        <screen language="ini">[libvirt]
inject_password=true</screen>
        <para>When enabled, Compute will modify the password of the admin account by
editing the <literal>/etc/shadow</literal> file inside the virtual machine instance.</para>
        <note>
          <para>Users can only use <command>ssh</command> to access the instance by using the admin
password if the virtual machine image is a Linux distribution, and it has
been configured to allow users to use <command>ssh</command> as the root user. This
is not the case for <link xlink:href="http://uec-images.ubuntu.com">Ubuntu cloud images</link>
which, by default, does not allow users to use <command>ssh</command> to access the
root account.</para>
        </note>
        <para>
          <emphasis role="bold">Password injection and XenAPI (XenServer/XCP)</emphasis>
        </para>
        <para>When using the XenAPI hypervisor back end, Compute uses the XenAPI agent
to inject passwords into guests. The virtual machine image must be
configured with the agent for password injection to work.</para>
        <para>
          <emphasis role="bold">Password injection and Windows images (all hypervisors)</emphasis>
        </para>
        <para>For Windows virtual machines, configure the Windows image to retrieve
the admin password on boot by installing an agent such as
<link xlink:href="https://cloudbase.it/cloudbase-init">cloudbase-init</link>.</para>
      </sect2>
      <sect2>
        <title>Manage the cloud</title>
        <para>System administrators can use the <command>openstack</command> and
          <command>euca2ools</command> commands to manage their clouds.</para>
        <para>The <literal>openstack</literal> client and <literal>euca2ools</literal> can be used by all users, though
          specific commands might be restricted by the Identity service.</para>
        <para>
          <emphasis role="bold">Managing the cloud with the openstack client</emphasis>
        </para>
        <procedure>
          <step>
            <para>The <literal>python-openstackclient</literal> package provides an <literal>openstack</literal> shell that
              enables Compute API interactions from the command line. Install the client,
              and provide your user name and password (which can be set as environment
              variables for convenience), for the ability to administer the cloud from
              the command line.</para>
            <para>To install python-openstackclient, follow the instructions in the
              <link xlink:href="http://docs.openstack.org/user-guide/common/cli-install-openstack-command-line-clients.html">OpenStack User Guide</link>.</para>
          </step>
          <step>
            <para>Confirm the installation was successful:</para>
            <screen language="console">$ openstack help
              usage: openstack [--version] [-v | -q] [--log-file LOG_FILE] [-h] [--debug]
              [--os-cloud &lt;cloud-config-name&gt;]
              [--os-region-name &lt;auth-region-name&gt;]
              [--os-cacert &lt;ca-bundle-file&gt;] [--verify | --insecure]
              [--os-default-domain &lt;auth-domain&gt;]
              ...</screen>
            <para>Running <command>openstack help</command> returns a list of <literal>openstack</literal> commands
              and parameters. To get help for a subcommand, run:</para>
            <screen language="console">$ openstack help SUBCOMMAND</screen>
            <para>For a complete list of <literal>openstack</literal> commands and parameters, see the
              <link xlink:href="http://docs.openstack.org/cli-reference/openstack.html">OpenStack Command-Line Reference</link>.</para>
          </step>
          <step>
            <para>Set the required parameters as environment variables to make running
              commands easier. For example, you can add <literal>--os-username</literal> as an
              <literal>openstack</literal> option, or set it as an environment variable. To set the user
              name, password, and project as environment variables, use:</para>
            <screen language="console">$ export OS_USERNAME=joecool
              $ export OS_PASSWORD=coolword
              $ export OS_TENANT_NAME=coolu</screen>
          </step>
          <step>
            <para>The Identity service gives you an authentication endpoint,
              which Compute recognizes as <literal>OS_AUTH_URL</literal>:</para>
            <screen language="console">$ export OS_AUTH_URL=http://hostname:5000/v2.0</screen>
          </step>
        </procedure>
        <sect3>
          <title>Managing the cloud with euca2ools</title>
          <para>The <literal>euca2ools</literal> command-line tool provides a command line interface to
EC2 API calls. For more information, see the <link xlink:href="http://docs.hpcloud.com/eucalyptus/">Official Eucalyptus Documentation</link>.</para>
        </sect3>
        <sect3>
          <title>Show usage statistics for hosts and instances</title>
          <para>You can show basic statistics on resource usage for hosts and instances.</para>
          <note>
            <para>For more sophisticated monitoring, see the
<link xlink:href="https://launchpad.net/ceilometer">ceilometer</link> project. You can
also use tools, such as <link xlink:href="http://ganglia.info/">Ganglia</link> or
<link xlink:href="http://graphite.wikidot.com/">Graphite</link>, to gather more detailed
data.</para>
          </note>
          <sect4>
            <title>Show host usage statistics</title>
            <para>The following examples show the host usage statistics for a host called
<literal>devstack</literal>.</para>
            <itemizedlist>
              <listitem>
                <para>List the hosts and the nova-related services that run on them:</para>
                <screen language="console">$ openstack host list
+-----------+-------------+----------+
| Host Name | Service     | Zone     |
+-----------+-------------+----------+
| devstack  | conductor   | internal |
| devstack  | compute     | nova     |
| devstack  | cert        | internal |
| devstack  | network     | internal |
| devstack  | scheduler   | internal |
| devstack  | consoleauth | internal |
+-----------+-------------+----------+</screen>
              </listitem>
              <listitem>
                <para>Get a summary of resource usage of all of the instances running on
the host:</para>
                <screen language="console">$ openstack host show devstack
+----------+----------------------------------+-----+-----------+---------+
| Host     | Project                          | CPU | MEMORY MB | DISK GB |
+----------+----------------------------------+-----+-----------+---------+
| devstack | (total)                          | 2   | 4003      | 157     |
| devstack | (used_now)                       | 3   | 5120      | 40      |
| devstack | (used_max)                       | 3   | 4608      | 40      |
| devstack | b70d90d65e464582b6b2161cf3603ced | 1   | 512       | 0       |
| devstack | 66265572db174a7aa66eba661f58eb9e | 2   | 4096      | 40      |
+----------+----------------------------------+-----+-----------+---------+</screen>
                <para>The <literal>CPU</literal> column shows the sum of the virtual CPUs for instances
running on the host.</para>
                <para>The <literal>MEMORY MB</literal> column shows the sum of the memory (in MB)
allocated to the instances that run on the host.</para>
                <para>The <literal>DISK GB</literal> column shows the sum of the root and ephemeral disk
sizes (in GB) of the instances that run on the host.</para>
                <para>The row that has the value <literal>used_now</literal> in the <literal>PROJECT</literal> column
shows the sum of the resources allocated to the instances that run on
the host, plus the resources allocated to the virtual machine of the
host itself.</para>
                <para>The row that has the value <literal>used_max</literal> in the <literal>PROJECT</literal> column
shows the sum of the resources allocated to the instances that run on
the host.</para>
                <note>
                  <para>These values are computed by using information about the flavors of
the instances that run on the hosts. This command does not query the
CPU usage, memory usage, or hard disk usage of the physical host.</para>
                </note>
              </listitem>
            </itemizedlist>
          </sect4>
          <sect4>
            <title>Show instance usage statistics</title>
            <itemizedlist>
              <listitem>
                <para>Get CPU, memory, I/O, and network statistics for an instance.</para>
                <procedure>
                  <step>
                    <para>List instances:</para>
                    <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack server list
+----------+----------------------+--------+------------+-------------+------------------+------------+
| ID       | Name                 | Status | Task State | Power State | Networks         | Image Name |
+----------+----------------------+--------+------------+-------------+------------------+------------+
| 84c6e... | myCirrosServer       | ACTIVE | None       | Running     | private=10.0.0.3 | cirros     |
| 8a995... | myInstanceFromVolume | ACTIVE | None       | Running     | private=10.0.0.4 | ubuntu     |
+----------+----------------------+--------+------------+-------------+------------------+------------+</screen>
                  </step>
                  <step>
                    <para>Get diagnostic statistics:</para>
                    <screen language="console">$ nova diagnostics myCirrosServer
+---------------------------+--------+
| Property                  | Value  |
+---------------------------+--------+
| memory                    | 524288 |
| memory-actual             | 524288 |
| memory-rss                | 6444   |
| tap1fec8fb8-7a_rx         | 22137  |
| tap1fec8fb8-7a_rx_drop    | 0      |
| tap1fec8fb8-7a_rx_errors  | 0      |
| tap1fec8fb8-7a_rx_packets | 166    |
| tap1fec8fb8-7a_tx         | 18032  |
| tap1fec8fb8-7a_tx_drop    | 0      |
| tap1fec8fb8-7a_tx_errors  | 0      |
| tap1fec8fb8-7a_tx_packets | 130    |
| vda_errors                | -1     |
| vda_read                  | 2048   |
| vda_read_req              | 2      |
| vda_write                 | 182272 |
| vda_write_req             | 74     |
+---------------------------+--------+</screen>
                  </step>
                </procedure>
              </listitem>
              <listitem>
                <para>Get summary statistics for each tenant:</para>
                <screen language="console">$ openstack usage list
Usage from 2013-06-25 to 2013-07-24:
+---------+---------+--------------+-----------+---------------+
| Project | Servers | RAM MB-Hours | CPU Hours | Disk GB-Hours |
+---------+---------+--------------+-----------+---------------+
| demo    | 1       | 344064.44    | 672.00    | 0.00          |
| stack   | 3       | 671626.76    | 327.94    | 6558.86       |
+---------+---------+--------------+-----------+---------------+</screen>
              </listitem>
            </itemizedlist>
          </sect4>
        </sect3>
      </sect2>
      <sect2>
        <title>Logging</title>
        <sect3>
          <title>Logging module</title>
          <para>Logging behavior can be changed by creating a configuration file. To
specify the configuration file, add this line to the
<literal>/etc/nova/nova.conf</literal> file:</para>
          <screen language="ini">log-config=/etc/nova/logging.conf</screen>
          <para>To change the logging level, add <literal>DEBUG</literal>, <literal>INFO</literal>, <literal>WARNING</literal>, or
<literal>ERROR</literal> as a parameter.</para>
          <para>The logging configuration file is an INI-style configuration file, which
must contain a section called <literal>logger_nova</literal>. This controls the
behavior of the logging facility in the <literal>nova-*</literal> services. For
example:</para>
          <screen language="ini">[logger_nova]
level = INFO
handlers = stderr
qualname = nova</screen>
          <para>This example sets the debugging level to <literal>INFO</literal> (which is less verbose
than the default <literal>DEBUG</literal> setting).</para>
          <para>For more about the logging configuration syntax, including the
<literal>handlers</literal> and <literal>quaname</literal> variables, see the
<link xlink:href="http://docs.python.org/release/2.7/library/logging.html#configuration-file-format">Python documentation</link>
on logging configuration files.</para>
          <para>For an example of the <literal>logging.conf</literal> file with various defined handlers, see
the <link xlink:href="http://docs.openstack.org/newton/config-reference/">OpenStack Configuration Reference</link>.</para>
        </sect3>
        <sect3>
          <title>Syslog</title>
          <para>OpenStack Compute services can send logging information to syslog. This
is useful if you want to use rsyslog to forward logs to a remote
machine. Separately configure the Compute service (nova), the Identity
service (keystone), the Image service (glance), and, if you are using
it, the Block Storage service (cinder) to send log messages to syslog.
Open these configuration files:</para>
          <itemizedlist>
            <listitem>
              <para>
                <literal>/etc/nova/nova.conf</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>/etc/keystone/keystone.conf</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>/etc/glance/glance-api.conf</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>/etc/glance/glance-registry.conf</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>/etc/cinder/cinder.conf</literal>
              </para>
            </listitem>
          </itemizedlist>
          <para>In each configuration file, add these lines:</para>
          <screen language="ini">debug = False
use_syslog = True
syslog_log_facility = LOG_LOCAL0</screen>
          <para>In addition to enabling syslog, these settings also turn off debugging output
from the log.</para>
          <note>
            <para>Although this example uses the same local facility for each service
(<literal>LOG_LOCAL0</literal>, which corresponds to syslog facility <literal>LOCAL0</literal>),
we recommend that you configure a separate local facility for each
service, as this provides better isolation and more flexibility. For
example, you can capture logging information at different severity
levels for different services. syslog allows you to define up to
eight local facilities, <literal>LOCAL0, LOCAL1, ..., LOCAL7</literal>. For more
information, see the syslog documentation.</para>
          </note>
        </sect3>
        <sect3>
          <title>Rsyslog</title>
          <para>rsyslog is useful for setting up a centralized log server across
multiple machines. This section briefly describe the configuration to
set up an rsyslog server. A full treatment of rsyslog is beyond the
scope of this book. This section assumes rsyslog has already been
installed on your hosts (it is installed by default on most Linux
distributions).</para>
          <para>This example provides a minimal configuration for <literal>/etc/rsyslog.conf</literal>
on the log server host, which receives the log files</para>
          <screen language="console"># provides TCP syslog reception
$ModLoad imtcp
$InputTCPServerRun 1024</screen>
          <para>Add a filter rule to <literal>/etc/rsyslog.conf</literal> which looks for a host name.
This example uses COMPUTE_01 as the compute host name:</para>
          <screen language="ini">:hostname, isequal, "COMPUTE_01" /mnt/rsyslog/logs/compute-01.log</screen>
          <para>On each compute host, create a file named
<literal>/etc/rsyslog.d/60-nova.conf</literal>, with the following content:</para>
          <screen language="console"># prevent debug from dnsmasq with the daemon.none parameter
*.*;auth,authpriv.none,daemon.none,local0.none -/var/log/syslog
# Specify a log level of ERROR
local0.error    @@172.20.1.43:1024</screen>
          <para>Once you have created the file, restart the <literal>rsyslog</literal> service. Error-level
log messages on the compute hosts should now be sent to the log server.</para>
        </sect3>
        <sect3>
          <title>Serial console</title>
          <para>The serial console provides a way to examine kernel output and other
system messages during troubleshooting if the instance lacks network
connectivity.</para>
          <para>Read-only access from server serial console is possible
using the <literal>os-GetSerialOutput</literal> server action. Most
cloud images enable this feature by default. For more information, see
<xref linkend="compute-common-errors-and-fixes"/>.</para>
          <para>OpenStack Juno and later supports read-write access using the serial
console using the <literal>os-GetSerialConsole</literal> server action. This feature
also requires a websocket client to access the serial console.</para>
          <para>
            <emphasis role="bold">Configuring read-write serial console access</emphasis>
          </para>
          <procedure>
            <step>
              <para>On a compute node, edit the <literal>/etc/nova/nova.conf</literal> file:</para>
              <para>In the <literal>[serial_console]</literal> section, enable the serial console:</para>
              <screen language="ini">[serial_console]
...
enabled = true</screen>
            </step>
            <step>
              <para>In the <literal>[serial_console]</literal> section, configure the serial console proxy
similar to graphical console proxies:</para>
              <screen language="ini">[serial_console]
...
base_url = ws://controller:6083/
listen = 0.0.0.0
proxyclient_address = MANAGEMENT_INTERFACE_IP_ADDRESS</screen>
              <para>The <literal>base_url</literal> option specifies the base URL that clients receive from
the API upon requesting a serial console. Typically, this refers to the
host name of the controller node.</para>
              <para>The <literal>listen</literal> option specifies the network interface nova-compute
should listen on for virtual console connections. Typically, 0.0.0.0
will enable listening on all interfaces.</para>
              <para>The <literal>proxyclient_address</literal> option specifies which network interface the
proxy should connect to. Typically, this refers to the IP address of the
management interface.</para>
              <para>When you enable read-write serial console access, Compute will add
serial console information to the Libvirt XML file for the instance. For
example:</para>
              <screen language="xml">&lt;console type='tcp'&gt;
  &lt;source mode='bind' host='127.0.0.1' service='10000'/&gt;
  &lt;protocol type='raw'/&gt;
  &lt;target type='serial' port='0'/&gt;
  &lt;alias name='serial0'/&gt;
&lt;/console&gt;</screen>
            </step>
          </procedure>
          <para>
            <emphasis role="bold">Accessing the serial console on an instance</emphasis>
          </para>
          <procedure>
            <step>
              <para>Use the <command>nova get-serial-proxy</command> command to retrieve the websocket
URL for the serial console on the instance:</para>
              <screen language="console">$ nova get-serial-proxy INSTANCE_NAME</screen>
              <informaltable>
                <tgroup cols="2">
                  <colspec colname="c1" colwidth="12.2*"/>
                  <colspec colname="c2" colwidth="87.8*"/>
                  <tbody>
                    <row>
                      <entry>
                        <para>Type</para>
                      </entry>
                      <entry>
                        <para>Url</para>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>serial</para>
                      </entry>
                      <entry>
                        <para>ws://127.0.0.1:6083/?token=18510769-71ad-4e5a-8348-4218b5613b3d</para>
                      </entry>
                    </row>
                  </tbody>
                </tgroup>
              </informaltable>
              <para>Alternatively, use the API directly:</para>
              <screen language="console">$ curl -i 'http://&lt;controller&gt;:8774/v2.1/&lt;tenant_uuid&gt;/servers/
  &lt;instance_uuid&gt;/action' \
  -X POST \
  -H "Accept: application/json" \
  -H "Content-Type: application/json" \
  -H "X-Auth-Project-Id: &lt;project_id&gt;" \
  -H "X-Auth-Token: &lt;auth_token&gt;" \
  -d '{"os-getSerialConsole": {"type": "serial"}}'</screen>
            </step>
            <step>
              <para>Use Python websocket with the URL to generate <literal>.send</literal>, <literal>.recv</literal>, and
<literal>.fileno</literal> methods for serial console access. For example:</para>
              <screen language="python">import websocket
ws = websocket.create_connection(
    'ws://127.0.0.1:6083/?token=18510769-71ad-4e5a-8348-4218b5613b3d',
    subprotocols=['binary', 'base64'])</screen>
            </step>
          </procedure>
          <para>Alternatively, use a <link xlink:href="https://github.com/larsks/novaconsole/">Python websocket client</link>.</para>
          <note>
            <para>When you enable the serial console, typical instance logging using
the <command>nova console-log</command> command is disabled. Kernel output
and other system messages will not be visible unless you are
actively viewing the serial console.</para>
          </note>
        </sect3>
      </sect2>
      <sect2>
        <title>Secure with rootwrap</title>
        <para>Rootwrap allows unprivileged users to safely run Compute actions as the
root user. Compute previously used <command>sudo</command> for this purpose, but this
was difficult to maintain, and did not allow advanced filters. The
<command>rootwrap</command> command replaces <command>sudo</command> for Compute.</para>
        <para>To use rootwrap, prefix the Compute command with <command>nova-rootwrap</command>. For
example:</para>
        <screen language="console">$ sudo nova-rootwrap /etc/nova/rootwrap.conf command</screen>
        <para>A generic <literal>sudoers</literal> entry lets the Compute user run <command>nova-rootwrap</command>
as root. The <command>nova-rootwrap</command> code looks for filter definition
directories in its configuration file, and loads command filters from
them. It then checks if the command requested by Compute matches one of
those filters and, if so, executes the command (as root). If no filter
matches, it denies the request.</para>
        <note>
          <para>Be aware of issues with using NFS and root-owned files. The NFS
share must be configured with the <literal>no_root_squash</literal> option enabled,
in order for rootwrap to work correctly.</para>
        </note>
        <para>Rootwrap is fully controlled by the root user. The root user
owns the sudoers entry which allows Compute to run a specific
rootwrap executable as root, and only with a specific
configuration file (which should also be owned by root).
The <command>nova-rootwrap</command> command imports the Python
modules it needs from a cleaned, system-default PYTHONPATH.
The root-owned configuration file points to root-owned
filter definition directories, which contain root-owned
filters definition files. This chain ensures that the Compute
user itself is not in control of the configuration or modules
used by the <command>nova-rootwrap</command> executable.</para>
        <sect3>
          <title>Configure rootwrap</title>
          <para>Configure rootwrap in the <literal>rootwrap.conf</literal> file. Because
it is in the trusted security path, it must be owned and writable
by only the root user. The <literal>rootwrap_config=entry</literal> parameter
specifies the file's location in the sudoers entry and in the
<literal>nova.conf</literal> configuration file.</para>
          <para>The <literal>rootwrap.conf</literal> file uses an INI file format with these
sections and parameters:</para>
          <table>
            <title>rootwrap.conf configuration options</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="67.4*"/>
              <colspec colname="c2" colwidth="32.6*"/>
              <tbody>
                <row>
                  <entry>
                    <para>Configuration option=Default value</para>
                  </entry>
                  <entry>
                    <para>(Type) Description</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[DEFAULT]
filters_path=/etc/nova/rootwrap.d,/usr/share/nova/rootwrap</para>
                  </entry>
                  <entry>
                    <para>(ListOpt) Comma-separated list of directories
containing filter definition files.
Defines where rootwrap filters are stored.
Directories defined on this line should all
exist, and be owned and writable only by the
root user.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
          <para>If the root wrapper is not performing correctly, you can add a
workaround option into the <literal>nova.conf</literal> configuration file. This
workaround re-configures the root wrapper configuration to fall back to
running commands as <literal>sudo</literal>, and is a Kilo release feature.</para>
          <para>Including this workaround in your configuration file safeguards your
environment from issues that can impair root wrapper performance. Tool
changes that have impacted
<link xlink:href="https://git.openstack.org/cgit/openstack-dev/pbr/">Python Build Reasonableness (PBR)</link>
for example, are a known issue that affects root wrapper performance.</para>
          <para>To set up this workaround, configure the <literal>disable_rootwrap</literal> option in
the <literal>[workaround]</literal> section of the <literal>nova.conf</literal> configuration file.</para>
          <para>The filters definition files contain lists of filters that rootwrap will
use to allow or deny a specific command. They are generally suffixed by
<literal>.filters</literal>. Since they are in the trusted security path, they need to
be owned and writable only by the root user. Their location is specified
in the <literal>rootwrap.conf</literal> file.</para>
          <para>Filter definition files use an INI file format with a <literal>[Filters]</literal>
section and several lines, each with a unique parameter name, which
should be different for each filter you define:</para>
          <table>
            <title>Filters configuration options</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="64.9*"/>
              <colspec colname="c2" colwidth="35.1*"/>
              <tbody>
                <row>
                  <entry>
                    <para>Configuration option=Default value</para>
                  </entry>
                  <entry>
                    <para>(Type) Description</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[Filters]
filter_name=kpartx: CommandFilter, /sbin/kpartx, root</para>
                  </entry>
                  <entry>
                    <para>(ListOpt) Comma-separated list containing the filter class to
use, followed by the Filter arguments (which vary depending
on the Filter class selected).</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
        </sect3>
        <sect3>
          <title>Configure the rootwrap daemon</title>
          <para>Administrators can use rootwrap daemon support instead of running
rootwrap with <command>sudo</command>. The rootwrap daemon reduces the
overhead and performance loss that results from running
<literal>oslo.rootwrap</literal> with <command>sudo</command>. Each call that needs rootwrap
privileges requires a new instance of rootwrap. The daemon
prevents overhead from the repeated calls. The daemon does not support
long running processes, however.</para>
          <para>To enable the rootwrap daemon, set <literal>use_rootwrap_daemon</literal> to <literal>True</literal>
in the Compute service configuration file.</para>
        </sect3>
      </sect2>
      <sect2 xml:id="section-configuring-compute-migrations">
        <title>Configure migrations</title>
        <note>
          <para>Only administrators can perform live migrations. If your cloud
is configured to use cells, you can perform live migration within
but not between cells.</para>
        </note>
        <para>Migration enables an administrator to move a virtual-machine instance
from one compute host to another. This feature is useful when a compute
host requires maintenance. Migration can also be useful to redistribute
the load when many VM instances are running on a specific physical
machine.</para>
        <para>The migration types are:</para>
        <itemizedlist>
          <listitem>
            <para><emphasis role="bold">Non-live migration</emphasis> (sometimes referred to simply as 'migration').
The instance is shut down for a period of time to be moved to another
hypervisor. In this case, the instance recognizes that it was
rebooted.</para>
          </listitem>
          <listitem>
            <para><emphasis role="bold">Live migration</emphasis> (or 'true live migration'). Almost no instance
downtime. Useful when the instances must be kept running during the
migration. The different types of live migration are:</para>
            <itemizedlist>
              <listitem>
                <para><emphasis role="bold">Shared storage-based live migration</emphasis>. Both hypervisors have
access to shared storage.</para>
              </listitem>
              <listitem>
                <para><emphasis role="bold">Block live migration</emphasis>. No shared storage is required.
Incompatible with read-only devices such as CD-ROMs and
<link xlink:href="http://docs.openstack.org/user-guide/cli-config-drive.html">Configuration Drive (config_drive)</link>.</para>
              </listitem>
              <listitem>
                <para><emphasis role="bold">Volume-backed live migration</emphasis>. Instances are backed by volumes
rather than ephemeral disk, no shared storage is required, and
migration is supported (currently only available for libvirt-based
hypervisors).</para>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
        <para>The following sections describe how to configure your hosts and compute
nodes for migrations by using the KVM and XenServer hypervisors.</para>
        <sect3>
          <title>KVM-Libvirt</title>
          <sect4 xml:id="configuring-migrations-kvm-shared-storage">
            <title>Shared storage</title>
            <para>
              <emphasis role="bold">Prerequisites</emphasis>
            </para>
            <itemizedlist>
              <listitem>
                <para><emphasis role="bold">Hypervisor:</emphasis> KVM with libvirt</para>
              </listitem>
              <listitem>
                <para><emphasis role="bold">Shared storage:</emphasis><literal>NOVA-INST-DIR/instances/</literal> (for example,
<literal>/var/lib/nova/instances</literal>) has to be mounted by shared storage.
This guide uses NFS but other options, including the
<link xlink:href="http://gluster.org/community/documentation//index.php/OSConnect">OpenStack Gluster Connector</link>
are available.</para>
              </listitem>
              <listitem>
                <para><emphasis role="bold">Instances:</emphasis> Instance can be migrated with iSCSI-based volumes.</para>
              </listitem>
            </itemizedlist>
            <para>
              <emphasis role="bold">Notes</emphasis>
            </para>
            <itemizedlist>
              <listitem>
                <para>Because the Compute service does not use the libvirt live
migration functionality by default, guests are suspended before
migration and might experience several minutes of downtime. For
details, see <literal>Enabling true live migration</literal>.</para>
              </listitem>
              <listitem>
                <para>Compute calculates the amount of downtime required using the RAM size of
the disk being migrated, in accordance with the <literal>live_migration_downtime</literal>
configuration parameters. Migration downtime is measured in steps, with an
exponential backoff between each step. This means that the maximum
downtime between each step starts off small, and is increased in ever
larger amounts as Compute waits for the migration to complete. This gives
the guest a chance to complete the migration successfully, with a minimum
amount of downtime.</para>
              </listitem>
              <listitem>
                <para>This guide assumes the default value for <literal>instances_path</literal> in
your <literal>nova.conf</literal> file (<literal>NOVA-INST-DIR/instances</literal>). If you
have changed the <literal>state_path</literal> or <literal>instances_path</literal> variables,
modify the commands accordingly.</para>
              </listitem>
              <listitem>
                <para>You must specify <literal>vncserver_listen=0.0.0.0</literal> or live migration
will not work correctly.</para>
              </listitem>
              <listitem>
                <para>You must specify the <literal>instances_path</literal> in each node that runs
<literal>nova-compute</literal>. The mount point for <literal>instances_path</literal> must be the
same value for each node, or live migration will not work
correctly.</para>
              </listitem>
            </itemizedlist>
          </sect4>
          <sect4>
            <title>Example Compute installation environment</title>
            <itemizedlist>
              <listitem>
                <para>Prepare at least three servers. In this example, we refer to the
servers as <literal>HostA</literal>, <literal>HostB</literal>, and <literal>HostC</literal>:</para>
                <itemizedlist>
                  <listitem>
                    <para><literal>HostA</literal> is the Cloud Controller, and should run these services:
<literal>nova-api</literal>, <literal>nova-scheduler</literal>, <literal>nova-network</literal>, <literal>cinder-volume</literal>,
and <literal>nova-objectstore</literal>.</para>
                  </listitem>
                  <listitem>
                    <para><literal>HostB</literal> and <literal>HostC</literal> are the compute nodes that run
<literal>nova-compute</literal>.</para>
                  </listitem>
                </itemizedlist>
                <para>Ensure that <literal>NOVA-INST-DIR</literal> (set with <literal>state_path</literal> in the
<literal>nova.conf</literal> file) is the same on all hosts.</para>
              </listitem>
              <listitem>
                <para>In this example, <literal>HostA</literal> is the NFSv4 server that exports
<literal>NOVA-INST-DIR/instances</literal> directory. <literal>HostB</literal> and <literal>HostC</literal> are
NFSv4 clients that mount <literal>HostA</literal>.</para>
              </listitem>
            </itemizedlist>
            <para>
              <emphasis role="bold">Configuring your system</emphasis>
            </para>
            <procedure>
              <step>
                <para>Configure your DNS or <literal>/etc/hosts</literal> and ensure it is consistent across
all hosts. Make sure that the three hosts can perform name resolution
with each other. As a test, use the <command>ping</command> command to ping each host
from one another:</para>
                <screen language="console">$ ping HostA
$ ping HostB
$ ping HostC</screen>
              </step>
              <step>
                <para>Ensure that the UID and GID of your Compute and libvirt users are
identical between each of your servers. This ensures that the
permissions on the NFS mount works correctly.</para>
              </step>
              <step>
                <para>Ensure you can access SSH without a password and without
StrictHostKeyChecking between <literal>HostB</literal> and <literal>HostC</literal> as <literal>nova</literal>
user (set with the owner of <literal>nova-compute</literal> service). Direct access
from one compute host to another is needed to copy the VM file
across. It is also needed to detect if the source and target
compute nodes share a storage subsystem.</para>
              </step>
              <step>
                <para>Export <literal>NOVA-INST-DIR/instances</literal> from <literal>HostA</literal>, and ensure it is
readable and writable by the Compute user on <literal>HostB</literal> and <literal>HostC</literal>.</para>
                <para>For more information, see: <link xlink:href="https://help.ubuntu.com/community/SettingUpNFSHowTo">SettingUpNFSHowTo</link>
or <link xlink:href="http://www.cyberciti.biz/faq/centos-fedora-rhel-nfs-v4-configuration/">CentOS/Red Hat: Setup NFS v4.0 File Server</link></para>
              </step>
              <step>
                <para>Configure the NFS server at <literal>HostA</literal> by adding the following line to
the <literal>/etc/exports</literal> file:</para>
                <screen language="ini">NOVA-INST-DIR/instances HostA/255.255.0.0(rw,sync,fsid=0,no_root_squash)</screen>
                <para>Change the subnet mask (<literal>255.255.0.0</literal>) to the appropriate value to
include the IP addresses of <literal>HostB</literal> and <literal>HostC</literal>. Then restart the
<literal>NFS</literal> server:</para>
                <screen language="console"># /etc/init.d/nfs-kernel-server restart
# /etc/init.d/idmapd restart</screen>
              </step>
              <step>
                <para>On both compute nodes, enable the <literal>execute/search</literal> bit on your shared
directory to allow qemu to be able to use the images within the
directories. On all hosts, run the following command:</para>
                <screen language="console">$ chmod o+x NOVA-INST-DIR/instances</screen>
              </step>
              <step>
                <para>Configure NFS on <literal>HostB</literal> and <literal>HostC</literal> by adding the following line to
the <literal>/etc/fstab</literal> file</para>
                <screen language="console">HostA:/ /NOVA-INST-DIR/instances nfs4 defaults 0 0</screen>
                <para>Ensure that you can mount the exported directory</para>
                <screen language="console">$ mount -a -v</screen>
                <para>Check that <literal>HostA</literal> can see the <literal>NOVA-INST-DIR/instances/</literal>
directory</para>
                <screen language="console">$ ls -ld NOVA-INST-DIR/instances/
drwxr-xr-x 2 nova nova 4096 2012-05-19 14:34 nova-install-dir/instances/</screen>
                <para>Perform the same check on <literal>HostB</literal> and <literal>HostC</literal>, paying special
attention to the permissions (Compute should be able to write)</para>
                <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ls -ld NOVA-INST-DIR/instances/
drwxr-xr-x 2 nova nova 4096 2012-05-07 14:34 nova-install-dir/instances/

$ df -k
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/sda1            921514972   4180880 870523828   1% /
none                  16498340      1228  16497112   1% /dev
none                  16502856         0  16502856   0% /dev/shm
none                  16502856       368  16502488   1% /var/run
none                  16502856         0  16502856   0% /var/lock
none                  16502856         0  16502856   0% /lib/init/rw
HostA:               921515008 101921792 772783104  12% /var/lib/nova/instances  ( &lt;--- this line is important.)</screen>
              </step>
              <step>
                <para>Update the libvirt configurations so that the calls can be made
securely. These methods enable remote access over TCP and are not
documented here.</para>
                <itemizedlist>
                  <listitem>
                    <para>SSH tunnel to libvirtd's UNIX socket</para>
                  </listitem>
                  <listitem>
                    <para>libvirtd TCP socket, with GSSAPI/Kerberos for auth+data encryption</para>
                  </listitem>
                  <listitem>
                    <para>libvirtd TCP socket, with TLS for encryption and x509 client certs
for authentication</para>
                  </listitem>
                  <listitem>
                    <para>libvirtd TCP socket, with TLS for encryption and Kerberos for
authentication</para>
                  </listitem>
                </itemizedlist>
                <para>Restart <literal>libvirt</literal>. After you run the command, ensure that libvirt is
successfully restarted</para>
                <screen language="console"># stop libvirt-bin &amp;&amp; start libvirt-bin
$ ps -ef | grep libvirt
root 1145 1 0 Nov27 ? 00:00:03 /usr/sbin/libvirtd -d -l\</screen>
              </step>
              <step>
                <para>Configure your firewall to allow libvirt to communicate between nodes.
By default, libvirt listens on TCP port 16509, and an ephemeral TCP
range from 49152 to 49261 is used for the KVM communications. Based on
the secure remote access TCP configuration you chose, be careful which
ports you open, and always understand who has access. For information
about ports that are used with libvirt,
see the <link xlink:href="http://libvirt.org/remote.html#Remote_libvirtd_configuration">libvirt documentation</link>.</para>
              </step>
              <step>
                <para>Configure the downtime required for the migration by adjusting these
parameters in the <literal>nova.conf</literal> file:</para>
                <screen language="ini">live_migration_downtime = 500
live_migration_downtime_steps = 10
live_migration_downtime_delay = 75</screen>
                <para>The <literal>live_migration_downtime</literal> parameter sets the maximum permitted
downtime for a live migration, in milliseconds. This setting defaults to
500 milliseconds.</para>
                <para>The <literal>live_migration_downtime_steps</literal> parameter sets the total number of
incremental steps to reach the maximum downtime value. This setting
defaults to 10 steps.</para>
                <para>The <literal>live_migration_downtime_delay</literal> parameter sets the amount of time
to wait between each step, in seconds. This setting defaults to 75 seconds.</para>
              </step>
              <step>
                <para>You can now configure other options for live migration. In most cases, you
will not need to configure any options. For advanced configuration options,
see the <link xlink:href="http://docs.openstack.org/liberty/config-reference/content/list-of-compute-config-options.html#config_table_nova_livemigration">OpenStack Configuration Reference Guide</link>.</para>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>Enabling true live migration</title>
            <para>Prior to the Kilo release, the Compute service did not use the libvirt
live migration function by default. To enable this function, add the
following line to the <literal>[libvirt]</literal> section of the <literal>nova.conf</literal> file:</para>
            <screen language="ini"><?dbsuse-fo font-size="8pt"?>live_migration_flag=VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_TUNNELLED</screen>
            <para>On versions older than Kilo, the Compute service does not use libvirt's
live migration by default because there is a risk that the migration
process will never end. This can happen if the guest operating system
uses blocks on the disk faster than they can be migrated.</para>
          </sect4>
          <sect4>
            <title>Block migration</title>
            <para>Configuring KVM for block migration is exactly the same as the above
configuration in <xref linkend="configuring-migrations-kvm-shared-storage"/>
the section called shared storage, except that <literal>NOVA-INST-DIR/instances</literal>
is local to each host rather than shared. No NFS client or server
configuration is required.</para>
            <note>
              <itemizedlist>
                <listitem>
                  <para>To use block migration, you must use the <literal>--block-migrate</literal>
parameter with the live migration command.</para>
                </listitem>
                <listitem>
                  <para>Block migration is incompatible with read-only devices such as
CD-ROMs and <link xlink:href="http://docs.openstack.org/user-guide/cli-config-drive.html">Configuration Drive (config_drive)</link>.</para>
                </listitem>
                <listitem>
                  <para>Since the ephemeral drives are copied over the network in block
migration, migrations of instances with heavy I/O loads may never
complete if the drives are writing faster than the data can be
copied over the network.</para>
                </listitem>
              </itemizedlist>
            </note>
          </sect4>
        </sect3>
        <sect3>
          <title>XenServer</title>
          <sect4>
            <title>Shared storage</title>
            <para>
              <emphasis role="bold">Prerequisites</emphasis>
            </para>
            <itemizedlist>
              <listitem>
                <para><emphasis role="bold">Compatible XenServer hypervisors</emphasis>. For more information, see the
<link xlink:href="http://docs.vmd.citrix.com/XenServer/6.0.0/1.0/en_gb/reference.html#pooling_homogeneity_requirements">Requirements for Creating Resource Pools</link> section of the XenServer
Administrator's Guide.</para>
              </listitem>
              <listitem>
                <para><emphasis role="bold">Shared storage</emphasis>. An NFS export, visible to all XenServer hosts.</para>
                <note>
                  <para>For the supported NFS versions, see the
<link xlink:href="http://docs.vmd.citrix.com/XenServer/6.0.0/1.0/en_gb/reference.html#id1002701">NFS VHD</link>
section of the XenServer Administrator's Guide.</para>
                </note>
              </listitem>
            </itemizedlist>
            <para>To use shared storage live migration with XenServer hypervisors, the
hosts must be joined to a XenServer pool. To create that pool, a host
aggregate must be created with specific metadata. This metadata is used
by the XAPI plug-ins to establish the pool.</para>
            <para>
              <emphasis role="bold">Using shared storage live migrations with XenServer Hypervisors</emphasis>
            </para>
            <procedure>
              <step>
                <para>Add an NFS VHD storage to your master XenServer, and set it as the
default storage repository. For more information, see NFS VHD in the
XenServer Administrator's Guide.</para>
              </step>
              <step>
                <para>Configure all compute nodes to use the default storage repository
(<literal>sr</literal>) for pool operations. Add this line to your <literal>nova.conf</literal>
configuration files on all compute nodes:</para>
                <screen language="ini">sr_matching_filter=default-sr:true</screen>
              </step>
              <step>
                <para>Create a host aggregate. This command creates the aggregate, and then
displays a table that contains the ID of the new aggregate</para>
                <screen language="console">$ openstack aggregate create --zone AVAILABILITY_ZONE POOL_NAME</screen>
                <para>Add metadata to the aggregate, to mark it as a hypervisor pool</para>
                <screen language="console">$ openstack aggregate set --property hypervisor_pool=true AGGREGATE_ID

$ openstack aggregate set --property operational_state=created AGGREGATE_ID</screen>
                <para>Make the first compute node part of that aggregate</para>
                <screen language="console">$ openstack aggregate add host AGGREGATE_ID MASTER_COMPUTE_NAME</screen>
                <para>The host is now part of a XenServer pool.</para>
              </step>
              <step>
                <para>Add hosts to the pool</para>
                <screen language="console">$ openstack aggregate add host AGGREGATE_ID COMPUTE_HOST_NAME</screen>
                <note>
                  <para>The added compute node and the host will shut down to join the host
to the XenServer pool. The operation will fail if any server other
than the compute node is running or suspended on the host.</para>
                </note>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>Block migration</title>
            <itemizedlist>
              <listitem>
                <para><emphasis role="bold">Compatible XenServer hypervisors</emphasis>.
The hypervisors must support the Storage XenMotion feature.
See your XenServer manual to make sure your edition
has this feature.</para>
                <note>
                  <itemizedlist>
                    <listitem>
                      <para>To use block migration, you must use the <literal>--block-migrate</literal>
parameter with the live migration command.</para>
                    </listitem>
                    <listitem>
                      <para>Block migration works only with EXT local storage storage
repositories, and the server must not have any volumes attached.</para>
                    </listitem>
                  </itemizedlist>
                </note>
              </listitem>
            </itemizedlist>
          </sect4>
        </sect3>
      </sect2>
      <sect2>
        <title>Migrate instances</title>
        <para>This section discusses how to migrate running instances from one
OpenStack Compute server to another OpenStack Compute server.</para>
        <para>Before starting a migration, review the Configure migrations section.
<xref linkend="section-configuring-compute-migrations"/>.</para>
        <note>
          <para>Although the <command>nova</command> command is called <command>live-migration</command>,
under the default Compute configuration options, the instances
are suspended before migration. For more information, see
<link xlink:href="http://docs.openstack.org/newton/config-reference/compute/config-options.html">Configure migrations</link>.
in the OpenStack Configuration Reference.</para>
        </note>
        <para>
          <emphasis role="bold">Migrating instances</emphasis>
        </para>
        <procedure>
          <step>
            <para>Check the ID of the instance to be migrated:</para>
            <screen language="console">$ openstack server list</screen>
            <informaltable>
              <tgroup cols="4">
                <colspec colname="c1" colwidth="49.5*"/>
                <colspec colname="c2" colwidth="12.9*"/>
                <colspec colname="c3" colwidth="14.0*"/>
                <colspec colname="c4" colwidth="23.7*"/>
                <thead>
                  <row>
                    <entry>
                      <para>ID</para>
                    </entry>
                    <entry>
                      <para>Name</para>
                    </entry>
                    <entry>
                      <para>Status</para>
                    </entry>
                    <entry>
                      <para>Networks</para>
                    </entry>
                  </row>
                </thead>
                <tbody>
                  <row>
                    <entry>
                      <para>d1df1b5a-70c4-4fed-98b7-423362f2c47c</para>
                    </entry>
                    <entry>
                      <para>vm1</para>
                    </entry>
                    <entry>
                      <para>ACTIVE</para>
                    </entry>
                    <entry>
                      <para>private=a.b.c.d</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>d693db9e-a7cf-45ef-a7c9-b3ecb5f22645</para>
                    </entry>
                    <entry>
                      <para>vm2</para>
                    </entry>
                    <entry>
                      <para>ACTIVE</para>
                    </entry>
                    <entry>
                      <para>private=e.f.g.h</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </informaltable>
          </step>
          <step>
            <para>Check the information associated with the instance. In this example,
<literal>vm1</literal> is running on <literal>HostB</literal>:</para>
            <screen language="console">$ openstack server show d1df1b5a-70c4-4fed-98b7-423362f2c47c</screen>
            <informaltable>
              <tgroup cols="2">
                <colspec colname="c1" colwidth="40.0*"/>
                <colspec colname="c2" colwidth="60.0*"/>
                <thead>
                  <row>
                    <entry>
                      <para>Property</para>
                    </entry>
                    <entry>
                      <para>Value</para>
                    </entry>
                  </row>
                </thead>
                <tbody>
                  <row>
                    <entry>
                      <para>...</para>
                      <para>OS-EXT-SRV-ATTR:host</para>
                      <para>...</para>
                      <para>flavor</para>
                      <para>id</para>
                      <para>name</para>
                      <para>private network</para>
                      <para>status</para>
                      <para>...</para>
                    </entry>
                    <entry>
                      <para>...</para>
                      <para>HostB</para>
                      <para>...</para>
                      <para>m1.tiny</para>
                      <para>d1df1b5a-70c4-4fed-98b7-423362f2c47c</para>
                      <para>vm1</para>
                      <para>a.b.c.d</para>
                      <para>ACTIVE</para>
                      <para>...</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </informaltable>
          </step>
          <step>
            <para>Select the compute node the instance will be migrated to. In this
example, we will migrate the instance to <literal>HostC</literal>, because
<literal>nova-compute</literal> is running on it:</para>
            <table>
              <title>openstack compute service list</title>
              <tgroup cols="6">
                <colspec colname="c1" colwidth="22.0*"/>
                <colspec colname="c2" colwidth="9.9*"/>
                <colspec colname="c3" colwidth="13.2*"/>
                <colspec colname="c4" colwidth="12.1*"/>
                <colspec colname="c5" colwidth="9.9*"/>
                <colspec colname="c6" colwidth="33.0*"/>
                <thead>
                  <row>
                    <entry>
                      <para>Binary</para>
                    </entry>
                    <entry>
                      <para>Host</para>
                    </entry>
                    <entry>
                      <para>Zone</para>
                    </entry>
                    <entry>
                      <para>Status</para>
                    </entry>
                    <entry>
                      <para>State</para>
                    </entry>
                    <entry>
                      <para>Updated_at</para>
                    </entry>
                  </row>
                </thead>
                <tbody>
                  <row>
                    <entry>
                      <para>nova-consoleauth</para>
                    </entry>
                    <entry>
                      <para>HostA</para>
                    </entry>
                    <entry>
                      <para>internal</para>
                    </entry>
                    <entry>
                      <para>enabled</para>
                    </entry>
                    <entry>
                      <para>up</para>
                    </entry>
                    <entry>
                      <para>2014-03-25T10:33:25.000000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>nova-scheduler</para>
                    </entry>
                    <entry>
                      <para>HostA</para>
                    </entry>
                    <entry>
                      <para>internal</para>
                    </entry>
                    <entry>
                      <para>enabled</para>
                    </entry>
                    <entry>
                      <para>up</para>
                    </entry>
                    <entry>
                      <para>2014-03-25T10:33:25.000000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>nova-conductor</para>
                    </entry>
                    <entry>
                      <para>HostA</para>
                    </entry>
                    <entry>
                      <para>internal</para>
                    </entry>
                    <entry>
                      <para>enabled</para>
                    </entry>
                    <entry>
                      <para>up</para>
                    </entry>
                    <entry>
                      <para>2014-03-25T10:33:27.000000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>nova-compute</para>
                    </entry>
                    <entry>
                      <para>HostB</para>
                    </entry>
                    <entry>
                      <para>nova</para>
                    </entry>
                    <entry>
                      <para>enabled</para>
                    </entry>
                    <entry>
                      <para>up</para>
                    </entry>
                    <entry>
                      <para>2014-03-25T10:33:31.000000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>nova-compute</para>
                    </entry>
                    <entry>
                      <para>HostC</para>
                    </entry>
                    <entry>
                      <para>nova</para>
                    </entry>
                    <entry>
                      <para>enabled</para>
                    </entry>
                    <entry>
                      <para>up</para>
                    </entry>
                    <entry>
                      <para>2014-03-25T10:33:31.000000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>nova-cert</para>
                    </entry>
                    <entry>
                      <para>HostA</para>
                    </entry>
                    <entry>
                      <para>internal</para>
                    </entry>
                    <entry>
                      <para>enabled</para>
                    </entry>
                    <entry>
                      <para>up</para>
                    </entry>
                    <entry>
                      <para>2014-03-25T10:33:31.000000</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </table>
          </step>
          <step>
            <para>Check that <literal>HostC</literal> has enough resources for migration:</para>
            <screen language="console"># openstack host show HostC</screen>
            <informaltable>
              <tgroup cols="5">
                <colspec colname="c1" colwidth="22.6*"/>
                <colspec colname="c2" colwidth="22.6*"/>
                <colspec colname="c3" colwidth="11.3*"/>
                <colspec colname="c4" colwidth="24.2*"/>
                <colspec colname="c5" colwidth="19.4*"/>
                <thead>
                  <row>
                    <entry>
                      <para>HOST</para>
                    </entry>
                    <entry>
                      <para>PROJECT</para>
                    </entry>
                    <entry>
                      <para>cpu</para>
                    </entry>
                    <entry>
                      <para>memory_mb</para>
                    </entry>
                    <entry>
                      <para>disk_gb</para>
                    </entry>
                  </row>
                </thead>
                <tbody>
                  <row>
                    <entry>
                      <para>HostC</para>
                    </entry>
                    <entry>
                      <para>(total)</para>
                    </entry>
                    <entry>
                      <para>16</para>
                    </entry>
                    <entry>
                      <para>32232</para>
                    </entry>
                    <entry>
                      <para>878</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>HostC</para>
                    </entry>
                    <entry>
                      <para>(used_now)</para>
                    </entry>
                    <entry>
                      <para>22</para>
                    </entry>
                    <entry>
                      <para>21284</para>
                    </entry>
                    <entry>
                      <para>442</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>HostC</para>
                    </entry>
                    <entry>
                      <para>(used_max)</para>
                    </entry>
                    <entry>
                      <para>22</para>
                    </entry>
                    <entry>
                      <para>21284</para>
                    </entry>
                    <entry>
                      <para>422</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>HostC</para>
                    </entry>
                    <entry>
                      <para>p1</para>
                    </entry>
                    <entry>
                      <para>22</para>
                    </entry>
                    <entry>
                      <para>21284</para>
                    </entry>
                    <entry>
                      <para>422</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>HostC</para>
                    </entry>
                    <entry>
                      <para>p2</para>
                    </entry>
                    <entry>
                      <para>22</para>
                    </entry>
                    <entry>
                      <para>21284</para>
                    </entry>
                    <entry>
                      <para>422</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </informaltable>
            <itemizedlist>
              <listitem>
                <para><literal>cpu</literal>: Number of CPUs</para>
              </listitem>
              <listitem>
                <para><literal>memory_mb</literal>: Total amount of memory, in MB</para>
              </listitem>
              <listitem>
                <para><literal>disk_gb</literal>: Total amount of space for NOVA-INST-DIR/instances, in GB</para>
              </listitem>
            </itemizedlist>
            <para>In this table, the first row shows the total amount of resources
available on the physical server. The second line shows the currently
used resources. The third line shows the maximum used resources. The
fourth line and below shows the resources available for each project.</para>
          </step>
          <step>
            <para>Migrate the instance using the <command>openstack server migrate</command> command:</para>
            <screen language="console">$ openstack server migrate SERVER --live HOST_NAME</screen>
            <para>In this example, SERVER can be the ID or name of the instance. Another
example:</para>
            <screen language="console">$ openstack server migrate d1df1b5a-70c4-4fed-98b7-423362f2c47c --live HostC
Migration of d1df1b5a-70c4-4fed-98b7-423362f2c47c initiated.</screen>
            <warning>
              <para>When using live migration to move workloads between
Icehouse and Juno compute nodes, it may cause data loss
because libvirt live migration with shared block storage
was buggy (potential loss of data) before version 3.32.
This issue can be solved when we upgrade to RPC API version 4.0.</para>
            </warning>
          </step>
          <step>
            <para>Check that the instance has been migrated successfully, using
<command>openstack server list</command>. If the instance is still running on
<literal>HostB</literal>, check the log files at <literal>src/dest</literal> for <literal>nova-compute</literal> and
<literal>nova-scheduler</literal> to determine why.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Configure remote console access</title>
        <para>To provide a remote console or remote desktop access to guest virtual
machines, use VNC or SPICE HTML5 through either the OpenStack dashboard
or the command line. Best practice is to select one or the other to run.</para>
        <sect3>
          <title>About nova-consoleauth</title>
          <para>Both client proxies leverage a shared service to manage token
authentication called <literal>nova-consoleauth</literal>. This service must be running for
either proxy to work. Many proxies of either type can be run against a
single <literal>nova-consoleauth</literal> service in a cluster configuration.</para>
          <para>Do not confuse the <literal>nova-consoleauth</literal> shared service with
<literal>nova-console</literal>, which is a XenAPI-specific service that most recent
VNC proxy architectures do not use.</para>
        </sect3>
        <sect3>
          <title>SPICE console</title>
          <para>OpenStack Compute supports VNC consoles to guests. The VNC protocol is
fairly limited, lacking support for multiple monitors, bi-directional
audio, reliable cut-and-paste, video streaming and more. SPICE is a new
protocol that aims to address the limitations in VNC and provide good
remote desktop support.</para>
          <para>SPICE support in OpenStack Compute shares a similar architecture to the
VNC implementation. The OpenStack dashboard uses a SPICE-HTML5 widget in
its console tab that communicates to the <literal>nova-spicehtml5proxy</literal> service by
using SPICE-over-websockets. The <literal>nova-spicehtml5proxy</literal> service
communicates directly with the hypervisor process by using SPICE.</para>
          <para>VNC must be explicitly disabled to get access to the SPICE console. Set
the <literal>vnc_enabled</literal> option to <literal>False</literal> in the <literal>[DEFAULT]</literal> section to
disable the VNC console.</para>
          <para>Use the following options to configure SPICE as the console for
OpenStack Compute:</para>
          <table>
            <title>Description of SPICE configuration options</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="50.0*"/>
              <colspec colname="c2" colwidth="50.0*"/>
              <thead>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">[spice]</emphasis>
                    </para>
                  </entry>
                  <entry/>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Spice configuration option = Default value</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>agent_enabled = True</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(BoolOpt) Enable spice guest agent support</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>enabled = False</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(BoolOpt) Enable spice related features</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>html5proxy_base_url = http://127.0.0.1:6082/spice_auto.html</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Location of spice HTML5 console proxy, in the form
"<link xlink:href="http://127.0.0.1:6082/spice_auto.html">http://127.0.0.1:6082/spice_auto.html</link>"</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>html5proxy_host = 0.0.0.0</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Host on which to listen for incoming requests</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>html5proxy_port = 6082</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(IntOpt) Port on which to listen for incoming requests</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>keymap = en-us</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Keymap for spice</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>server_listen = 127.0.0.1</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(StrOpt) IP address on which instance spice server should listen</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>server_proxyclient_address = 127.0.0.1</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>(StrOpt) The address to which proxy clients (like nova-spicehtml5proxy)
should connect</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
        </sect3>
        <sect3>
          <title>VNC console proxy</title>
          <para>The VNC proxy is an OpenStack component that enables compute service
users to access their instances through VNC clients.</para>
          <note>
            <para>The web proxy console URLs do not support the websocket protocol
scheme (ws://) on python versions less than 2.7.4.</para>
          </note>
          <para>The VNC console connection works as follows:</para>
          <procedure>
            <step>
              <para>A user connects to the API and gets an <literal>access_url</literal> such as,
<literal>http://ip:port/?token=xyz</literal>.</para>
            </step>
            <step>
              <para>The user pastes the URL in a browser or uses it as a client
parameter.</para>
            </step>
            <step>
              <para>The browser or client connects to the proxy.</para>
            </step>
            <step>
              <para>The proxy talks to <literal>nova-consoleauth</literal> to authorize the token for the
user, and maps the token to the <emphasis>private</emphasis> host and port of the VNC
server for an instance.</para>
              <para>The compute host specifies the address that the proxy should use to
connect through the <literal>nova.conf</literal> file option,
<literal>vncserver_proxyclient_address</literal>. In this way, the VNC proxy works
as a bridge between the public network and private host network.</para>
            </step>
            <step>
              <para>The proxy initiates the connection to VNC server and continues to
proxy until the session ends.</para>
            </step>
          </procedure>
          <para>The proxy also tunnels the VNC protocol over WebSockets so that the
<literal>noVNC</literal> client can talk to VNC servers. In general, the VNC proxy:</para>
          <itemizedlist>
            <listitem>
              <para>Bridges between the public network where the clients live and the
private network where VNC servers live.</para>
            </listitem>
            <listitem>
              <para>Mediates token authentication.</para>
            </listitem>
            <listitem>
              <para>Transparently deals with hypervisor-specific connection details to
provide a uniform client experience.</para>
            </listitem>
          </itemizedlist>
          <figure>
            <title/>
            <mediaobject>
              <imageobject role="fo">
                <imagedata fileref="SCH_5009_V00_NUAC-VNC_OpenStack.png" width="95%"/>
              </imageobject>
              <imageobject role="html">
                <imagedata fileref="SCH_5009_V00_NUAC-VNC_OpenStack.png" width="95%"/>
              </imageobject>
            </mediaobject>
          </figure>
          <sect4>
            <title>VNC configuration options</title>
            <para>To customize the VNC console, use the following configuration options in
your <literal>nova.conf</literal> file:</para>
            <note>
              <para>To support <xref linkend="section-configuring-compute-migrations"/>,
you cannot specify a specific IP address for <literal>vncserver_listen</literal>,
because that IP address does not exist on the destination host.</para>
            </note>
            <table>
              <title>Description of VNC configuration options</title>
              <tgroup cols="2">
                <colspec colname="c1" colwidth="50.0*"/>
                <colspec colname="c2" colwidth="50.0*"/>
                <thead>
                  <row>
                    <entry>
                      <para>Configuration option = Default value</para>
                    </entry>
                    <entry>
                      <para>Description</para>
                    </entry>
                  </row>
                </thead>
                <tbody>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">[DEFAULT]</emphasis>
                      </para>
                    </entry>
                    <entry/>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>daemon = False</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(BoolOpt) Become a daemon (background process)</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>key = None</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(StrOpt) SSL key file (if separate from cert)</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>novncproxy_host = 0.0.0.0</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(StrOpt) Host on which to listen for incoming requests</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>novncproxy_port = 6080</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(IntOpt) Port on which to listen for incoming requests</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>record = False</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(BoolOpt) Record sessions to FILE.[session_number]</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>source_is_ipv6 = False</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(BoolOpt) Source is ipv6</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>ssl_only = False</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(BoolOpt) Disallow non-encrypted connections</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>web = /usr/share/spice-html5</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(StrOpt) Run webserver on same port. Serve files from DIR.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">[vmware]</emphasis>
                      </para>
                    </entry>
                    <entry/>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>vnc_port = 5900</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>(IntOpt) VNC starting port</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>vnc_port_total = 10000</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>vnc_port_total = 10000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <emphasis role="bold">[vnc]</emphasis>
                      </para>
                    </entry>
                    <entry/>
                  </row>
                  <row>
                    <entry>
                      <para>enabled = True</para>
                    </entry>
                    <entry>
                      <para>(BoolOpt) Enable VNC related features</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>novncproxy_base_url = <link xlink:href="http://127.0.0.1:6080/vnc_auto.html">http://127.0.0.1:6080/vnc_auto.html</link></para>
                    </entry>
                    <entry>
                      <para>(StrOpt) Location of VNC console proxy, in the form
"<link xlink:href="http://127.0.0.1:6080/vnc_auto.html">http://127.0.0.1:6080/vnc_auto.html</link>"</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>vncserver_listen = 127.0.0.1</para>
                    </entry>
                    <entry>
                      <para>(StrOpt) IP address on which instance vncservers should listen</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>vncserver_proxyclient_address = 127.0.0.1</para>
                    </entry>
                    <entry>
                      <para>(StrOpt) The address to which proxy clients <!-- (like nova-xvpvncproxy)-->
should connect</para>
                    </entry>
                  </row>
                  <!--<row>
                    <entry>
                      <para>xvpvncproxy_base_url = <link xlink:href="http://127.0.0.1:6081/console">http://127.0.0.1:6081/console</link></para>
                    </entry>
                    <entry>
                      <para>(StrOpt) Location of nova xvp VNC console proxy, in the form
"<link xlink:href="http://127.0.0.1:6081/console">http://127.0.0.1:6081/console</link>"</para>
                    </entry>
                  </row>-->
                </tbody>
              </tgroup>
            </table>
            <note>
              <itemizedlist>
                <listitem>
                  <para>The <literal>vncserver_proxyclient_address</literal> defaults to <literal>127.0.0.1</literal>,
which is the address of the compute host that Compute instructs
proxies to use when connecting to instance servers.</para>
                </listitem>
                <listitem>
                  <para>For all-in-one XenServer domU deployments, set this to
<literal>169.254.0.1.</literal></para>
                </listitem>
                <listitem>
                  <para>For multi-host XenServer domU deployments, set to a <literal>dom0
management IP</literal> on the same network as the proxies.</para>
                </listitem>
                <listitem>
                  <para>For multi-host libvirt deployments, set to a host management IP
on the same network as the proxies.</para>
                </listitem>
              </itemizedlist>
            </note>
          </sect4>
          <sect4>
            <title>Typical deployment</title>
            <para>A typical deployment has the following components:</para>
            <itemizedlist>
              <listitem>
                <para>A <literal>nova-consoleauth</literal> process. Typically runs on the controller host.</para>
              </listitem>
              <listitem>
                <para>One or more <literal>nova-novncproxy</literal> services. Supports browser-based noVNC
clients. For simple deployments, this service typically runs on the
same machine as <literal>nova-api</literal> because it operates as a proxy between the
public network and the private compute host network.</para>
              </listitem>
             <!-- <listitem>
                <para>One or more <literal>nova-xvpvncproxy</literal> services. Supports the special Java
client discussed here. For simple deployments, this service typically
runs on the same machine as <literal>nova-api</literal> because it acts as a proxy
between the public network and the private compute host network.</para>
              </listitem>-->
              <listitem>
                <para>One or more compute hosts. These compute hosts must have correctly
configured options, as follows.</para>
              </listitem>
            </itemizedlist>
          </sect4>
          <sect4>
            <title>nova-novncproxy (noVNC)</title>
            <para>You must install the noVNC package, which contains the <literal>nova-novncproxy</literal>
service. As root, run the following command:</para>
            <screen language="console"># apt-get install nova-novncproxy</screen>
            <para>The service starts automatically on installation.</para>
            <para>To restart the service, run:</para>
            <screen language="console"># service nova-novncproxy restart</screen>
            <para>The configuration option parameter should point to your <literal>nova.conf</literal>
file, which includes the message queue server address and credentials.</para>
            <para>By default, <literal>nova-novncproxy</literal> binds on <literal>0.0.0.0:6080</literal>.</para>
            <para>To connect the service to your Compute deployment, add the following
configuration options to your <literal>nova.conf</literal> file:</para>
            <itemizedlist>
              <listitem>
                <para>
                  <literal>vncserver_listen=0.0.0.0</literal>
                </para>
                <para>Specifies the address on which the VNC service should bind. Make sure
it is assigned one of the compute node interfaces. This address is
the one used by your domain file.</para>
                <screen language="console">&lt;graphics type="vnc" autoport="yes" keymap="en-us" listen="0.0.0.0"/&gt;</screen>
                <note>
                  <para>To use live migration, use the 0.0.0.0 address.</para>
                </note>
              </listitem>
              <listitem>
                <para>
                  <literal>vncserver_proxyclient_address=127.0.0.1</literal>
                </para>
                <para>The address of the compute host that Compute instructs proxies to use
when connecting to instance <literal>vncservers</literal>.</para>
              </listitem>
            </itemizedlist>
          </sect4>
          <sect4>
            <title>Frequently asked questions about VNC access to virtual machines</title>
            <itemizedlist>
              <!--<listitem>
                <para>
                  <emphasis role="bold">Q: What is the difference between ``nova-xvpvncproxy`` and
``nova-novncproxy``?</emphasis>
                </para>
                <para>A: <literal>nova-xvpvncproxy</literal>, which ships with OpenStack Compute, is a
proxy that supports a simple Java client. nova-novncproxy uses noVNC
to provide VNC support through a web browser.</para>
              </listitem>-->
              <listitem>
                <para>
                  <emphasis role="bold">Q: I want VNC support in the OpenStack dashboard. What services do
I need?</emphasis>
                </para>
                <para>A: You need <literal>nova-novncproxy</literal>, <literal>nova-consoleauth</literal>, and correctly
configured compute hosts.</para>
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Q: When I use ``nova get-vnc-console`` or click on the VNC tab of
the OpenStack dashboard, it hangs. Why?</emphasis>
                </para>
                <para>A: Make sure you are running <literal>nova-consoleauth</literal> (in addition to
<literal>nova-novncproxy</literal>). The proxies rely on <literal>nova-consoleauth</literal> to validate
tokens, and waits for a reply from them until a timeout is reached.</para>
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Q: My VNC proxy worked fine during my all-in-one test, but now it
doesn't work on multi host. Why?</emphasis>
                </para>
                <para>A: The default options work for an all-in-one install, but changes
must be made on your compute hosts once you start to build a cluster.
As an example, suppose you have two servers:</para>
                <screen language="bash">PROXYSERVER (public_ip=172.24.1.1, management_ip=192.168.1.1)
COMPUTESERVER (management_ip=192.168.1.2)</screen>
                <para>Your <literal>nova-compute</literal> configuration file must set the following values:</para>
                <screen language="console"># These flags help construct a connection data structure
vncserver_proxyclient_address=192.168.1.2
novncproxy_base_url=http://172.24.1.1:6080/vnc_auto.html


# This is the address where the underlying vncserver (not the proxy)
# will listen for connections.
vncserver_listen=192.168.1.2</screen>
                <!--<note>
                  <para><literal>novncproxy_base_url</literal> and <literal>xvpvncproxy_base_url</literal> use a public
IP; this is the URL that is ultimately returned to clients, which
generally do not have access to your private network. Your
PROXYSERVER must be able to reach <literal>vncserver_proxyclient_address</literal>,
because that is the address over which the VNC connection is proxied.</para>
                </note>-->
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Q: My noVNC does not work with recent versions of web browsers. Why?</emphasis>
                </para>
                <para>A: Make sure you have installed <literal>python-numpy</literal>, which is required
to support a newer version of the WebSocket protocol (HyBi-07+).</para>
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Q: How do I adjust the dimensions of the VNC window image in the
OpenStack dashboard?</emphasis>
                </para>
                <para>A: These values are hard-coded in a Django HTML template. To alter
them, edit the <literal>_detail_vnc.html</literal> template file. The location of
this file varies based on Linux distribution. On Ubuntu 14.04, the
file is at
<literal>/usr/share/pyshared/horizon/dashboards/nova/instances/templates/instances/_detail_vnc.html</literal>.</para>
                <para>Modify the <literal>width</literal> and <literal>height</literal> options, as follows:</para>
                <screen language="console">&lt;iframe src="{{ vnc_url }}" width="720" height="430"&gt;&lt;/iframe&gt;</screen>
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Q: My noVNC connections failed with ValidationError: Origin header
protocol does not match. Why?</emphasis>
                </para>
                <para>A: Make sure the <literal>base_url</literal> match your TLS setting. If you are
using https console connections, make sure that the value of
<literal>novncproxy_base_url</literal> is set explicitly where the <literal>nova-novncproxy</literal>
service is running.</para>
              </listitem>
            </itemizedlist>
          </sect4>
        </sect3>
      </sect2>
      <sect2>
        <title>Configure Compute service groups</title>
        <para>The Compute service must know the status of each compute node to
effectively manage and use them. This can include events like a user
launching a new VM, the scheduler sending a request to a live node, or a
query to the ServiceGroup API to determine if a node is live.</para>
        <para>When a compute worker running the nova-compute daemon starts, it calls
the join API to join the compute group. Any service (such as the
scheduler) can query the group's membership and the status of its nodes.
Internally, the ServiceGroup client driver automatically updates the
compute worker status.</para>
        <sect3>
          <title>Database ServiceGroup driver</title>
          <para>By default, Compute uses the database driver to track if a node is live.
In a compute worker, this driver periodically sends a <literal>db update</literal>
command to the database, saying “I'm OK” with a timestamp. Compute uses
a pre-defined timeout (<literal>service_down_time</literal>) to determine if a node is
dead.</para>
          <para>The driver has limitations, which can be problematic depending on your
environment. If a lot of compute worker nodes need to be checked, the
database can be put under heavy load, which can cause the timeout to
trigger, and a live node could incorrectly be considered dead. By
default, the timeout is 60 seconds. Reducing the timeout value can help
in this situation, but you must also make the database update more
frequently, which again increases the database workload.</para>
          <para>The database contains data that is both transient (such as whether the
node is alive) and persistent (such as entries for VM owners). With the
ServiceGroup abstraction, Compute can treat each type separately.</para>
          <sect4>
            <title>ZooKeeper ServiceGroup driver</title>
            <para>The ZooKeeper ServiceGroup driver works by using ZooKeeper ephemeral
nodes. ZooKeeper, unlike databases, is a distributed system, with its
load divided among several servers. On a compute worker node, the driver
can establish a ZooKeeper session, then create an ephemeral znode in the
group directory. Ephemeral znodes have the same lifespan as the session.
If the worker node or the nova-compute daemon crashes, or a network
partition is in place between the worker and the ZooKeeper server
quorums, the ephemeral znodes are removed automatically. The driver
can be given group membership by running the <command>ls</command> command in the
group directory.</para>
            <para>The ZooKeeper driver requires the ZooKeeper servers and client
libraries. Setting up ZooKeeper servers is outside the scope of this
guide (for more information, see <link xlink:href="http://zookeeper.apache.org/">Apache Zookeeper</link>). These client-side
Python libraries must be installed on every compute node:</para>
            <variablelist>
              <varlistentry>
                <term>
                  <emphasis role="bold">python-zookeeper</emphasis>
                </term>
                <listitem>
                  <para>The official Zookeeper Python binding</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>
                  <emphasis role="bold">evzookeeper</emphasis>
                </term>
                <listitem>
                  <para>This library makes the binding work with the eventlet threading model.</para>
                </listitem>
              </varlistentry>
            </variablelist>
            <para>This example assumes the ZooKeeper server addresses and ports are
<literal>192.168.2.1:2181</literal>, <literal>192.168.2.2:2181</literal>, and <literal>192.168.2.3:2181</literal>.</para>
            <para>These values in the <literal>/etc/nova/nova.conf</literal> file are required on every
node for the ZooKeeper driver:</para>
            <screen language="ini"># Driver for the ServiceGroup service
servicegroup_driver="zk"

[zookeeper]
address="192.168.2.1:2181,192.168.2.2:2181,192.168.2.3:2181"</screen>
          </sect4>
          <sect4>
            <title>Memcache ServiceGroup driver</title>
            <para>The memcache ServiceGroup driver uses memcached, a distributed memory
object caching system that is used to increase site performance. For
more details, see <link xlink:href="http://memcached.org/">memcached.org</link>.</para>
            <para>To use the memcache driver, you must install memcached. You might
already have it installed, as the same driver is also used for the
OpenStack Object Storage and OpenStack dashboard. To install
memcached, see the <emphasis>Environment -&gt; Memcached</emphasis> section in the
<link xlink:href="http://docs.openstack.org/project-install-guide/newton">Installation Tutorials and Guides</link>
depending on your distribution.</para>
            <para>These values in the <literal>/etc/nova/nova.conf</literal> file are required on every
node for the memcache driver:</para>
            <screen language="ini"><?dbsuse-fo font-size="8pt"?># Driver for the ServiceGroup service
servicegroup_driver = "mc"

# Memcached servers. Use either a list of memcached servers to use for caching (list value),
# or "&lt;None&gt;" for in-process caching (default).
memcached_servers = &lt;None&gt;

# Timeout; maximum time since last check-in for up service (integer value).
# Helps to define whether a node is dead
service_down_time = 60</screen>
          </sect4>
        </sect3>
      </sect2>
      <sect2>
        <title>Security hardening</title>
        <para>OpenStack Compute can be integrated with various third-party
technologies to increase security. For more information, see the
<link xlink:href="http://docs.openstack.org/sec/">OpenStack Security Guide</link>.</para>
        <sect3>
          <title>Trusted compute pools</title>
          <para>Administrators can designate a group of compute hosts as trusted using
trusted compute pools. The trusted hosts use hardware-based security
features, such as the Intel Trusted Execution Technology (TXT), to
provide an additional level of security. Combined with an external
stand-alone, web-based remote attestation server, cloud providers can
ensure that the compute node runs only software with verified
measurements and can ensure a secure cloud stack.</para>
          <para>Trusted compute pools provide the ability for cloud subscribers to
request services run only on verified compute nodes.</para>
          <para>The remote attestation server performs node verification like this:</para>
          <procedure>
            <step>
              <para>Compute nodes boot with Intel TXT technology enabled.</para>
            </step>
            <step>
              <para>The compute node BIOS, hypervisor, and operating system are measured.</para>
            </step>
            <step>
              <para>When the attestation server challenges the compute node, the measured
data is sent to the attestation server.</para>
            </step>
            <step>
              <para>The attestation server verifies the measurements against a known good
database to determine node trustworthiness.</para>
            </step>
          </procedure>
          <para>A description of how to set up an attestation service is beyond the
scope of this document. For an open source project that you can use to
implement an attestation service, see the <link xlink:href="https://github.com/OpenAttestation/OpenAttestation">Open
Attestation</link>
project.</para>
          <figure>
            <title>Configuring Compute to use trusted compute pools</title>
            <mediaobject>
              <imageobject role="fo">
                <imagedata fileref="OpenStackTrustedComputePool1.png" width="99%"/>
              </imageobject>
              <imageobject role="html">
                <imagedata fileref="OpenStackTrustedComputePool1.png" width="99%"/>
              </imageobject>
            </mediaobject>
          </figure>
          <procedure>
            <step>
              <para>Enable scheduling support for trusted compute pools by adding these
lines to the <literal>DEFAULT</literal> section of the <literal>/etc/nova/nova.conf</literal> file:</para>
              <screen language="ini"><?dbsuse-fo font-size="8pt"?>[DEFAULT]
compute_scheduler_driver=nova.scheduler.filter_scheduler.FilterScheduler
scheduler_available_filters=nova.scheduler.filters.all_filters
scheduler_default_filters=AvailabilityZoneFilter,RamFilter,ComputeFilter,TrustedFilter</screen>
            </step>
            <step>
              <para>Specify the connection information for your attestation service by
adding these lines to the <literal>trusted_computing</literal> section of the
<literal>/etc/nova/nova.conf</literal> file:</para>
              <screen language="ini">[trusted_computing]
attestation_server = 10.1.71.206
attestation_port = 8443
# If using OAT v2.0 after, use this port:
# attestation_port = 8181
attestation_server_ca_file = /etc/nova/ssl.10.1.71.206.crt
# If using OAT v1.5, use this api_url:
attestation_api_url = /AttestationService/resources
# If using OAT pre-v1.5, use this api_url:
# attestation_api_url = /OpenAttestationWebServices/V1.0
attestation_auth_blob = i-am-openstack</screen>
              <para>In this example:</para>
              <variablelist>
                <varlistentry>
                  <term>server</term>
                  <listitem>
                    <para>Host name or IP address of the host that runs the attestation
service</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>port</term>
                  <listitem>
                    <para>HTTPS port for the attestation service</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>server_ca_file</term>
                  <listitem>
                    <para>Certificate file used to verify the attestation server's identity</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>api_url</term>
                  <listitem>
                    <para>The attestation service's URL path</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>auth_blob</term>
                  <listitem>
                    <para>An authentication blob, required by the attestation service.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </step>
            <step>
              <para>Save the file, and restart the <literal>nova-compute</literal> and <literal>nova-scheduler</literal>
service to pick up the changes.</para>
            </step>
          </procedure>
          <para>To customize the trusted compute pools, use these configuration option
settings:</para>
          <table>
            <title>Description of trusted computing configuration options</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="50.0*"/>
              <colspec colname="c2" colwidth="50.0*"/>
              <thead>
                <row>
                  <entry>
                    <para>Configuration option = Default value</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>[trusted_computing]</para>
                  </entry>
                  <entry/>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>attestation_api_url = /OpenAttestationWebServices/V1.0</para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Attestation web API URL</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>attestation_auth_blob = None</para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Attestation authorization blob - must change</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>attestation_auth_timeout = 60</para>
                  </entry>
                  <entry>
                    <para>(IntOpt) Attestation status cache valid period length</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>attestation_insecure_ssl = False</para>
                  </entry>
                  <entry>
                    <para>(BoolOpt) Disable SSL cert verification for Attestation service</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>attestation_port = 8443</para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Attestation server port</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>attestation_server = None</para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Attestation server HTTP</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>attestation_server_ca_file = None</para>
                  </entry>
                  <entry>
                    <para>(StrOpt) Attestation server Cert file for Identity verification</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
          <procedure>
            <step>
              <para>Flavors can be designated as trusted using the
<command>nova flavor-key set</command> command. In this example, the <literal>m1.tiny</literal>
flavor is being set as trusted:</para>
              <screen language="console">$ nova flavor-key m1.tiny set trust:trusted_host=trusted</screen>
            </step>
            <step>
              <para>You can request that your instance is run on a trusted host by
specifying a trusted flavor when booting the instance:</para>
              <screen language="console">$ openstack server create --flavor m1.tiny \
  --key-name myKeypairName --image myImageID newInstanceName</screen>
            </step>
          </procedure>
          <figure>
            <title/>
            <mediaobject>
              <imageobject role="fo">
                <imagedata fileref="OpenStackTrustedComputePool2.png" width="99%"/>
              </imageobject>
              <imageobject role="html">
                <imagedata fileref="OpenStackTrustedComputePool2.png" width="99%"/>
              </imageobject>
            </mediaobject>
          </figure>
        </sect3>
        <sect3>
          <title>Encrypt Compute metadata traffic</title>
          <para>
            <emphasis role="bold">Enabling SSL encryption</emphasis>
          </para>
          <para>OpenStack supports encrypting Compute metadata traffic with HTTPS.
Enable SSL encryption in the <literal>metadata_agent.ini</literal> file.</para>
          <procedure>
            <step>
              <para>Enable the HTTPS protocol.</para>
              <screen language="ini">nova_metadata_protocol = https</screen>
            </step>
            <step>
              <para>Determine whether insecure SSL connections are accepted for Compute
metadata server requests. The default value is <literal>False</literal>.</para>
              <screen language="ini">nova_metadata_insecure = False</screen>
            </step>
            <step>
              <para>Specify the path to the client certificate.</para>
              <screen language="ini">nova_client_cert = PATH_TO_CERT</screen>
            </step>
            <step>
              <para>Specify the path to the private key.</para>
              <screen language="ini">nova_client_priv_key = PATH_TO_KEY</screen>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2>
        <title>Recover from a failed compute node</title>
        <para>If you deploy Compute with a shared file system, you can use several methods
to quickly recover from a node failure. This section discusses manual
recovery.</para>
        <sect3>
          <title>Evacuate instances</title>
          <para>If a hardware malfunction or other error causes the cloud compute node to
fail, you can use the <command>nova evacuate</command> command to evacuate instances.
See the <link xlink:href="http://docs.openstack.org/admin-guide/cli-nova-evacuate.html">OpenStack Administrator Guide</link>.</para>
        </sect3>
        <sect3>
          <title>Manual recovery</title>
          <para>To manually recover a failed compute node:</para>
          <procedure>
            <step>
              <para>Identify the VMs on the affected hosts by using a combination of
the <command>openstack server list</command> and <command>openstack server show</command>
commands or the <command>euca-describe-instances</command> command.</para>
              <para>For example, this command displays information about the i-000015b9
instance that runs on the np-rcc54 node:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ euca-describe-instances
i-000015b9 at3-ui02 running nectarkey (376, np-rcc54) 0 m1.xxlarge 2012-06-19T00:48:11.000Z 115.146.93.60</screen>
            </step>
            <step>
              <para>Query the Compute database for the status of the host. This example
converts an EC2 API instance ID to an OpenStack ID. If you use the
<command>nova</command> commands, you can substitute the ID directly. This example
output is truncated:</para>
              <screen language="mysql">mysql&gt; SELECT * FROM instances WHERE id = CONV('15b9', 16, 10) \G;
*************************** 1. row ***************************
created_at: 2012-06-19 00:48:11
updated_at: 2012-07-03 00:35:11
deleted_at: NULL
...
id: 5561
...
power_state: 5
vm_state: shutoff
...
hostname: at3-ui02
host: np-rcc54
...
uuid: 3f57699a-e773-4650-a443-b4b37eed5a06
...
task_state: NULL
...</screen>
              <note>
                <para>Find the credentials for your database in <literal>/etc/nova.conf</literal> file.</para>
              </note>
            </step>
            <step>
              <para>Decide to which compute host to move the affected VM. Run this database
command to move the VM to that host:</para>
              <screen language="mysql"><?dbsuse-fo font-size="8pt"?>mysql&gt; UPDATE instances SET host = 'np-rcc46' WHERE uuid = '3f57699a-e773-4650-a443-b4b37eed5a06';</screen>
            </step>
            <step>
              <para>If you use a hypervisor that relies on libvirt, such as KVM, update the
<literal>libvirt.xml</literal> file in <literal>/var/lib/nova/instances/[instance ID]</literal> with
these changes:</para>
              <itemizedlist>
                <listitem>
                  <para>Change the <literal>DHCPSERVER</literal> value to the host IP address of the new
compute host.</para>
                </listitem>
                <listitem>
                  <para>Update the VNC IP to <literal>0.0.0.0</literal>.</para>
                </listitem>
              </itemizedlist>
            </step>
            <step>
              <para>Reboot the VM:</para>
              <screen language="console">$ openstack server reboot 3f57699a-e773-4650-a443-b4b37eed5a06</screen>
            </step>
          </procedure>
          <para>Typically, the database update and <command>openstack server reboot</command> command
recover a VM from a failed host. However, if problems persist, try one of
these actions:</para>
          <itemizedlist>
            <listitem>
              <para>Use <command>virsh</command> to recreate the network filter configuration.</para>
            </listitem>
            <listitem>
              <para>Restart Compute services.</para>
            </listitem>
            <listitem>
              <para>Update the <literal>vm_state</literal> and <literal>power_state</literal> fields in the Compute database.</para>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Recover from a UID/GID mismatch</title>
          <para>Sometimes when you run Compute with a shared file system or an automated
configuration tool, files on your compute node might use the wrong UID or GID.
This UID or GID mismatch can prevent you from running live migrations or
starting virtual machines.</para>
          <para>This procedure runs on <literal>nova-compute</literal> hosts, based on the KVM hypervisor:</para>
          <procedure>
            <step>
              <para>Set the nova UID to the same number in <literal>/etc/passwd</literal> on all hosts. For
example, set the UID to <literal>112</literal>.</para>
              <note>
                <para>Choose UIDs or GIDs that are not in use for other users or groups.</para>
              </note>
            </step>
            <step>
              <para>Set the <literal>libvirt-qemu</literal> UID to the same number in the <literal>/etc/passwd</literal> file
on all hosts. For example, set the UID to <literal>119</literal>.</para>
            </step>
            <step>
              <para>Set the <literal>nova</literal> group to the same number in the <literal>/etc/group</literal> file on all
hosts. For example, set the group to <literal>120</literal>.</para>
            </step>
            <step>
              <para>Set the <literal>libvirtd</literal> group to the same number in the <literal>/etc/group</literal> file on
all hosts. For example, set the group to <literal>119</literal>.</para>
            </step>
            <step>
              <para>Stop the services on the compute node.</para>
            </step>
            <step>
              <para>Change all files that the nova user or group owns. For example:</para>
              <screen language="console"># find / -uid 108 -exec chown nova {} \;
# note the 108 here is the old nova UID before the change
# find / -gid 120 -exec chgrp nova {} \;</screen>
            </step>
            <step>
              <para>Repeat all steps for the <literal>libvirt-qemu</literal> files, if required.</para>
            </step>
            <step>
              <para>Restart the services.</para>
            </step>
            <step>
              <para>To verify that all files use the correct IDs, run the <command>find</command>
command.</para>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Recover cloud after disaster</title>
          <para>This section describes how to manage your cloud after a disaster and back up
persistent storage volumes. Backups are mandatory, even outside of disaster
scenarios.</para>
          <para>For a definition of a disaster recovery plan (DRP), see
<link xlink:href="http://en.wikipedia.org/wiki/Disaster_Recovery_Plan">http://en.wikipedia.org/wiki/Disaster_Recovery_Plan</link>.</para>
          <para>A disk crash, network loss, or power failure can affect several components in
your cloud architecture. The worst disaster for a cloud is a power loss. A
power loss affects these components:</para>
          <itemizedlist>
            <listitem>
              <para>A cloud controller (<literal>nova-api</literal>, <literal>nova-objectstore</literal>, <literal>nova-network</literal>)</para>
            </listitem>
            <listitem>
              <para>A compute node (<literal>nova-compute</literal>)</para>
            </listitem>
            <listitem>
              <para>A storage area network (SAN) used by OpenStack Block Storage
(<literal>cinder-volumes</literal>)</para>
            </listitem>
          </itemizedlist>
          <para>Before a power loss:</para>
          <itemizedlist>
            <listitem>
              <para>Create an active iSCSI session from the SAN to the cloud controller
(used for the <literal>cinder-volumes</literal> LVM's VG).</para>
            </listitem>
            <listitem>
              <para>Create an active iSCSI session from the cloud controller to the compute
node (managed by <literal>cinder-volume</literal>).</para>
            </listitem>
            <listitem>
              <para>Create an iSCSI session for every volume (so 14 EBS volumes requires 14
iSCSI sessions).</para>
            </listitem>
            <listitem>
              <para>Create <literal>iptables</literal> or <literal>ebtables</literal> rules from the cloud controller to the
compute node. This allows access from the cloud controller to the
running instance.</para>
            </listitem>
            <listitem>
              <para>Save the current state of the database, the current state of the running
instances, and the attached volumes (mount point, volume ID, volume
status, etc), at least from the cloud controller to the compute node.</para>
            </listitem>
          </itemizedlist>
          <para>After power resumes and all hardware components restart:</para>
          <itemizedlist>
            <listitem>
              <para>The iSCSI session from the SAN to the cloud no longer exists.</para>
            </listitem>
            <listitem>
              <para>The iSCSI session from the cloud controller to the compute node no
longer exists.</para>
            </listitem>
            <listitem>
              <para>nova-network reapplies configurations on boot and, as a result, recreates
the iptables and ebtables from the cloud controller to the compute node.</para>
            </listitem>
            <listitem>
              <para>Instances stop running.</para>
              <para>Instances are not lost because neither <literal>destroy</literal> nor <literal>terminate</literal> ran.
The files for the instances remain on the compute node.</para>
            </listitem>
            <listitem>
              <para>The database does not update.</para>
            </listitem>
          </itemizedlist>
          <para>
            <emphasis role="bold">Begin recovery</emphasis>
          </para>
          <warning>
            <para>Do not add any steps or change the order of steps in this procedure.</para>
          </warning>
          <procedure>
            <step>
              <para>Check the current relationship between the volume and its instance, so
that you can recreate the attachment.</para>
              <para>Use the <command>openstack volume list</command> command to get this information.
Note that the <command>openstack</command> client can get volume information
from OpenStack Block Storage.</para>
            </step>
            <step>
              <para>Update the database to clean the stalled state. Do this for every
volume by using these queries:</para>
              <screen language="mysql">mysql&gt; use cinder;
mysql&gt; update volumes set mountpoint=NULL;
mysql&gt; update volumes set status="available" where status &lt;&gt;"error_deleting";
mysql&gt; update volumes set attach_status="detached";
mysql&gt; update volumes set instance_id=0;</screen>
              <para>Use <command>openstack volume list</command> command to list all volumes.</para>
            </step>
            <step>
              <para>Restart the instances by using the
<command>openstack server reboot INSTANCE</command> command.</para>
              <important>
                <para>Some instances completely reboot and become reachable, while some might
stop at the plymouth stage. This is expected behavior. DO NOT reboot a
second time.</para>
                <para>Instance state at this stage depends on whether you added an
<literal>/etc/fstab</literal> entry for that volume. Images built with the cloud-init
package remain in a <literal>pending</literal> state, while others skip the missing
volume and start. You perform this step to ask Compute to reboot every
instance so that the stored state is preserved. It does not matter if
not all instances come up successfully. For more information about
cloud-init, see
<link xlink:href="https://help.ubuntu.com/community/CloudInit/">help.ubuntu.com/community/CloudInit/</link>.</para>
              </important>
            </step>
            <step>
              <para>If required, run the <command>openstack server add volume</command> command to
reattach the volumes to their respective instances. This example uses
a file of listed volumes to reattach them:</para>
              <screen language="bash">#!/bin/bash

while read line; do
    volume=`echo $line | $CUT -f 1 -d " "`
    instance=`echo $line | $CUT -f 2 -d " "`
    mount_point=`echo $line | $CUT -f 3 -d " "`
        echo "ATTACHING VOLUME FOR INSTANCE - $instance"
    openstack server add volume $instance $volume $mount_point
    sleep 2
done &lt; $volumes_tmp_file</screen>
              <para>Instances that were stopped at the plymouth stage now automatically
continue booting and start normally. Instances that previously started
successfully can now see the volume.</para>
            </step>
            <step>
              <para>Log in to the instances with SSH and reboot them.</para>
              <para>If some services depend on the volume or if a volume has an entry in fstab,
you can now restart the instance. Restart directly from the instance itself
and not through <command>nova</command>:</para>
              <screen language="console"># shutdown -r now</screen>
              <para>When you plan for and complete a disaster recovery, follow these tips:</para>
            </step>
          </procedure>
          <itemizedlist>
            <listitem>
              <para>Use the <literal>errors=remount</literal> option in the <literal>fstab</literal> file to prevent
data corruption.</para>
              <para>In the event of an I/O error, this option prevents writes to the disk. Add
this configuration option into the cinder-volume server that performs the
iSCSI connection to the SAN and into the instances' <literal>fstab</literal> files.</para>
            </listitem>
            <listitem>
              <para>Do not add the entry for the SAN's disks to the cinder-volume's
<literal>fstab</literal> file.</para>
              <para>Some systems hang on that step, which means you could lose access to
your cloud-controller. To re-run the session manually, run this
command before performing the mount:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?># iscsiadm -m discovery -t st -p $SAN_IP $ iscsiadm -m node --target-name $IQN -p $SAN_IP -l</screen>
            </listitem>
            <listitem>
              <para>On your instances, if you have the whole <literal>/home/</literal> directory on the
disk, leave a user's directory with the user's bash files and the
<literal>authorized_keys</literal> file instead of emptying the <literal>/home/</literal> directory
and mapping the disk on it.</para>
              <para>This action enables you to connect to the instance without the volume
attached, if you allow only connections through public keys.</para>
            </listitem>
          </itemizedlist>
          <para>To script the disaster recovery plan (DRP), use the
<link xlink:href="https://github.com/Razique/BashStuff/blob/master/SYSTEMS/OpenStack/SCR_5006_V00_NUAC-OPENSTACK-DRP-OpenStack.sh">https://github.com/Razique</link> bash script.</para>
          <para>This script completes these steps:</para>
          <procedure>
            <step>
              <para>Creates an array for instances and their attached volumes.</para>
            </step>
            <step>
              <para>Updates the MySQL database.</para>
            </step>
            <step>
              <para>Restarts all instances with euca2ools.</para>
            </step>
            <step>
              <para>Reattaches the volumes.</para>
            </step>
            <step>
              <para>Uses Compute credentials to make an SSH connection into every instance.</para>
            </step>
          </procedure>
          <para>The script includes a <literal>test mode</literal>, which enables you to perform the sequence
for only one instance.</para>
          <para>To reproduce the power loss, connect to the compute node that runs that
instance and close the iSCSI session. Do not detach the volume by using the
<command>openstack server remove volume</command> command. You must manually close the
iSCSI session. This example closes an iSCSI session with the number <literal>15</literal>:</para>
          <screen language="console"># iscsiadm -m session -u -r 15</screen>
          <para>Do not forget the <literal>-r</literal> option. Otherwise, all sessions close.</para>
          <warning>
            <para>There is potential for data loss while running instances during
this procedure. If you are using Liberty or earlier, ensure you have the
correct patch and set the options appropriately.</para>
          </warning>
        </sect3>
      </sect2>
      <sect2>
        <title>Advanced configuration</title>
        <para>OpenStack clouds run on platforms that differ greatly in the capabilities that
they provide. By default, the Compute service seeks to abstract the underlying
hardware that it runs on, rather than exposing specifics about the underlying
host platforms. This abstraction manifests itself in many ways. For example,
rather than exposing the types and topologies of CPUs running on hosts, the
service exposes a number of generic CPUs (virtual CPUs, or vCPUs) and allows
for overcommitting of these. In a similar manner, rather than exposing the
individual types of network devices available on hosts, generic
software-powered network ports are provided. These features are designed to
allow high resource utilization and allows the service to provide a generic
cost-effective and highly scalable cloud upon which to build applications.</para>
        <para>This abstraction is beneficial for most workloads. However, there are some
workloads where determinism and per-instance performance are important, if
not vital. In these cases, instances can be expected to deliver near-native
performance. The Compute service provides features to improve individual
instance for these kind of workloads.</para>
        <sect3>
          <title>Attaching physical PCI devices to guests</title>
          <para>The PCI passthrough feature in OpenStack allows full access and direct control
of a physical PCI device in guests. This mechanism is generic for any kind of
PCI device, and runs with a Network Interface Card (NIC), Graphics Processing
Unit (GPU), or any other devices that can be attached to a PCI bus. Correct
driver installation is the only requirement for the guest to properly
use the devices.</para>
          <para>Some PCI devices provide Single Root I/O Virtualization and Sharing (SR-IOV)
capabilities. When SR-IOV is used, a physical device is virtualized and appears
as multiple PCI devices. Virtual PCI devices are assigned to the same or
different guests. In the case of PCI passthrough, the full physical device is
assigned to only one guest and cannot be shared.</para>
          <note>
            <para>For information on attaching virtual SR-IOV devices to guests, refer to the
<link xlink:href="http://docs.openstack.org/newton/networking-guide/config-sriov.html">Networking Guide</link>.</para>
          </note>
          <para>To enable PCI passthrough, follow the steps below:</para>
          <procedure>
            <step>
              <para>Configure nova-scheduler (Controller)</para>
            </step>
            <step>
              <para>Configure nova-api (Controller)**</para>
            </step>
            <step>
              <para>Configure a flavor (Controller)</para>
            </step>
            <step>
              <para>Enable PCI passthrough (Compute)</para>
            </step>
            <step>
              <para>Configure PCI devices in nova-compute (Compute)</para>
            </step>
          </procedure>
          <note>
            <para>The PCI device with address <literal>0000:41:00.0</literal> is used as an example. This
will differ between environments.</para>
          </note>
          <sect4>
            <title>Configure nova-scheduler (Controller)</title>
            <procedure>
              <step>
                <para>Configure <literal>nova-scheduler</literal> as specified in <link xlink:href="http://docs.openstack.org/newton/networking-guide/config-sriov.html#configure-nova-scheduler-controller">Configure nova-scheduler</link>.</para>
              </step>
              <step>
                <para>Restart the <literal>nova-scheduler</literal> service.</para>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>Configure nova-api (Controller)</title>
            <procedure>
              <step>
                <para>Specify the PCI alias for the device.</para>
                <para>Configure a PCI alias <literal>a1</literal> to request a PCI device with a <literal>vendor_id</literal> of
<literal>0x8086</literal> and a <literal>product_id</literal> of <literal>0x154d</literal>. The <literal>vendor_id</literal> and
<literal>product_id</literal> correspond the PCI device with address <literal>0000:41:00.0</literal>.</para>
                <para>Edit <literal>/etc/nova/nova.conf</literal>:</para>
                <screen language="ini"><?dbsuse-fo font-size="8pt"?>[default]
pci_alias = { "vendor_id":"8086", "product_id":"154d", "device_type":"type-PF", "name":"a1" }</screen>
                <para>For more information about the syntax of <literal>pci_alias</literal>, refer to <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/config-options.html">nova.conf
configuration options</link>.</para>
              </step>
              <step>
                <para>Restart the <literal>nova-api</literal> service.</para>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>Configure a flavor (Controller)</title>
            <para>Configure a flavor to request two PCI devices, each with <literal>vendor_id</literal> of
<literal>0x8086</literal> and <literal>product_id</literal> of <literal>0x154d</literal>:</para>
            <screen language="console"># openstack flavor set m1.large --property "pci_passthrough:alias"="a1:2"</screen>
            <para>For more information about the syntax for <literal>pci_passthrough:alias</literal>, refer to
<link xlink:href="http://docs.openstack.org/admin-guide/compute-flavors.html">flavor</link>.</para>
          </sect4>
          <sect4>
            <title>Enable PCI passthrough (Compute)</title>
            <para>Enable VT-d and IOMMU. For more information, refer to steps one and two in
<link xlink:href="http://docs.openstack.org/newton/networking-guide/config-sriov.html#create-virtual-functions-compute">Create Virtual Functions</link>.</para>
          </sect4>
          <sect4>
            <title>Configure PCI devices (Compute)</title>
            <procedure>
              <step>
                <para>Configure <literal>nova-compute</literal> to allow the PCI device to pass through to
VMs. Edit <literal>/etc/nova/nova.conf</literal>:</para>
                <screen language="ini">[default]
pci_passthrough_whitelist = { "address": "0000:41:00.0" }</screen>
                <para>Alternatively specify multiple PCI devices using whitelisting:</para>
                <screen language="ini">[default]
pci_passthrough_whitelist = { "vendor_id": "8086", "product_id": "10fb" }</screen>
                <para>All PCI devices matching the <literal>vendor_id</literal> and <literal>product_id</literal> are added to
the pool of PCI devices available for passthrough to VMs.</para>
                <para>For more information about the syntax of <literal>pci_passthrough_whitelist</literal>,
refer to <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/config-options.html">nova.conf configuration options</link>.</para>
              </step>
              <step>
                <para>Specify the PCI alias for the device.</para>
                <para>From the Newton release, to resize guest with PCI device, configure the PCI
alias on the compute node as well.</para>
                <para>Configure a PCI alias <literal>a1</literal> to request a PCI device with a <literal>vendor_id</literal> of
<literal>0x8086</literal> and a <literal>product_id</literal> of <literal>0x154d</literal>. The <literal>vendor_id</literal> and
<literal>product_id</literal> correspond the PCI device with address <literal>0000:41:00.0</literal>.</para>
                <para>Edit <literal>/etc/nova/nova.conf</literal>:</para>
                <screen language="ini"><?dbsuse-fo font-size="8pt"?>[default]
pci_alias = { "vendor_id":"8086", "product_id":"154d", "device_type":"type-PF", "name":"a1" }</screen>
                <para>For more information about the syntax of <literal>pci_alias</literal>, refer to <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/config-options.html">nova.conf
configuration options</link>.</para>
              </step>
              <step>
                <para>Restart the <literal>nova-compute</literal> service.</para>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>Create instances with PCI passthrough devices</title>
            <para>The <literal>nova-scheduler</literal> selects a destination host that has PCI devices
available with the specified <literal>vendor_id</literal> and <literal>product_id</literal> that matches the
<literal>pci_alias</literal> from the flavor.</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?># openstack server create --flavor m1.large --image cirros-0.3.4-x86_64-uec --wait test-pci</screen>
          </sect4>
        </sect3>
        <sect3 xml:id="sec.cpu.topo">
          <title>CPU topologies</title>
          <para>The NUMA topology and CPU pinning features in OpenStack provide high-level
control over how instances run on hypervisor CPUs and the topology of virtual
CPUs available to instances. These features help minimize latency and maximize
performance.</para>
          <sect4>
            <title>SMP, NUMA, and SMT</title>
            <variablelist>
              <varlistentry>
                <term>Symmetric multiprocessing (SMP)</term>
                <listitem>
                  <para>SMP is a design found in many modern multi-core systems. In an SMP system,
there are two or more CPUs and these CPUs are connected by some interconnect.
This provides CPUs with equal access to system resources like memory and
input/output ports.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Non-uniform memory access (NUMA)</term>
                <listitem>
                  <para>NUMA is a derivative of the SMP design that is found in many multi-socket
systems. In a NUMA system, system memory is divided into cells or nodes that
are associated with particular CPUs. Requests for memory on other nodes are
possible through an interconnect bus. However, bandwidth across this shared
bus is limited. As a result, competition for this resource can incur
performance penalties.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Simultaneous Multi-Threading (SMT)</term>
                <listitem>
                  <para>SMT is a design complementary to SMP. Whereas CPUs in SMP systems share a bus
and some memory, CPUs in SMT systems share many more components. CPUs that
share components are known as thread siblings.  All CPUs appear as usable
CPUs on the system and can execute workloads in parallel. However, as with
NUMA, threads compete for shared resources.</para>
                </listitem>
              </varlistentry>
            </variablelist>
            <para>In OpenStack, SMP CPUs are known as <emphasis>cores</emphasis>, NUMA cells or nodes are known as
<emphasis>sockets</emphasis>, and SMT CPUs are known as <emphasis>threads</emphasis>. For example, a quad-socket,
eight core system with Hyper-Threading would have four sockets, eight cores per
socket and two threads per core, for a total of 64 CPUs.</para>
          </sect4>
          <sect4>
            <title>Customizing instance NUMA placement policies</title>
            <important>
              <para>The functionality described below is currently only supported by the
libvirt/KVM driver.</para>
            </important>
            <para>When running workloads on NUMA hosts, it is important that the vCPUs executing
processes are on the same NUMA node as the memory used by these processes.
This ensures all memory accesses are local to the node and thus do not consume
the limited cross-node memory bandwidth, adding latency to memory accesses.
Similarly, large pages are assigned from memory and benefit from the same
performance improvements as memory allocated using standard pages. Thus, they
also should be local. Finally, PCI devices are directly associated with
specific NUMA nodes for the purposes of DMA. Instances that use PCI or SR-IOV
devices should be placed on the NUMA node associated with these devices.</para>
            <para>By default, an instance floats across all NUMA nodes on a host. NUMA awareness
can be enabled implicitly through the use of huge pages or pinned CPUs or
explicitly through the use of flavor extra specs or image metadata.  In all
cases, the <literal>NUMATopologyFilter</literal> filter must be enabled. Details on this
filter are provided in <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/scheduler.html">Scheduling</link> configuration guide.</para>
            <important>
              <para>The NUMA node(s) used are normally chosen at random. However, if a PCI
passthrough or SR-IOV device is attached to the instance, then the NUMA
node that the device is associated with will be used. This can provide
important performance improvements. However, booting a large number of
similar instances can result in unbalanced NUMA node usage. Care should
be taken to mitigate this issue. See this <link xlink:href="http://lists.openstack.org/pipermail/openstack-dev/2016-March/090367.html">discussion</link> for more details.</para>
            </important>
            <important>
              <para>Inadequate per-node resources will result in scheduling failures. Resources
that are specific to a node include not only CPUs and memory, but also PCI
and SR-IOV resources. It is not possible to use multiple resources from
different nodes without requesting a multi-node layout. As such, it may be
necessary to ensure PCI or SR-IOV resources are associated with the same
NUMA node or force a multi-node layout.</para>
            </important>
            <para>When used, NUMA awareness allows the operating system of the instance to
intelligently schedule the workloads that it runs and minimize cross-node
memory bandwidth. To restrict an instance's vCPUs to a single host NUMA node,
run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:numa_nodes=1</screen>
            <para>Some workloads have very demanding requirements for memory access latency or
bandwidth that exceed the memory bandwidth available from a single NUMA node.
For such workloads, it is beneficial to spread the instance across multiple
host NUMA nodes, even if the instance's RAM/vCPUs could theoretically fit on a
single NUMA node. To force an instance's vCPUs to spread across two host NUMA
nodes, run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:numa_nodes=2</screen>
            <para>The allocation of instances vCPUs and memory from different host NUMA nodes can
be configured. This allows for asymmetric allocation of vCPUs and memory, which
can be important for some workloads. To spread the 6 vCPUs and 6 GB of memory
of an instance across two NUMA nodes and create an asymmetric 1:2 vCPU and
memory mapping between the two nodes, run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:numa_nodes=2
$ openstack flavor set m1.large \  # configure guest node 0
  --property hw:numa_cpus.0=0,1 \
  --property hw:numa_mem.0=2048
$ openstack flavor set m1.large \  # configure guest node 1
  --property hw:numa_cpus.1=2,3,4,5 \
  --property hw:numa_mem.1=4096</screen>
            <para>For more information about the syntax for <literal>hw:numa_nodes</literal>, <literal>hw:numa_cpus.N</literal>
and <literal>hw:num_mem.N</literal>, refer to the <link xlink:href="http://docs.openstack.org/admin-guide/compute-flavors.html">Flavors</link> guide.</para>
          </sect4>
          <sect4>
            <title>Customizing instance CPU pinning policies</title>
            <important>
              <para>The functionality described below is currently only supported by the
libvirt/KVM driver.</para>
            </important>
            <para>By default, instance vCPU processes are not assigned to any particular host
CPU, instead, they float across host CPUs like any other process. This allows
for features like overcommitting of CPUs. In heavily contended systems, this
provides optimal system performance at the expense of performance and latency
for individual instances.</para>
            <para>Some workloads require real-time or near real-time behavior, which is not
possible with the latency introduced by the default CPU policy. For such
workloads, it is beneficial to control which host CPUs are bound to an
instance's vCPUs. This process is known as pinning. No instance with pinned
CPUs can use the CPUs of another pinned instance, thus preventing resource
contention between instances. To configure a flavor to use pinned vCPUs, a
use a dedicated CPU policy. To force this, run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:cpu_policy=dedicated</screen>
            <important>
              <para>Host aggregates should be used to separate pinned instances from unpinned
instances as the latter will not respect the resourcing requirements of
the former.</para>
            </important>
            <para>When running workloads on SMT hosts, it is important to be aware of the impact
that thread siblings can have. Thread siblings share a number of components
and contention on these components can impact performance. To configure how
to use threads, a CPU thread policy should be specified. For workloads where
sharing benefits performance, use thread siblings. To force this, run:</para>
            <screen language="console">$ openstack flavor set m1.large \
  --property hw:cpu_policy=dedicated \
  --property hw:cpu_thread_policy=require</screen>
            <para>For other workloads where performance is impacted by contention for resources,
use non-thread siblings or non-SMT hosts. To force this, run:</para>
            <screen language="console">$ openstack flavor set m1.large \
  --property hw:cpu_policy=dedicated \
  --property hw:cpu_thread_policy=isolate</screen>
            <para>Finally, for workloads where performance is minimally impacted, use thread
siblings if available. This is the default, but it can be set explicitly:</para>
            <screen language="console">$ openstack flavor set m1.large \
  --property hw:cpu_policy=dedicated \
  --property hw:cpu_thread_policy=prefer</screen>
            <para>For more information about the syntax for <literal>hw:cpu_policy</literal> and
<literal>hw:cpu_thread_policy</literal>, refer to the <link xlink:href="http://docs.openstack.org/admin-guide/compute-flavors.html">Flavors</link> guide.</para>
            <para>Applications are frequently packaged as images. For applications that require
real-time or near real-time behavior, configure image metadata to ensure
created instances are always pinned regardless of flavor. To configure an
image to use pinned vCPUs and avoid thread siblings, run:</para>
            <screen language="console">$ openstack image set [IMAGE_ID] \
  --property hw_cpu_policy=dedicated \
  --property hw_cpu_thread_policy=isolate</screen>
            <para>Image metadata takes precedence over flavor extra specs. Thus, configuring
competing policies causes an exception. By setting a <literal>shared</literal> policy
through image metadata, administrators can prevent users configuring CPU
policies in flavors and impacting resource utilization. To configure this
policy, run:</para>
            <screen language="console">$ openstack image set [IMAGE_ID] --property hw_cpu_policy=shared</screen>
            <note>
              <para>There is no correlation required between the NUMA topology exposed in the
instance and how the instance is actually pinned on the host. This is by
design. See this <link xlink:href="https://bugs.launchpad.net/nova/+bug/1466780">invalid bug</link> for more information.</para>
            </note>
            <para>For more information about image metadata, refer to the <link xlink:href="http://docs.openstack.org/image-guide/image-metadata.html">Image metadata</link>
guide.</para>
          </sect4>
          <sect4>
            <title>Customizing instance CPU topologies</title>
            <important>
              <para>The functionality described below is currently only supported by the
libvirt/KVM driver.</para>
            </important>
            <para>In addition to configuring how an instance is scheduled on host CPUs, it is
possible to configure how CPUs are represented in the instance itself. By
default, when instance NUMA placement is not specified, a topology of N
sockets, each with one core and one thread, is used for an instance, where N
corresponds to the number of instance vCPUs requested. When instance NUMA
placement is specified, the number of sockets is fixed to the number of host
NUMA nodes to use and the total number of instance CPUs is split over these
sockets.</para>
            <para>Some workloads benefit from a custom topology. For example, in some operating
systems, a different license may be needed depending on the number of CPU
sockets. To configure a flavor to use a maximum of two sockets, run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:cpu_sockets=2</screen>
            <para>Similarly, to configure a flavor to use one core and one thread, run:</para>
            <screen language="console">$ openstack flavor set m1.large \
  --property hw:cpu_cores=1 \
  --property hw:cpu_threads=1</screen>
            <important>
              <para>If specifying all values, the product of sockets multiplied by cores
multiplied by threads must equal the number of instance vCPUs. If specifying
any one of these values or the multiple of two values, the values must be a
factor of the number of instance vCPUs to prevent an exception. For example,
specifying <literal>hw:cpu_sockets=2</literal> on a host with an odd number of cores fails.
Similarly, specifying <literal>hw:cpu_cores=2</literal> and <literal>hw:cpu_threads=4</literal> on a host
with ten cores fails.</para>
            </important>
            <para>For more information about the syntax for <literal>hw:cpu_sockets</literal>, <literal>hw:cpu_cores</literal>
and <literal>hw:cpu_threads</literal>, refer to the <link xlink:href="http://docs.openstack.org/admin-guide/compute-flavors.html">Flavors</link> guide.</para>
            <para>It is also possible to set upper limits on the number of sockets, cores, and
threads used. Unlike the hard values above, it is not necessary for this exact
number to used because it only provides a limit. This can be used to provide
some flexibility in scheduling, while ensuring certains limits are not
exceeded. For example, to ensure no more than two sockets are defined in the
instance topology, run:</para>
            <screen language="console">$ openstack flavor set m1.large --property=hw:cpu_max_sockets=2</screen>
            <para>For more information about the syntax for <literal>hw:cpu_max_sockets</literal>,
<literal>hw:cpu_max_cores</literal>, and <literal>hw:cpu_max_threads</literal>, refer to the <link xlink:href="http://docs.openstack.org/admin-guide/compute-flavors.html">Flavors</link>
guide.</para>
            <para>Applications are frequently packaged as images. For applications that prefer
certain CPU topologies, configure image metadata to hint that created instances
should have a given topology regardless of flavor. To configure an image to
request a two-socket, four-core per socket topology, run:</para>
            <screen language="console">$ openstack image set [IMAGE_ID] \
  --property hw_cpu_sockets=2 \
  --property hw_cpu_cores=4</screen>
            <para>To constrain instances to a given limit of sockets, cores or threads, use the
<literal>max_</literal> variants. To configure an image to have a maximum of two sockets and a
maximum of one thread, run:</para>
            <screen language="console">$ openstack image set [IMAGE_ID] \
  --property hw_cpu_max_sockets=2 \
  --property hw_cpu_max_threads=1</screen>
            <para>Image metadata takes precedence over flavor extra specs. Configuring competing
constraints causes an exception. By setting a <literal>max</literal> value for sockets, cores,
or threads, administrators can prevent users configuring topologies that might,
for example, incur an additional licensing fees.</para>
            <para>For more information about image metadata, refer to the <link xlink:href="http://docs.openstack.org/image-guide/image-metadata.html">Image metadata</link>
guide.</para>
          </sect4>
        </sect3>
        <sect3>
          <title>Huge pages</title>
          <para>The huge page feature in OpenStack provides important performance improvements
for applications that are highly memory IO-bound.</para>
          <note>
            <para>Huge pages may also be referred to hugepages or large pages, depending on
the source. These terms are synonyms.</para>
          </note>
          <sect4>
            <title>Pages, the TLB and huge pages</title>
            <variablelist>
              <varlistentry>
                <term>Pages</term>
                <listitem>
                  <para>Physical memory is segmented into a series of contiguous regions called
pages. Each page contains a number of bytes, referred to as the page size.
The system retrieves memory by accessing entire pages, rather than byte by
byte.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Translation Lookaside Buffer (TLB)</term>
                <listitem>
                  <para>A TLB is used to map the virtual addresses of pages to the physical addresses
in actual memory. The TLB is a cache and is not limitless, storing only the
most recent or frequently accessed pages. During normal operation, processes
will sometimes attempt to retrieve pages that are not stored in the cache.
This is known as a TLB miss and results in a delay as the processor iterates
through the pages themselves to find the missing address mapping.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Huge Pages</term>
                <listitem>
                  <para>The standard page size in x86 systems is 4 kB. This is optimal for general
purpose computing but larger page sizes - 2 MB and 1 GB - are also available.
These larger page sizes are known as huge pages. Huge pages result in less
efficient memory usage as a process will not generally use all memory
available in each page. However, use of huge pages will result in fewer
overall pages and a reduced risk of TLB misses. For processes that have
significant memory requirements or are memory intensive, the benefits of huge
pages frequently outweigh the drawbacks.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Persistent Huge Pages</term>
                <listitem>
                  <para>On Linux hosts, persistent huge pages are huge pages that are reserved
upfront. The HugeTLB provides for the mechanism for this upfront
configuration of huge pages. The HugeTLB allows for the allocation of varying
quantities of different huge page sizes. Allocation can be made at boot time
or run time. Refer to the <link xlink:href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt">Linux hugetlbfs guide</link> for more information.</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>Transparent Huge Pages (THP)</term>
                <listitem>
                  <para>On Linux hosts, transparent huge pages are huge pages that are automatically
provisioned based on process requests. Transparent huge pages are provisioned
on a best effort basis, attempting to provision 2 MB huge pages if available
but falling back to 4 kB small pages if not. However, no upfront
configuration is necessary. Refer to the <link xlink:href="https://www.kernel.org/doc/Documentation/vm/transhuge.txt">Linux THP guide</link> for more
information.</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </sect4>
          <sect4>
            <title>Enabling huge pages on the host</title>
            <para>Persistent huge pages are required owing to their guaranteed availability.
However, persistent huge pages are not enabled by default in most environments.
The steps for enabling huge pages differ from platform to platform and only the
steps for Linux hosts are described here. On Linux hosts, the number of
persistent huge pages on the host can be queried by checking <literal>/proc/meminfo</literal>:</para>
            <screen language="console">$ grep Huge /proc/meminfo
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB</screen>
            <para>In this instance, there are 0 persistent huge pages (<literal>HugePages_Total</literal>) and 0
transparent huge pages (<literal>AnonHugePages</literal>) allocated. Huge pages can be
allocated at boot time or run time. Huge pages require a contiguous area of
memory - memory that gets increasingly fragmented the long a host is running.
Identifying contiguous areas of memory is a issue for all huge page sizes, but
it's particularly problematic for larger huge page sizes such as 1 GB huge
pages. Allocating huge pages at boot time will ensure the correct number of huge
pages is always available, while allocating them at run time can fail if memory
has become too fragmented.</para>
            <para>To allocate huge pages at run time, the kernel boot parameters must be extended
to include some huge page-specific parameters. This can be achieved by
modifying <literal>/etc/default/grub</literal> and appending the <literal>hugepagesz</literal>,
<literal>hugepages</literal>, and <literal>transparent_hugepages=never</literal> arguments to
<literal>GRUB_CMDLINE_LINUX</literal>. To allocate, for example, 2048 persistent 2 MB huge
pages at boot time, run:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?># echo 'GRUB_CMDLINE_LINUX="$GRUB_CMDLINE_LINUX hugepagesz=2M hugepages=2048 transparent_hugepage=never"' &gt; /etc/default/grub
$ grep GRUB_CMDLINE_LINUX /etc/default/grub
GRUB_CMDLINE_LINUX="..."
GRUB_CMDLINE_LINUX="$GRUB_CMDLINE_LINUX hugepagesz=2M hugepages=2048 transparent_hugepage=never"</screen>
            <important>
              <para>Persistent huge pages are not usable by standard host OS processes. Ensure
enough free, non-huge page memory is reserved for these processes.</para>
            </important>
            <para>Reboot the host, then validate that huge pages are now available:</para>
            <screen language="console">$ grep "Huge" /proc/meminfo
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
HugePages_Total:    2048
HugePages_Free:     2048
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB</screen>
            <para>There are now 2048 2 MB huge pages totalling 4 GB of huge pages. These huge
pages must be mounted. On most platforms, this happens automatically. To verify
that the huge pages are mounted, run:</para>
            <screen language="console"># mount | grep huge
hugetlbfs on /dev/hugepages type hugetlbfs (rw)</screen>
            <para>In this instance, the huge pages are mounted at <literal>/dev/hugepages</literal>. This mount
point varies from platform to platform. If the above command did not return
anything, the hugepages must be mounted manually. To mount the huge pages at
<literal>/dev/hugepages</literal>, run:</para>
            <screen language="console"># mkdir -p /dev/hugepages
# mount -t hugetlbfs hugetlbfs /dev/hugepages</screen>
            <para>There are many more ways to configure huge pages, including allocating huge
pages at run time, specifying varying allocations for different huge page
sizes, or allocating huge pages from memory affinitized to different NUMA
nodes. For more information on configuring huge pages on Linux hosts, refer to
the <link xlink:href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt">Linux hugetlbfs guide</link>.</para>
          </sect4>
          <sect4>
            <title>Customizing instance huge pages allocations</title>
            <important>
              <para>The functionality described below is currently only supported by the
libvirt/KVM driver.</para>
            </important>
            <important>
              <para>For performance reasons, configuring huge pages for an instance will
implicitly result in a NUMA topology being configured for the instance.
Configuring a NUMA topology for an instance requires enablement of
<literal>NUMATopologyFilter</literal>. Refer to <xref linkend="sec.cpu.topo"/> for more
information.</para>
            </important>
            <para>By default, an instance does not use huge pages for its underlying memory.
However, huge pages can bring important or required performance improvements
for some workloads. Huge pages must be requested explicitly through the use of
flavor extra specs or image metadata. To request an instance use huge pages,
run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:mem_page_size=large</screen>
            <para>Different platforms offer different huge page sizes. For example: x86-based
platforms offer 2 MB and 1 GB huge page sizes. Specific huge page sizes can be
also be requested, with or without a unit suffix. The unit suffix must be one
of: Kb(it), Kib(it), Mb(it), Mib(it), Gb(it), Gib(it), Tb(it), Tib(it), KB,
KiB, MB, MiB, GB, GiB, TB, TiB. Where a unit suffix is not provided, Kilobytes
are assumed. To request an instance to use 2 MB huge pages, run one of:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:mem_page_size=2Mb</screen>
            <screen language="console">$ openstack flavor set m1.large --property hw:mem_page_size=2048</screen>
            <para>Enabling huge pages for an instance can have negative consequences for other
instances by consuming limited huge pages resources. To explicitly request
an instance use small pages, run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:mem_page_size=small</screen>
            <note>
              <para>Explicitly requesting any page size will still result in a NUMA topology
being applied to the instance, as described earlier in this document.</para>
            </note>
            <para>Finally, to leave the decision of huge or small pages to the compute driver,
run:</para>
            <screen language="console">$ openstack flavor set m1.large --property hw:mem_page_size=any</screen>
            <para>For more information about the syntax for <literal>hw:mem_page_size</literal>, refer to the
<link xlink:href="http://docs.openstack.org/admin-guide/compute-flavors.html">Flavors</link> guide.</para>
            <para>Applications are frequently packaged as images. For applications that require
the IO performance improvements that huge pages provides, configure image
metadata to ensure instances always request the specific page size regardless
of flavor. To configure an image to use 1 GB huge pages, run:</para>
            <screen language="console">$ openstack image set [IMAGE_ID]  --property hw_mem_page_size=1GB</screen>
            <para>Image metadata takes precedence over flavor extra specs. Thus, configuring
competing page sizes causes an exception. By setting a <literal>small</literal> page size
through image metadata, administrators can prevent users requesting huge pages
in flavors and impacting resource utilization. To configure this page size,
run:</para>
            <screen language="console">$ openstack image set [IMAGE_ID] --property hw_mem_page_size=small</screen>
            <note>
              <para>Explicitly requesting any page size will still result in a NUMA topology
being applied to the instance, as described earlier in this document.</para>
            </note>
            <para>For more information about image metadata, refer to the <link xlink:href="http://docs.openstack.org/image-guide/image-metadata.html">Image metadata</link>
guide.</para>
          </sect4>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Troubleshoot Compute</title>
      <para>Common problems for Compute typically involve misconfigured
networking or credentials that are not sourced properly in the
environment. Also, most flat networking configurations do not
enable <command>ping</command> or <command>ssh</command> from a compute node
to the instances that run on that node. Another common problem
is trying to run 32-bit images on a 64-bit compute node.
This section shows you how to troubleshoot Compute.</para>
      <sect2>
        <title>Compute service logging</title>
        <para>Compute stores a log file for each service in
<literal>/var/log/nova</literal>. For example, <literal>nova-compute.log</literal>
is the log for the <literal>nova-compute</literal> service. You can set the
following options to format log strings for the <literal>nova.log</literal>
module in the <literal>nova.conf</literal> file:</para>
        <itemizedlist>
          <listitem>
            <para>
              <literal>logging_context_format_string</literal>
            </para>
          </listitem>
          <listitem>
            <para>
              <literal>logging_default_format_string</literal>
            </para>
          </listitem>
        </itemizedlist>
        <para>If the log level is set to <literal>debug</literal>, you can also specify
<literal>logging_debug_format_suffix</literal> to append extra formatting.
For information about what variables are available for the
formatter, see <link xlink:href="http://docs.python.org/library/logging.html#formatter-objects">Formatter Objects</link>.</para>
        <para>You have two logging options for OpenStack Compute based on
configuration settings. In <literal>nova.conf</literal>, include the
<literal>logfile</literal> option to enable logging. Alternatively you can set
<literal>use_syslog = 1</literal> so that the nova daemon logs to syslog.</para>
      </sect2>
      <sect2>
        <title>Guru Meditation reports</title>
        <para>A Guru Meditation report is sent by the Compute service upon receipt of the
<literal>SIGUSR2</literal> signal (<literal>SIGUSR1</literal> before Mitaka). This report is a
general-purpose error report that includes details about the current state
of the service. The error report is sent to <literal>stderr</literal>.</para>
        <para>For example, if you redirect error output to <literal>nova-api-err.log</literal>
using <command>nova-api 2&gt;/var/log/nova/nova-api-err.log</command>,
resulting in the process ID 8675, you can then run:</para>
        <screen language="console"># kill -USR2 8675</screen>
        <para>This command triggers the Guru Meditation report to be printed to
<literal>/var/log/nova/nova-api-err.log</literal>.</para>
        <para>The report has the following sections:</para>
        <itemizedlist>
          <listitem>
            <para>Package: Displays information about the package to which the process
belongs, including version information.</para>
          </listitem>
          <listitem>
            <para>Threads: Displays stack traces and thread IDs for each of the threads
within the process.</para>
          </listitem>
          <listitem>
            <para>Green Threads: Displays stack traces for each of the green threads
within the process (green threads do not have thread IDs).</para>
          </listitem>
          <listitem>
            <para>Configuration: Lists all configuration options currently accessible
through the CONF object for the current process.</para>
          </listitem>
        </itemizedlist>
        <para>For more information, see <link xlink:href="http://docs.openstack.org/developer/nova/devref/gmr.html">Guru Meditation Reports</link>.</para>
      </sect2>
      <sect2 xml:id="compute-common-errors-and-fixes">
        <title>Common errors and fixes for Compute</title>
        <para>The <link xlink:href="http://ask.openstack.org">ask.openstack.org</link> site offers a place to ask
and answer questions, and you can also mark questions as frequently asked
questions. This section describes some errors people have posted previously.
Bugs are constantly being fixed, so online resources are a great way to get
the most up-to-date errors and fixes.</para>
      </sect2>
      <sect2>
        <title>Credential errors, 401, and 403 forbidden errors</title>
        <sect3>
          <title>Problem</title>
          <para>Missing credentials cause a <literal>403 forbidden</literal> error.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To resolve this issue, use one of these methods:</para>
          <procedure>
            <step>
              <variablelist>
                <varlistentry>
                  <term>Manual method</term>
                  <listitem>
                    <para>Gets the <literal>novarc</literal> file from the project ZIP file, saves existing
credentials in case of override, and manually sources the <literal>novarc</literal>
file.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </step>
            <step>
              <variablelist>
                <varlistentry>
                  <term>Script method</term>
                  <listitem>
                    <para>Generates <literal>novarc</literal> from the project ZIP file and sources it for you.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </step>
          </procedure>
          <para>When you run <literal>nova-api</literal> the first time, it generates the certificate
authority information, including <literal>openssl.cnf</literal>. If you
start the CA services before this, you might not be
able to create your ZIP file. Restart the services.
When your CA information is available, create your ZIP file.</para>
          <para>Also, check your HTTP proxy settings to see whether they cause problems with
<literal>novarc</literal> creation.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Instance errors</title>
        <sect3>
          <title>Problem</title>
          <para>Sometimes a particular instance shows <literal>pending</literal> or you cannot SSH to
it. Sometimes the image itself is the problem. For example, when you
use flat manager networking, you do not have a DHCP server and certain
images do not support interface injection; you cannot connect to
them.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To fix instance errors use an image that does support
this method, such as Ubuntu, which obtains an IP address correctly
with FlatManager network settings.</para>
          <para>To troubleshoot other possible problems with an instance, such as
an instance that stays in a spawning state, check the directory for
the particular instance under <literal>/var/lib/nova/instances</literal> on
the <literal>nova-compute</literal> host and make sure that these files are present:</para>
          <itemizedlist>
            <listitem>
              <para>
                <literal>libvirt.xml</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>disk</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>disk-raw</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>kernel</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>ramdisk</literal>
              </para>
            </listitem>
            <listitem>
              <para><literal>console.log</literal>, after the instance starts.</para>
            </listitem>
          </itemizedlist>
          <para>If any files are missing, empty, or very small, the <literal>nova-compute</literal>
service did not successfully download the images from the Image service.</para>
          <para>Also check <literal>nova-compute.log</literal> for exceptions. Sometimes they do not
appear in the console output.</para>
          <para>Next, check the log file for the instance in the <literal>/var/log/libvirt/qemu</literal>
directory to see if it exists and has any useful error messages in it.</para>
          <para>Finally, from the <literal>/var/lib/nova/instances</literal> directory for the instance,
see if this command returns an error:</para>
          <screen language="console"># virsh create libvirt.xml</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Empty log output for Linux instances</title>
        <sect3>
          <title>Problem</title>
          <para>You can view the log output of running instances
from either the <guimenu>Log</guimenu> tab of the dashboard or the output of
<command>nova console-log</command>. In some cases, the log output of a running
Linux instance will be empty or only display a single character (for example,
the <literal>?</literal> character).</para>
          <para>This occurs when the Compute service attempts to retrieve the log output
of the instance via a serial console while the instance itself is not
configured to send output to the console.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To rectify this, append the following parameters to kernel arguments
specified in the instance's boot loader:</para>
          <screen language="ini">console=tty0 console=ttyS0,115200n8</screen>
          <para>Upon rebooting, the instance will be configured to send output to the Compute
service.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Reset the state of an instance</title>
        <sect3>
          <title>Problem</title>
          <para>Instances can remain in an intermediate state, such as <literal>deleting</literal>.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>You can use the <command>nova reset-state</command> command to manually reset
the state of an instance to an error state. You can then delete the
instance. For example:</para>
          <screen language="console">$ nova reset-state c6bbbf26-b40a-47e7-8d5c-eb17bf65c485
$ openstack server delete c6bbbf26-b40a-47e7-8d5c-eb17bf65c485</screen>
          <para>You can also use the <literal>--active</literal> parameter to force the instance back
to an active state instead of an error state. For example:</para>
          <screen language="console">$ nova reset-state --active c6bbbf26-b40a-47e7-8d5c-eb17bf65c485</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Injection problems</title>
        <sect3>
          <title>Problem</title>
          <para>Instances may boot slowly, or do not boot. File injection can cause this
problem.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To disable injection in libvirt, set the following in <literal>nova.conf</literal>:</para>
          <screen language="ini">[libvirt]
inject_partition = -2</screen>
          <note>
            <para>If you have not enabled the configuration drive and
you want to make user-specified files available from
the metadata server for to improve performance and
avoid boot failure if injection fails, you must
disable injection.</para>
          </note>
        </sect3>
      </sect2>
      <sect2>
        <title>Disable live snapshotting</title>
        <sect3>
          <title>Problem</title>
          <para>Administrators using libvirt version <literal>1.2.2</literal> may experience problems
with live snapshot creation. Occasionally, libvirt version <literal>1.2.2</literal> fails
to create live snapshots under the load of creating concurrent snapshot.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To effectively disable the libvirt live snapshotting, until the problem
is resolved, configure the <literal>disable_libvirt_livesnapshot</literal> option.
You can turn off the live snapshotting mechanism by setting up its value to
<literal>True</literal> in the <literal>[workarounds]</literal> section of the <literal>nova.conf</literal> file:</para>
          <screen language="ini">[workarounds]
disable_libvirt_livesnapshot = True</screen>
        </sect3>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Object Storage</title>
    <info/>
    <sect1>
      <title>Introduction to Object Storage</title>
      <para>OpenStack Object Storage (swift) is used for redundant, scalable data
storage using clusters of standardized servers to store petabytes of
accessible data. It is a long-term storage system for large amounts of
static data which can be retrieved and updated. Object Storage uses a
distributed architecture
with no central point of control, providing greater scalability,
redundancy, and permanence. Objects are written to multiple hardware
devices, with the OpenStack software responsible for ensuring data
replication and integrity across the cluster. Storage clusters scale
horizontally by adding new nodes. Should a node fail, OpenStack works to
replicate its content from other active nodes. Because OpenStack uses
software logic to ensure data replication and distribution across
different devices, inexpensive commodity hard drives and servers can be
used in lieu of more expensive equipment.</para>
      <para>Object Storage is ideal for cost effective, scale-out storage. It
provides a fully distributed, API-accessible storage platform that can
be integrated directly into applications or used for backup, archiving,
and data retention.</para>
    </sect1>
    <sect1>
      <title>Features and benefits</title>
      <informaltable>
        <tgroup cols="2">
          <colspec colname="c1" colwidth="20.0*"/>
          <colspec colname="c2" colwidth="80.0*"/>
          <thead>
            <row>
              <entry>
                <para>Features</para>
              </entry>
              <entry>
                <para>Benefits</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>Leverages commodity hardware</para>
              </entry>
              <entry>
                <para>No lock-in, lower price/GB.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>HDD/node failure agnostic</para>
              </entry>
              <entry>
                <para>Self-healing, reliable, data redundancy protects from failures.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Unlimited storage</para>
              </entry>
              <entry>
                <para>Large and flat namespace, highly scalable read/write access,
able to serve content directly from storage system.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Multi-dimensional scalability</para>
              </entry>
              <entry>
                <para>Scale-out architecture: Scale vertically and
horizontally-distributed storage. Backs up and archives large
amounts of data with linear performance.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Account/container/object structure</para>
              </entry>
              <entry>
                <para>No nesting, not a traditional file system: Optimized for scale,
it scales to multiple petabytes and billions of objects.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Built-in replication 3✕ + data redundancy (compared with 2✕ on
RAID)</para>
              </entry>
              <entry>
                <para>A configurable number of accounts, containers and object copies
for high availability.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Easily add capacity (unlike RAID resize)</para>
              </entry>
              <entry>
                <para>Elastic data scaling with ease.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>No central database</para>
              </entry>
              <entry>
                <para>Higher performance, no bottlenecks.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>RAID not required</para>
              </entry>
              <entry>
                <para>Handle many small, random reads and writes efficiently.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Built-in management utilities</para>
              </entry>
              <entry>
                <para>Account management: Create, add, verify, and delete users;
Container management: Upload, download, and verify; Monitoring:
Capacity, host, network, log trawling, and cluster health.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Drive auditing</para>
              </entry>
              <entry>
                <para>Detect drive failures preempting data corruption.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Expiring objects</para>
              </entry>
              <entry>
                <para>Users can set an expiration time or a TTL on an object to
control access.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Direct object access</para>
              </entry>
              <entry>
                <para>Enable direct browser access to content, such as for a control
panel.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Realtime visibility into client requests</para>
              </entry>
              <entry>
                <para>Know what users are requesting.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Supports S3 API</para>
              </entry>
              <entry>
                <para>Utilize tools that were designed for the popular S3 API.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Restrict containers per account</para>
              </entry>
              <entry>
                <para>Limit access to control usage by user.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Support for NetApp, Nexenta, Solidfire</para>
              </entry>
              <entry>
                <para>Unified support for block volumes using a variety of storage
systems.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Snapshot and backup API for block volumes.</para>
              </entry>
              <entry>
                <para>Data protection and recovery for VM data.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Standalone volume API available</para>
              </entry>
              <entry>
                <para>Separate endpoint and API for integration with other compute
systems.</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Integration with Compute</para>
              </entry>
              <entry>
                <para>Fully integrated with Compute for attaching block volumes and
reporting on usage.</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
    </sect1>
    <sect1>
      <title>Object Storage characteristics</title>
      <para>The key characteristics of Object Storage are that:</para>
      <itemizedlist>
        <listitem>
          <para>All objects stored in Object Storage have a URL.</para>
        </listitem>
        <listitem>
          <para>All objects stored are replicated 3✕ in as-unique-as-possible zones,
which can be defined as a group of drives, a node, a rack, and so on.</para>
        </listitem>
        <listitem>
          <para>All objects have their own metadata.</para>
        </listitem>
        <listitem>
          <para>Developers interact with the object storage system through a RESTful
HTTP API.</para>
        </listitem>
        <listitem>
          <para>Object data can be located anywhere in the cluster.</para>
        </listitem>
        <listitem>
          <para>The cluster scales by adding additional nodes without sacrificing
performance, which allows a more cost-effective linear storage
expansion than fork-lift upgrades.</para>
        </listitem>
        <listitem>
          <para>Data does not have to be migrated to an entirely new storage system.</para>
        </listitem>
        <listitem>
          <para>New nodes can be added to the cluster without downtime.</para>
        </listitem>
        <listitem>
          <para>Failed nodes and disks can be swapped out without downtime.</para>
        </listitem>
        <listitem>
          <para>It runs on industry-standard hardware, such as Dell, HP, and
Supermicro.</para>
        </listitem>
      </itemizedlist>
      <para>Object Storage (swift)</para>
      <figure>
        <title/>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="objectstorage.png" width="99%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="objectstorage.png" width="99%"/>
          </imageobject>
        </mediaobject>
      </figure>
      <para>Developers can either write directly to the Swift API or use one of the
many client libraries that exist for all of the popular programming
languages, such as Java, Python, Ruby, and C#. Amazon S3 and RackSpace
Cloud Files users should be very familiar with Object Storage. Users new
to object storage systems will have to adjust to a different approach
and mindset than those required for a traditional filesystem.</para>
    </sect1>
    <sect1>
      <title>Components</title>
      <para>Object Storage uses the following components to deliver high
availability, high durability, and high concurrency:</para>
      <itemizedlist>
        <listitem>
          <para><emphasis role="bold">Proxy servers</emphasis> - Handle all of the incoming API requests.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Rings</emphasis> - Map logical names of data to locations on particular
disks.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Zones</emphasis> - Isolate data from other zones. A failure in one zone
does not impact the rest of the cluster as data replicates
across zones.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Accounts and containers</emphasis> - Each account and container are
individual databases that are distributed across the cluster. An
account database contains the list of containers in that account. A
container database contains the list of objects in that container.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Objects</emphasis> - The data itself.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Partitions</emphasis> - A partition stores objects, account databases, and
container databases and helps manage locations where data lives in
the cluster.</para>
        </listitem>
      </itemizedlist>
      <para>
        <emphasis role="bold">Object Storage building blocks</emphasis>
      </para>
      <figure>
        <title/>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="objectstorage-buildingblocks.png" width="99%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="objectstorage-buildingblocks.png" width="99%"/>
          </imageobject>
        </mediaobject>
      </figure>
      <sect2>
        <title>Proxy servers</title>
        <para>Proxy servers are the public face of Object Storage and handle all of
the incoming API requests. Once a proxy server receives a request, it
determines the storage node based on the object's URL, for example:
<link xlink:href="https://swift.example.com/v1/account/container/object">https://swift.example.com/v1/account/container/object</link>. Proxy servers
also coordinate responses, handle failures, and coordinate timestamps.</para>
        <para>Proxy servers use a shared-nothing architecture and can be scaled as
needed based on projected workloads. A minimum of two proxy servers
should be deployed for redundancy. If one proxy server fails, the others
take over.</para>
        <para>For more information concerning proxy server configuration, see
<link xlink:href="http://docs.openstack.org/newton/config-reference/object-storage/proxy-server.html">Configuration Reference</link>.</para>
      </sect2>
      <sect2>
        <title>Rings</title>
        <para>A ring represents a mapping between the names of entities stored on disks
and their physical locations. There are separate rings for accounts,
containers, and objects. When other components need to perform any
operation on an object, container, or account, they need to interact
with the appropriate ring to determine their location in the cluster.</para>
        <para>The ring maintains this mapping using zones, devices, partitions, and
replicas. Each partition in the ring is replicated, by default, three
times across the cluster, and partition locations are stored in the
mapping maintained by the ring. The ring is also responsible for
determining which devices are used for handoff in failure scenarios.</para>
        <para>Data can be isolated into zones in the ring. Each partition replica is
guaranteed to reside in a different zone. A zone could represent a
drive, a server, a cabinet, a switch, or even a data center.</para>
        <para>The partitions of the ring are equally divided among all of the devices
in the Object Storage installation. When partitions need to be moved
around (for example, if a device is added to the cluster), the ring
ensures that a minimum number of partitions are moved at a time, and
only one replica of a partition is moved at a time.</para>
        <para>You can use weights to balance the distribution of partitions on drives
across the cluster. This can be useful, for example, when differently
sized drives are used in a cluster.</para>
        <para>The ring is used by the proxy server and several background processes
(like replication).</para>
        <para>
          <emphasis role="bold">The ring</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="objectstorage-ring.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="objectstorage-ring.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>These rings are externally managed. The server processes themselves
do not modify the rings, they are instead given new rings modified by
other tools.</para>
        <para>The ring uses a configurable number of bits from an <literal>MD5</literal> hash for a path
as a partition index that designates a device. The number of bits kept
from the hash is known as the partition power, and 2 to the partition
power indicates the partition count. Partitioning the full <literal>MD5</literal> hash ring
allows other parts of the cluster to work in batches of items at once
which ends up either more efficient or at least less complex than
working with each item separately or the entire cluster all at once.</para>
        <para>Another configurable value is the replica count, which indicates how
many of the partition-device assignments make up a single ring. For a
given partition number, each replica's device will not be in the same
zone as any other replica's device. Zones can be used to group devices
based on physical locations, power separations, network separations, or
any other attribute that would improve the availability of multiple
replicas at the same time.</para>
      </sect2>
      <sect2>
        <title>Zones</title>
        <para>Object Storage allows configuring zones in order to isolate failure
boundaries. If possible, each data replica resides in a separate zone.
At the smallest level, a zone could be a single drive or a grouping of a
few drives. If there were five object storage servers, then each server
would represent its own zone. Larger deployments would have an entire
rack (or multiple racks) of object servers, each representing a zone.
The goal of zones is to allow the cluster to tolerate significant
outages of storage servers without losing all replicas of the data.</para>
        <para>
          <emphasis role="bold">Zones</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="objectstorage-zones.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="objectstorage-zones.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
      </sect2>
      <sect2>
        <title>Accounts and containers</title>
        <para>Each account and container is an individual SQLite database that is
distributed across the cluster. An account database contains the list of
containers in that account. A container database contains the list of
objects in that container.</para>
        <para>
          <emphasis role="bold">Accounts and containers</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="objectstorage-accountscontainers.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="objectstorage-accountscontainers.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>To keep track of object data locations, each account in the system has a
database that references all of its containers, and each container
database references each object.</para>
      </sect2>
      <sect2>
        <title>Partitions</title>
        <para>A partition is a collection of stored data. This includes account databases,
container databases, and objects. Partitions are core to the replication
system.</para>
        <para>Think of a partition as a bin moving throughout a fulfillment center
warehouse. Individual orders get thrown into the bin. The system treats
that bin as a cohesive entity as it moves throughout the system. A bin
is easier to deal with than many little things. It makes for fewer
moving parts throughout the system.</para>
        <para>System replicators and object uploads/downloads operate on partitions.
As the system scales up, its behavior continues to be predictable
because the number of partitions is a fixed number.</para>
        <para>Implementing a partition is conceptually simple, a partition is just a
directory sitting on a disk with a corresponding hash table of what it
contains.</para>
        <para>
          <emphasis role="bold">Partitions</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="objectstorage-partitions.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="objectstorage-partitions.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
      </sect2>
      <sect2>
        <title>Replicators</title>
        <para>In order to ensure that there are three copies of the data everywhere,
replicators continuously examine each partition. For each local
partition, the replicator compares it against the replicated copies in
the other zones to see if there are any differences.</para>
        <para>The replicator knows if replication needs to take place by examining
hashes. A hash file is created for each partition, which contains hashes
of each directory in the partition. Each of the three hash files is
compared. For a given partition, the hash files for each of the
partition's copies are compared. If the hashes are different, then it is
time to replicate, and the directory that needs to be replicated is
copied over.</para>
        <para>This is where partitions come in handy. With fewer things in the system,
larger chunks of data are transferred around (rather than lots of little
TCP connections, which is inefficient) and there is a consistent number
of hashes to compare.</para>
        <para>The cluster eventually has a consistent behavior where the newest data
has a priority.</para>
        <para>
          <emphasis role="bold">Replication</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="objectstorage-replication.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="objectstorage-replication.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>If a zone goes down, one of the nodes containing a replica notices and
proactively copies data to a handoff location.</para>
      </sect2>
      <sect2>
        <title>Use cases</title>
        <para>The following sections show use cases for object uploads and downloads
and introduce the components.</para>
        <sect3>
          <title>Upload</title>
          <para>A client uses the REST API to make a HTTP request to PUT an object into
an existing container. The cluster receives the request. First, the
system must figure out where the data is going to go. To do this, the
account name, container name, and object name are all used to determine
the partition where this object should live.</para>
          <para>Then a lookup in the ring figures out which storage nodes contain the
partitions in question.</para>
          <para>The data is then sent to each storage node where it is placed in the
appropriate partition. At least two of the three writes must be
successful before the client is notified that the upload was successful.</para>
          <para>Next, the container database is updated asynchronously to reflect that
there is a new object in it.</para>
          <para>
            <emphasis role="bold">Object Storage in use</emphasis>
          </para>
          <figure>
            <title/>
            <mediaobject>
              <imageobject role="fo">
                <imagedata fileref="objectstorage-usecase.png" width="99%"/>
              </imageobject>
              <imageobject role="html">
                <imagedata fileref="objectstorage-usecase.png" width="99%"/>
              </imageobject>
            </mediaobject>
          </figure>
        </sect3>
        <sect3>
          <title>Download</title>
          <para>A request comes in for an account/container/object. Using the same
consistent hashing, the partition name is generated. A lookup in the
ring reveals which storage nodes contain that partition. A request is
made to one of the storage nodes to fetch the object and, if that fails,
requests are made to the other nodes.</para>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Ring-builder</title>
      <para>Use the swift-ring-builder utility to build and manage rings. This
utility assigns partitions to devices and writes an optimized Python
structure to a gzipped, serialized file on disk for transmission to the
servers. The server processes occasionally check the modification time
of the file and reload in-memory copies of the ring structure as needed.
If you use a slightly older version of the ring, one of the three
replicas for a partition subset will be incorrect because of the way the
ring-builder manages changes to the ring. You can work around this
issue.</para>
      <para>The ring-builder also keeps its own builder file with the ring
information and additional data required to build future rings. It is
very important to keep multiple backup copies of these builder files.
One option is to copy the builder files out to every server while
copying the ring files themselves. Another is to upload the builder
files into the cluster itself. If you lose the builder file, you have to
create a new ring from scratch. Nearly all partitions would be assigned
to different devices and, therefore, nearly all of the stored data would
have to be replicated to new locations. So, recovery from a builder file
loss is possible, but data would be unreachable for an extended time.</para>
      <sect2>
        <title>Ring data structure</title>
        <para>The ring data structure consists of three top level fields: a list of
devices in the cluster, a list of lists of device ids indicating
partition to device assignments, and an integer indicating the number of
bits to shift an MD5 hash to calculate the partition for the hash.</para>
      </sect2>
      <sect2>
        <title>Partition assignment list</title>
        <para>This is a list of <literal>array('H')</literal> of devices ids. The outermost list
contains an <literal>array('H')</literal> for each replica. Each <literal>array('H')</literal> has a
length equal to the partition count for the ring. Each integer in the
<literal>array('H')</literal> is an index into the above list of devices. The partition
list is known internally to the Ring class as <literal>_replica2part2dev_id</literal>.</para>
        <para>So, to create a list of device dictionaries assigned to a partition, the
Python code would look like:</para>
        <screen language="python">devices = [self.devs[part2dev_id[partition]] for
part2dev_id in self._replica2part2dev_id]</screen>
        <para>That code is a little simplistic because it does not account for the
removal of duplicate devices. If a ring has more replicas than devices,
a partition will have more than one replica on a device.</para>
        <para><literal>array('H')</literal> is used for memory conservation as there may be millions
of partitions.</para>
      </sect2>
      <sect2>
        <title>Overload</title>
        <para>The ring builder tries to keep replicas as far apart as possible while
still respecting device weights. When it can not do both, the overload
factor determines what happens. Each device takes an extra
fraction of its desired partitions to allow for replica dispersion;
after that extra fraction is exhausted, replicas are placed closer
together than optimal.</para>
        <para>The overload factor lets the operator trade off replica
dispersion (durability) against data dispersion (uniform disk usage).</para>
        <para>The default overload factor is 0, so device weights are strictly
followed.</para>
        <para>With an overload factor of 0.1, each device accepts 10% more
partitions than it otherwise would, but only if it needs to maintain
partition dispersion.</para>
        <para>For example, consider a 3-node cluster of machines with equal-size disks;
node A has 12 disks, node B has 12 disks, and node C has
11 disks. The ring has an overload factor of 0.1 (10%).</para>
        <para>Without the overload, some partitions would end up with replicas only
on nodes A and B. However, with the overload, every device can accept
up to 10% more partitions for the sake of dispersion. The
missing disk in C means there is one disk's worth of partitions
to spread across the remaining 11 disks, which gives each
disk in C an extra 9.09% load. Since this is less than the 10%
overload, there is one replica of each partition on each node.</para>
        <para>However, this does mean that the disks in node C have more data
than the disks in nodes A and B. If 80% full is the warning
threshold for the cluster, node C's disks reach 80% full while A
and B's disks are only 72.7% full.</para>
      </sect2>
      <sect2>
        <title>Replica counts</title>
        <para>To support the gradual change in replica counts, a ring can have a real
number of replicas and is not restricted to an integer number of
replicas.</para>
        <para>A fractional replica count is for the whole ring and not for individual
partitions. It indicates the average number of replicas for each
partition. For example, a replica count of 3.2 means that 20 percent of
partitions have four replicas and 80 percent have three replicas.</para>
        <para>The replica count is adjustable. For example:</para>
        <screen language="console">$ swift-ring-builder account.builder set_replicas 4
$ swift-ring-builder account.builder rebalance</screen>
        <para>You must rebalance the replica ring in globally distributed clusters.
Operators of these clusters generally want an equal number of replicas
and regions. Therefore, when an operator adds or removes a region, the
operator adds or removes a replica. Removing unneeded replicas saves on
the cost of disks.</para>
        <para>You can gradually increase the replica count at a rate that does not
adversely affect cluster performance. For example:</para>
        <screen language="console">$ swift-ring-builder object.builder set_replicas 3.01
$ swift-ring-builder object.builder rebalance
&lt;distribute rings and wait&gt;...

$ swift-ring-builder object.builder set_replicas 3.02
$ swift-ring-builder object.builder rebalance
&lt;distribute rings and wait&gt;...</screen>
        <para>Changes take effect after the ring is rebalanced. Therefore, if you
intend to change from 3 replicas to 3.01 but you accidentally type
2.01, no data is lost.</para>
        <para>Additionally, the <command>swift-ring-builder X.builder create</command> command can
now take a decimal argument for the number of replicas.</para>
      </sect2>
      <sect2>
        <title>Partition shift value</title>
        <para>The partition shift value is known internally to the Ring class as
<literal>_part_shift</literal>. This value is used to shift an MD5 hash to calculate
the partition where the data for that hash should reside. Only the top
four bytes of the hash is used in this process. For example, to compute
the partition for the <literal>/account/container/object</literal> path using Python:</para>
        <screen language="python">partition = unpack_from('&gt;I',
md5('/account/container/object').digest())[0] &gt;&gt;
self._part_shift</screen>
        <para>For a ring generated with part_power P, the partition shift value is
<literal>32 - P</literal>.</para>
      </sect2>
      <sect2>
        <title>Build the ring</title>
        <para>The ring builder process includes these high-level steps:</para>
        <procedure>
          <step>
            <para>The utility calculates the number of partitions to assign to each
device based on the weight of the device. For example, for a
partition at the power of 20, the ring has 1,048,576 partitions. One
thousand devices of equal weight each want 1,048.576 partitions. The
devices are sorted by the number of partitions they desire and kept
in order throughout the initialization process.</para>
            <note>
              <para>Each device is also assigned a random tiebreaker value that is
used when two devices desire the same number of partitions. This
tiebreaker is not stored on disk anywhere, and so two different
rings created with the same parameters will have different
partition assignments. For repeatable partition assignments,
<literal>RingBuilder.rebalance()</literal> takes an optional seed value that
seeds the Python pseudo-random number generator.</para>
            </note>
          </step>
          <step>
            <para>The ring builder assigns each partition replica to the device that
requires most partitions at that point while keeping it as far away
as possible from other replicas. The ring builder prefers to assign a
replica to a device in a region that does not already have a replica.
If no such region is available, the ring builder searches for a
device in a different zone, or on a different server. If it does not
find one, it looks for a device with no replicas. Finally, if all
options are exhausted, the ring builder assigns the replica to the
device that has the fewest replicas already assigned.</para>
            <note>
              <para>The ring builder assigns multiple replicas to one device only if
the ring has fewer devices than it has replicas.</para>
            </note>
          </step>
          <step>
            <para>When building a new ring from an old ring, the ring builder
recalculates the desired number of partitions that each device wants.</para>
          </step>
          <step>
            <para>The ring builder unassigns partitions and gathers these partitions
for reassignment, as follows:</para>
            <itemizedlist>
              <listitem>
                <para>The ring builder unassigns any assigned partitions from any
removed devices and adds these partitions to the gathered list.</para>
              </listitem>
              <listitem>
                <para>The ring builder unassigns any partition replicas that can be
spread out for better durability and adds these partitions to the
gathered list.</para>
              </listitem>
              <listitem>
                <para>The ring builder unassigns random partitions from any devices that
have more partitions than they need and adds these partitions to
the gathered list.</para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>The ring builder reassigns the gathered partitions to devices by
using a similar method to the one described previously.</para>
          </step>
          <step>
            <para>When the ring builder reassigns a replica to a partition, the ring
builder records the time of the reassignment. The ring builder uses
this value when it gathers partitions for reassignment so that no
partition is moved twice in a configurable amount of time. The
RingBuilder class knows this configurable amount of time as
<literal>min_part_hours</literal>. The ring builder ignores this restriction for
replicas of partitions on removed devices because removal of a device
happens on device failure only, and reassignment is the only choice.</para>
          </step>
        </procedure>
        <para>These steps do not always perfectly rebalance a ring due to the random
nature of gathering partitions for reassignment. To help reach a more
balanced ring, the rebalance process is repeated until near perfect
(less than 1 percent off) or when the balance does not improve by at
least 1 percent (indicating we probably cannot get perfect balance due
to wildly imbalanced zones or too many partitions recently moved).</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Cluster architecture</title>
      <sect2>
        <title>Access tier</title>
        <para>Large-scale deployments segment off an access tier, which is considered
the Object Storage system's central hub. The access tier fields the
incoming API requests from clients and moves data in and out of the
system. This tier consists of front-end load balancers, ssl-terminators,
and authentication services. It runs the (distributed) brain of the
Object Storage system: the proxy server processes.</para>
        <note>
          <para>If you want to use OpenStack Identity API v3 for authentication, you
have the following options available in <literal>/etc/swift/dispersion.conf</literal>:
<literal>auth_version</literal>, <literal>user_domain_name</literal>, <literal>project_domain_name</literal>,
and <literal>project_name</literal>.</para>
        </note>
        <para>
          <emphasis role="bold">Object Storage architecture</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="objectstorage-arch.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="objectstorage-arch.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Because access servers are collocated in their own tier, you can scale
out read/write access regardless of the storage capacity. For example,
if a cluster is on the public Internet, requires SSL termination, and
has a high demand for data access, you can provision many access
servers. However, if the cluster is on a private network and used
primarily for archival purposes, you need fewer access servers.</para>
        <para>Since this is an HTTP addressable storage service, you may incorporate a
load balancer into the access tier.</para>
        <para>Typically, the tier consists of a collection of 1U servers. These
machines use a moderate amount of RAM and are network I/O intensive.
Since these systems field each incoming API request, you should
provision them with two high-throughput (10GbE) interfaces - one for the
incoming <literal>front-end</literal> requests and the other for the <literal>back-end</literal> access to
the object storage nodes to put and fetch data.</para>
        <sect3>
          <title>Factors to consider</title>
          <para>For most publicly facing deployments as well as private deployments
available across a wide-reaching corporate network, you use SSL to
encrypt traffic to the client. SSL adds significant processing load to
establish sessions between clients, which is why you have to provision
more capacity in the access layer. SSL may not be required for private
deployments on trusted networks.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Storage nodes</title>
        <para>In most configurations, each of the five zones should have an equal
amount of storage capacity. Storage nodes use a reasonable amount of
memory and CPU. Metadata needs to be readily available to return objects
quickly. The object stores run services not only to field incoming
requests from the access tier, but to also run replicators, auditors,
and reapers. You can provision object stores provisioned with single
gigabit or 10 gigabit network interface depending on the expected
workload and desired performance.</para>
        <para>
          <emphasis role="bold">Object Storage (swift)</emphasis>
        </para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="objectstorage-nodes.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="objectstorage-nodes.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Currently, a 2 TB or 3 TB SATA disk delivers good performance for the
price. You can use desktop-grade drives if you have responsive remote
hands in the datacenter and enterprise-grade drives if you don't.</para>
        <sect3>
          <title>Factors to consider</title>
          <para>You should keep in mind the desired I/O performance for single-threaded
requests. This system does not use RAID, so a single disk handles each
request for an object. Disk performance impacts single-threaded response
rates.</para>
          <para>To achieve apparent higher throughput, the object storage system is
designed to handle concurrent uploads/downloads. The network I/O
capacity (1GbE, bonded 1GbE pair, or 10GbE) should match your desired
concurrent throughput needs for reads and writes.</para>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Replication</title>
      <para>Because each replica in Object Storage functions independently and
clients generally require only a simple majority of nodes to respond to
consider an operation successful, transient failures like network
partitions can quickly cause replicas to diverge. These differences are
eventually reconciled by asynchronous, peer-to-peer replicator
processes. The replicator processes traverse their local file systems
and concurrently perform operations in a manner that balances load
across physical disks.</para>
      <para>Replication uses a push model, with records and files generally only
being copied from local to remote replicas. This is important because
data on the node might not belong there (as in the case of hand offs and
ring changes), and a replicator cannot know which data it should pull in
from elsewhere in the cluster. Any node that contains data must ensure
that data gets to where it belongs. The ring handles replica placement.</para>
      <para>To replicate deletions in addition to creations, every deleted record or
file in the system is marked by a tombstone. The replication process
cleans up tombstones after a time period known as the <literal>consistency
window</literal>. This window defines the duration of the replication and how
long transient failure can remove a node from the cluster. Tombstone
cleanup must be tied to replication to reach replica convergence.</para>
      <para>If a replicator detects that a remote drive has failed, the replicator
uses the <literal>get_more_nodes</literal> interface for the ring to choose an
alternate node with which to synchronize. The replicator can maintain
desired levels of replication during disk failures, though some replicas
might not be in an immediately usable location.</para>
      <note>
        <para>The replicator does not maintain desired levels of replication when
failures such as entire node failures occur; most failures are
transient.</para>
      </note>
      <para>The main replication types are:</para>
      <itemizedlist>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>Database replication</term>
              <listitem>
                <para>Replicates containers and objects.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
        <listitem>
          <variablelist>
            <varlistentry>
              <term>Object replication</term>
              <listitem>
                <para>Replicates object data.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </listitem>
      </itemizedlist>
      <sect2>
        <title>Database replication</title>
        <para>Database replication completes a low-cost hash comparison to determine
whether two replicas already match. Normally, this check can quickly
verify that most databases in the system are already synchronized. If
the hashes differ, the replicator synchronizes the databases by sharing
records added since the last synchronization point.</para>
        <para>This synchronization point is a high water mark that notes the last
record at which two databases were known to be synchronized, and is
stored in each database as a tuple of the remote database ID and record
ID. Database IDs are unique across all replicas of the database, and
record IDs are monotonically increasing integers. After all new records
are pushed to the remote database, the entire synchronization table of
the local database is pushed, so the remote database can guarantee that
it is synchronized with everything with which the local database was
previously synchronized.</para>
        <para>If a replica is missing, the whole local database file is transmitted to
the peer by using rsync(1) and is assigned a new unique ID.</para>
        <para>In practice, database replication can process hundreds of databases per
concurrency setting per second (up to the number of available CPUs or
disks) and is bound by the number of database transactions that must be
performed.</para>
      </sect2>
      <sect2>
        <title>Object replication</title>
        <para>The initial implementation of object replication performed an rsync to
push data from a local partition to all remote servers where it was
expected to reside. While this worked at small scale, replication times
skyrocketed once directory structures could no longer be held in RAM.
This scheme was modified to save a hash of the contents for each suffix
directory to a per-partition hashes file. The hash for a suffix
directory is no longer valid when the contents of that suffix directory
is modified.</para>
        <para>The object replication process reads in hash files and calculates any
invalidated hashes. Then, it transmits the hashes to each remote server
that should hold the partition, and only suffix directories with
differing hashes on the remote server are rsynced. After pushing files
to the remote server, the replication process notifies it to recalculate
hashes for the rsynced suffix directories.</para>
        <para>The number of uncached directories that object replication must
traverse, usually as a result of invalidated suffix directory hashes,
impedes performance. To provide acceptable replication speeds, object
replication is designed to invalidate around 2 percent of the hash space
on a normal node each day.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Large object support</title>
      <para>Object Storage (swift) uses segmentation to support the upload of large
objects. By default, Object Storage limits the download size of a single
object to 5GB. Using segmentation, uploading a single object is virtually
unlimited. The segmentation process works by fragmenting the object,
and automatically creating a file that sends the segments together as
a single object. This option offers greater upload speed with the possibility
of parallel uploads.</para>
      <sect2>
        <title>Large objects</title>
        <para>The large object is comprised of two types of objects:</para>
        <itemizedlist>
          <listitem>
            <para><emphasis role="bold">Segment objects</emphasis> store the object content. You can divide your
content into segments, and upload each segment into its own segment
object. Segment objects do not have any special features. You create,
update, download, and delete segment objects just as you would normal
objects.</para>
          </listitem>
          <listitem>
            <para>A <emphasis role="bold">manifest object</emphasis> links the segment objects into one logical
large object. When you download a manifest object, Object Storage
concatenates and returns the contents of the segment objects in the
response body of the request. The manifest object types are:</para>
            <itemizedlist>
              <listitem>
                <para>
                  <emphasis role="bold">Static large objects</emphasis>
                </para>
              </listitem>
              <listitem>
                <para>
                  <emphasis role="bold">Dynamic large objects</emphasis>
                </para>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
        <para>To find out more information on large object support, see <link xlink:href="http://docs.openstack.org/user-guide/cli-swift-large-object-creation.html">Large objects</link>
in the OpenStack End User Guide, or <link xlink:href="http://docs.openstack.org/developer/swift/overview_large_objects.html">Large Object Support</link>
in the developer documentation.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Object Auditor</title>
      <para>On system failures, the XFS file system can sometimes truncate files it is
trying to write and produce zero-byte files. The object-auditor will catch
these problems but in the case of a system crash it is advisable to run
an extra, less rate limited sweep, to check for these specific files.
You can run this command as follows:</para>
      <screen language="console">$ swift-object-auditor /path/to/object-server/config/file.conf once -z 1000</screen>
      <note>
        <para>"-z" means to only check for zero-byte files at 1000 files per second.</para>
      </note>
      <para>It is useful to run the object auditor on a specific device or set of devices.
You can run the object-auditor once as follows:</para>
      <screen language="console">$ swift-object-auditor /path/to/object-server/config/file.conf once \
  --devices=sda,sdb</screen>
      <note>
        <para>This will run the object auditor on only the <literal>sda</literal> and <literal>sdb</literal> devices.
This parameter accepts a comma-separated list of values.</para>
      </note>
    </sect1>
    <sect1>
      <title>Erasure coding</title>
      <para>Erasure coding is a set of algorithms that allows the reconstruction of
missing data from a set of original data. In theory, erasure coding uses
less capacity with similar durability characteristics as replicas.
From an application perspective, erasure coding support is transparent.
Object Storage (swift) implements erasure coding as a Storage Policy.
See <link xlink:href="http://docs.openstack.org/developer/swift/overview_policies.html">Storage Policies</link>
for more details.</para>
      <para>There is no external API related to erasure coding. Create a container using a
Storage Policy; the interaction with the cluster is the same as any
other durability policy. Because support implements as a Storage Policy,
you can isolate all storage devices that associate with your cluster's
erasure coding capability. It is entirely possible to share devices between
storage policies, but for erasure coding it may make more sense to use
not only separate devices but possibly even entire nodes dedicated for erasure
coding.</para>
      <important>
        <para>The erasure code support in Object Storage is considered beta in Kilo.
Most major functionality is included, but it has not been tested or
validated at large scale. This feature relies on <literal>ssync</literal> for durability.
We recommend deployers do extensive testing and not deploy production
data using an erasure code storage policy.
If any bugs are found during testing, please report them to
<link xlink:href="https://bugs.launchpad.net/swift">https://bugs.launchpad.net/swift</link></para>
      </important>
    </sect1>
    <sect1>
      <title>Account reaper</title>
      <para>The purpose of the account reaper is to remove data from the deleted accounts.</para>
      <para>A reseller marks an account for deletion by issuing a <literal>DELETE</literal> request
on the account's storage URL. This action sets the <literal>status</literal> column of
the account_stat table in the account database and replicas to
<literal>DELETED</literal>, marking the account's data for deletion.</para>
      <para>Typically, a specific retention time or undelete are not provided.
However, you can set a <literal>delay_reaping</literal> value in the
<literal>[account-reaper]</literal> section of the <literal>account-server.conf</literal> file to
delay the actual deletion of data. At this time, to undelete you have to update
the account database replicas directly, set the status column to an
empty string and update the put_timestamp to be greater than the
delete_timestamp.</para>
      <note>
        <para>It is on the development to-do list to write a utility that performs
this task, preferably through a REST call.</para>
      </note>
      <para>The account reaper runs on each account server and scans the server
occasionally for account databases marked for deletion. It only fires up
on the accounts for which the server is the primary node, so that
multiple account servers aren't trying to do it simultaneously. Using
multiple servers to delete one account might improve the deletion speed
but requires coordination to avoid duplication. Speed really is not a
big concern with data deletion, and large accounts aren't deleted often.</para>
      <para>Deleting an account is simple. For each account container, all objects
are deleted and then the container is deleted. Deletion requests that
fail will not stop the overall process but will cause the overall
process to fail eventually (for example, if an object delete times out,
you will not be able to delete the container or the account). The
account reaper keeps trying to delete an account until it is empty, at
which point the database reclaim process within the db_replicator will
remove the database files.</para>
      <para>A persistent error state may prevent the deletion of an object or
container. If this happens, you will see a message in the log, for example:</para>
      <screen language="console">Account &lt;name&gt; has not been reaped since &lt;date&gt;</screen>
      <para>You can control when this is logged with the <literal>reap_warn_after</literal> value in the
<literal>[account-reaper]</literal> section of the <literal>account-server.conf</literal> file.
The default value is 30 days.</para>
    </sect1>
    <sect1>
      <title>Configure project-specific image locations with Object Storage</title>
      <para>For some deployers, it is not ideal to store all images in one place to
enable all projects and users to access them. You can configure the Image
service to store image data in project-specific image locations. Then,
only the following projects can use the Image service to access the
created image:</para>
      <itemizedlist>
        <listitem>
          <para>The project who owns the image</para>
        </listitem>
        <listitem>
          <para>Projects that are defined in <literal>swift_store_admin_tenants</literal> and that
have admin-level accounts</para>
        </listitem>
      </itemizedlist>
      <para>
        <emphasis role="bold">To configure project-specific image locations</emphasis>
      </para>
      <procedure>
        <step>
          <para>Configure swift as your <literal>default_store</literal> in the
<literal>glance-api.conf</literal> file.</para>
        </step>
        <step>
          <para>Set these configuration options in the <literal>glance-api.conf</literal> file:</para>
          <itemizedlist>
            <listitem>
              <variablelist>
                <varlistentry>
                  <term>swift_store_multi_tenant</term>
                  <listitem>
                    <para>Set to <literal>True</literal> to enable tenant-specific storage locations.
Default is <literal>False</literal>.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </listitem>
            <listitem>
              <variablelist>
                <varlistentry>
                  <term>swift_store_admin_tenants</term>
                  <listitem>
                    <para>Specify a list of tenant IDs that can grant read and write access to all
Object Storage containers that are created by the Image service.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </listitem>
          </itemizedlist>
        </step>
      </procedure>
      <para>With this configuration, images are stored in an Object Storage service
(swift) endpoint that is pulled from the service catalog for the
authenticated user.</para>
    </sect1>
    <sect1>
      <title>Object Storage monitoring</title>
      <note>
        <para>This section was excerpted from a blog post by <link xlink:href="http://swiftstack.com/blog/2012/04/11/swift-monitoring-with-statsd">Darrell
Bishop</link> and
has since been edited.</para>
      </note>
      <para>An OpenStack Object Storage cluster is a collection of many daemons that
work together across many nodes. With so many different components, you
must be able to tell what is going on inside the cluster. Tracking
server-level meters like CPU utilization, load, memory consumption, disk
usage and utilization, and so on is necessary, but not sufficient.</para>
      <sect2>
        <title>Swift Recon</title>
        <para>The Swift Recon middleware (see
<link xlink:href="http://swift.openstack.org/admin_guide.html#cluster-telemetry-and-monitoring">Defining Storage Policies</link>)
provides general machine statistics, such as load average, socket
statistics, <literal>/proc/meminfo</literal> contents, as well as Swift-specific meters:</para>
        <itemizedlist>
          <listitem>
            <para>The <literal>MD5</literal> sum of each ring file.</para>
          </listitem>
          <listitem>
            <para>The most recent object replication time.</para>
          </listitem>
          <listitem>
            <para>Count of each type of quarantined file: Account, container, or
object.</para>
          </listitem>
          <listitem>
            <para>Count of "async_pendings" (deferred container updates) on disk.</para>
          </listitem>
        </itemizedlist>
        <para>Swift Recon is middleware that is installed in the object servers
pipeline and takes one required option: A local cache directory. To
track <literal>async_pendings</literal>, you must set up an additional cron job for
each object server. You access data by either sending HTTP requests
directly to the object server or using the <literal>swift-recon</literal> command-line
client.</para>
        <para>There are Object Storage cluster statistics but the typical
server meters overlap with existing server monitoring systems. To get
the Swift-specific meters into a monitoring system, they must be polled.
Swift Recon acts as a middleware meters collector. The
process that feeds meters to your statistics system, such as
<literal>collectd</literal> and <literal>gmond</literal>, should already run on the storage node.
You can choose to either talk to Swift Recon or collect the meters
directly.</para>
      </sect2>
      <sect2>
        <title>Swift-Informant</title>
        <para>Swift-Informant middleware (see
<link xlink:href="https://github.com/pandemicsyn/swift-informant">swift-informant</link>) has
real-time visibility into Object Storage client requests. It sits in the
pipeline for the proxy server, and after each request to the proxy server it
sends three meters to a <literal>StatsD</literal> server:</para>
        <itemizedlist>
          <listitem>
            <para>A counter increment for a meter like <literal>obj.GET.200</literal> or
<literal>cont.PUT.404</literal>.</para>
          </listitem>
          <listitem>
            <para>Timing data for a meter like <literal>acct.GET.200</literal> or <literal>obj.GET.200</literal>.
[The README says the meters look like <literal>duration.acct.GET.200</literal>, but
I do not see the <literal>duration</literal> in the code. I am not sure what the
Etsy server does but our StatsD server turns timing meters into five
derivative meters with new segments appended, so it probably works as
coded. The first meter turns into <literal>acct.GET.200.lower</literal>,
<literal>acct.GET.200.upper</literal>, <literal>acct.GET.200.mean</literal>,
<literal>acct.GET.200.upper_90</literal>, and <literal>acct.GET.200.count</literal>].</para>
          </listitem>
          <listitem>
            <para>A counter increase by the bytes transferred for a meter like
<literal>tfer.obj.PUT.201</literal>.</para>
          </listitem>
        </itemizedlist>
        <para>This is used for receiving information on the quality of service clients
experience with the timing meters, as well as sensing the volume of the
various modifications of a request server type, command, and response
code. Swift-Informant requires no change to core Object
Storage code because it is implemented as middleware. However, it gives
no insight into the workings of the cluster past the proxy server.
If the responsiveness of one storage node degrades, you can only see
that some of the requests are bad, either as high latency or error
status codes.</para>
      </sect2>
      <sect2>
        <title>Statsdlog</title>
        <para>The <link xlink:href="https://github.com/pandemicsyn/statsdlog">Statsdlog</link>
project increments StatsD counters based on logged events. Like
Swift-Informant, it is also non-intrusive, however statsdlog can track
events from all Object Storage daemons, not just proxy-server. The
daemon listens to a UDP stream of syslog messages, and StatsD counters
are incremented when a log line matches a regular expression. Meter
names are mapped to regex match patterns in a JSON file, allowing
flexible configuration of what meters are extracted from the log stream.</para>
        <para>Currently, only the first matching regex triggers a StatsD counter
increment, and the counter is always incremented by one. There is no way
to increment a counter by more than one or send timing data to StatsD
based on the log line content. The tool could be extended to handle more
meters for each line and data extraction, including timing data. But a
coupling would still exist between the log textual format and the log
parsing regexes, which would themselves be more complex to support
multiple matches for each line and data extraction. Also, log processing
introduces a delay between the triggering event and sending the data to
StatsD. It would be preferable to increment error counters where they
occur and send timing data as soon as it is known to avoid coupling
between a log string and a parsing regex and prevent a time delay
between events and sending data to StatsD.</para>
        <para>The next section describes another method for gathering Object Storage
operational meters.</para>
      </sect2>
      <sect2>
        <title>Swift StatsD logging</title>
        <para>StatsD (see <link xlink:href="http://codeascraft.etsy.com/2011/02/15/measure-anything-measure-everything/">Measure Anything, Measure Everything</link>)
was designed for application code to be deeply instrumented. Meters are
sent in real-time by the code that just noticed or did something. The
overhead of sending a meter is extremely low: a <literal>sendto</literal> of one UDP
packet. If that overhead is still too high, the StatsD client library
can send only a random portion of samples and StatsD approximates the
actual number when flushing meters upstream.</para>
        <para>To avoid the problems inherent with middleware-based monitoring and
after-the-fact log processing, the sending of StatsD meters is
integrated into Object Storage itself. The submitted change set (see
<link xlink:href="https://review.openstack.org/#change,6058">https://review.openstack.org/#change,6058</link>) currently reports 124 meters
across 15 Object Storage daemons and the tempauth middleware. Details of
the meters tracked are in the <link xlink:href="http://docs.openstack.org/developer/swift/admin_guide.html">Administrator's
Guide</link>.</para>
        <para>The sending of meters is integrated with the logging framework. To
enable, configure <literal>log_statsd_host</literal> in the relevant config file. You
can also specify the port and a default sample rate. The specified
default sample rate is used unless a specific call to a statsd logging
method (see the list below) overrides it. Currently, no logging calls
override the sample rate, but it is conceivable that some meters may
require accuracy (<literal>sample_rate=1</literal>) while others may not.</para>
        <screen language="ini">[DEFAULT]
     ...
log_statsd_host = 127.0.0.1
log_statsd_port = 8125
log_statsd_default_sample_rate = 1</screen>
        <para>Then the LogAdapter object returned by <literal>get_logger()</literal>, usually stored
in <literal>self.logger</literal>, has these new methods:</para>
        <itemizedlist>
          <listitem>
            <para><literal>set_statsd_prefix(self, prefix)</literal> Sets the client library stat
prefix value which gets prefixed to every meter. The default prefix
is the <literal>name</literal> of the logger such as <literal>object-server</literal>,
<literal>container-auditor</literal>, and so on. This is currently used to turn
<literal>proxy-server</literal> into one of <literal>proxy-server.Account</literal>,
<literal>proxy-server.Container</literal>, or <literal>proxy-server.Object</literal> as soon as the
Controller object is determined and instantiated for the request.</para>
          </listitem>
          <listitem>
            <para><literal>update_stats(self, metric, amount, sample_rate=1)</literal> Increments
the supplied meter by the given amount. This is used when you need
to add or subtract more that one from a counter, like incrementing
<literal>suffix.hashes</literal> by the number of computed hashes in the object
replicator.</para>
          </listitem>
          <listitem>
            <para><literal>increment(self, metric, sample_rate=1)</literal> Increments the given counter
meter by one.</para>
          </listitem>
          <listitem>
            <para><literal>decrement(self, metric, sample_rate=1)</literal> Lowers the given counter
meter by one.</para>
          </listitem>
          <listitem>
            <para><literal>timing(self, metric, timing_ms, sample_rate=1)</literal> Record that the
given meter took the supplied number of milliseconds.</para>
          </listitem>
          <listitem>
            <para><literal>timing_since(self, metric, orig_time, sample_rate=1)</literal>
Convenience method to record a timing meter whose value is "now"
minus an existing timestamp.</para>
          </listitem>
        </itemizedlist>
        <note>
          <para>These logging methods may safely be called anywhere you have a
logger object. If StatsD logging has not been configured, the methods
are no-ops. This avoids messy conditional logic each place a meter is
recorded. These example usages show the new logging methods:</para>
          <screen language="python"># swift/obj/replicator.py
def update(self, job):
     # ...
    begin = time.time()
    try:
        hashed, local_hash = tpool.execute(tpooled_get_hashes, job['path'],
                do_listdir=(self.replication_count % 10) == 0,
                reclaim_age=self.reclaim_age)
        # See tpooled_get_hashes "Hack".
        if isinstance(hashed, BaseException):
            raise hashed
        self.suffix_hash += hashed
        self.logger.update_stats('suffix.hashes', hashed)
        # ...
    finally:
        self.partition_times.append(time.time() - begin)
        self.logger.timing_since('partition.update.timing', begin)</screen>
          <screen language="python"># swift/container/updater.py
def process_container(self, dbfile):
    # ...
    start_time = time.time()
    # ...
        for event in events:
            if 200 &lt;= event.wait() &lt; 300:
                successes += 1
            else:
                failures += 1
        if successes &gt; failures:
          self.logger.increment('successes')
            # ...
        else:
            self.logger.increment('failures')
            # ...
        # Only track timing data for attempted updates:
        self.logger.timing_since('timing', start_time)
    else:
        self.logger.increment('no_changes')
        self.no_changes += 1</screen>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>System administration for Object Storage</title>
      <para>By understanding Object Storage concepts, you can better monitor and
administer your storage solution. The majority of the administration
information is maintained in developer documentation at
<link xlink:href="http://docs.openstack.org/developer/swift/">docs.openstack.org/developer/swift/</link>.</para>
      <para>See the <link xlink:href="http://docs.openstack.org/newton/config-reference/object-storage.html">OpenStack Configuration Reference</link>
for a list of configuration options for Object Storage.</para>
    </sect1>
    <sect1>
      <title>Troubleshoot Object Storage</title>
      <para>For Object Storage, everything is logged in <literal>/var/log/syslog</literal> (or
<literal>messages</literal> on some distros). Several settings enable further
customization of logging, such as <literal>log_name</literal>, <literal>log_facility</literal>, and
<literal>log_level</literal>, within the object server configuration files.</para>
      <sect2>
        <title>Drive failure</title>
        <sect3>
          <title>Problem</title>
          <para>Drive failure can prevent Object Storage performing replication.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>In the event that a drive has failed, the first step is to make sure the
drive is unmounted. This will make it easier for Object Storage to work
around the failure until it has been resolved. If the drive is going to
be replaced immediately, then it is just best to replace the drive,
format it, remount it, and let replication fill it up.</para>
          <para>If you cannot replace the drive immediately, then it is best to leave it
unmounted, and remove the drive from the ring. This will allow all the
replicas that were on that drive to be replicated elsewhere until the
drive is replaced. Once the drive is replaced, it can be re-added to the
ring.</para>
          <para>You can look at error messages in the <literal>/var/log/kern.log</literal> file for
hints of drive failure.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Server failure</title>
        <sect3>
          <title>Problem</title>
          <para>The server is potentially offline, and may have failed, or require a
reboot.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>If a server is having hardware issues, it is a good idea to make sure
the Object Storage services are not running. This will allow Object
Storage to work around the failure while you troubleshoot.</para>
          <para>If the server just needs a reboot, or a small amount of work that should
only last a couple of hours, then it is probably best to let Object
Storage work around the failure and get the machine fixed and back
online. When the machine comes back online, replication will make sure
that anything that is missing during the downtime will get updated.</para>
          <para>If the server has more serious issues, then it is probably best to
remove all of the server's devices from the ring. Once the server has
been repaired and is back online, the server's devices can be added back
into the ring. It is important that the devices are reformatted before
putting them back into the ring as it is likely to be responsible for a
different set of partitions than before.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Detect failed drives</title>
        <sect3>
          <title>Problem</title>
          <para>When drives fail, it can be difficult to detect that a drive has failed,
and the details of the failure.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>It has been our experience that when a drive is about to fail, error
messages appear in the <literal>/var/log/kern.log</literal> file. There is a script called
<literal>swift-drive-audit</literal> that can be run via cron to watch for bad drives. If
errors are detected, it will unmount the bad drive, so that Object
Storage can work around it. The script takes a configuration file with
the following settings:</para>
          <table>
            <title>Description of configuration options for [drive-audit] in drive-audit.conf</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="50.0*"/>
              <colspec colname="c2" colwidth="50.0*"/>
              <thead>
                <row>
                  <entry>
                    <para>Configuration option = Default value</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>
                      <literal>device_dir = /srv/node</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Directory devices are mounted under</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>error_limit = 1</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Number of errors to find before a device is unmounted</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>log_address = /dev/log</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Location where syslog sends the logs to</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>log_facility = LOG_LOCAL0</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Syslog log facility</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>log_file_pattern = /var/log/kern.*[!.][!g][!z]</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Location of the log file with globbing pattern to check against device
errors locate device blocks with errors in the log file</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>log_level = INFO</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Logging level</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>log_max_line_length = 0</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Caps the length of log lines to the value given; no limit if set to 0,
the default.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>log_to_console = False</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>No help text available for this option.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>minutes = 60</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Number of minutes to look back in <literal>/var/log/kern.log</literal></para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>recon_cache_path = /var/cache/swift</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Directory where stats for a few items will be stored</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>regex_pattern_1 = \berror\b.*\b(dm-[0-9]{1,2}\d?)\b</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>No help text available for this option.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>unmount_failed_device = True</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>No help text available for this option.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
          <warning>
            <para>This script has only been tested on Ubuntu 10.04; use with caution on
other operating systems in production.</para>
          </warning>
        </sect3>
      </sect2>
      <sect2>
        <title>Emergency recovery of ring builder files</title>
        <sect3>
          <title>Problem</title>
          <para>An emergency might prevent a successful backup from restoring the
cluster to operational status.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>You should always keep a backup of swift ring builder files. However, if
an emergency occurs, this procedure may assist in returning your cluster
to an operational state.</para>
          <para>Using existing swift tools, there is no way to recover a builder file
from a <literal>ring.gz</literal> file. However, if you have a knowledge of Python, it
is possible to construct a builder file that is pretty close to the one
you have lost.</para>
          <warning>
            <para>This procedure is a last-resort for emergency circumstances. It
requires knowledge of the swift python code and may not succeed.</para>
          </warning>
          <procedure>
            <step>
              <para>Load the ring and a new ringbuilder object in a Python REPL:</para>
              <screen language="python">&gt;&gt;&gt; from swift.common.ring import RingData, RingBuilder
&gt;&gt;&gt; ring = RingData.load('/path/to/account.ring.gz')</screen>
            </step>
            <step>
              <para>Start copying the data we have in the ring into the builder:</para>
              <screen language="python">&gt;&gt;&gt; import math
&gt;&gt;&gt; partitions = len(ring._replica2part2dev_id[0])
&gt;&gt;&gt; replicas = len(ring._replica2part2dev_id)

&gt;&gt;&gt; builder = RingBuilder(int(math.log(partitions, 2)), replicas, 1)
&gt;&gt;&gt; builder.devs = ring.devs
&gt;&gt;&gt; builder._replica2part2dev = ring._replica2part2dev_id
&gt;&gt;&gt; builder._last_part_moves_epoch = 0
&gt;&gt;&gt; from array import array
&gt;&gt;&gt; builder._last_part_moves = array('B', (0 for _ in xrange(partitions)))
&gt;&gt;&gt; builder._set_parts_wanted()
&gt;&gt;&gt; for d in builder._iter_devs():
            d['parts'] = 0
&gt;&gt;&gt; for p2d in builder._replica2part2dev:
            for dev_id in p2d:
                builder.devs[dev_id]['parts'] += 1

This is the extent of the recoverable fields.</screen>
            </step>
            <step>
              <para>For <literal>min_part_hours</literal> you either have to remember what the value you
used was, or just make up a new one:</para>
              <screen language="python">&gt;&gt;&gt; builder.change_min_part_hours(24) # or whatever you want it to be</screen>
            </step>
            <step>
              <para>Validate the builder. If this raises an exception, check your
previous code:</para>
              <screen language="python">&gt;&gt;&gt; builder.validate()</screen>
            </step>
            <step>
              <para>After it validates, save the builder and create a new <literal>account.builder</literal>:</para>
              <screen language="python">&gt;&gt;&gt; import pickle
&gt;&gt;&gt; pickle.dump(builder.to_dict(), open('account.builder', 'wb'), protocol=2)
&gt;&gt;&gt; exit ()</screen>
            </step>
            <step>
              <para>You should now have a file called <literal>account.builder</literal> in the current
working directory. Run
<command>swift-ring-builder account.builder write_ring</command> and compare the new
<literal>account.ring.gz</literal> to the <literal>account.ring.gz</literal> that you started
from. They probably are not byte-for-byte identical, but if you load them
in a REPL and their <literal>_replica2part2dev_id</literal> and <literal>devs</literal> attributes are
the same (or nearly so), then you are in good shape.</para>
            </step>
            <step>
              <para>Repeat the procedure for <literal>container.ring.gz</literal> and
<literal>object.ring.gz</literal>, and you might get usable builder files.</para>
            </step>
          </procedure>
        </sect3>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Block Storage</title>
    <info/>
    <para>The OpenStack Block Storage service works through the interaction of
a series of daemon processes named <literal>cinder-*</literal> that reside
persistently on the host machine or machines. You can run all the
binaries from a single node, or spread across multiple nodes. You can
also run them on the same node as other OpenStack services.</para>
    <para>To administer the OpenStack Block Storage service, it is helpful to
understand a number of concepts. You must make certain choices when
you configure the Block Storage service in OpenStack. The bulk of the
options come down to two choices - single node or multi-node install.
You can read a longer discussion about <link xlink:href="http://docs.openstack.org/ops-guide/arch-storage.html">Storage Decisions</link> in the
<link xlink:href="http://docs.openstack.org/ops-guide/">OpenStack Operations Guide</link>.</para>
    <para>OpenStack Block Storage enables you to add extra block-level storage
to your OpenStack Compute instances. This service is similar to the
Amazon EC2 Elastic Block Storage (EBS) offering.</para>
    <sect1>
      <title>Increase Block Storage API service throughput</title>
      <para>By default, the Block Storage API service runs in one process. This
limits the number of API requests that the Block Storage service can
process at any given time. In a production environment, you should
increase the Block Storage API throughput by allowing the Block Storage
API service to run in as many processes as the machine capacity allows.</para>
      <note>
        <para>The Block Storage API service is named <literal>openstack-cinder-api</literal> on
the following distributions: CentOS, Fedora, openSUSE, Red Hat
Enterprise Linux, and SUSE Linux Enterprise. In Ubuntu and Debian
distributions, the Block Storage API service is named <literal>cinder-api</literal>.</para>
      </note>
      <para>To do so, use the Block Storage API service option <literal>osapi_volume_workers</literal>.
This option allows you to specify the number of API service workers
(or OS processes) to launch for the Block Storage API service.</para>
      <para>To configure this option, open the <literal>/etc/cinder/cinder.conf</literal>
configuration file and set the <literal>osapi_volume_workers</literal> configuration
key to the number of CPU cores/threads on a machine.</para>
      <para>On distributions that include <literal>openstack-config</literal>, you can configure
this by running the following command instead:</para>
      <screen language="console"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT osapi_volume_workers CORES</screen>
      <para>Replace <literal>CORES</literal> with the number of CPU cores/threads on a machine.</para>
    </sect1>
    <sect1>
      <title>Manage volumes</title>
      <para>The default OpenStack Block Storage service implementation is an
iSCSI solution that uses <xref linkend="term-logical-volume-manager-lvm"/> for Linux.</para>
      <note>
        <para>The OpenStack Block Storage service is not a shared storage
solution like a Network Attached Storage (NAS) of NFS volumes
where you can attach a volume to multiple servers. With the
OpenStack Block Storage service, you can attach a volume to only
one instance at a time.</para>
        <para>The OpenStack Block Storage service also provides drivers that
enable you to use several vendors' back-end storage devices in
addition to the base LVM implementation.  These storage devices can
also be used instead of the base LVM installation.</para>
      </note>
      <para>This high-level procedure shows you how to create and attach a volume
to a server instance.</para>
      <para>
        <emphasis role="bold">To create and attach a volume to an instance</emphasis>
      </para>
      <procedure>
        <step>
          <para>Configure the OpenStack Compute and the OpenStack Block Storage
services through the <literal>/etc/cinder/cinder.conf</literal> file.</para>
        </step>
        <step>
          <para>Use the <command>openstack volume create</command> command to create a volume.
This command creates an LV into the volume group (VG) <literal>cinder-volumes</literal>.</para>
        </step>
        <step>
          <para>Use the <command>openstack server add volume</command> command to attach the
volume to an instance. This command creates a unique <xref linkend="term-iscsi-qualified-name-iqn"/> that is exposed to the compute node.</para>
          <itemizedlist>
            <listitem>
              <para>The compute node, which runs the instance, now has an active
iSCSI session and new local storage (usually a <literal>/dev/sdX</literal>
disk).</para>
            </listitem>
            <listitem>
              <para>Libvirt uses that local storage as storage for the instance. The
instance gets a new disk (usually a <literal>/dev/vdX</literal> disk).</para>
            </listitem>
          </itemizedlist>
        </step>
      </procedure>
      <para>For this particular walkthrough, one cloud controller runs
<literal>nova-api</literal>, <literal>nova-scheduler</literal>, <literal>nova-objectstore</literal>,
<literal>nova-network</literal> and <literal>cinder-*</literal> services. Two additional compute
nodes run <literal>nova-compute</literal>. The walkthrough uses a custom
partitioning scheme that carves out 60 GB of space and labels it as
LVM. The network uses the <literal>FlatManager</literal> and <literal>NetworkManager</literal>
settings for OpenStack Compute.</para>
      <para>The network mode does not interfere with OpenStack Block Storage
operations, but you must set up networking for Block Storage to work.
For details, see <xref linkend="networking"/>.</para>
      <para>To set up Compute to use volumes, ensure that Block Storage is
installed along with <literal>lvm2</literal>. This guide describes how to
troubleshoot your installation and back up your Compute volumes.</para>
      <sect2>
        <title>Boot from volume</title>
        <para>In some cases, you can store and run instances from inside volumes.
For information, see the <link xlink:href="http://docs.openstack.org/user-guide/cli-nova-launch-instance-from-volume.html">Launch an instance from a volume</link> section
in the <link xlink:href="http://docs.openstack.org/user-guide/">OpenStack End User Guide</link>.</para>
      </sect2>
      <sect2>
        <title>Configure an NFS storage back end</title>
        <para>This section explains how to configure OpenStack Block Storage to use
NFS storage. You must be able to access the NFS shares from the server
that hosts the <literal>cinder</literal> volume service.</para>
        <note>
          <para>The <literal>cinder</literal> volume service is named <literal>openstack-cinder-volume</literal>
on the following distributions:</para>
          <itemizedlist>
            <listitem>
              <para>CentOS</para>
            </listitem>
            <listitem>
              <para>Fedora</para>
            </listitem>
            <listitem>
              <para>openSUSE</para>
            </listitem>
            <listitem>
              <para>Red Hat Enterprise Linux</para>
            </listitem>
            <listitem>
              <para>SUSE Linux Enterprise</para>
            </listitem>
          </itemizedlist>
          <para>In Ubuntu and Debian distributions, the <literal>cinder</literal> volume service is
named <literal>cinder-volume</literal>.</para>
        </note>
        <para>
          <emphasis role="bold">Configure Block Storage to use an NFS storage back end</emphasis>
        </para>
        <procedure>
          <step>
            <para>Log in as <literal>root</literal> to the system hosting the <literal>cinder</literal> volume
service.</para>
          </step>
          <step>
            <para>Create a text file named <literal>nfsshares</literal> in the <literal>/etc/cinder/</literal> directory.</para>
          </step>
          <step>
            <para>Add an entry to <literal>/etc/cinder/nfsshares</literal> for each NFS share
that the <literal>cinder</literal> volume service should use for back end storage.
Each entry should be a separate line, and should use the following
format:</para>
            <screen language="ini">HOST:SHARE</screen>
            <para>Where:</para>
            <itemizedlist>
              <listitem>
                <para>HOST is the IP address or host name of the NFS server.</para>
              </listitem>
              <listitem>
                <para>SHARE is the absolute path to an existing and accessible NFS share.</para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>Set <literal>/etc/cinder/nfsshares</literal> to be owned by the <literal>root</literal> user and
the <literal>cinder</literal> group:</para>
            <screen language="console"># chown root:cinder /etc/cinder/nfsshares</screen>
          </step>
          <step>
            <para>Set <literal>/etc/cinder/nfsshares</literal> to be readable by members of the
cinder group:</para>
            <screen language="console"># chmod 0640 /etc/cinder/nfsshares</screen>
          </step>
          <step>
            <para>Configure the <literal>cinder</literal> volume service to use the
<literal>/etc/cinder/nfsshares</literal> file created earlier. To do so, open
the <literal>/etc/cinder/cinder.conf</literal> configuration file and set
the <literal>nfs_shares_config</literal> configuration key
to <literal>/etc/cinder/nfsshares</literal>.</para>
            <para>On distributions that include <literal>openstack-config</literal>, you can configure
this by running the following command instead:</para>
            <screen language="console"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_shares_config /etc/cinder/nfsshares</screen>
            <para>The following distributions include openstack-config:</para>
            <itemizedlist>
              <listitem>
                <para>CentOS</para>
              </listitem>
              <listitem>
                <para>Fedora</para>
              </listitem>
              <listitem>
                <para>openSUSE</para>
              </listitem>
              <listitem>
                <para>Red Hat Enterprise Linux</para>
              </listitem>
              <listitem>
                <para>SUSE Linux Enterprise</para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>Optionally, provide any additional NFS mount options required in
your environment in the <literal>nfs_mount_options</literal> configuration key
of <literal>/etc/cinder/cinder.conf</literal>. If your NFS shares do not
require any additional mount options (or if you are unsure),
skip this step.</para>
            <para>On distributions that include <literal>openstack-config</literal>, you can
configure this by running the following command instead:</para>
            <screen language="console"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_mount_options OPTIONS</screen>
            <para>Replace OPTIONS with the mount options to be used when accessing
NFS shares. See the manual page for NFS for more information on
available mount options (<command>man nfs</command>).</para>
          </step>
          <step>
            <para>Configure the <literal>cinder</literal> volume service to use the correct volume
driver, namely <literal>cinder.volume.drivers.nfs.NfsDriver</literal>. To do so,
open the <literal>/etc/cinder/cinder.conf</literal> configuration file and
set the volume_driver configuration key
to <literal>cinder.volume.drivers.nfs.NfsDriver</literal>.</para>
            <para>On distributions that include <literal>openstack-config</literal>, you can configure
this by running the following command instead:</para>
            <screen language="console"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT volume_driver cinder.volume.drivers.nfs.NfsDriver</screen>
          </step>
          <step>
            <para>You can now restart the service to apply the configuration.</para>
            <note>
              <para>The <literal>nfs_sparsed_volumes</literal> configuration key determines whether
volumes are created as sparse files and grown as needed or fully
allocated up front. The default and recommended value is <literal>true</literal>,
which ensures volumes are initially created as sparse files.</para>
              <para>Setting <literal>nfs_sparsed_volumes</literal> to <literal>false</literal> will result in
volumes being fully allocated at the time of creation. This leads
to increased delays in volume creation.</para>
              <para>However, should you choose to set <literal>nfs_sparsed_volumes</literal> to
<literal>false</literal>, you can do so directly in <literal>/etc/cinder/cinder.conf</literal>.</para>
              <para>On distributions that include <literal>openstack-config</literal>, you can
configure this by running the following command instead:</para>
              <screen language="console"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_sparsed_volumes false</screen>
            </note>
            <warning>
              <para>If a client host has SELinux enabled, the <literal>virt_use_nfs</literal>
boolean should also be enabled if the host requires access to
NFS volumes on an instance. To enable this boolean, run the
following command as the <literal>root</literal> user:</para>
              <screen language="console"># setsebool -P virt_use_nfs on</screen>
              <para>This command also makes the boolean persistent across reboots.
Run this command on all client hosts that require access to NFS
volumes on an instance. This includes all compute nodes.</para>
            </warning>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Configure a GlusterFS back end</title>
        <para>This section explains how to configure OpenStack Block Storage to use
GlusterFS as a back end. You must be able to access the GlusterFS shares
from the server that hosts the <literal>cinder</literal> volume service.</para>
        <note>
          <para>The cinder volume service is named <literal>openstack-cinder-volume</literal> on the
following distributions:</para>
          <itemizedlist>
            <listitem>
              <para>CentOS</para>
            </listitem>
            <listitem>
              <para>Fedora</para>
            </listitem>
            <listitem>
              <para>openSUSE</para>
            </listitem>
            <listitem>
              <para>Red Hat Enterprise Linux</para>
            </listitem>
            <listitem>
              <para>SUSE Linux Enterprise</para>
            </listitem>
          </itemizedlist>
          <para>In Ubuntu and Debian distributions, the <literal>cinder</literal> volume service is
named <literal>cinder-volume</literal>.</para>
        </note>
        <para>Mounting GlusterFS volumes requires utilities and libraries from the
<literal>glusterfs-fuse</literal> package. This package must be installed on all systems
that will access volumes backed by GlusterFS.</para>
        <note>
          <para>The utilities and libraries required for mounting GlusterFS volumes on
Ubuntu and Debian distributions are available from the <literal>glusterfs-client</literal>
package instead.</para>
        </note>
        <para>For information on how to install and configure GlusterFS, refer to the
<link xlink:href="http://www.gluster.org/community/documentation/index.php/Main_Page">GlusterDocumentation</link> page.</para>
        <para>
          <emphasis role="bold">Configure GlusterFS for OpenStack Block Storage</emphasis>
        </para>
        <para>The GlusterFS server must also be configured accordingly in order to allow
OpenStack Block Storage to use GlusterFS shares:</para>
        <procedure>
          <step>
            <para>Log in as <literal>root</literal> to the GlusterFS server.</para>
          </step>
          <step>
            <para>Set each Gluster volume to use the same UID and GID as the <literal>cinder</literal> user:</para>
            <screen language="console"># gluster volume set VOL_NAME storage.owner-uid CINDER_UID
# gluster volume set VOL_NAME storage.owner-gid CINDER_GID</screen>
            <para>Where:</para>
            <itemizedlist>
              <listitem>
                <para>VOL_NAME is the Gluster volume name.</para>
              </listitem>
              <listitem>
                <para>CINDER_UID is the UID of the <literal>cinder</literal> user.</para>
              </listitem>
              <listitem>
                <para>CINDER_GID is the GID of the <literal>cinder</literal> user.</para>
              </listitem>
            </itemizedlist>
            <note>
              <para>The default UID and GID of the <literal>cinder</literal> user is 165 on
most distributions.</para>
            </note>
          </step>
          <step>
            <para>Configure each Gluster volume to accept <literal>libgfapi</literal> connections.
To do this, set each Gluster volume to allow insecure ports:</para>
            <screen language="console"># gluster volume set VOL_NAME server.allow-insecure on</screen>
          </step>
          <step>
            <para>Enable client connections from unprivileged ports. To do this,
add the following line to <literal>/etc/glusterfs/glusterd.vol</literal>:</para>
            <screen language="ini">option rpc-auth-allow-insecure on</screen>
          </step>
          <step>
            <para>Restart the <literal>glusterd</literal> service:</para>
            <screen language="console"># service glusterd restart</screen>
          </step>
        </procedure>
        <para>
          <emphasis role="bold">Configure Block Storage to use a GlusterFS back end</emphasis>
        </para>
        <para>After you configure the GlusterFS service, complete these steps:</para>
        <procedure>
          <step>
            <para>Log in as <literal>root</literal> to the system hosting the Block Storage service.</para>
          </step>
          <step>
            <para>Create a text file named <literal>glusterfs</literal> in <literal>/etc/cinder/</literal> directory.</para>
          </step>
          <step>
            <para>Add an entry to <literal>/etc/cinder/glusterfs</literal> for each GlusterFS
share that OpenStack Block Storage should use for back end storage.
Each entry should be a separate line, and should use the following
format:</para>
            <screen language="ini">HOST:/VOL_NAME</screen>
            <para>Where:</para>
            <itemizedlist>
              <listitem>
                <para>HOST is the IP address or host name of the Red Hat Storage server.</para>
              </listitem>
              <listitem>
                <para>VOL_NAME is the name of an existing and accessible volume on the
GlusterFS server.</para>
              </listitem>
            </itemizedlist>
            <para>Optionally, if your environment requires additional mount options for
a share, you can add them to the share's entry:</para>
            <screen language="ini">HOST:/VOL_NAME -o OPTIONS</screen>
            <para>Replace OPTIONS with a comma-separated list of mount options.</para>
          </step>
          <step>
            <para>Set <literal>/etc/cinder/glusterfs</literal> to be owned by the root user
and the <literal>cinder</literal> group:</para>
            <screen language="console"># chown root:cinder /etc/cinder/glusterfs</screen>
          </step>
          <step>
            <para>Set <literal>/etc/cinder/glusterfs</literal> to be readable by members of
the <literal>cinder</literal> group:</para>
            <screen language="console"># chmod 0640 /etc/cinder/glusterfs</screen>
          </step>
          <step>
            <para>Configure OpenStack Block Storage to use the <literal>/etc/cinder/glusterfs</literal>
file created earlier. To do so, open the <literal>/etc/cinder/cinder.conf</literal>
configuration file and set the <literal>glusterfs_shares_config</literal> configuration
key to <literal>/etc/cinder/glusterfs</literal>.</para>
            <para>On distributions that include openstack-config, you can configure this
by running the following command instead:</para>
            <screen language="console"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT glusterfs_shares_config /etc/cinder/glusterfs</screen>
            <para>The following distributions include <literal>openstack-config</literal>:</para>
            <itemizedlist>
              <listitem>
                <para>CentOS</para>
              </listitem>
              <listitem>
                <para>Fedora</para>
              </listitem>
              <listitem>
                <para>openSUSE</para>
              </listitem>
              <listitem>
                <para>Red Hat Enterprise Linux</para>
              </listitem>
              <listitem>
                <para>SUSE Linux Enterprise</para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>Configure OpenStack Block Storage to use the correct volume driver,
namely <literal>cinder.volume.drivers.glusterfs.GlusterfsDriver</literal>. To do so,
open the <literal>/etc/cinder/cinder.conf</literal> configuration file and set
the <literal>volume_driver</literal> configuration key to
<literal>cinder.volume.drivers.glusterfs.GlusterfsDriver</literal>.</para>
            <para>On distributions that include <literal>openstack-config</literal>, you can configure
this by running the following command instead:</para>
            <screen language="console"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT volume_driver cinder.volume.drivers.glusterfs.GlusterfsDriver</screen>
          </step>
          <step>
            <para>You can now restart the service to apply the configuration.</para>
          </step>
        </procedure>
        <para>OpenStack Block Storage is now configured to use a GlusterFS back end.</para>
        <warning>
          <para>If a client host has SELinux enabled, the <literal>virt_use_fusefs</literal> boolean
should also be enabled if the host requires access to GlusterFS volumes
on an instance. To enable this Boolean, run the following command as
the <literal>root</literal> user:</para>
          <screen language="console"># setsebool -P virt_use_fusefs on</screen>
          <para>This command also makes the Boolean persistent across reboots. Run
this command on all client hosts that require access to GlusterFS
volumes on an instance. This includes all compute nodes.</para>
        </warning>
      </sect2>
      <sect2 xml:id="multi-backend">
        <title>Configure multiple-storage back ends</title>
        <para>When you configure multiple-storage back ends, you can create several
back-end storage solutions that serve the same OpenStack Compute
configuration and one <literal>cinder-volume</literal> is launched for each back-end
storage or back-end storage pool.</para>
        <para>In a multiple-storage back-end configuration, each back end has a name
(<literal>volume_backend_name</literal>). Several back ends can have the same name.
In that case, the scheduler properly decides which back end the volume
has to be created in.</para>
        <para>The name of the back end is declared as an extra-specification of a
volume type (such as, <literal>volume_backend_name=LVM</literal>). When a volume
is created, the scheduler chooses an appropriate back end to handle the
request, according to the volume type specified by the user.</para>
        <sect3>
          <title>Enable multiple-storage back ends</title>
          <para>To enable a multiple-storage back ends, you must set the
<literal>enabled_backends</literal> flag in the <literal>cinder.conf</literal> file.
This flag defines the names (separated by a comma) of the configuration
groups for the different back ends: one name is associated to one
configuration group for a back end (such as, <literal>[lvmdriver-1]</literal>).</para>
          <note>
            <para>The configuration group name is not related to the <literal>volume_backend_name</literal>.</para>
          </note>
          <note>
            <para>After setting the <literal>enabled_backends</literal> flag on an existing cinder
service, and restarting the Block Storage services, the original <literal>host</literal>
service is replaced with a new host service. The new service appears
with a name like <literal>host@backend</literal>. Use:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ cinder-manage volume update_host --currenthost CURRENTHOST --newhost CURRENTHOST@BACKEND</screen>
            <para>to convert current block devices to the new host name.</para>
          </note>
          <para>The options for a configuration group must be defined in the group
(or default options are used). All the standard Block Storage
configuration options (<literal>volume_group</literal>, <literal>volume_driver</literal>, and so on)
might be used in a configuration group. Configuration values in
the <literal>[DEFAULT]</literal> configuration group are not used.</para>
          <para>These examples show three back ends:</para>
          <screen language="ini">enabled_backends=lvmdriver-1,lvmdriver-2,lvmdriver-3
[lvmdriver-1]
volume_group=cinder-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
[lvmdriver-2]
volume_group=cinder-volumes-2
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
[lvmdriver-3]
volume_group=cinder-volumes-3
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM_b</screen>
          <para>In this configuration, <literal>lvmdriver-1</literal> and <literal>lvmdriver-2</literal> have the same
<literal>volume_backend_name</literal>. If a volume creation requests the <literal>LVM</literal>
back end name, the scheduler uses the capacity filter scheduler to choose
the most suitable driver, which is either <literal>lvmdriver-1</literal> or <literal>lvmdriver-2</literal>.
The capacity filter scheduler is enabled by default. The next section
provides more information. In addition, this example presents a
<literal>lvmdriver-3</literal> back end.</para>
          <note>
            <para>For Fiber Channel drivers that support multipath, the configuration group
requires the <literal>use_multipath_for_image_xfer=true</literal> option. In
the example below, you can see details for HPE 3PAR and EMC Fiber
Channel drivers.</para>
          </note>
          <screen language="ini">[3par]
use_multipath_for_image_xfer = true
volume_driver = cinder.volume.drivers.hpe.hpe_3par_fc.HPE3PARFCDriver
volume_backend_name = 3parfc

[emc]
use_multipath_for_image_xfer = true
volume_driver = cinder.volume.drivers.emc.emc_smis_fc.EMCSMISFCDriver
volume_backend_name = emcfc</screen>
        </sect3>
        <sect3>
          <title>Configure Block Storage scheduler multi back end</title>
          <para>You must enable the <literal>filter_scheduler</literal> option to use
multiple-storage back ends. The filter scheduler:</para>
          <procedure>
            <step>
              <para>Filters the available back ends. By default, <literal>AvailabilityZoneFilter</literal>,
<literal>CapacityFilter</literal> and <literal>CapabilitiesFilter</literal> are enabled.</para>
            </step>
            <step>
              <para>Weights the previously filtered back ends. By default, the
<literal>CapacityWeigher</literal> option is enabled. When this option is
enabled, the filter scheduler assigns the highest weight to back
ends with the most available capacity.</para>
            </step>
          </procedure>
          <para>The scheduler uses filters and weights to pick the best back end to
handle the request. The scheduler uses volume types to explicitly create
volumes on specific back ends. For more information about filter and weighing,
see <xref linkend="filter-weigh-scheduler"/>.</para>
        </sect3>
        <sect3>
          <title>Volume type</title>
          <para>Before using it, a volume type has to be declared to Block Storage.
This can be done by the following command:</para>
          <screen language="console">$ openstack --os-username admin --os-tenant-name admin volume type create lvm</screen>
          <para>Then, an extra-specification has to be created to link the volume
type to a back end name. Run this command:</para>
          <screen language="console">$ openstack --os-username admin --os-tenant-name admin volume type set lvm \
  --property volume_backend_name=LVM_iSCSI</screen>
          <para>This example creates a <literal>lvm</literal> volume type with
<literal>volume_backend_name=LVM_iSCSI</literal> as extra-specifications.</para>
          <para>Create another volume type:</para>
          <screen language="console">$ openstack --os-username admin --os-tenant-name admin volume type create lvm_gold

$ openstack --os-username admin --os-tenant-name admin volume type set lvm_gold \
  --property volume_backend_name=LVM_iSCSI_b</screen>
          <para>This second volume type is named <literal>lvm_gold</literal> and has <literal>LVM_iSCSI_b</literal> as
back end name.</para>
          <note>
            <para>To list the extra-specifications, use this command:</para>
            <screen language="console">$ cinder --os-username admin --os-tenant-name admin extra-specs-list</screen>
          </note>
          <note>
            <para>If a volume type points to a <literal>volume_backend_name</literal> that does not
exist in the Block Storage configuration, the <literal>filter_scheduler</literal>
returns an error that it cannot find a valid host with the suitable
back end.</para>
          </note>
        </sect3>
        <sect3>
          <title>Usage</title>
          <para>When you create a volume, you must specify the volume type.
The extra-specifications of the volume type are used to determine which
back end has to be used.</para>
          <screen language="console">$ openstack volume create --size 1 --type lvm test_multi_backend</screen>
          <para>Considering the <literal>cinder.conf</literal> described previously, the scheduler
creates this volume on <literal>lvmdriver-1</literal> or <literal>lvmdriver-2</literal>.</para>
          <screen language="console">$ openstack volume create --size 1 --type lvm_gold test_multi_backend</screen>
          <para>This second volume is created on <literal>lvmdriver-3</literal>.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Back up Block Storage service disks</title>
        <para>While you can use the LVM snapshot to create snapshots, you can also use
it to back up your volumes. By using LVM snapshot, you reduce the size
of the backup; only existing data is backed up instead of the entire
volume.</para>
        <para>To back up a volume, you must create a snapshot of it. An LVM snapshot
is the exact copy of a logical volume, which contains data in a frozen
state. This prevents data corruption because data cannot be manipulated
during the volume creation process. Remember that the volumes created
through a <command>nova volume-create</command> command exist in an LVM logical
volume.</para>
        <para>You must also make sure that the operating system is not using the
volume and that all data has been flushed on the guest file systems.
This usually means that those file systems have to be unmounted during
the snapshot creation. They can be mounted again as soon as the logical
volume snapshot has been created.</para>
        <para>Before you create the snapshot you must have enough space to save it.
As a precaution, you should have at least twice as much space as the
potential snapshot size. If insufficient space is available, the snapshot
might become corrupted.</para>
        <para>For this example assume that a 100 GB volume named <literal>volume-00000001</literal>
was created for an instance while only 4 GB are used. This example uses
these commands to back up only those 4 GB:</para>
        <itemizedlist>
          <listitem>
            <para><command>lvm2</command> command. Directly manipulates the volumes.</para>
          </listitem>
          <listitem>
            <para><command>kpartx</command> command. Discovers the partition table created inside the
instance.</para>
          </listitem>
          <listitem>
            <para><command>tar</command> command. Creates a minimum-sized backup.</para>
          </listitem>
          <listitem>
            <para><command>sha1sum</command> command. Calculates the backup checksum to check its
consistency.</para>
          </listitem>
        </itemizedlist>
        <para>You can apply this process to volumes of any size.</para>
        <para>
          <emphasis role="bold">To back up Block Storage service disks</emphasis>
        </para>
        <procedure>
          <step>
            <para>Create a snapshot of a used volume</para>
            <itemizedlist>
              <listitem>
                <para>Use this command to list all volumes</para>
                <screen language="console"># lvdisplay</screen>
              </listitem>
              <listitem>
                <para>Create the snapshot; you can do this while the volume is attached
to an instance:</para>
                <screen language="console"># lvcreate --size 10G --snapshot --name volume-00000001-snapshot \
  /dev/cinder-volumes/volume-00000001</screen>
                <para>Use the <literal>--snapshot</literal> configuration option to tell LVM that you want a
snapshot of an already existing volume. The command includes the size
of the space reserved for the snapshot volume, the name of the snapshot,
and the path of an already existing volume. Generally, this path
is <literal>/dev/cinder-volumes/VOLUME_NAME</literal>.</para>
                <para>The size does not have to be the same as the volume of the snapshot.
The <literal>--size</literal> parameter defines the space that LVM reserves
for the snapshot volume. As a precaution, the size should be the same
as that of the original volume, even if the whole space is not
currently used by the snapshot.</para>
              </listitem>
              <listitem>
                <para>Run the <command>lvdisplay</command> command again to verify the snapshot:</para>
                <screen language="console">--- Logical volume ---
LV Name                /dev/cinder-volumes/volume-00000001
VG Name                cinder-volumes
LV UUID                gI8hta-p21U-IW2q-hRN1-nTzN-UC2G-dKbdKr
LV Write Access        read/write
LV snapshot status     source of
                       /dev/cinder-volumes/volume-00000026-snap [active]
LV Status              available
# open                 1
LV Size                15,00 GiB
Current LE             3840
Segments               1
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           251:13

--- Logical volume ---
LV Name                /dev/cinder-volumes/volume-00000001-snap
VG Name                cinder-volumes
LV UUID                HlW3Ep-g5I8-KGQb-IRvi-IRYU-lIKe-wE9zYr
LV Write Access        read/write
LV snapshot status     active destination for /dev/cinder-volumes/volume-00000026
LV Status              available
# open                 0
LV Size                15,00 GiB
Current LE             3840
COW-table size         10,00 GiB
COW-table LE           2560
Allocated to snapshot  0,00%
Snapshot chunk size    4,00 KiB
Segments               1
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           251:14</screen>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>Partition table discovery</para>
            <itemizedlist>
              <listitem>
                <para>To exploit the snapshot with the <command>tar</command> command, mount
your partition on the Block Storage service server.</para>
                <para>The <command>kpartx</command> utility discovers and maps table partitions.
You can use it to view partitions that are created inside the
instance. Without using the partitions created inside instances,
you cannot see its content and create efficient backups.</para>
                <screen language="console"># kpartx -av /dev/cinder-volumes/volume-00000001-snapshot</screen>
                <note>
                  <para>On a Debian-based distribution, you can use the
<command>apt-get install kpartx</command> command to install
<command>kpartx</command>.</para>
                </note>
                <para>If the tools successfully find and map the partition table,
no errors are returned.</para>
              </listitem>
              <listitem>
                <para>To check the partition table map, run this command:</para>
                <screen language="console">$ ls /dev/mapper/nova*</screen>
                <para>You can see the <literal>cinder--volumes-volume--00000001--snapshot1</literal>
partition.</para>
                <para>If you created more than one partition on that volume, you see
several partitions; for example:
<literal>cinder--volumes-volume--00000001--snapshot2</literal>,
<literal>cinder--volumes-volume--00000001--snapshot3</literal>, and so on.</para>
              </listitem>
              <listitem>
                <para>Mount your partition</para>
                <screen language="console"># mount /dev/mapper/cinder--volumes-volume--volume--00000001--snapshot1 /mnt</screen>
                <para>If the partition mounts successfully, no errors are returned.</para>
                <para>You can directly access the data inside the instance. If a message
prompts you for a partition or you cannot mount it, determine whether
enough space was allocated for the snapshot or the <command>kpartx</command>
command failed to discover the partition table.</para>
                <para>Allocate more space to the snapshot and try the process again.</para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>Use the <command>tar</command> command to create archives</para>
            <para>Create a backup of the volume:</para>
            <screen language="console">$ tar --exclude="lost+found" --exclude="some/data/to/exclude" -czf \
  volume-00000001.tar.gz -C /mnt/ /backup/destination</screen>
            <para>This command creates a <literal>tar.gz</literal> file that contains the data,
<emphasis>and data only</emphasis>. This ensures that you do not waste space by backing
up empty sectors.</para>
          </step>
          <step>
            <para>Checksum calculation I</para>
            <para>You should always have the checksum for your backup files. When you
transfer the same file over the network, you can run a checksum
calculation to ensure that your file was not corrupted during its
transfer. The checksum is a unique ID for a file. If the checksums are
different, the file is corrupted.</para>
            <para>Run this command to run a checksum for your file and save the result
to a file:</para>
            <screen language="console">$ sha1sum volume-00000001.tar.gz &gt; volume-00000001.checksum</screen>
            <note>
              <para>Use the <command>sha1sum</command> command carefully because the time it
takes to complete the calculation is directly proportional to the
size of the file.</para>
              <para>Depending on your CPU, the process might take a long time for
files larger than around 4 to 6 GB.</para>
            </note>
          </step>
          <step>
            <para>After work cleaning</para>
            <para>Now that you have an efficient and consistent backup, use this command
to clean up the file system:</para>
            <itemizedlist>
              <listitem>
                <para>Unmount the volume.</para>
                <screen language="console">$ umount /mnt</screen>
              </listitem>
              <listitem>
                <para>Delete the partition table.</para>
                <screen language="console">$ kpartx -dv /dev/cinder-volumes/volume-00000001-snapshot</screen>
              </listitem>
              <listitem>
                <para>Remove the snapshot.</para>
                <screen language="console">$ lvremove -f /dev/cinder-volumes/volume-00000001-snapshot</screen>
              </listitem>
            </itemizedlist>
            <para>Repeat these steps for all your volumes.</para>
          </step>
          <step>
            <para>Automate your backups</para>
            <para>Because more and more volumes might be allocated to your Block Storage
service, you might want to automate your backups.
The <link xlink:href="https://github.com/Razique/BashStuff/blob/master/SYSTEMS/OpenStack/SCR_5005_V01_NUAC-OPENSTACK-EBS-volumes-backup.sh">SCR_5005_V01_NUAC-OPENSTACK-EBS-volumes-backup.sh</link> script assists
you with this task. The script performs the operations from the previous
example, but also provides a mail report and runs the backup based on
the <literal>backups_retention_days</literal> setting.</para>
            <para>Launch this script from the server that runs the Block Storage service.</para>
            <para>This example shows a mail report:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>Backup Start Time - 07/10 at 01:00:01
Current retention - 7 days

The backup volume is mounted. Proceed...
Removing old backups...  : /BACKUPS/EBS-VOL/volume-00000019/volume-00000019_28_09_2011.tar.gz
     /BACKUPS/EBS-VOL/volume-00000019 - 0 h 1 m and 21 seconds. Size - 3,5G

The backup volume is mounted. Proceed...
Removing old backups...  : /BACKUPS/EBS-VOL/volume-0000001a/volume-0000001a_28_09_2011.tar.gz
     /BACKUPS/EBS-VOL/volume-0000001a - 0 h 4 m and 15 seconds. Size - 6,9G
---------------------------------------
Total backups size - 267G - Used space : 35%
Total execution time - 1 h 75 m and 35 seconds</screen>
            <para>The script also enables you to SSH to your instances and run a
<command>mysqldump</command> command into them. To make this work, enable
the connection to the Compute project keys. If you do not want to
run the <command>mysqldump</command> command, you can add
<literal>enable_mysql_dump=0</literal> to the script to turn off this functionality.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Migrate volumes</title>
        <para>OpenStack has the ability to migrate volumes between back ends which support
its volume-type. Migrating a volume transparently moves its data from the
current back end for the volume to a new one. This is an administrator
function, and can be used for functions including storage evacuation (for
maintenance or decommissioning), or manual optimizations (for example,
performance, reliability, or cost).</para>
        <para>These workflows are possible for a migration:</para>
        <procedure>
          <step>
            <para>If the storage can migrate the volume on its own, it is given the
opportunity to do so. This allows the Block Storage driver to enable
optimizations that the storage might be able to perform. If the back end
is not able to perform the migration, the Block Storage uses one of two
generic flows, as follows.</para>
          </step>
          <step>
            <para>If the volume is not attached, the Block Storage service creates a volume
and copies the data from the original to the new volume.</para>
            <note>
              <para>While most back ends support this function, not all do. See the <link xlink:href="http://docs.openstack.org/newton/config-reference/block-storage/volume-drivers.html">driver
documentation</link>
in the OpenStack Configuration Reference for more details.</para>
            </note>
          </step>
          <step>
            <para>If the volume is attached to a VM instance, the Block Storage creates a
volume, and calls Compute to copy the data from the original to the new
volume. Currently this is supported only by the Compute libvirt driver.</para>
          </step>
        </procedure>
        <para>As an example, this scenario shows two LVM back ends and migrates an attached
volume from one to the other. This scenario uses the third migration flow.</para>
        <para>First, list the available back ends:</para>
        <screen language="console"># cinder get-pools
+----------+----------------------------------------------------+
| Property |                       Value                        |
+----------+----------------------------------------------------+
|   name   |           server1@lvmstorage-1#lvmstorage-1        |
+----------+----------------------------------------------------+
+----------+----------------------------------------------------+
| Property |                      Value                         |
+----------+----------------------------------------------------+
|   name   |           server2@lvmstorage-2#lvmstorage-2        |
+----------+----------------------------------------------------+</screen>
        <note>
          <para>Only Block Storage V2 API supports <command>cinder get-pools</command>.</para>
        </note>
        <para>You can also get available back ends like following:</para>
        <screen language="console"># cinder-manage host list
server1@lvmstorage-1    zone1
server2@lvmstorage-2    zone1</screen>
        <para>But it needs to add pool name in the end. For example,
<literal>server1@lvmstorage-1#zone1</literal>.</para>
        <para>Next, as the admin user, you can see the current status of the volume
(replace the example ID with your own):</para>
        <screen language="console">$ openstack volume show 6088f80a-f116-4331-ad48-9afb0dfb196c

+--------------------------------+--------------------------------------+
| Field                          | Value                                |
+--------------------------------+--------------------------------------+
| attachments                    | []                                   |
| availability_zone              | zone1                                |
| bootable                       | false                                |
| consistencygroup_id            | None                                 |
| created_at                     | 2013-09-01T14:53:22.000000           |
| description                    | test                                 |
| encrypted                      | False                                |
| id                             | 6088f80a-f116-4331-ad48-9afb0dfb196c |
| migration_status               | None                                 |
| multiattach                    | False                                |
| name                           | test                                 |
| os-vol-host-attr:host          | controller@lvm#LVM                   |
| os-vol-mig-status-attr:migstat | None                                 |
| os-vol-mig-status-attr:name_id | None                                 |
| os-vol-tenant-attr:tenant_id   | d88310717a8e4ebcae84ed075f82c51e     |
| properties                     | readonly='False'                     |
| replication_status             | disabled                             |
| size                           | 1                                    |
| snapshot_id                    | None                                 |
| source_volid                   | None                                 |
| status                         | in-use                               |
| type                           | None                                 |
| updated_at                     | 2016-07-31T07:22:19.000000           |
| user_id                        | d8e5e5727f3a4ce1886ac8ecec058e83     |
+--------------------------------+--------------------------------------+</screen>
        <para>Note these attributes:</para>
        <itemizedlist>
          <listitem>
            <para><literal>os-vol-host-attr:host</literal> - the volume's current back end.</para>
          </listitem>
          <listitem>
            <para><literal>os-vol-mig-status-attr:migstat</literal> - the status of this volume's migration
(None means that a migration is not currently in progress).</para>
          </listitem>
          <listitem>
            <para><literal>os-vol-mig-status-attr:name_id</literal> - the volume ID that this volume's name
on the back end is based on. Before a volume is ever migrated, its name on
the back end storage may be based on the volume's ID (see the
<literal>volume_name_template</literal> configuration parameter). For example, if
<literal>volume_name_template</literal> is kept as the default value (<literal>volume-%s</literal>), your
first LVM back end has a logical volume named
<literal>volume-6088f80a-f116-4331-ad48-9afb0dfb196c</literal>. During the course of a
migration, if you create a volume and copy over the data, the volume get
the new name but keeps its original ID. This is exposed by the <literal>name_id</literal>
attribute.</para>
            <note>
              <para>If you plan to decommission a block storage node, you must stop the
<literal>cinder</literal> volume service on the node after performing the migration.</para>
              <para>On nodes that run CentOS, Fedora, openSUSE, Red Hat Enterprise Linux,
or SUSE Linux Enterprise, run:</para>
              <screen language="console"># service openstack-cinder-volume stop
# chkconfig openstack-cinder-volume off</screen>
              <para>On nodes that run Ubuntu or Debian, run:</para>
              <screen language="console"># service cinder-volume stop
# chkconfig cinder-volume off</screen>
              <para>Stopping the cinder volume service will prevent volumes from being
allocated to the node.</para>
            </note>
          </listitem>
        </itemizedlist>
        <para>Migrate this volume to the second LVM back end:</para>
        <screen language="console">$ cinder migrate 6088f80a-f116-4331-ad48-9afb0dfb196c \
  server2@lvmstorage-2#lvmstorage-2</screen>
        <para>You can use the <command>openstack volume show</command> command to see the status of
the migration. While migrating, the <literal>migstat</literal> attribute shows states such as
<literal>migrating</literal> or <literal>completing</literal>. On error, <literal>migstat</literal> is set to None and the
host attribute shows the original <literal>host</literal>. On success, in this example, the
output looks like:</para>
        <screen language="console">+--------------------------------+--------------------------------------+
| Field                          | Value                                |
+--------------------------------+--------------------------------------+
| attachments                    | []                                   |
| availability_zone              | zone1                                |
| bootable                       | false                                |
| consistencygroup_id            | None                                 |
| created_at                     | 2013-09-01T14:53:22.000000           |
| description                    | test                                 |
| encrypted                      | False                                |
| id                             | 6088f80a-f116-4331-ad48-9afb0dfb196c |
| migration_status               | None                                 |
| multiattach                    | False                                |
| name                           | test                                 |
| os-vol-host-attr:host          | controller@lvm#LVM                   |
| os-vol-mig-status-attr:migstat | None                                 |
| os-vol-mig-status-attr:name_id | None                                 |
| os-vol-tenant-attr:tenant_id   | d88310717a8e4ebcae84ed075f82c51e     |
| properties                     | readonly='False'                     |
| replication_status             | disabled                             |
| size                           | 1                                    |
| snapshot_id                    | None                                 |
| source_volid                   | None                                 |
| status                         | in-use                               |
| type                           | None                                 |
| updated_at                     | 2016-07-31T07:22:19.000000           |
| user_id                        | d8e5e5727f3a4ce1886ac8ecec058e83     |
+--------------------------------+--------------------------------------+</screen>
        <para>Note that <literal>migstat</literal> is None, host is the new host, and <literal>name_id</literal> holds the
ID of the volume created by the migration. If you look at the second LVM back
end, you find the logical volume
<literal>volume-133d1f56-9ffc-4f57-8798-d5217d851862</literal>.</para>
        <note>
          <para>The migration is not visible to non-admin users (for example, through the
volume <literal>status</literal>). However, some operations are not allowed while a
migration is taking place, such as attaching/detaching a volume and
deleting a volume. If a user performs such an action during a migration,
an error is returned.</para>
        </note>
        <note>
          <para>Migrating volumes that have snapshots are currently not allowed.</para>
        </note>
      </sect2>
      <sect2>
        <title>Gracefully remove a GlusterFS volume from usage</title>
        <para>Configuring the <literal>cinder</literal> volume service to use GlusterFS involves creating a
shares file (for example, <literal>/etc/cinder/glusterfs</literal>). This shares file
lists each GlusterFS volume (with its corresponding storage server) that
the <literal>cinder</literal> volume service can use for back end storage.</para>
        <para>To remove a GlusterFS volume from usage as a back end, delete the volume's
corresponding entry from the shares file. After doing so, restart the Block
Storage services.</para>
        <para>Restarting the Block Storage services will prevent the <literal>cinder</literal> volume
service from exporting the deleted GlusterFS volume. This will prevent any
instances from mounting the volume from that point onwards.</para>
        <para>However, the removed GlusterFS volume might still be mounted on an instance
at this point. Typically, this is the case when the volume was already
mounted while its entry was deleted from the shares file.
Whenever this occurs, you will have to unmount the volume as normal after
the Block Storage services are restarted.</para>
      </sect2>
      <sect2 xml:id="volume-backups">
        <title>Back up and restore volumes and snapshots</title>
        <para>The <literal>openstack</literal> command-line interface provides the tools for creating a
volume backup. You can restore a volume from a backup as long as the
backup's associated database information (or backup metadata) is intact
in the Block Storage database.</para>
        <para>Run this command to create a backup of a volume:</para>
        <screen language="console">$ openstack volume backup create [--incremental] [--force] VOLUME</screen>
        <para>Where <literal>VOLUME</literal> is the name or ID of the volume, <literal>incremental</literal> is
a flag that indicates whether an incremental backup should be performed,
and <literal>force</literal> is a flag that allows or disallows backup of a volume
when the volume is attached to an instance.</para>
        <para>Without the <literal>incremental</literal> flag, a full backup is created by default.
With the <literal>incremental</literal> flag, an incremental backup is created.</para>
        <para>Without the <literal>force</literal> flag, the volume will be backed up only if its
status is <literal>available</literal>. With the <literal>force</literal> flag, the volume will be
backed up whether its status is <literal>available</literal> or <literal>in-use</literal>. A volume
is <literal>in-use</literal> when it is attached to an instance. The backup of an
<literal>in-use</literal> volume means your data is crash consistent. The <literal>force</literal>
flag is False by default.</para>
        <note>
          <para>The <literal>incremental</literal> and <literal>force</literal> flags are only available for block
storage API v2. You have to specify <literal>[--os-volume-api-version 2]</literal> in the
<literal>cinder</literal> command-line interface to use this parameter.</para>
        </note>
        <note>
          <para>The <literal>force</literal> flag is new in OpenStack Liberty.</para>
        </note>
        <para>The incremental backup is based on a parent backup which is an existing
backup with the latest timestamp. The parent backup can be a full backup
or an incremental backup depending on the timestamp.</para>
        <note>
          <para>The first backup of a volume has to be a full backup. Attempting to do
an incremental backup without any existing backups will fail.
There is an <literal>is_incremental</literal> flag that indicates whether a backup is
incremental when showing details on the backup.
Another flag, <literal>has_dependent_backups</literal>, returned when showing backup
details, will indicate whether the backup has dependent backups.
If it is <literal>true</literal>, attempting to delete this backup will fail.</para>
        </note>
        <para>A new configure option <literal>backup_swift_block_size</literal> is introduced into
<literal>cinder.conf</literal> for the default Swift backup driver. This is the size in
bytes that changes are tracked for incremental backups. The existing
<literal>backup_swift_object_size</literal> option, the size in bytes of Swift backup
objects, has to be a multiple of <literal>backup_swift_block_size</literal>. The default
is 32768 for <literal>backup_swift_block_size</literal>, and the default is 52428800 for
<literal>backup_swift_object_size</literal>.</para>
        <para>The configuration option <literal>backup_swift_enable_progress_timer</literal> in
<literal>cinder.conf</literal> is used when backing up the volume to Object Storage
back end. This option enables or disables the timer. It is enabled by default
to send the periodic progress notifications to the Telemetry service.</para>
        <para>This command also returns a backup ID. Use this backup ID when restoring
the volume:</para>
        <screen language="console">$ openstack volume backup restore BACKUP_ID VOLUME_ID</screen>
        <para>When restoring from a full backup, it is a full restore.</para>
        <para>When restoring from an incremental backup, a list of backups is built based
on the IDs of the parent backups. A full restore is performed based on the
full backup first, then restore is done based on the incremental backup,
laying on top of it in order.</para>
        <para>You can view a backup list with the <command>cinder backup-list</command>
command. Optional arguments to clarify the status of your backups
include: running <literal>--name</literal>, <literal>--status</literal>, and
<literal>--volume-id</literal> to filter through backups by the specified name,
status, or volume-id. Search with <literal>--all-tenants</literal> for details of the
projects associated with the listed backups.</para>
        <para>Because volume backups are dependent on the Block Storage database, you must
also back up your Block Storage database regularly to ensure data recovery.</para>
        <note>
          <para>Alternatively, you can export and save the metadata of selected volume
backups. Doing so precludes the need to back up the entire Block Storage
database. This is useful if you need only a small subset of volumes to
survive a catastrophic database failure.</para>
          <para>If you specify a UUID encryption key when setting up the volume
specifications, the backup metadata ensures that the key will remain valid
when you back up and restore the volume.</para>
          <para>For more information about how to export and import volume backup metadata,
see the section called <xref linkend="volume-backups-export-import"/>.</para>
        </note>
        <para>By default, the swift object store is used for the backup repository.</para>
        <para>If instead you want to use an NFS export as the backup repository, add the
following configuration options to the <literal>[DEFAULT]</literal> section of the
<literal>cinder.conf</literal> file and restart the Block Storage services:</para>
        <screen language="ini">backup_driver = cinder.backup.drivers.nfs
backup_share = HOST:EXPORT_PATH</screen>
        <para>For the <literal>backup_share</literal> option, replace <literal>HOST</literal> with the DNS resolvable
host name or the IP address of the storage server for the NFS share, and
<literal>EXPORT_PATH</literal> with the path to that share. If your environment requires
that non-default mount options be specified for the share, set these as
follows:</para>
        <screen language="ini">backup_mount_options = MOUNT_OPTIONS</screen>
        <para><literal>MOUNT_OPTIONS</literal> is a comma-separated string of NFS mount options as detailed
in the NFS man page.</para>
        <para>There are several other options whose default values may be overridden as
appropriate for your environment:</para>
        <screen language="ini">backup_compression_algorithm = zlib
backup_sha_block_size_bytes = 32768
backup_file_size = 1999994880</screen>
        <para>The option <literal>backup_compression_algorithm</literal> can be set to <literal>bz2</literal> or <literal>None</literal>.
The latter can be a useful setting when the server providing the share for the
backup repository itself performs deduplication or compression on the backup
data.</para>
        <para>The option <literal>backup_file_size</literal> must be a multiple of
<literal>backup_sha_block_size_bytes</literal>. It is effectively the maximum file size to be
used, given your environment, to hold backup data. Volumes larger than this
will be stored in multiple files in the backup repository. The
<literal>backup_sha_block_size_bytes</literal> option determines the size of blocks from the
cinder volume being backed up on which digital signatures are calculated in
order to enable incremental backup capability.</para>
        <para>You also have the option of resetting the state of a backup. When creating or
restoring a backup, sometimes it may get stuck in the creating or restoring
states due to problems like the database or rabbitmq being down. In situations
like these resetting the state of the backup can restore it to a functional
status.</para>
        <para>Run this command to restore the state of a backup:</para>
        <screen language="console">$ cinder backup-reset-state [--state STATE] BACKUP_ID-1 BACKUP_ID-2 ...</screen>
        <para>Run this command to create a backup of a snapshot:</para>
        <screen language="console">$ openstack volume backup create [--incremental] [--force] \
  [--snapshot SNAPSHOT_ID] VOLUME</screen>
        <para>Where <literal>VOLUME</literal> is the name or ID of the volume, <literal>SNAPSHOT_ID</literal> is the ID of
the volume's snapshot.</para>
      </sect2>
      <sect2 xml:id="volume-backups-export-import">
        <title>Export and import backup metadata</title>
        <para>A volume backup can only be restored on the same Block Storage service. This
is because restoring a volume from a backup requires metadata available on
the database used by the Block Storage service.</para>
        <note>
          <para>For information about how to back up and restore a volume, see
the section called <xref linkend="volume-backups"/>.</para>
        </note>
        <para>You can, however, export the metadata of a volume backup. To do so, run
this command as an OpenStack <literal>admin</literal> user (presumably, after creating
a volume backup):</para>
        <screen language="console">$ cinder backup-export BACKUP_ID</screen>
        <para>Where <literal>BACKUP_ID</literal> is the volume backup's ID. This command should return the
backup's corresponding database information as encoded string metadata.</para>
        <para>Exporting and storing this encoded string metadata allows you to completely
restore the backup, even in the event of a catastrophic database failure.
This will preclude the need to back up the entire Block Storage database,
particularly if you only need to keep complete backups of a small subset
of volumes.</para>
        <para>If you have placed encryption on your volumes, the encryption will still be
in place when you restore the volume if a UUID encryption key is specified
when creating volumes. Using backup metadata support, UUID keys set up for
a volume (or volumes) will remain valid when you restore a backed-up volume.
The restored volume will remain encrypted, and will be accessible with your
credentials.</para>
        <para>In addition, having a volume backup and its backup metadata also provides
volume portability. Specifically, backing up a volume and exporting its
metadata will allow you to restore the volume on a completely different Block
Storage database, or even on a different cloud service. To do so, first
import the backup metadata to the Block Storage database and then restore
the backup.</para>
        <para>To import backup metadata, run the following command as an OpenStack
<literal>admin</literal>:</para>
        <screen language="console">$ cinder backup-import METADATA</screen>
        <para>Where <literal>METADATA</literal> is the backup metadata exported earlier.</para>
        <para>Once you have imported the backup metadata into a Block Storage database,
restore the volume (see the section called <xref linkend="volume-backups"/>).</para>
      </sect2>
      <sect2>
        <title>Use LIO iSCSI support</title>
        <para>The default mode for the <literal>iscsi_helper</literal> tool is <literal>tgtadm</literal>.
To use LIO iSCSI, install the <literal>python-rtslib</literal> package, and set
<literal>iscsi_helper=lioadm</literal> in the <literal>cinder.conf</literal> file.</para>
        <para>Once configured, you can use the <command>cinder-rtstool</command> command to
manage the volumes. This command enables you to create, delete, and
verify volumes and determine targets and add iSCSI initiators to the
system.</para>
      </sect2>
      <sect2>
        <title>Configure and use volume number weigher</title>
        <para>OpenStack Block Storage enables you to choose a volume back end according
to <literal>free_capacity</literal> and <literal>allocated_capacity</literal>. The volume number weigher
feature lets the scheduler choose a volume back end based on its volume
number in the volume back end. This can provide another means to improve
the volume back ends' I/O balance and the volumes' I/O performance.</para>
        <sect3>
          <title>Enable volume number weigher</title>
          <para>To enable a volume number weigher, set the
<literal>scheduler_default_weighers</literal> to <literal>VolumeNumberWeigher</literal> flag in the
<literal>cinder.conf</literal> file to define <literal>VolumeNumberWeigher</literal>
as the selected weigher.</para>
        </sect3>
        <sect3>
          <title>Configure multiple-storage back ends</title>
          <para>To configure <literal>VolumeNumberWeigher</literal>, use <literal>LVMVolumeDriver</literal>
as the volume driver.</para>
          <para>This configuration defines two LVM volume groups: <literal>stack-volumes</literal> with
10 GB capacity and <literal>stack-volumes-1</literal> with 60 GB capacity.
This example configuration defines two back ends:</para>
          <screen language="ini">scheduler_default_weighers=VolumeNumberWeigher
enabled_backends=lvmdriver-1,lvmdriver-2
[lvmdriver-1]
volume_group=stack-volumes
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM

[lvmdriver-2]
volume_group=stack-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM</screen>
        </sect3>
        <sect3>
          <title>Volume type</title>
          <para>Define a volume type in Block Storage:</para>
          <screen language="console">$ openstack volume type create lvm</screen>
          <para>Create an extra specification that links the volume type to a back-end name:</para>
          <screen language="console">$ openstack volume type set lvm --property volume_backend_name=LVM</screen>
          <para>This example creates a lvm volume type with
<literal>volume_backend_name=LVM</literal> as extra specifications.</para>
        </sect3>
        <sect3>
          <title>Usage</title>
          <para>To create six 1-GB volumes, run the
<command>openstack volume create --size 1 --type lvm volume1</command> command
six times:</para>
          <screen language="console">$ openstack volume create --size 1 --type lvm volume1</screen>
          <para>This command creates three volumes in <literal>stack-volumes</literal> and
three volumes in <literal>stack-volumes-1</literal>.</para>
          <para>List the available volumes:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?># lvs
LV                                          VG              Attr      LSize  Pool Origin Data%  Move Log Copy%  Convert
volume-3814f055-5294-4796-b5e6-1b7816806e5d stack-volumes   -wi-a----  1.00g
volume-72cf5e79-99d2-4d23-b84e-1c35d3a293be stack-volumes   -wi-a----  1.00g
volume-96832554-0273-4e9d-902b-ad421dfb39d1 stack-volumes   -wi-a----  1.00g
volume-169386ef-3d3e-4a90-8439-58ceb46889d9 stack-volumes-1 -wi-a----  1.00g
volume-460b0bbb-d8a0-4bc3-9882-a129a5fe8652 stack-volumes-1 -wi-a----  1.00g
volume-9a08413b-0dbc-47c9-afb8-41032ab05a41 stack-volumes-1 -wi-a----  1.00g</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Consistency groups</title>
        <para>Consistency group support is available in OpenStack Block Storage. The
support is added for creating snapshots of consistency groups. This
feature leverages the storage level consistency technology. It allows
snapshots of multiple volumes in the same consistency group to be taken
at the same point-in-time to ensure data consistency. The consistency
group operations can be performed using the Block Storage command line.</para>
        <note>
          <para>Only Block Storage V2 API supports consistency groups. You can
specify <literal>--os-volume-api-version 2</literal> when using Block Storage
command line for consistency group operations.</para>
        </note>
        <para>Before using consistency groups, make sure the Block Storage driver that
you are running has consistency group support by reading the Block
Storage manual or consulting the driver maintainer. There are a small
number of drivers that have implemented this feature. The default LVM
driver does not support consistency groups yet because the consistency
technology is not available at the storage level.</para>
        <para>Before using consistency groups, you must change policies for the
consistency group APIs in the <literal>/etc/cinder/policy.json</literal> file.
By default, the consistency group APIs are disabled.
Enable them before running consistency group operations.</para>
        <para>Here are existing policy entries for consistency groups:</para>
        <screen language="json">"consistencygroup:create": "group:nobody",
"consistencygroup:delete": "group:nobody",
"consistencygroup:update": "group:nobody",
"consistencygroup:get": "group:nobody",
"consistencygroup:get_all": "group:nobody",
"consistencygroup:create_cgsnapshot" : "group:nobody",
"consistencygroup:delete_cgsnapshot": "group:nobody",
"consistencygroup:get_cgsnapshot": "group:nobody",
"consistencygroup:get_all_cgsnapshots": "group:nobody",</screen>
        <para>Remove <literal>group:nobody</literal> to enable these APIs:</para>
        <screen language="json">"consistencygroup:create": "",
"consistencygroup:delete": "",
"consistencygroup:update": "",
"consistencygroup:get": "",
"consistencygroup:get_all": "",
"consistencygroup:create_cgsnapshot" : "",
"consistencygroup:delete_cgsnapshot": "",
"consistencygroup:get_cgsnapshot": "",
"consistencygroup:get_all_cgsnapshots": "",</screen>
        <para>Restart Block Storage API service after changing policies.</para>
        <para>The following consistency group operations are supported:</para>
        <itemizedlist>
          <listitem>
            <para>Create a consistency group, given volume types.</para>
            <note>
              <para>A consistency group can support more than one volume type. The
scheduler is responsible for finding a back end that can support
all given volume types.</para>
              <para>A consistency group can only contain volumes hosted by the same
back end.</para>
              <para>A consistency group is empty upon its creation. Volumes need to
be created and added to it later.</para>
            </note>
          </listitem>
          <listitem>
            <para>Show a consistency group.</para>
          </listitem>
          <listitem>
            <para>List consistency groups.</para>
          </listitem>
          <listitem>
            <para>Create a volume and add it to a consistency group, given volume type
and consistency group id.</para>
          </listitem>
          <listitem>
            <para>Create a snapshot for a consistency group.</para>
          </listitem>
          <listitem>
            <para>Show a snapshot of a consistency group.</para>
          </listitem>
          <listitem>
            <para>List consistency group snapshots.</para>
          </listitem>
          <listitem>
            <para>Delete a snapshot of a consistency group.</para>
          </listitem>
          <listitem>
            <para>Delete a consistency group.</para>
          </listitem>
          <listitem>
            <para>Modify a consistency group.</para>
          </listitem>
          <listitem>
            <para>Create a consistency group from the snapshot of another consistency
group.</para>
          </listitem>
          <listitem>
            <para>Create a consistency group from a source consistency group.</para>
          </listitem>
        </itemizedlist>
        <para>The following operations are not allowed if a volume is in a consistency
group:</para>
        <itemizedlist>
          <listitem>
            <para>Volume migration.</para>
          </listitem>
          <listitem>
            <para>Volume retype.</para>
          </listitem>
          <listitem>
            <para>Volume deletion.</para>
            <note>
              <para>A consistency group has to be deleted as a whole with all the
volumes.</para>
            </note>
          </listitem>
        </itemizedlist>
        <para>The following operations are not allowed if a volume snapshot is in a
consistency group snapshot:</para>
        <itemizedlist>
          <listitem>
            <para>Volume snapshot deletion.</para>
            <note>
              <para>A consistency group snapshot has to be deleted as a whole with
all the volume snapshots.</para>
            </note>
          </listitem>
        </itemizedlist>
        <para>The details of consistency group operations are shown in the following.</para>
        <note>
          <para>Currently, no OpenStack client command is available to run in
place of the cinder consistency group creation commands. Use the
cinder commands detailed in the following examples.</para>
        </note>
        <para><emphasis role="bold">Create a consistency group</emphasis>:</para>
        <screen language="console">cinder consisgroup-create
[--name name]
[--description description]
[--availability-zone availability-zone]
volume-types</screen>
        <note>
          <para>The parameter <literal>volume-types</literal> is required. It can be a list of
names or UUIDs of volume types separated by commas without spaces in
between. For example, <literal>volumetype1,volumetype2,volumetype3.</literal>.</para>
        </note>
        <screen language="console">$ cinder consisgroup-create --name bronzeCG2 volume_type_1

+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
| availability_zone |                 nova                 |
|     created_at    |      2014-12-29T12:59:08.000000      |
|    description    |                 None                 |
|         id        | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|        name       |              bronzeCG2               |
|       status      |               creating               |
+-------------------+--------------------------------------+</screen>
        <para><emphasis role="bold">Show a consistency group</emphasis>:</para>
        <screen language="console">$ cinder consisgroup-show 1de80c27-3b2f-47a6-91a7-e867cbe36462

+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
| availability_zone |                 nova                 |
|     created_at    |      2014-12-29T12:59:08.000000      |
|    description    |                 None                 |
|         id        | 2a6b2bda-1f43-42ce-9de8-249fa5cbae9a |
|        name       |              bronzeCG2               |
|       status      |              available               |
|     volume_types  |              volume_type_1           |
+-------------------+--------------------------------------+</screen>
        <para><emphasis role="bold">List consistency groups</emphasis>:</para>
        <screen language="console">$ cinder consisgroup-list

+--------------------------------------+-----------+-----------+
|                  ID                  |   Status  |    Name   |
+--------------------------------------+-----------+-----------+
| 1de80c27-3b2f-47a6-91a7-e867cbe36462 | available | bronzeCG2 |
| 3a2b3c42-b612-479a-91eb-1ed45b7f2ad5 |   error   |  bronzeCG |
+--------------------------------------+-----------+-----------+</screen>
        <para><emphasis role="bold">Create a volume and add it to a consistency group</emphasis>:</para>
        <note>
          <para>When creating a volume and adding it to a consistency group, a
volume type and a consistency group id must be provided. This is
because a consistency group can support more than one volume type.</para>
        </note>
        <screen language="console">$ openstack volume create --type volume_type_1 --consistency-group \
  1de80c27-3b2f-47a6-91a7-e867cbe36462 --size 1 cgBronzeVol

+---------------------------------------+--------------------------------------+
| Field                                 | Value                                |
+---------------------------------------+--------------------------------------+
|              attachments              |                  []                  |
|           availability_zone           |                 nova                 |
|                bootable               |                false                 |
|          consistencygroup_id          | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|               created_at              |      2014-12-29T13:16:47.000000      |
|              description              |                 None                 |
|               encrypted               |                False                 |
|                   id                  | 5e6d1386-4592-489f-a56b-9394a81145fe |
|                metadata               |                  {}                  |
|                  name                 |             cgBronzeVol              |
|         os-vol-host-attr:host         |      server-1@backend-1#pool-1       |
|     os-vol-mig-status-attr:migstat    |                 None                 |
|     os-vol-mig-status-attr:name_id    |                 None                 |
|      os-vol-tenant-attr:tenant_id     |   1349b21da2a046d8aa5379f0ed447bed   |
|   os-volume-replication:driver_data   |                 None                 |
| os-volume-replication:extended_status |                 None                 |
|           replication_status          |               disabled               |
|                  size                 |                  1                   |
|              snapshot_id              |                 None                 |
|              source_volid             |                 None                 |
|                 status                |               creating               |
|                user_id                |   93bdea12d3e04c4b86f9a9f172359859   |
|              volume_type              |            volume_type_1             |
+---------------------------------------+--------------------------------------+</screen>
        <para><emphasis role="bold">Create a snapshot for a consistency group</emphasis>:</para>
        <screen language="console">$ cinder cgsnapshot-create 1de80c27-3b2f-47a6-91a7-e867cbe36462

+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
| consistencygroup_id | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|      created_at     |      2014-12-29T13:19:44.000000      |
|     description     |                 None                 |
|          id         | d4aff465-f50c-40b3-b088-83feb9b349e9 |
|         name        |                 None                 |
|        status       |               creating               |
+---------------------+-------------------------------------+</screen>
        <para><emphasis role="bold">Show a snapshot of a consistency group</emphasis>:</para>
        <screen language="console">$ cinder cgsnapshot-show d4aff465-f50c-40b3-b088-83feb9b349e9</screen>
        <para><emphasis role="bold">List consistency group snapshots</emphasis>:</para>
        <screen language="console">$ cinder cgsnapshot-list

+--------------------------------------+--------+----------+
|                  ID                  | Status | Name     |
+--------------------------------------+--------+----------+
| 6d9dfb7d-079a-471e-b75a-6e9185ba0c38 | available  | None |
| aa129f4d-d37c-4b97-9e2d-7efffda29de0 | available  | None |
| bb5b5d82-f380-4a32-b469-3ba2e299712c | available  | None |
| d4aff465-f50c-40b3-b088-83feb9b349e9 | available  | None |
+--------------------------------------+--------+----------+</screen>
        <para><emphasis role="bold">Delete a snapshot of a consistency group</emphasis>:</para>
        <screen language="console">$ cinder cgsnapshot-delete d4aff465-f50c-40b3-b088-83feb9b349e9</screen>
        <para><emphasis role="bold">Delete a consistency group</emphasis>:</para>
        <note>
          <para>The force flag is needed when there are volumes in the consistency
group:</para>
          <screen language="console">$ cinder consisgroup-delete --force 1de80c27-3b2f-47a6-91a7-e867cbe36462</screen>
        </note>
        <para><emphasis role="bold">Modify a consistency group</emphasis>:</para>
        <screen language="console">cinder consisgroup-update
[--name NAME]
[--description DESCRIPTION]
[--add-volumes UUID1,UUID2,......]
[--remove-volumes UUID3,UUID4,......]
CG</screen>
        <para>The parameter <literal>CG</literal> is required. It can be a name or UUID of a consistency
group. UUID1,UUID2,...... are UUIDs of one or more volumes to be added
to the consistency group, separated by commas. Default is None.
UUID3,UUID4,...... are UUIDs of one or more volumes to be removed from
the consistency group, separated by commas. Default is None.</para>
        <screen language="console">$ cinder consisgroup-update --name 'new name' --description 'new descripti\
  on' --add-volumes 0b3923f5-95a4-4596-a536-914c2c84e2db,1c02528b-3781-4e3\
  2-929c-618d81f52cf3 --remove-volumes 8c0f6ae4-efb1-458f-a8fc-9da2afcc5fb\
  1,a245423f-bb99-4f94-8c8c-02806f9246d8 1de80c27-3b2f-47a6-91a7-e867cbe36462</screen>
        <para><emphasis role="bold">Create a consistency group from the snapshot of another consistency
group</emphasis>:</para>
        <screen language="console">$ cinder consisgroup-create-from-src
[--cgsnapshot CGSNAPSHOT]
[--name NAME]
[--description DESCRIPTION]</screen>
        <para>The parameter <literal>CGSNAPSHOT</literal> is a name or UUID of a snapshot of a
consistency group:</para>
        <screen language="console">$ cinder consisgroup-create-from-src --cgsnapshot 6d9dfb7d-079a-471e-b75a-\
  6e9185ba0c38 --name 'new cg' --description 'new cg from cgsnapshot'</screen>
        <para><emphasis role="bold">Create a consistency group from a source consistency group</emphasis>:</para>
        <screen language="console">$ cinder consisgroup-create-from-src
[--source-cg SOURCECG]
[--name NAME]
[--description DESCRIPTION]</screen>
        <para>The parameter <literal>SOURCECG</literal> is a name or UUID of a source
consistency group:</para>
        <screen language="console">$ cinder consisgroup-create-from-src --source-cg 6d9dfb7d-079a-471e-b75a-\
  6e9185ba0c38 --name 'new cg' --description 'new cloned cg'</screen>
      </sect2>
      <sect2 xml:id="filter-weigh-scheduler">
        <title>Configure and use driver filter and weighing for scheduler</title>
        <para>OpenStack Block Storage enables you to choose a volume back end based on
back-end specific properties by using the DriverFilter and
GoodnessWeigher for the scheduler. The driver filter and weigher
scheduling can help ensure that the scheduler chooses the best back end
based on requested volume properties as well as various back-end
specific properties.</para>
        <sect3>
          <title>What is driver filter and weigher and when to use it</title>
          <para>The driver filter and weigher gives you the ability to more finely
control how the OpenStack Block Storage scheduler chooses the best back
end to use when handling a volume request. One example scenario where
using the driver filter and weigher can be if a back end that utilizes
thin-provisioning is used. The default filters use the <literal>free capacity</literal>
property to determine the best back end, but that is not always perfect.
If a back end has the ability to provide a more accurate back-end
specific value you can use that as part of the weighing. Another example
of when the driver filter and weigher can prove useful is if a back end
exists where there is a hard limit of 1000 volumes. The maximum volume
size is 500 GB. Once 75% of the total space is occupied the performance
of the back end degrades. The driver filter and weigher can provide a
way for these limits to be checked for.</para>
        </sect3>
        <sect3>
          <title>Enable driver filter and weighing</title>
          <para>To enable the driver filter, set the <literal>scheduler_default_filters</literal> option in
the <literal>cinder.conf</literal> file to <literal>DriverFilter</literal> or add it to the list if
other filters are already present.</para>
          <para>To enable the goodness filter as a weigher, set the
<literal>scheduler_default_weighers</literal> option in the <literal>cinder.conf</literal> file to
<literal>GoodnessWeigher</literal> or add it to the list if other weighers are already
present.</para>
          <para>You can choose to use the <literal>DriverFilter</literal> without the
<literal>GoodnessWeigher</literal> or vice-versa. The filter and weigher working
together, however, create the most benefits when helping the scheduler
choose an ideal back end.</para>
          <important>
            <para>The support for the <literal>DriverFilter</literal> and <literal>GoodnessWeigher</literal> is
optional for back ends. If you are using a back end that does not
support the filter and weigher functionality you may not get the
full benefit.</para>
          </important>
          <para>Example <literal>cinder.conf</literal> configuration file:</para>
          <screen language="ini">scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher</screen>
          <note>
            <para>It is useful to use the other filters and weighers available in
OpenStack in combination with these custom ones. For example, the
<literal>CapacityFilter</literal> and <literal>CapacityWeigher</literal> can be combined with
these.</para>
          </note>
        </sect3>
        <sect3>
          <title>Defining your own filter and goodness functions</title>
          <para>You can define your own filter and goodness functions through the use of
various properties that OpenStack Block Storage has exposed. Properties
exposed include information about the volume request being made,
<literal>volume_type</literal> settings, and back-end specific information about drivers.
All of these allow for a lot of control over how the ideal back end for
a volume request will be decided.</para>
          <para>The <literal>filter_function</literal> option is a string defining an equation that
will determine whether a back end should be considered as a potential
candidate in the scheduler.</para>
          <para>The <literal>goodness_function</literal> option is a string defining an equation that
will rate the quality of the potential host (0 to 100, 0 lowest, 100
highest).</para>
          <important>
            <para>The drive filter and weigher will use default values for filter and
goodness functions for each back end if you do not define them
yourself. If complete control is desired then a filter and goodness
function should be defined for each of the back ends in
the <literal>cinder.conf</literal> file.</para>
          </important>
        </sect3>
        <sect3>
          <title>Supported operations in filter and goodness functions</title>
          <para>Below is a table of all the operations currently usable in custom filter
and goodness functions created by you:</para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="56.1*"/>
              <colspec colname="c2" colwidth="43.9*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operations</para>
                  </entry>
                  <entry>
                    <para>Type</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>+, -, *, /, ^</para>
                  </entry>
                  <entry>
                    <para>standard math</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>not, and, or, &amp;, |, !</para>
                  </entry>
                  <entry>
                    <para>logic</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>&gt;, &gt;=, &lt;, &lt;=, ==, &lt;&gt;, !=</para>
                  </entry>
                  <entry>
                    <para>equality</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>+, -</para>
                  </entry>
                  <entry>
                    <para>sign</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>x ? a : b</para>
                  </entry>
                  <entry>
                    <para>ternary</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>abs(x), max(x, y), min(x, y)</para>
                  </entry>
                  <entry>
                    <para>math helper functions</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <important>
            <para>Syntax errors you define in filter or goodness strings
are thrown at a volume request time.</para>
          </important>
        </sect3>
        <sect3>
          <title>Available properties when creating custom functions</title>
          <para>There are various properties that can be used in either the
<literal>filter_function</literal> or the <literal>goodness_function</literal> strings. The properties allow
access to volume info, qos settings, extra specs, and so on.</para>
          <para>The following properties and their sub-properties are currently
available for use:</para>
          <sect4>
            <title>Host stats for a back end</title>
            <variablelist>
              <varlistentry>
                <term>host</term>
                <listitem>
                  <para>The host's name</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>volume_backend_name</term>
                <listitem>
                  <para>The volume back end name</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>vendor_name</term>
                <listitem>
                  <para>The vendor name</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>driver_version</term>
                <listitem>
                  <para>The driver version</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>storage_protocol</term>
                <listitem>
                  <para>The storage protocol</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>QoS_support</term>
                <listitem>
                  <para>Boolean signifying whether QoS is supported</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>total_capacity_gb</term>
                <listitem>
                  <para>The total capacity in GB</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>allocated_capacity_gb</term>
                <listitem>
                  <para>The allocated capacity in GB</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>reserved_percentage</term>
                <listitem>
                  <para>The reserved storage percentage</para>
                </listitem>
              </varlistentry>
            </variablelist>
          </sect4>
          <sect4>
            <title>Capabilities specific to a back end</title>
            <para>These properties are determined by the specific back end
you are creating filter and goodness functions for. Some back ends
may not have any properties available here.</para>
          </sect4>
          <sect4>
            <title>Requested volume properties</title>
            <variablelist>
              <varlistentry>
                <term>status</term>
                <listitem>
                  <para>Status for the requested volume</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>volume_type_id</term>
                <listitem>
                  <para>The volume type ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>display_name</term>
                <listitem>
                  <para>The display name of the volume</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>volume_metadata</term>
                <listitem>
                  <para>Any metadata the volume has</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>reservations</term>
                <listitem>
                  <para>Any reservations the volume has</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>user_id</term>
                <listitem>
                  <para>The volume's user ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>attach_status</term>
                <listitem>
                  <para>The attach status for the volume</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>display_description</term>
                <listitem>
                  <para>The volume's display description</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>id</term>
                <listitem>
                  <para>The volume's ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>replication_status</term>
                <listitem>
                  <para>The volume's replication status</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>snapshot_id</term>
                <listitem>
                  <para>The volume's snapshot ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>encryption_key_id</term>
                <listitem>
                  <para>The volume's encryption key ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>source_volid</term>
                <listitem>
                  <para>The source volume ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>volume_admin_metadata</term>
                <listitem>
                  <para>Any admin metadata for this volume</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>source_replicaid</term>
                <listitem>
                  <para>The source replication ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>consistencygroup_id</term>
                <listitem>
                  <para>The consistency group ID</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>size</term>
                <listitem>
                  <para>The size of the volume in GB</para>
                </listitem>
              </varlistentry>
              <varlistentry>
                <term>metadata</term>
                <listitem>
                  <para>General metadata</para>
                </listitem>
              </varlistentry>
            </variablelist>
            <para>The property most used from here will most likely be the <literal>size</literal> sub-property.</para>
          </sect4>
        </sect3>
        <sect3>
          <title>Extra specs for the requested volume type</title>
          <para>View the available properties for volume types by running:</para>
          <screen language="console">$ cinder extra-specs-list</screen>
        </sect3>
        <sect3>
          <title>Current QoS specs for the requested volume type</title>
          <para>View the available properties for volume types by running:</para>
          <screen language="console">$ cinder qos-list</screen>
          <para>In order to access these properties in a custom string use the following
format:</para>
          <para>
            <literal>&lt;property&gt;.&lt;sub_property&gt;</literal>
          </para>
        </sect3>
        <sect3>
          <title>Driver filter and weigher usage examples</title>
          <para>Below are examples for using the filter and weigher separately,
together, and using driver-specific properties.</para>
          <para>Example <literal>cinder.conf</literal> file configuration for customizing the filter
function:</para>
          <screen language="ini">[default]
scheduler_default_filters = DriverFilter
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "volume.size &lt; 10"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "volume.size &gt;= 10"</screen>
          <para>The above example will filter volumes to different back ends depending
on the size of the requested volume. Default OpenStack Block Storage
scheduler weighing is done. Volumes with a size less than 10 GB are sent
to lvm-1 and volumes with a size greater than or equal to 10 GB are sent
to lvm-2.</para>
          <para>Example <literal>cinder.conf</literal> file configuration for customizing the goodness
function:</para>
          <screen language="ini">[default]
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
goodness_function = "(volume.size &lt; 5) ? 100 : 50"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
goodness_function = "(volume.size &gt;= 5) ? 100 : 25"</screen>
          <para>The above example will determine the goodness rating of a back end based
off of the requested volume's size. Default OpenStack Block Storage
scheduler filtering is done. The example shows how the ternary if
statement can be used in a filter or goodness function. If a requested
volume is of size 10 GB then lvm-1 is rated as 50 and lvm-2 is rated as
100. In this case lvm-2 wins. If a requested volume is of size 3 GB then
lvm-1 is rated 100 and lvm-2 is rated 25. In this case lvm-1 would win.</para>
          <para>Example <literal>cinder.conf</literal> file configuration for customizing both the
filter and goodness functions:</para>
          <screen language="ini">[default]
scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "stats.total_capacity_gb &lt; 500"
goodness_function = "(volume.size &lt; 25) ? 100 : 50"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "stats.total_capacity_gb &gt;= 500"
goodness_function = "(volume.size &gt;= 25) ? 100 : 75"</screen>
          <para>The above example combines the techniques from the first two examples.
The best back end is now decided based off of the total capacity of the
back end and the requested volume's size.</para>
          <para>Example <literal>cinder.conf</literal> file configuration for accessing driver specific
properties:</para>
          <screen language="ini">[default]
scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1,lvm-2,lvm-3

[lvm-1]
volume_group = stack-volumes-lvmdriver-1
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = lvmdriver-1
filter_function = "volume.size &lt; 5"
goodness_function = "(capabilities.total_volumes &lt; 3) ? 100 : 50"

[lvm-2]
volume_group = stack-volumes-lvmdriver-2
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = lvmdriver-2
filter_function = "volumes.size &lt; 5"
goodness_function = "(capabilities.total_volumes &lt; 8) ? 100 : 50"

[lvm-3]
volume_group = stack-volumes-lvmdriver-3
volume_driver = cinder.volume.drivers.LVMVolumeDriver
volume_backend_name = lvmdriver-3
goodness_function = "55"</screen>
          <para>The above is an example of how back-end specific properties can be used
in the filter and goodness functions. In this example the LVM driver's
<literal>total_volumes</literal> capability is being used to determine which host gets
used during a volume request. In the above example, lvm-1 and lvm-2 will
handle volume requests for all volumes with a size less than 5 GB. The
lvm-1 host will have priority until it contains three or more volumes.
After than lvm-2 will have priority until it contains eight or more
volumes. The lvm-3 will collect all volumes greater or equal to 5 GB as
well as all volumes once lvm-1 and lvm-2 lose priority.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Rate-limit volume copy bandwidth</title>
        <para>When you create a new volume from an image or an existing volume, or
when you upload a volume image to the Image service, large data copy
may stress disk and network bandwidth. To mitigate slow down of data
access from the instances, OpenStack Block Storage supports rate-limiting
of volume data copy bandwidth.</para>
        <sect3>
          <title>Configure volume copy bandwidth limit</title>
          <para>To configure the volume copy bandwidth limit, set the
<literal>volume_copy_bps_limit</literal> option in the configuration groups for each
back end in the <literal>cinder.conf</literal> file. This option takes the integer of
maximum bandwidth allowed for volume data copy in byte per second. If
this option is set to <literal>0</literal>, the rate-limit is disabled.</para>
          <para>While multiple volume data copy operations are running in the same back
end, the specified bandwidth is divided to each copy.</para>
          <para>Example <literal>cinder.conf</literal> configuration file to limit volume copy bandwidth
of <literal>lvmdriver-1</literal> up to 100 MiB/s:</para>
          <screen language="ini">[lvmdriver-1]
volume_group=cinder-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
volume_copy_bps_limit=104857600</screen>
          <note>
            <para>This feature requires libcgroup to set up blkio cgroup for disk I/O
bandwidth limit. The libcgroup is provided by the cgroup-bin package
in Debian and Ubuntu, or by the libcgroup-tools package in Fedora,
Red Hat Enterprise Linux, CentOS, openSUSE, and SUSE Linux Enterprise.</para>
          </note>
          <note>
            <para>Some back ends which use remote file systems such as NFS are not
supported by this feature.</para>
          </note>
        </sect3>
      </sect2>
      <sect2>
        <title>Oversubscription in thin provisioning</title>
        <para>OpenStack Block Storage enables you to choose a volume back end based on
virtual capacities for thin provisioning using the oversubscription ratio.</para>
        <para>A reference implementation is provided for the default LVM driver. The
illustration below uses the LVM driver as an example.</para>
        <sect3>
          <title>Configure oversubscription settings</title>
          <para>To support oversubscription in thin provisioning, a flag
<literal>max_over_subscription_ratio</literal> is introduced into <literal>cinder.conf</literal>.
This is a float representation of the oversubscription ratio when thin
provisioning is involved. Default ratio is 20.0, meaning provisioned
capacity can be 20 times of the total physical capacity. A ratio of 10.5
means provisioned capacity can be 10.5 times of the total physical capacity.
A ratio of 1.0 means provisioned capacity cannot exceed the total physical
capacity. A ratio lower than 1.0 is ignored and the default value is used
instead.</para>
          <note>
            <para><literal>max_over_subscription_ratio</literal> can be configured for each back end when
multiple-storage back ends are enabled. It is provided as a reference
implementation and is used by the LVM driver. However, it is not a
requirement for a driver to use this option from <literal>cinder.conf</literal>.</para>
            <para><literal>max_over_subscription_ratio</literal> is for configuring a back end. For a
driver that supports multiple pools per back end, it can report this
ratio for each pool. The LVM driver does not support multiple pools.</para>
          </note>
          <para>The existing <literal>reserved_percentage</literal> flag is used to prevent over provisioning.
This flag represents the percentage of the back-end capacity that is reserved.</para>
          <note>
            <para>There is a change on how <literal>reserved_percentage</literal> is used. It was measured
against the free capacity in the past. Now it is measured against the total
capacity.</para>
          </note>
        </sect3>
        <sect3>
          <title>Capabilities</title>
          <para>Drivers can report the following capabilities for a back end or a pool:</para>
          <screen language="ini">thin_provisioning_support = True(or False)
thick_provisioning_support = True(or False)
provisioned_capacity_gb = PROVISIONED_CAPACITY
max_over_subscription_ratio = MAX_RATIO</screen>
          <para>Where <literal>PROVISIONED_CAPACITY</literal> is the apparent allocated space indicating
how much capacity has been provisioned and <literal>MAX_RATIO</literal> is the maximum
oversubscription ratio. For the LVM driver, it is
<literal>max_over_subscription_ratio</literal> in <literal>cinder.conf</literal>.</para>
          <para>Two capabilities are added here to allow a back end or pool to claim support
for thin provisioning, or thick provisioning, or both.</para>
          <para>The LVM driver reports <literal>thin_provisioning_support=True</literal> and
<literal>thick_provisioning_support=False</literal> if the <literal>lvm_type</literal> flag in
<literal>cinder.conf</literal> is <literal>thin</literal>. Otherwise it reports
<literal>thin_provisioning_support=False</literal> and <literal>thick_provisioning_support=True</literal>.</para>
        </sect3>
        <sect3>
          <title>Volume type extra specs</title>
          <para>If volume type is provided as part of the volume creation request, it can
have the following extra specs defined:</para>
          <screen language="ini">'capabilities:thin_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'
'capabilities:thick_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'</screen>
          <note>
            <para><literal>capabilities</literal> scope key before <literal>thin_provisioning_support</literal> and
<literal>thick_provisioning_support</literal> is not required. So the following works too:</para>
          </note>
          <screen language="ini">'thin_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'
'thick_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'</screen>
          <para>The above extra specs are used by the scheduler to find a back end that
supports thin provisioning, thick provisioning, or both to match the needs
of a specific volume type.</para>
        </sect3>
        <sect3>
          <title>Volume replication extra specs</title>
          <para>OpenStack Block Storage has the ability to create volume replicas.
Administrators can define a storage policy that includes
replication by adjusting the cinder volume driver. Volume replication
for OpenStack Block Storage helps safeguard OpenStack environments from
data loss during disaster recovery.</para>
          <para>To enable replication when creating volume types, configure the cinder
volume with <literal>capabilities:replication="&lt;is&gt; True"</literal>.</para>
          <para>Each volume created with the replication capability set to <literal>True</literal>
generates a copy of the volume on a storage back end.</para>
          <para>One use case for replication involves an OpenStack cloud environment
installed across two data centers located nearby each other. The
distance between the two data centers in this use case is the length of
a city.</para>
          <para>At each data center, a cinder host supports the Block Storage service.
Both data centers include storage back ends.</para>
          <para>Depending on the storage requirements, there can be one or two cinder
hosts. The administrator accesses the
<literal>/etc/cinder/cinder.conf</literal> configuration file and sets
<literal>capabilities:replication="&lt;is&gt; True"</literal>.</para>
          <para>If one data center experiences a service failure, administrators
can redeploy the VM. The VM will run using a replicated, backed up
volume on a host in the second data center.</para>
        </sect3>
        <sect3>
          <title>Capacity filter</title>
          <para>In the capacity filter, <literal>max_over_subscription_ratio</literal> is used when
choosing a back end if <literal>thin_provisioning_support</literal> is True and
<literal>max_over_subscription_ratio</literal> is greater than 1.0.</para>
        </sect3>
        <sect3>
          <title>Capacity weigher</title>
          <para>In the capacity weigher, virtual free capacity is used for ranking if
<literal>thin_provisioning_support</literal> is True. Otherwise, real free capacity
will be used as before.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Image-Volume cache</title>
        <para>OpenStack Block Storage has an optional Image cache which can dramatically
improve the performance of creating a volume from an image. The improvement
depends on many factors, primarily how quickly the configured back end can
clone a volume.</para>
        <para>When a volume is first created from an image, a new cached image-volume
will be created that is owned by the Block Storage Internal Tenant. Subsequent
requests to create volumes from that image will clone the cached version
instead of downloading the image contents and copying data to the volume.</para>
        <para>The cache itself is configurable per back end and will contain the most
recently used images.</para>
        <sect3>
          <title>Configure the Internal Tenant</title>
          <para>The Image-Volume cache requires that the Internal Tenant be configured for
the Block Storage services. This project will own the cached image-volumes so
they can be managed like normal users including tools like volume quotas. This
protects normal users from having to see the cached image-volumes, but does
not make them globally hidden.</para>
          <para>To enable the Block Storage services to have access to an Internal Tenant, set
the following options in the <literal>cinder.conf</literal> file:</para>
          <screen language="ini">cinder_internal_tenant_project_id = PROJECT_ID
cinder_internal_tenant_user_id = USER_ID</screen>
          <para>An example <literal>cinder.conf</literal> configuration file:</para>
          <screen language="ini">cinder_internal_tenant_project_id = b7455b8974bb4064ad247c8f375eae6c
cinder_internal_tenant_user_id = f46924c112a14c80ab0a24a613d95eef</screen>
          <note>
            <para>The actual user and project that are configured for the Internal Tenant do
not require any special privileges. They can be the Block Storage service
project or can be any normal project and user.</para>
          </note>
        </sect3>
        <sect3>
          <title>Configure the Image-Volume cache</title>
          <para>To enable the Image-Volume cache, set the following configuration option in
the <literal>cinder.conf</literal> file:</para>
          <screen language="ini">image_volume_cache_enabled = True</screen>
          <note>
            <para>If you use Ceph as a back end, set the following configuration option in
the <literal>cinder.conf</literal> file:</para>
            <screen language="ini">[ceph]
image_volume_cache_enabled = True</screen>
          </note>
          <para>This can be scoped per back end definition or in the default options.</para>
          <para>There are optional configuration settings that can limit the size of the cache.
These can also be scoped per back end or in the default options in
the <literal>cinder.conf</literal> file:</para>
          <screen language="ini">image_volume_cache_max_size_gb = SIZE_GB
image_volume_cache_max_count = MAX_COUNT</screen>
          <para>By default they will be set to 0, which means unlimited.</para>
          <para>For example, a configuration which would limit the max size to 200 GB and 50
cache entries will be configured as:</para>
          <screen language="ini">image_volume_cache_max_size_gb = 200
image_volume_cache_max_count = 50</screen>
        </sect3>
        <sect3>
          <title>Notifications</title>
          <para>Cache actions will trigger Telemetry messages. There are several that will be
sent.</para>
          <itemizedlist>
            <listitem>
              <para><literal>image_volume_cache.miss</literal> - A volume is being created from an image which
was not found in the cache. Typically this will mean a new cache entry would
be created for it.</para>
            </listitem>
            <listitem>
              <para><literal>image_volume_cache.hit</literal> - A volume is being created from an image which
was found in the cache and the fast path can be taken.</para>
            </listitem>
            <listitem>
              <para><literal>image_volume_cache.evict</literal> - A cached image-volume has been deleted from
the cache.</para>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Managing cached Image-Volumes</title>
          <para>In normal usage there should be no need for manual intervention with the cache.
The entries and their backing Image-Volumes are managed automatically.</para>
          <para>If needed, you can delete these volumes manually to clear the cache.
By using the standard volume deletion APIs, the Block Storage service will
clean up correctly.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Volume-backed image</title>
        <para>OpenStack Block Storage can quickly create a volume from an image that refers
to a volume storing image data (Image-Volume). Compared to the other stores
such as file and swift, creating a volume from a Volume-backed image performs
better when the block storage driver supports efficient volume cloning.</para>
        <para>If the image is set to public in the Image service, the volume data can be
shared among projects.</para>
        <sect3>
          <title>Configure the Volume-backed image</title>
          <para>Volume-backed image feature requires locations information from the cinder
store of the Image service. To enable the Image service to use the cinder
store, add <literal>cinder</literal> to the <literal>stores</literal> option in the <literal>glance_store</literal> section
of the <literal>glance-api.conf</literal> file:</para>
          <screen language="ini">stores = file, http, swift, cinder</screen>
          <para>To expose locations information, set the following options in the <literal>DEFAULT</literal>
section of the <literal>glance-api.conf</literal> file:</para>
          <screen language="ini">show_multiple_locations = True</screen>
          <para>To enable the Block Storage services to create a new volume by cloning Image-
Volume, set the following options in the <literal>DEFAULT</literal> section of the
<literal>cinder.conf</literal> file. For example:</para>
          <screen language="ini">glance_api_version = 2
allowed_direct_url_schemes = cinder</screen>
          <para>To enable the <command>openstack image create --volume &lt;volume&gt;</command> command to
create an image that refers an <literal>Image-Volume</literal>, set the following options in
each back-end section of the <literal>cinder.conf</literal> file:</para>
          <screen language="ini">image_upload_use_cinder_backend = True</screen>
          <para>By default, the <command>openstack image create --volume &lt;volume&gt;</command> command
creates the Image-Volume in the current project. To store the Image-Volume into
the internal project, set the following options in each back-end section of the
<literal>cinder.conf</literal> file:</para>
          <screen language="ini">image_upload_use_internal_tenant = True</screen>
          <para>To make the Image-Volume in the internal project accessible from the Image
service, set the following options in the <literal>glance_store</literal> section of
the <literal>glance-api.conf</literal> file:</para>
          <itemizedlist>
            <listitem>
              <para>
                <literal>cinder_store_auth_address</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>cinder_store_user_name</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>cinder_store_password</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>cinder_store_project_name</literal>
              </para>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Creating a Volume-backed image</title>
          <para>To register an existing volume as a new Volume-backed image, use the following
commands:</para>
          <screen language="console">$ openstack image create --disk-format raw --container-format bare IMAGE_NAME

$ glance location-add &lt;image-uuid&gt; --url cinder://&lt;volume-uuid&gt;</screen>
          <para>If the <literal>image_upload_use_cinder_backend</literal> option is enabled, the following
command creates a new Image-Volume by cloning the specified volume and then
registers its location to a new image. The disk format and the container format
must be raw and bare (default). Otherwise, the image is uploaded to the default
store of the Image service.</para>
          <screen language="console">$ openstack image create --volume SOURCE_VOLUME IMAGE_NAME</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Get capabilities</title>
        <para>When an administrator configures <literal>volume type</literal> and <literal>extra specs</literal> of storage
on the back end, the administrator has to read the right documentation that
corresponds to the version of the storage back end. Deep knowledge of
storage is also required.</para>
        <para>OpenStack Block Storage enables administrators to configure <literal>volume type</literal>
and <literal>extra specs</literal> without specific knowledge of the storage back end.</para>
        <note>
          <itemizedlist>
            <listitem>
              <para><literal>Volume Type</literal>: A group of volume policies.</para>
            </listitem>
            <listitem>
              <para><literal>Extra Specs</literal>: The definition of a volume type. This is a group of
policies. For example, provision type, QOS that will be used to
define a volume at creation time.</para>
            </listitem>
            <listitem>
              <para><literal>Capabilities</literal>: What the current deployed back end in Cinder is able
to do. These correspond to extra specs.</para>
            </listitem>
          </itemizedlist>
        </note>
        <sect3>
          <title>Usage of cinder client</title>
          <para>When an administrator wants to define new volume types for their
OpenStack cloud, the administrator would fetch a list of <literal>capabilities</literal>
for a particular back end using the cinder client.</para>
          <para>First, get a list of the services:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume service list
+------------------+-------------------+------+---------+-------+----------------------------+
| Binary           | Host              | Zone | Status  | State | Updated At                 |
+------------------+-------------------+------+---------+-------+----------------------------+
| cinder-scheduler | controller        | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
| cinder-volume    | block1@ABC-driver | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
+------------------+-------------------+------+---------+-------+----------------------------+</screen>
          <para>With one of the listed hosts, pass that to <literal>get-capabilities</literal>, then
the administrator can obtain volume stats and also back end <literal>capabilities</literal>
as listed below.</para>
          <screen language="console">$ cinder get-capabilities block1@ABC-driver
+---------------------+----------------------------------------------+
|     Volume stats    |                    Value                     |
+---------------------+----------------------------------------------+
|     description     |                     None                     |
|     display_name    |   Capabilities of Cinder Vendor ABC driver   |
|    driver_version   |                    2.0.0                     |
|      namespace      | OS::Storage::Capabilities::block1@ABC-driver |
|      pool_name      |                     None                     |
| replication_targets |                      []                      |
|   storage_protocol  |                    iSCSI                     |
|     vendor_name     |                  Vendor ABC                  |
|      visibility     |                     pool                     |
| volume_backend_name |                  ABC-driver                  |
+---------------------+----------------------------------------------+
+----------------------+-----------------------------------------------------+
|  Backend properties  |                     Value                           |
+----------------------+-----------------------------------------------------+
|      compression     | {u'type':u'boolean', u'title':u'Compression',  ...} |
| ABC:compression_type | {u'enum':u'['lossy', 'lossless', 'special']',  ...} |
|         qos          | {u'type':u'boolean', u'title':u'QoS',          ...} |
|     replication      | {u'type':u'boolean', u'title':u'Replication',  ...} |
|  thin_provisioning   | {u'type':u'boolean', u'title':u'Thin Provisioning'} |
|     ABC:minIOPS      | {u'type':u'integer', u'title':u'Minimum IOPS QoS',} |
|     ABC:maxIOPS      | {u'type':u'integer', u'title':u'Maximum IOPS QoS',} |
|    ABC:burstIOPS     | {u'type':u'integer', u'title':u'Burst IOPS QoS',..} |
+----------------------+-----------------------------------------------------+</screen>
        </sect3>
        <sect3>
          <title>Disable a service</title>
          <para>When an administrator wants to disable a service, identify the Binary
and the Host of the service. Use the <command>cinder service-disable</command>
command combined with the Binary and Host to disable the service:</para>
          <procedure>
            <step>
              <para>Determine the binary and host of the service you want to remove
initially.</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume service list
+------------------+----------------------+------+---------+-------+----------------------------+
| Binary           | Host                 | Zone | Status  | State | Updated At                 |
+------------------+----------------------+------+---------+-------+----------------------------+
| cinder-scheduler | devstack             | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
| cinder-volume    | devstack@lvmdriver-1 | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
+------------------+----------------------+------+---------+-------+----------------------------+</screen>
            </step>
            <step>
              <para>Disable the service using the Binary and Host name, placing the Host
before the Binary name.</para>
              <screen language="console">$ cinder service-disable HOST_NAME BINARY_NAME</screen>
            </step>
            <step>
              <para>Remove the service from the database.</para>
              <screen language="console">$ cinder-manage service remove BINARY_NAME HOST_NAME</screen>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Usage of REST API</title>
          <para>New endpoint to <literal>get capabilities</literal> list for specific storage back end
is also available. For more details, refer to the Block Storage API reference.</para>
          <para>API request:</para>
          <screen language="console">GET /v2/{tenant_id}/capabilities/{hostname}</screen>
          <para>Example of return value:</para>
          <screen language="json">{
  "namespace": "OS::Storage::Capabilities::block1@ABC-driver",
  "volume_backend_name": "ABC-driver",
  "pool_name": "pool",
  "driver_version": "2.0.0",
  "storage_protocol": "iSCSI",
  "display_name": "Capabilities of Cinder Vendor ABC driver",
  "description": "None",
  "visibility": "public",
  "properties": {
   "thin_provisioning": {
      "title": "Thin Provisioning",
      "description": "Sets thin provisioning.",
      "type": "boolean"
    },
    "compression": {
      "title": "Compression",
      "description": "Enables compression.",
      "type": "boolean"
    },
    "ABC:compression_type": {
      "title": "Compression type",
      "description": "Specifies compression type.",
      "type": "string",
      "enum": [
        "lossy", "lossless", "special"
      ]
    },
    "replication": {
      "title": "Replication",
      "description": "Enables replication.",
      "type": "boolean"
    },
    "qos": {
      "title": "QoS",
      "description": "Enables QoS.",
      "type": "boolean"
    },
    "ABC:minIOPS": {
      "title": "Minimum IOPS QoS",
      "description": "Sets minimum IOPS if QoS is enabled.",
      "type": "integer"
    },
    "ABC:maxIOPS": {
      "title": "Maximum IOPS QoS",
      "description": "Sets maximum IOPS if QoS is enabled.",
      "type": "integer"
    },
    "ABC:burstIOPS": {
      "title": "Burst IOPS QoS",
      "description": "Sets burst IOPS if QoS is enabled.",
      "type": "integer"
    },
  }
}</screen>
        </sect3>
        <sect3>
          <title>Usage of volume type access extension</title>
          <para>Some volume types should be restricted only. For example, test volume types
where you are testing a new technology or ultra high performance volumes
(for special cases) where you do not want most users to be able to select
these volumes. An administrator/operator can then define private volume types
using cinder client.
Volume type access extension adds the ability to manage volume type access.
Volume types are public by default. Private volume types can be created by
setting the <literal>is_public</literal> Boolean field to <literal>False</literal> at creation time. Access to a
private volume type can be controlled by adding or removing a project from it.
Private volume types without projects are only visible by users with the
admin role/context.</para>
          <para>Create a public volume type by setting <literal>is_public</literal> field to <literal>True</literal>:</para>
          <screen language="console">$ openstack volume type create vol_Type1 --description test1 --public
+-------------+--------------------------------------+
| Field       | Value                                |
+-------------+--------------------------------------+
| description | test1                                |
| id          | b7dbed9e-de78-49f8-a840-651ae7308592 |
| is_public   | True                                 |
| name        | vol_Type1                            |
+-------------+--------------------------------------+</screen>
          <para>Create a private volume type by setting <literal>is_public</literal> field to <literal>False</literal>:</para>
          <screen language="console">$ openstack volume type create vol_Type2 --description test2 --private
+-------------+--------------------------------------+
| Field       | Value                                |
+-------------+--------------------------------------+
| description | test2                                |
| id          | 154baa73-d2c4-462f-8258-a2df251b0d39 |
| is_public   | False                                |
| name        | vol_Type2                            |
+-------------+--------------------------------------+</screen>
          <para>Get a list of the volume types:</para>
          <screen language="console">$ openstack volume type list
+--------------------------------------+-------------+
| ID                                   | Name        |
+--------------------------------------+-------------+
| 0a948c84-bad5-4fba-88a2-c062006e4f6b | vol_Type1   |
| 87e5be6f-9491-4ea5-9906-9ac56494bb91 | lvmdriver-1 |
| fd508846-213f-4a07-aaf2-40518fb9a23f | vol_Type2   |
+--------------------------------------+-------------+</screen>
          <para>Get a list of the projects:</para>
          <screen language="console">$ openstack project list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| 4105ead90a854100ab6b121266707f2b | alt_demo           |
| 4a22a545cedd4fcfa9836eb75e558277 | admin              |
| 71f9cdb1a3ab4b8e8d07d347a2e146bb | service            |
| c4860af62ffe465e99ed1bc08ef6082e | demo               |
| e4b648ba5108415cb9e75bff65fa8068 | invisible_to_admin |
+----------------------------------+--------------------+</screen>
          <para>Add volume type access for the given demo project, using its project-id:</para>
          <screen language="console">$ openstack volume type set --project c4860af62ffe465e99ed1bc08ef6082e \
  vol_Type2</screen>
          <para>List the access information about the given volume type:</para>
          <screen language="console">$ cinder type-access-list --volume-type vol_Type2
+--------------------------------------+----------------------------------+
|            Volume_type_ID            |            Project_ID            |
+--------------------------------------+----------------------------------+
| fd508846-213f-4a07-aaf2-40518fb9a23f | c4860af62ffe465e99ed1bc08ef6082e |
+--------------------------------------+----------------------------------+</screen>
          <para>Remove volume type access for the given project:</para>
          <screen language="console">$ openstack volume type unset --project c4860af62ffe465e99ed1bc08ef6082e \
  vol_Type2
$ cinder type-access-list --volume-type vol_Type2
+----------------+------------+
| Volume_type_ID | Project_ID |
+----------------+------------+
+----------------+------------+</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Generic volume groups</title>
        <para>Generic volume group support is available in OpenStack Block Storage (cinder)
since the Newton release. The support is added for creating group types and
group specs, creating groups of volumes, and creating snapshots of groups.
The group operations can be performed using the Block Storage command line.</para>
        <para>A group type is a type for a group just like a volume type for a volume.
A group type can also have associated group specs similar to extra specs
for a volume type.</para>
        <para>In cinder, there is a group construct called <literal>consistency group</literal>. Consistency
groups only support consistent group snapshots and only a small number of
drivers can support it. The following is a list of drivers that support
consistency groups and the release when the support was added:</para>
        <itemizedlist>
          <listitem>
            <para>Juno: EMC VNX</para>
          </listitem>
          <listitem>
            <para>Kilo: EMC VMAX, IBM (GPFS, Storwize, SVC, and XIV), ProphetStor, Pure</para>
          </listitem>
          <listitem>
            <para>Liberty: Dell Storage Center, EMC XtremIO, HPE 3Par and LeftHand</para>
          </listitem>
          <listitem>
            <para>Mitaka: EMC ScaleIO, NetApp Data ONTAP and E-Series, SolidFire</para>
          </listitem>
          <listitem>
            <para>Newton: CoprHD, FalconStor, Huawei</para>
          </listitem>
        </itemizedlist>
        <para>Consistency group cannot be extended easily to serve other purposes. A tenant
may want to put volumes used in the same application together in a group so
that it is easier to manage them together, and this group of volumes may or
may not support consistent group snapshot. Generic volume group is introduced
to solve this problem.</para>
        <para>There is a plan to migrate existing consistency group operations to use
generic volume group operations in future releases. More information can be
found in <link xlink:href="https://github.com/openstack/cinder-specs/blob/master/specs/newton/group-snapshots.rst">Cinder specs</link>.</para>
        <note>
          <para>Only Block Storage V3 API supports groups. You can
specify <literal>--os-volume-api-version 3.x</literal> when using the <literal>cinder</literal>
command line for group operations where <literal>3.x</literal> contains a microversion value
for that command. The generic volume group feature was completed in several
patches. As a result, the minimum required microversion is different for
group types, groups, and group snapshots APIs.</para>
        </note>
        <para>The following group type operations are supported:</para>
        <itemizedlist>
          <listitem>
            <para>Create a group type.</para>
          </listitem>
          <listitem>
            <para>Delete a group type.</para>
          </listitem>
          <listitem>
            <para>Set group spec for a group type.</para>
          </listitem>
          <listitem>
            <para>Unset group spec for a group type.</para>
          </listitem>
          <listitem>
            <para>List group types.</para>
          </listitem>
          <listitem>
            <para>Show a group type details.</para>
          </listitem>
          <listitem>
            <para>Update a group.</para>
          </listitem>
          <listitem>
            <para>List group types and group specs.</para>
          </listitem>
        </itemizedlist>
        <para>The following group and group snapshot operations are supported:</para>
        <itemizedlist>
          <listitem>
            <para>Create a group, given group type and volume types.</para>
            <note>
              <para>A group must have one group type. A group can support more than one
volume type. The scheduler is responsible for finding a back end that
can support the given group type and volume types.</para>
              <para>A group can only contain volumes hosted by the same back end.</para>
              <para>A group is empty upon its creation. Volumes need to be created and added
to it later.</para>
            </note>
          </listitem>
          <listitem>
            <para>Show a group.</para>
          </listitem>
          <listitem>
            <para>List groups.</para>
          </listitem>
          <listitem>
            <para>Delete a group.</para>
          </listitem>
          <listitem>
            <para>Modify a group.</para>
          </listitem>
          <listitem>
            <para>Create a volume and add it to a group.</para>
          </listitem>
          <listitem>
            <para>Create a snapshot for a group.</para>
          </listitem>
          <listitem>
            <para>Show a group snapshot.</para>
          </listitem>
          <listitem>
            <para>List group snapshots.</para>
          </listitem>
          <listitem>
            <para>Delete a group snapshot.</para>
          </listitem>
          <listitem>
            <para>Create a group from a group snapshot.</para>
          </listitem>
          <listitem>
            <para>Create a group from a source group.</para>
          </listitem>
        </itemizedlist>
        <para>The following operations are not allowed if a volume is in a group:</para>
        <itemizedlist>
          <listitem>
            <para>Volume migration.</para>
          </listitem>
          <listitem>
            <para>Volume retype.</para>
          </listitem>
          <listitem>
            <para>Volume deletion.</para>
            <note>
              <para>A group has to be deleted as a whole with all the volumes.</para>
            </note>
          </listitem>
        </itemizedlist>
        <para>The following operations are not allowed if a volume snapshot is in a
group snapshot:</para>
        <itemizedlist>
          <listitem>
            <para>Volume snapshot deletion.</para>
            <note>
              <para>A group snapshot has to be deleted as a whole with all the volume
snapshots.</para>
            </note>
          </listitem>
        </itemizedlist>
        <para>The details of group type operations are shown in the following. The minimum
microversion to support group type and group specs is 3.11:</para>
        <para><emphasis role="bold">Create a group type</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.11 group-type-create
[--description DESCRIPTION]
[--is-public IS_PUBLIC]
NAME</screen>
        <note>
          <para>The parameter <literal>NAME</literal> is required. The
<literal>--is-public IS_PUBLIC</literal> determines whether the group type is
accessible to the public. It is <literal>True</literal> by default. By default, the
policy on privileges for creating a group type is admin-only.</para>
        </note>
        <para><emphasis role="bold">Show a group type</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.11 group-type-show
GROUP_TYPE</screen>
        <note>
          <para>The parameter <literal>GROUP_TYPE</literal> is the name or UUID of a group type.</para>
        </note>
        <para><emphasis role="bold">List group types</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.11 group-type-list</screen>
        <note>
          <para>Only admin can see private group types.</para>
        </note>
        <para><emphasis role="bold">Update a group type</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.11 group-type-update
[--name NAME]
[--description DESCRIPTION]
[--is-public IS_PUBLIC]
GROUP_TYPE_ID</screen>
        <note>
          <para>The parameter <literal>GROUP_TYPE_ID</literal> is the UUID of a group type. By default,
the policy on privileges for updating a group type is admin-only.</para>
        </note>
        <para><emphasis role="bold">Delete group type or types</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.11 group-type-delete
GROUP_TYPE [GROUP_TYPE ...]</screen>
        <note>
          <para>The parameter <literal>GROUP_TYPE</literal> is name or UUID of the group type or
group types to be deleted. By default, the policy on privileges for
deleting a group type is admin-only.</para>
        </note>
        <para><emphasis role="bold">Set or unset group spec for a group type</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.11 group-type-key
GROUP_TYPE ACTION KEY=VALUE [KEY=VALUE ...]</screen>
        <note>
          <para>The parameter <literal>GROUP_TYPE</literal> is the name or UUID of a group type. Valid
values for the parameter <literal>ACTION</literal> are <literal>set</literal> or <literal>unset</literal>.
<literal>KEY=VALUE</literal> is the group specs key and value pair to set or unset.
For unset, specify only the key. By default, the policy on privileges
for setting or unsetting group specs key is admin-only.</para>
        </note>
        <para><emphasis role="bold">List group types and group specs</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.11 group-specs-list</screen>
        <note>
          <para>By default, the policy on privileges for seeing group specs is admin-only.</para>
        </note>
        <para>The details of group operations are shown in the following. The minimum
microversion to support groups operations is 3.13.</para>
        <para><emphasis role="bold">Create a group</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.13 group-create
[--name NAME]
[--description DESCRIPTION]
[--availability-zone AVAILABILITY_ZONE]
GROUP_TYPE VOLUME_TYPES</screen>
        <note>
          <para>The parameters <literal>GROUP_TYPE</literal> and <literal>VOLUME_TYPES</literal> are required.
<literal>GROUP_TYPE</literal> is the name or UUID of a group type. <literal>VOLUME_TYPES</literal>
can be a list of names or UUIDs of volume types separated by commas
without spaces in between. For example,
<literal>volumetype1,volumetype2,volumetype3.</literal>.</para>
        </note>
        <para><emphasis role="bold">Show a group</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.13 group-show
GROUP</screen>
        <note>
          <para>The parameter <literal>GROUP</literal> is the name or UUID of a group.</para>
        </note>
        <para><emphasis role="bold">List groups</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.13 group-list
[--all-tenants [&lt;0|1&gt;]]</screen>
        <note>
          <para><literal>--all-tenants</literal> specifies whether to list groups for all tenants.
Only admin can use this option.</para>
        </note>
        <para><emphasis role="bold">Create a volume and add it to a group</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.13 create
--volume-type VOLUME_TYPE
--group-id GROUP_ID SIZE</screen>
        <note>
          <para>When creating a volume and adding it to a group, the parameters
<literal>VOLUME_TYPE</literal> and <literal>GROUP_ID</literal> must be provided. This is because a group
can support more than one volume type.</para>
        </note>
        <para><emphasis role="bold">Delete a group</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.13 group-delete
[--delete-volumes]
GROUP [GROUP ...]</screen>
        <note>
          <para><literal>--delete-volumes</literal> allows or disallows groups to be deleted
if they are not empty. If the group is empty, it can be deleted without
<literal>--delete-volumes</literal>. If the group is not empty, the flag is
required for it to be deleted. When the flag is specified, the group
and all volumes in the group will be deleted.</para>
        </note>
        <para><emphasis role="bold">Modify a group</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.13 group-update
[--name NAME]
[--description DESCRIPTION]
[--add-volumes UUID1,UUID2,......]
[--remove-volumes UUID3,UUID4,......]
GROUP</screen>
        <note>
          <para>The parameter <literal>UUID1,UUID2,......</literal> is the UUID of one or more volumes
to be added to the group, separated by commas. Similarly the parameter
<literal>UUID3,UUID4,......</literal> is the UUID of one or more volumes to be removed
from the group, separated by commas.</para>
        </note>
        <para>The details of group snapshots operations are shown in the following. The
minimum microversion to support group snapshots operations is 3.14.</para>
        <para><emphasis role="bold">Create a snapshot for a group</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.14 group-snapshot-create
[--name NAME]
[--description DESCRIPTION]
GROUP</screen>
        <note>
          <para>The parameter <literal>GROUP</literal> is the name or UUID of a group.</para>
        </note>
        <para><emphasis role="bold">Show a group snapshot</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.14 group-snapshot-show
GROUP_SNAPSHOT</screen>
        <note>
          <para>The parameter <literal>GROUP_SNAPSHOT</literal> is the name or UUID of a group snapshot.</para>
        </note>
        <para><emphasis role="bold">List group snapshots</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.14 group-snapshot-list
[--all-tenants [&lt;0|1&gt;]]
[--status STATUS]
[--group-id GROUP_ID]</screen>
        <note>
          <para><literal>--all-tenants</literal> specifies whether to list group snapshots for
all tenants. Only admin can use this option. <literal>--status STATUS</literal>
filters results by a status. <literal>--group-id GROUP_ID</literal> filters
results by a group id.</para>
        </note>
        <para><emphasis role="bold">Delete group snapshot</emphasis>:</para>
        <screen language="console">cinder --os-volume-api-version 3.14 group-snapshot-delete
GROUP_SNAPSHOT [GROUP_SNAPSHOT ...]</screen>
        <note>
          <para>The parameter <literal>GROUP_SNAPSHOT</literal> specifies the name or UUID of one or more
group snapshots to be deleted.</para>
        </note>
        <para><emphasis role="bold">Create a group from a group snapshot or a source group</emphasis>:</para>
        <screen language="console">$ cinder --os-volume-api-version 3.14 group-create-from-src
[--group-snapshot GROUP_SNAPSHOT]
[--source-group SOURCE_GROUP]
[--name NAME]
[--description DESCRIPTION]</screen>
        <note>
          <para>The parameter <literal>GROUP_SNAPSHOT</literal> is a name or UUID of a group snapshot.
The parameter <literal>SOURCE_GROUP</literal> is a name or UUID of a source group.
Either <literal>GROUP_SNAPSHOT</literal> or <literal>SOURCE_GROUP</literal> must be specified, but not
both.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>Troubleshoot your installation</title>
      <para>This section provides useful tips to help you troubleshoot your Block
Storage installation.</para>
      <sect2>
        <title>Troubleshoot the Block Storage configuration</title>
        <para>Most Block Storage errors are caused by incorrect volume configurations
that result in volume creation failures. To resolve these failures,
review these logs:</para>
        <itemizedlist>
          <listitem>
            <para><literal>cinder-api</literal> log (<literal>/var/log/cinder/api.log</literal>)</para>
          </listitem>
          <listitem>
            <para><literal>cinder-volume</literal> log (<literal>/var/log/cinder/volume.log</literal>)</para>
          </listitem>
        </itemizedlist>
        <para>The <literal>cinder-api</literal> log is useful for determining if you have endpoint or
connectivity issues. If you send a request to create a volume and it
fails, review the <literal>cinder-api</literal> log to determine whether the request made
it to the Block Storage service. If the request is logged and you see no
errors or tracebacks, check the <literal>cinder-volume</literal> log for errors or
tracebacks.</para>
        <note>
          <para>Create commands are listed in the <literal>cinder-api</literal> log.</para>
        </note>
        <para>These entries in the <literal>cinder.openstack.common.log</literal> file can be used to
assist in troubleshooting your Block Storage configuration.</para>
        <screen language="console"># Print debugging output (set logging level to DEBUG instead
# of default WARNING level). (boolean value)
# debug=false

# Print more verbose output (set logging level to INFO instead
# of default WARNING level). (boolean value)
# verbose=false

# Log output to standard error (boolean value)
# use_stderr=true

# Default file mode used when creating log files (string
# value)
# logfile_mode=0644

# format string to use for log messages with context (string
# value)
# logging_context_format_string=%(asctime)s.%(msecs)03d %(levelname)s
# %(name)s [%(request_id)s %(user)s %(tenant)s] %(instance)s%(message)s

# format string to use for log mes #logging_default_format_string=%(asctime)s.
# %(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s

# data to append to log format when level is DEBUG (string
# value)
# logging_debug_format_suffix=%(funcName)s %(pathname)s:%(lineno)d

# prefix each line of exception output with this format
# (string value)
# logging_exception_prefix=%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s
# %(instance)s

# list of logger=LEVEL pairs (list value)
# default_log_levels=amqplib=WARN,sqlalchemy=WARN,boto=WARN,suds=INFO,
# keystone=INFO,eventlet.wsgi.server=WARNsages without context
# (string value)

# If an instance is passed with the log message, format it
# like this (string value)
# instance_format="[instance: %(uuid)s]"

# If an instance UUID is passed with the log message, format
# it like this (string value)
#instance_uuid_format="[instance: %(uuid)s] "

# Format string for %%(asctime)s in log records. Default:
# %(default)s (string value)
# log_date_format=%Y-%m-%d %H:%M:%S

# (Optional) Name of log file to output to. If not set,
# logging will go to stdout. (string value)
# log_file=&lt;None&gt;

# (Optional) The directory to keep log files in (will be
# prepended to --log-file) (string value)
# log_dir=&lt;None&gt;
# instance_uuid_format="[instance: %(uuid)s]"

# If this option is specified, the logging configuration file
# specified is used and overrides any other logging options
# specified. Please see the Python logging module
# documentation for details on logging configuration files.
# (string value)
# Use syslog for logging. (boolean value)
# use_syslog=false

# syslog facility to receive log lines (string value)
# syslog_log_facility=LOG_USER
# log_config=&lt;None&gt;</screen>
        <para>These common issues might occur during configuration, and the following
potential solutions describe how to address the issues.</para>
        <sect3>
          <title>Issues with <literal>state_path</literal> and <literal>volumes_dir</literal> settings</title>
          <sect4>
            <title>Problem</title>
            <para>The OpenStack Block Storage uses <literal>tgtd</literal> as the default iSCSI helper
and implements persistent targets. This means that in the case of a
<literal>tgt</literal> restart, or even a node reboot, your existing volumes on that
node will be restored automatically with their original <xref linkend="term-iscsi-qualified-name-iqn"/>.</para>
            <para>By default, Block Storage uses a <literal>state_path</literal> variable, which if
installing with Yum or APT should be set to <literal>/var/lib/cinder/</literal>.
The next part is the <literal>volumes_dir</literal> variable, by default this appends
a <literal>volumes</literal> directory to the <literal>state_path</literal>. The result is a
file-tree: <literal>/var/lib/cinder/volumes/</literal>.</para>
          </sect4>
          <sect4>
            <title>Solution</title>
            <para>In order to ensure nodes are restored to their original IQN,
the iSCSI target information needs to be stored in a file on creation
that can be queried in case of restart of the <literal>tgt daemon</literal>. While the
installer should handle all this, it can go wrong.</para>
            <para>If you have trouble creating volumes and this directory does not exist
you should see an error message in the <literal>cinder-volume</literal> log indicating
that the <literal>volumes_dir</literal> does not exist, and it should provide
information about which path it was looking for.</para>
          </sect4>
        </sect3>
        <sect3>
          <title>The persistent tgt include file</title>
          <sect4>
            <title>Problem</title>
            <para>The Block Storage service may have issues locating the persistent
<literal>tgt include</literal> file. Along with the <literal>volumes_dir</literal> option, the
iSCSI target driver also needs to be configured to look in the correct
place for the persistent <literal>tgt include `` file. This is an entry
in the ``/etc/tgt/conf.d</literal> file that should have been set during the
OpenStack installation.</para>
          </sect4>
          <sect4>
            <title>Solution</title>
            <para>If issues occur, verify that you have a <literal>/etc/tgt/conf.d/cinder.conf</literal>
file. If the file is not present, create it with:</para>
            <screen language="console"># echo 'include /var/lib/cinder/volumes/ *' &gt;&gt; /etc/tgt/conf.d/cinder.conf</screen>
          </sect4>
        </sect3>
        <sect3>
          <title>No sign of attach call in the <literal>cinder-api</literal> log</title>
          <sect4>
            <title>Problem</title>
            <para>The attach call is unavailable, or not appearing in the <literal>cinder-api</literal> log.</para>
          </sect4>
          <sect4>
            <title>Solution</title>
            <para>Adjust the <literal>nova.conf</literal> file, and make sure that your <literal>nova.conf</literal>
has this entry:</para>
            <screen language="ini">volume_api_class=nova.volume.cinder.API</screen>
          </sect4>
        </sect3>
        <sect3>
          <title>Failed to create iscsi target error in the <literal>cinder-volume.log</literal> file</title>
          <sect4>
            <title>Problem</title>
            <screen language="console">2013-03-12 01:35:43 1248 TRACE cinder.openstack.common.rpc.amqp \
ISCSITargetCreateFailed: \
Failed to create iscsi target for volume \
volume-137641b2-af72-4a2f-b243-65fdccd38780.</screen>
            <para>You might see this error in <literal>cinder-volume.log</literal> after trying to
create a volume that is 1 GB.</para>
          </sect4>
          <sect4>
            <title>Solution</title>
            <para>To fix this issue, change the content of the <literal>/etc/tgt/targets.conf</literal>
file from <literal>include /etc/tgt/conf.d/*.conf</literal> to
<literal>include /etc/tgt/conf.d/cinder_tgt.conf</literal>, as follows:</para>
            <screen language="ini">include /etc/tgt/conf.d/cinder_tgt.conf
include /etc/tgt/conf.d/cinder.conf
default-driver iscsi</screen>
            <para>Restart <literal>tgt</literal> and <literal>cinder-*</literal> services, so they pick up the new
configuration.</para>
          </sect4>
        </sect3>
      </sect2>
      <sect2>
        <title>Multipath call failed exit</title>
        <sect3>
          <title>Problem</title>
          <para>Multipath call failed exit. This warning occurs in the Compute log
if you do not have the optional <literal>multipath-tools</literal> package installed
on the compute node. This is an optional package and the volume
attachment does work without the multipath tools installed.
If the <literal>multipath-tools</literal> package is installed on the compute node,
it is used to perform the volume attachment.
The IDs in your message are unique to your system.</para>
          <screen language="console">WARNING nova.storage.linuxscsi [req-cac861e3-8b29-4143-8f1b-705d0084e571
    admin admin|req-cac861e3-8b29-4143-8f1b-705d0084e571 admin admin]
    Multipath call failed exit (96)</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>Run the following command on the compute node to install the
<literal>multipath-tools</literal> packages.</para>
          <screen language="console"># apt-get install multipath-tools</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Addressing discrepancies in reported volume sizes for EqualLogic storage</title>
        <sect3>
          <title>Problem</title>
          <para>There is a discrepancy between both the actual volume size in EqualLogic
(EQL) storage and the image size in the Image service, with what is
reported to OpenStack database. This could lead to confusion
if a user is creating volumes from an image that was uploaded from an EQL
volume (through the Image service). The image size is slightly larger
than the target volume size; this is because EQL size reporting accounts
for additional storage used by EQL for internal volume metadata.</para>
          <para>To reproduce the issue follow the steps in the following procedure.</para>
          <para>This procedure assumes that the EQL array is provisioned, and that
appropriate configuration settings have been included in
<literal>/etc/cinder/cinder.conf</literal> to connect to the EQL array.</para>
          <para>Create a new volume. Note the ID and size of the volume. In the
following example, the ID and size are
<literal>74cf9c04-4543-47ae-a937-a9b7c6c921e7</literal> and <literal>1</literal>, respectively:</para>
          <screen language="console">$ openstack volume create volume1 --size 1

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-12-06T11:33:30.957318           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | 74cf9c04-4543-47ae-a937-a9b7c6c921e7 |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | volume1                              |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | iscsi                                |
| updated_at          | None                                 |
| user_id             | c36cec73b0e44876a4478b1e6cd749bb     |
+---------------------+--------------------------------------+</screen>
          <para>Verify the volume size on the EQL array by using its command-line
interface.</para>
          <para>The actual size (<literal>VolReserve</literal>) is 1.01 GB. The EQL Group Manager
should also report a volume size of 1.01 GB:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>eql&gt; volume select volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
eql (volume_volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7)&gt; show
_______________________________ Volume Information ________________________________
Name: volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
Size: 1GB
VolReserve: 1.01GB
VolReservelnUse: 0MB
ReplReservelnUse: 0MB
iSCSI Alias: volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
iSCSI Name: iqn.2001-05.com.equallogic:0-8a0906-19f91850c-067000000b4532cl-volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
ActualMembers: 1
Snap-Warn: 10%
Snap-Depletion: delete-oldest
Description:
Snap-Reserve: 100%
Snap-Reserve-Avail: 100% (1.01GB)
Permission: read-write
DesiredStatus: online
Status: online
Connections: O
Snapshots: O
Bind:
Type: not-replicated
ReplicationReserveSpace: 0MB</screen>
          <para>Create a new image from this volume:</para>
          <screen language="console">$ openstack image create --volume volume1 \
  --disk-format raw --container-format bare image_from_volume1

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| container_format    | bare                                 |
| disk_format         | raw                                  |
| display_description | None                                 |
| id                  | 850fd393-a968-4259-9c65-6b495cba5209 |
| image_id            | 3020a21d-ba37-4495-8899-07fc201161b9 |
| image_name          | image_from_volume1                   |
| is_public           | False                                |
| protected           | False                                |
| size                | 1                                    |
| status              | uploading                            |
| updated_at          | 2016-12-05T12:43:56.000000           |
| volume_type         | iscsi                                |
+---------------------+--------------------------------------+</screen>
          <para>When you uploaded the volume in the previous step, the Image service
reported the volume's size as <literal>1</literal> (GB). However, when using
<command>openstack image show</command> to show the image, the displayed size is
1085276160 bytes, or roughly 1.01 GB:</para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="32.1*"/>
              <colspec colname="c2" colwidth="67.9*"/>
              <tbody>
                <row>
                  <entry>
                    <para>Property</para>
                  </entry>
                  <entry>
                    <para>Value</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>checksum
container_format
created_at
disk_format
id
min_disk
min_ram
name
owner
protected
size
status
tags
updated_at
virtual_size
visibility</para>
                  </entry>
                  <entry>
                    <para>cd573cfaace07e7949bc0c46028904ff
bare
2016-12-06T11:39:06Z
raw
3020a21d-ba37-4495-8899-07fc201161b9
0
0
image_from_volume1
5669caad86a04256994cdf755df4d3c1
False
1085276160
active
[]
2016-12-06T11:39:24Z
None
private</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>Create a new volume using the previous image (<literal>image_id 3020a21d-ba37-4495
-8899-07fc201161b9</literal> in this example) as
the source. Set the target volume size to 1 GB; this is the size
reported by the <literal>cinder</literal> tool when you uploaded the volume to the
Image service:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume create volume2 --size 1 --image 3020a21d-ba37-4495-8899-07fc201161b9
ERROR: Invalid input received: Size of specified image 2 is larger
than volume size 1. (HTTP 400) (Request-ID: req-4b9369c0-dec5-4e16-a114-c0cdl6bSd210)</screen>
          <para>The attempt to create a new volume based on the size reported by the
<literal>cinder</literal> tool will then fail.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To work around this problem, increase the target size of the new image
to the next whole number. In the problem example, you created a 1 GB
volume to be used as volume-backed image, so a new volume using this
volume-backed image should use a size of 2 GB:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume create volume2 --size 1 --image 3020a21d-ba37-4495-8899-07fc201161b9
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-12-06T11:49:06.031768           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | a70d6305-f861-4382-84d8-c43128be0013 |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | volume2                              |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | iscsi                                |
| updated_at          | None                                 |
| user_id             | c36cec73b0e44876a4478b1e6cd749bb     |
+---------------------+--------------------------------------+</screen>
          <note>
            <para>The dashboard suggests a suitable size when you create a new volume
based on a volume-backed image.</para>
          </note>
          <para>You can then check this new volume into the EQL array:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>eql&gt; volume select volume-64e8eb18-d23f-437b-bcac-b352afa6843a
eql (volume_volume-61e8eb18-d23f-437b-bcac-b352afa6843a)&gt; show
______________________________ Volume Information _______________________________
Name: volume-64e8eb18-d23f-437b-bcac-b352afa6843a
Size: 2GB
VolReserve: 2.01GB
VolReserveInUse: 1.01GB
ReplReserveInUse: 0MB
iSCSI Alias: volume-64e8eb18-d23f-437b-bcac-b352afa6843a
iSCSI Name: iqn.2001-05.com.equallogic:0-8a0906-e3091850e-eae000000b7S32cl-volume-64e8eb18-d23f-437b-bcac-b3S2afa6Bl3a
ActualMembers: 1
Snap-Warn: 10%
Snap-Depletion: delete-oldest
Description:
Snap-Reserve: 100%
Snap-Reserve-Avail: 100% (2GB)
Permission: read-write
DesiredStatus: online
Status: online
Connections: 1
Snapshots: O
Bind:
Type: not-replicated
ReplicationReserveSpace: 0MB</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Failed to Attach Volume, Missing sg_scan</title>
        <sect3>
          <title>Problem</title>
          <para>Failed to attach volume to an instance, <literal>sg_scan</literal> file not found. This
error occurs when the sg3-utils package is not installed on the compute node.
The IDs in your message are unique to your system:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>ERROR nova.compute.manager [req-cf2679fd-dd9e-4909-807f-48fe9bda3642 admin admin|req-cf2679fd-dd9e-4909-807f-48fe9bda3642 admin admin]
[instance: 7d7c92e0-49fa-4a8e-87c7-73f22a9585d5|instance:  7d7c92e0-49fa-4a8e-87c7-73f22a9585d5]
Failed to attach volume  4cc104c4-ac92-4bd6-9b95-c6686746414a at /dev/vdcTRACE nova.compute.manager
[instance:  7d7c92e0-49fa-4a8e-87c7-73f22a9585d5|instance: 7d7c92e0-49fa-4a8e-87c7-73f22a9585d5]
Stdout: '/usr/local/bin/nova-rootwrap: Executable not found: /usr/bin/sg_scan'</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>Run this command on the compute node to install the <literal>sg3-utils</literal> package:</para>
          <screen language="console"># apt-get install sg3-utils</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>HTTP bad request in cinder volume log</title>
        <sect3>
          <title>Problem</title>
          <para>These errors appear in the <literal>cinder-volume.log</literal> file:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>2013-05-03 15:16:33 INFO [cinder.volume.manager] Updating volume status
2013-05-03 15:16:33 DEBUG [hp3parclient.http]
REQ: curl -i https://10.10.22.241:8080/api/v1/cpgs -X GET -H "X-Hp3Par-Wsapi-Sessionkey: 48dc-b69ed2e5
f259c58e26df9a4c85df110c-8d1e8451" -H "Accept: application/json" -H "User-Agent: python-3parclient"

2013-05-03 15:16:33 DEBUG [hp3parclient.http] RESP:{'content-length': 311, 'content-type': 'text/plain',
'status': '400'}

2013-05-03 15:16:33 DEBUG [hp3parclient.http] RESP BODY:Second simultaneous read on fileno 13 detected.
Unless you really know what you're doing, make sure that only one greenthread can read any particular socket.
Consider using a pools.Pool. If you do know what you're doing and want to disable this error,
call eventlet.debug.hub_multiple_reader_prevention(False)

2013-05-03 15:16:33 ERROR [cinder.manager] Error during VolumeManager._report_driver_status: Bad request (HTTP 400)
Traceback (most recent call last):
File "/usr/lib/python2.7/dist-packages/cinder/manager.py", line 167, in periodic_tasks task(self, context)
File "/usr/lib/python2.7/dist-packages/cinder/volume/manager.py", line 690, in _report_driver_status volume_stats =
self.driver.get_volume_stats(refresh=True)
File "/usr/lib/python2.7/dist-packages/cinder/volume/drivers/san/hp/hp_3par_fc.py", line 77, in get_volume_stats stats =
self.common.get_volume_stats(refresh, self.client)
File "/usr/lib/python2.7/dist-packages/cinder/volume/drivers/san/hp/hp_3par_common.py", line 421, in get_volume_stats cpg =
client.getCPG(self.config.hp3par_cpg)
File "/usr/lib/python2.7/dist-packages/hp3parclient/client.py", line 231, in getCPG cpgs = self.getCPGs()
File "/usr/lib/python2.7/dist-packages/hp3parclient/client.py", line 217, in getCPGs response, body = self.http.get('/cpgs')
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 255, in get return self._cs_request(url, 'GET', **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 224, in _cs_request **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 198, in _time_request resp, body = self.request(url, method, **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 192, in request raise exceptions.from_response(resp, body)
HTTPBadRequest: Bad request (HTTP 400)</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>You need to update your copy of the <literal>hp_3par_fc.py</literal> driver which
contains the synchronization code.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Duplicate 3PAR host</title>
        <sect3>
          <title>Problem</title>
          <para>This error may be caused by a volume being exported outside of OpenStack
using a host name different from the system name that OpenStack expects.
This error could be displayed with the <xref linkend="term-iscsi-qualified-name-iqn"/> if the host was exported using iSCSI:</para>
          <screen language="console">Duplicate3PARHost: 3PAR Host already exists: Host wwn 50014380242B9750 \
already used by host cld4b5ubuntuW(id = 68. The hostname must be called\
'cld4b5ubuntu'.</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>Change the 3PAR host name to match the one that OpenStack expects. The
3PAR host constructed by the driver uses just the local host name, not
the fully qualified domain name (FQDN) of the compute host. For example,
if the FQDN was <emphasis>myhost.example.com</emphasis>, just <emphasis>myhost</emphasis> would be used as the
3PAR host name. IP addresses are not allowed as host names on the 3PAR
storage server.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Failed to attach volume after detaching</title>
        <sect3>
          <title>Problem</title>
          <para>Failed to attach a volume after detaching the same volume.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>You must change the device name on the <command>nova-attach</command> command. The VM
might not clean up after a <command>nova-detach</command> command runs. This example
shows how the <command>nova-attach</command> command fails when you use the <literal>vdb</literal>,
<literal>vdc</literal>, or <literal>vdd</literal> device names:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?># ls -al /dev/disk/by-path/
total 0
drwxr-xr-x 2 root root 200 2012-08-29 17:33 .
drwxr-xr-x 5 root root 100 2012-08-29 17:33 ..
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0 -&gt; ../../vda
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part1 -&gt; ../../vda1
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part2 -&gt; ../../vda2
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part5 -&gt; ../../vda5
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:06.0-virtio-pci-virtio2 -&gt; ../../vdb
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:08.0-virtio-pci-virtio3 -&gt; ../../vdc
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:09.0-virtio-pci-virtio4 -&gt; ../../vdd
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:09.0-virtio-pci-virtio4-part1 -&gt; ../../vdd1</screen>
          <para>You might also have this problem after attaching and detaching the same
volume from the same VM with the same mount point multiple times. In
this case, restart the KVM host.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Failed to attach volume, systool is not installed</title>
        <sect3>
          <title>Problem</title>
          <para>This warning and error occurs if you do not have the required
<literal>sysfsutils</literal> package installed on the compute node:</para>
          <screen language="console">WARNING nova.virt.libvirt.utils [req-1200f887-c82b-4e7c-a891-fac2e3735dbb\
admin admin|req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin admin] systool\
is not installed
ERROR nova.compute.manager [req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin\
admin|req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin admin]
[instance: df834b5a-8c3f-477a-be9b-47c97626555c|instance: df834b5a-8c3f-47\
7a-be9b-47c97626555c]
Failed to attach volume 13d5c633-903a-4764-a5a0-3336945b1db1 at /dev/vdk.</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>Run the following command on the compute node to install the
<literal>sysfsutils</literal> packages:</para>
          <screen language="console"># apt-get install sysfsutils</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Failed to connect volume in FC SAN</title>
        <sect3>
          <title>Problem</title>
          <para>The compute node failed to connect to a volume in a Fibre Channel (FC) SAN
configuration. The WWN may not be zoned correctly in your FC SAN that
links the compute host to the storage array:</para>
          <screen language="console">ERROR nova.compute.manager [req-2ddd5297-e405-44ab-aed3-152cd2cfb8c2 admin\
demo|req-2ddd5297-e405-44ab-aed3-152cd2cfb8c2 admin demo] [instance: 60ebd\
6c7-c1e3-4bf0-8ef0-f07aa4c3d5f3|instance: 60ebd6c7-c1e3-4bf0-8ef0-f07aa4c3\
d5f3]
Failed to connect to volume 6f6a6a9c-dfcf-4c8d-b1a8-4445ff883200 while\
attaching at /dev/vdjTRACE nova.compute.manager [instance: 60ebd6c7-c1e3-4\
bf0-8ef0-f07aa4c3d5f3|instance: 60ebd6c7-c1e3-4bf0-8ef0-f07aa4c3d5f3]
Traceback (most recent call last):…f07aa4c3d5f3\] ClientException: The\
server has either erred or is incapable of performing the requested\
operation.(HTTP 500)(Request-ID: req-71e5132b-21aa-46ee-b3cc-19b5b4ab2f00)</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>The network administrator must configure the FC SAN fabric by correctly
zoning the WWN (port names) from your compute node HBAs.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Cannot find suitable emulator for x86_64</title>
        <sect3>
          <title>Problem</title>
          <para>When you attempt to create a VM, the error shows the VM is in the
<literal>BUILD</literal> then <literal>ERROR</literal> state.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>On the KVM host, run <command>cat /proc/cpuinfo</command>. Make sure the <literal>vmx</literal> or
<literal>svm</literal> flags are set.</para>
          <para>Follow the instructions in the <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/hypervisor-kvm.html#enable-kvm">Enable KVM</link> section in the OpenStack Configuration Reference to enable hardware
virtualization support in your BIOS.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Non-existent host</title>
        <sect3>
          <title>Problem</title>
          <para>This error could be caused by a volume being exported outside of
OpenStack using a host name different from the system name that
OpenStack expects. This error could be displayed with the <xref linkend="term-iscsi-qualified-name-iqn"/> if the host was exported using iSCSI.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>2013-04-19 04:02:02.336 2814 ERROR cinder.openstack.common.rpc.common [-] Returning exception Not found (HTTP 404)
NON_EXISTENT_HOST - HOST '10' was not found to caller.</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>Host names constructed by the driver use just the local host name, not
the fully qualified domain name (FQDN) of the Compute host. For example,
if the FQDN was <emphasis role="bold">myhost.example.com</emphasis>, just <emphasis role="bold">myhost</emphasis> would be used as the
3PAR host name. IP addresses are not allowed as host names on the 3PAR
storage server.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Non-existent VLUN</title>
        <sect3>
          <title>Problem</title>
          <para>This error occurs if the 3PAR host exists with the correct host name
that the OpenStack Block Storage drivers expect but the volume was
created in a different domain.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>HTTPNotFound: Not found (HTTP 404) NON_EXISTENT_VLUN - VLUN 'osv-DqT7CE3mSrWi4gZJmHAP-Q' was not found.</screen>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>The <literal>hpe3par_domain</literal> configuration items either need to be updated to
use the domain the 3PAR host currently resides in, or the 3PAR host
needs to be moved to the domain that the volume was created in.</para>
        </sect3>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Shared File Systems</title>
    <info/>
    <para>Shared File Systems service provides a set of services for management of
shared file systems in a multi-project cloud environment. The service resembles
OpenStack block-based storage management from the OpenStack Block Storage
service project. With the Shared File Systems service, you can
create a remote file system, mount the file system on your instances, and then
read and write data from your instances to and from your file system.</para>
    <para>The Shared File Systems service serves same purpose as the Amazon Elastic File
System (EFS) does.</para>
    <sect1>
      <title>Introduction</title>
      <para>The OpenStack File Share service allows you to offer shared file systems
service to OpenStack users in your installation. The Shared File Systems
service can run in a single-node or multiple node configuration.
The Shared File Systems service can be configured to provision shares
from one or more back ends, so it is required to declare at least one
back end. Shared File System service contains several configurable
components.</para>
      <para>It is important to understand these components:</para>
      <itemizedlist>
        <listitem>
          <para>Share networks</para>
        </listitem>
        <listitem>
          <para>Shares</para>
        </listitem>
        <listitem>
          <para>Multi-tenancy</para>
        </listitem>
        <listitem>
          <para>Back ends</para>
        </listitem>
      </itemizedlist>
      <para>The Shared File Systems service consists of four types of services,
most of which are similar to those of the Block Storage service:</para>
      <itemizedlist>
        <listitem>
          <para>
            <literal>manila-api</literal>
          </para>
        </listitem>
        <listitem>
          <para>
            <literal>manila-data</literal>
          </para>
        </listitem>
        <listitem>
          <para>
            <literal>manila-scheduler</literal>
          </para>
        </listitem>
        <listitem>
          <para>
            <literal>manila-share</literal>
          </para>
        </listitem>
      </itemizedlist>
      <para>Installation of first three - <literal>manila-api</literal>, <literal>manila-data</literal>, and
<literal>manila-scheduler</literal> is common for almost all deployments. But configuration
of <literal>manila-share</literal> is backend-specific and can differ from deployment to
deployment.</para>
    </sect1>
    <sect1>
      <title>Key concepts</title>
      <sect2>
        <title>Share</title>
        <para>In the Shared File Systems service <literal>share</literal> is the fundamental resource unit
allocated by the Shared File System service. It represents an allocation of a
persistent, readable, and writable filesystems. Compute instances access these
filesystems. Depending on the deployment configuration, clients outside of
OpenStack can also access the filesystem.</para>
        <note>
          <para>A <literal>share</literal> is an abstract storage object that may or may not directly
map to a "share" concept from the underlying storage provider.
See the description of <literal>share instance</literal> for more details.</para>
        </note>
      </sect2>
      <sect2>
        <title>Share instance</title>
        <para>This concept is tied with <literal>share</literal> and represents created resource on specific
back end, when <literal>share</literal> represents abstraction between end user and
back-end storages. In common cases, it is one-to-one relation.
One single <literal>share</literal> has more than one <literal>share instance</literal> in two cases:</para>
        <itemizedlist>
          <listitem>
            <para>When <literal>share migration</literal> is being applied</para>
          </listitem>
          <listitem>
            <para>When <literal>share replication</literal> is enabled</para>
          </listitem>
        </itemizedlist>
        <para>Therefore, each <literal>share instance</literal> stores information specific to real
allocated resource on storage. And <literal>share</literal> represents the information
that is common for <literal>share instances</literal>.
A user with <literal>member</literal> role will not be able to work with it directly. Only
a user with <literal>admin</literal> role has rights to perform actions against specific
share instances.</para>
      </sect2>
      <sect2>
        <title>Snapshot</title>
        <para>A <literal>snapshot</literal> is a point-in-time, read-only copy of a <literal>share</literal>. You can
create <literal>Snapshots</literal> from an existing, operational <literal>share</literal> regardless
of whether a client has mounted the file system. A <literal>snapshot</literal>
can serve as the content source for a new <literal>share</literal>. Specify the
<emphasis role="bold">Create from snapshot</emphasis> option when creating a new <literal>share</literal> on the
dashboard.</para>
      </sect2>
      <sect2>
        <title>Storage Pools</title>
        <para>With the Kilo release of OpenStack, Shared File Systems can use
<literal>storage pools</literal>. The storage may present one or more logical storage
resource pools that the Shared File Systems service
will select as a storage location when provisioning <literal>shares</literal>.</para>
      </sect2>
      <sect2>
        <title>Share Type</title>
        <para><literal>Share type</literal> is an abstract collection of criteria used to characterize
<literal>shares</literal>. They are most commonly used to create a hierarchy of functional
capabilities. This hierarchy represents tiered storage services levels. For
example, an administrator might define a premium <literal>share type</literal> that
indicates a greater level of performance than a basic <literal>share type</literal>.
Premium represents the best performance level.</para>
      </sect2>
      <sect2>
        <title>Share Access Rules</title>
        <para><literal>Share access rules</literal> define which users can access a particular <literal>share</literal>.
For example, administrators can declare rules for NFS shares by
listing the valid IP networks which will access the <literal>share</literal>. List the
IP networks in CIDR notation.</para>
      </sect2>
      <sect2>
        <title>Security Services</title>
        <para><literal>Security services``allow granular client access rules for
administrators. They can declare rules for authentication or
authorization to access ``share</literal> content. External services including LDAP,
Active Directory, and Kerberos can be declared as resources. Examine and
consult these resources when making an access decision for a
particular <literal>share</literal>. You can associate <literal>Shares</literal> with multiple
security services, but only one service per one type.</para>
      </sect2>
      <sect2>
        <title>Share Networks</title>
        <para>A <literal>share network</literal> is an object that defines a relationship between a
project network and subnet, as defined in an OpenStack Networking service or
Compute service. The <literal>share network</literal> is also defined in <literal>shares</literal>
created by the same project. A project may find it desirable to
provision <literal>shares</literal> such that only instances connected to a particular
OpenStack-defined network have access to the <literal>share</literal>. Also,
<literal>security services</literal> can be attached to <literal>share networks</literal>,
because most of auth protocols require some interaction with network services.</para>
        <para>The Shared File Systems service has the ability to work outside of OpenStack.
That is due to the <literal>StandaloneNetworkPlugin</literal>. The plugin is compatible with
any network platform, and does not require specific network services in
OpenStack like Compute or Networking service. You can set the network
parameters in the <literal>manila.conf</literal> file.</para>
      </sect2>
      <sect2>
        <title>Share Servers</title>
        <para>A <literal>share server</literal> is a logical entity that hosts the shares created
on a specific <literal>share network</literal>. A <literal>share server</literal> may be a
configuration object within the storage controller, or it may represent
logical resources provisioned within an OpenStack deployment used to
support the data path used to access <literal>shares</literal>.</para>
        <para><literal>Share servers</literal> interact with network services to determine the appropriate
IP addresses on which to export <literal>shares</literal> according to the related <literal>share
network</literal>. The Shared File Systems service has a pluggable network model that
allows <literal>share servers</literal> to work with different implementations of
the Networking service.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Share management</title>
      <para>A share is a remote, mountable file system. You can mount a share to and access
a share from several hosts by several users at a time.</para>
      <para>You can create a share and associate it with a network, list shares, and show
information for, update, and delete a specified share.
You can also create snapshots of shares. To create a snapshot, you specify the
ID of the share that you want to snapshot.</para>
      <para>The shares are based on of the supported Shared File Systems protocols:</para>
      <itemizedlist>
        <listitem>
          <para><emphasis>NFS</emphasis>. Network File System (NFS).</para>
        </listitem>
        <listitem>
          <para><emphasis>CIFS</emphasis>. Common Internet File System (CIFS).</para>
        </listitem>
        <listitem>
          <para><emphasis>GLUSTERFS</emphasis>. Gluster file system (GlusterFS).</para>
        </listitem>
        <listitem>
          <para><emphasis>HDFS</emphasis>. Hadoop Distributed File System (HDFS).</para>
        </listitem>
        <listitem>
          <para><emphasis>CEPHFS</emphasis>. Ceph File System (CephFS).</para>
        </listitem>
      </itemizedlist>
      <para>The Shared File Systems service provides set of drivers that enable you to use
various network file storage devices, instead of the base implementation. That
is the real purpose of the Shared File Systems service in production.</para>
      <sect2>
        <title>Share basic operations</title>
        <sect3>
          <title>General concepts</title>
          <para>To create a file share, and access it, the following general concepts
are prerequisite knowledge:</para>
          <procedure>
            <step>
              <para>To create a share, use <command>manila create</command> command and
specify the required arguments: the size of the share and the shared file
system protocol. <literal>NFS</literal>, <literal>CIFS</literal>, <literal>GlusterFS</literal>, <literal>HDFS</literal>, or
<literal>CephFS</literal> share file system protocols are supported.</para>
            </step>
            <step>
              <para>You can also optionally specify the share network and the share type.</para>
            </step>
            <step>
              <para>After the share becomes available, use the <command>manila show</command> command
to get the share export locations.</para>
            </step>
            <step>
              <para>After getting the share export locations, you can create an
<xref linkend="access-to-share"/> for the share, mount it and work with
files on the remote file system.</para>
            </step>
          </procedure>
          <para>There are big number of the share drivers created by different vendors in the
Shared File Systems service. As a Python class, each share driver can be set
for the <xref linkend="shared-file-systems-multi-backend"/> and run in the back
end to manage the share operations.</para>
          <para>Initially there are two driver modes for the back ends:</para>
          <itemizedlist>
            <listitem>
              <para>no share servers mode</para>
            </listitem>
            <listitem>
              <para>share servers mode</para>
            </listitem>
          </itemizedlist>
          <para>Each share driver supports one or two of possible back end modes that can be
configured in the <literal>manila.conf</literal> file. The configuration option
<literal>driver_handles_share_servers</literal> in the <literal>manila.conf</literal> file sets the share
servers mode or no share servers mode, and defines the driver mode for share
storage lifecycle management:</para>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="24.0*"/>
              <colspec colname="c2" colwidth="49.3*"/>
              <colspec colname="c3" colwidth="26.7*"/>
              <thead>
                <row>
                  <entry>
                    <para>Mode</para>
                  </entry>
                  <entry>
                    <para>Config option</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>no share servers</para>
                  </entry>
                  <entry>
                    <para>driver_handles_share_servers = False</para>
                  </entry>
                  <entry>
                    <para>An administrator
rather than a share
driver manages the
bare metal storage
with some net
interface instead
of the presence of
the share servers.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>share servers</para>
                  </entry>
                  <entry>
                    <para>driver_handles_share_servers = True</para>
                  </entry>
                  <entry>
                    <para>The share driver
creates the share
server and manages,
or handles, the
share server life
cycle.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>It is <xref linkend="shared-file-systems-share-types"/> which have the
extra specifications that help scheduler to filter back ends and choose the
appropriate back end for the user that requested to create a share. The
required extra boolean specification for each share type is
<literal>driver_handles_share_servers</literal>. As an administrator, you can create the share
types with the specifications you need. For details of managing the share types
and configuration the back ends, see <xref linkend="shared-file-systems-share-types"/> and
<xref linkend="shared-file-systems-multi-backend"/> documentation.</para>
          <para>You can create a share in two described above modes:</para>
          <itemizedlist>
            <listitem>
              <para>in a no share servers mode without specifying the share network and
specifying the share type with <literal>driver_handles_share_servers = False</literal>
parameter. See subsection <xref linkend="create-share-in-no-share-server-mode"/>.</para>
            </listitem>
            <listitem>
              <para>in a share servers mode with specifying the share network and the share
type with <literal>driver_handles_share_servers = True</literal> parameter. See subsection
<xref linkend="create-share-in-share-server-mode"/>.</para>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3 xml:id="create-share-in-no-share-server-mode">
          <title>Create a share in no share servers mode</title>
          <para>To create a file share in no share servers mode, you need to:</para>
          <procedure>
            <step>
              <para>To create a share, use <command>manila create</command> command and
specify the required arguments: the size of the share and the shared file
system protocol. <literal>NFS</literal>, <literal>CIFS</literal>, <literal>GlusterFS</literal>, <literal>HDFS</literal>, or
<literal>CephFS</literal> share file system protocols are supported.</para>
            </step>
            <step>
              <para>You should specify the <xref linkend="shared-file-systems-share-types"/>
with <literal>driver_handles_share_servers = False</literal> extra specification.</para>
            </step>
            <step>
              <para>You must not specify the <literal>share network</literal> because no share servers are
created. In this mode the Shared File Systems service expects that
administrator has some bare metal storage with some net interface.</para>
            </step>
            <step>
              <para>The <command>manila create</command> command creates a share. This command does the
following things:</para>
              <itemizedlist>
                <listitem>
                  <para>The <xref linkend="shared-file-systems-scheduling"/> service will
find the back end with <literal>driver_handles_share_servers = False</literal> mode due
to filtering the extra specifications of the share type.</para>
                </listitem>
                <listitem>
                  <para>The share is created using the storage that is specified in the found
back end.</para>
                </listitem>
              </itemizedlist>
            </step>
            <step>
              <para>After the share becomes available, use the <command>manila show</command> command
to get the share export locations.</para>
            </step>
          </procedure>
          <para>In the example to create a share, the created already share type named
<literal>my_type</literal> with <literal>driver_handles_share_servers = False</literal> extra specification
is used.</para>
          <para>Check share types that exist, run:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila type-list
+------+---------+------------+------------+--------------------------------------+-------------------------+
| ID   | Name    | visibility | is_default | required_extra_specs                 | optional_extra_specs    |
+------+---------+------------+------------+--------------------------------------+-------------------------+
| %ID% | my_type | public     | -          | driver_handles_share_servers : False | snapshot_support : True |
+------+---------+------------+------------+--------------------------------------+-------------------------+</screen>
          <para>Create a private share with <literal>my_type</literal> share type, NFS shared file system
protocol, and size 1 GB:</para>
          <screen language="console">$ manila create nfs 1 --name Share1 --description "My share" --share-type my_type
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | creating                             |
| share_type_name             | my_type                              |
| description                 | My share                             |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| share_server_id             | None                                 |
| host                        |                                      |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 |
| size                        | 1                                    |
| name                        | Share1                               |
| share_type                  | 14ee8575-aac2-44af-8392-d9c9d344f392 |
| has_replicas                | False                                |
| replication_type            | None                                 |
| created_at                  | 2016-03-25T12:02:46.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 907004508ef4447397ce6741a8f037c1     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</screen>
          <para>New share <literal>Share2</literal> should have a status <literal>available</literal>:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila show Share2
+-----------------------------+----------------------------------------------------------+
| Property                    | Value                                                    |
+-----------------------------+----------------------------------------------------------+
| status                      | available                                                |
| share_type_name             | my_type                                                  |
| description                 | My share                                                 |
| availability_zone           | nova                                                     |
| share_network_id            | None                                                     |
| export_locations            |                                                          |
|                             | path = 10.0.0.4:/shares/manila_share_a5fb1ab7_...        |
|                             | preferred = False                                        |
|                             | is_admin_only = False                                    |
|                             | id = 9e078eee-bcad-40b8-b4fe-1c916cf98ed1                |
|                             | share_instance_id = a5fb1ab7-0bbd-465b-ac14-05706294b6e9 |
|                             | path = 172.18.198.52:/shares/manila_share_a5fb1ab7_...   |
|                             | preferred = False                                        |
|                             | is_admin_only = True                                     |
|                             | id = 44933f59-e0e3-4483-bb88-72ba7c486f41                |
|                             | share_instance_id = a5fb1ab7-0bbd-465b-ac14-05706294b6e9 |
| share_server_id             | None                                                     |
| host                        | manila@paris#epsilon                                     |
| access_rules_status         | active                                                   |
| snapshot_id                 | None                                                     |
| is_public                   | False                                                    |
| task_state                  | None                                                     |
| snapshot_support            | True                                                     |
| id                          | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88                     |
| size                        | 1                                                        |
| name                        | Share1                                                   |
| share_type                  | 14ee8575-aac2-44af-8392-d9c9d344f392                     |
| has_replicas                | False                                                    |
| replication_type            | None                                                     |
| created_at                  | 2016-03-25T12:02:46.000000                               |
| share_proto                 | NFS                                                      |
| consistency_group_id        | None                                                     |
| source_cgsnapshot_member_id | None                                                     |
| project_id                  | 907004508ef4447397ce6741a8f037c1                         |
| metadata                    | {}                                                       |
+-----------------------------+----------------------------------------------------------+</screen>
        </sect3>
        <sect3 xml:id="create-share-in-share-server-mode">
          <title>Create a share in share servers mode</title>
          <para>To create a file share in share servers mode, you need to:</para>
          <procedure>
            <step>
              <para>To create a share, use <command>manila create</command> command and
specify the required arguments: the size of the share and the shared file
system protocol. <literal>NFS</literal>, <literal>CIFS</literal>, <literal>GlusterFS</literal>, <literal>HDFS</literal>, or
<literal>CephFS</literal> share file system protocols are supported.</para>
            </step>
            <step>
              <para>You should specify the <xref linkend="shared-file-systems-share-types"/>
with <literal>driver_handles_share_servers = True</literal> extra specification.</para>
            </step>
            <step>
              <para>You should specify the
<xref linkend="shared-file-systems-share-networks"/>.</para>
            </step>
            <step>
              <para>The <command>manila create</command> command creates a share. This command does the
following things:</para>
              <itemizedlist>
                <listitem>
                  <para>The <xref linkend="shared-file-systems-scheduling"/> service will
find the back end with <literal>driver_handles_share_servers = True</literal> mode due to
filtering the extra specifications of the share type.</para>
                </listitem>
                <listitem>
                  <para>The share driver will create a share server with the share network. For
details of creating the resources, see the <link xlink:href="http://docs.openstack.org/developer/manila/devref/index.html#share-backends">documentation</link> of the
specific share driver.</para>
                </listitem>
              </itemizedlist>
            </step>
            <step>
              <para>After the share becomes available, use the <command>manila show</command> command
to get the share export location.</para>
            </step>
          </procedure>
          <para>In the example to create a share, the default share type and the already
existing share network are used.</para>
          <note>
            <para>There is no default share type just after you started manila as the
administrator. See <xref linkend="shared-file-systems-share-types"/> to
create the default share type. To create a share network, use
<xref linkend="shared-file-systems-share-networks"/>.</para>
          </note>
          <para>Check share types that exist, run:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila type-list
+------+---------+------------+------------+--------------------------------------+-------------------------+
| ID   | Name    | visibility | is_default | required_extra_specs                 | optional_extra_specs    |
+------+---------+------------+------------+--------------------------------------+-------------------------+
| %id% | default | public     | YES        | driver_handles_share_servers : True  | snapshot_support : True |
+------+---------+------------+------------+--------------------------------------+-------------------------+</screen>
          <para>Check share networks that exist, run:</para>
          <screen language="console">$ manila share-network-list
+--------------------------------------+--------------+
| id                                   | name         |
+--------------------------------------+--------------+
| c895fe26-92be-4152-9e6c-f2ad230efb13 | my_share_net |
+--------------------------------------+--------------+</screen>
          <para>Create a public share with <literal>my_share_net</literal> network, <literal>default</literal>
share type, NFS shared file system protocol, and size 1 GB:</para>
          <screen language="console">$ manila create nfs 1 \
    --name "Share2" \
    --description "My second share" \
    --share-type default \
    --share-network my_share_net \
    --metadata aim=testing \
    --public
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | creating                             |
| share_type_name             | default                              |
| description                 | My second share                      |
| availability_zone           | None                                 |
| share_network_id            | c895fe26-92be-4152-9e6c-f2ad230efb13 |
| share_server_id             | None                                 |
| host                        |                                      |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | True                                 |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | 195e3ba2-9342-446a-bc93-a584551de0ac |
| size                        | 1                                    |
| name                        | Share2                               |
| share_type                  | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf |
| has_replicas                | False                                |
| replication_type            | None                                 |
| created_at                  | 2016-03-25T12:13:40.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 907004508ef4447397ce6741a8f037c1     |
| metadata                    | {u'aim': u'testing'}                 |
+-----------------------------+--------------------------------------+</screen>
          <para>The share also can be created from a share snapshot. For details, see
<xref linkend="shared-file-systems-snapshots"/>.</para>
          <para>See the share in a share list:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila list
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| ID                                   | Name    | Size | Share Proto | Status    | Is Public | Share Type Name | Host                 | Availability Zone |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 | Share1  | 1    | NFS         | available | False     | my_type         | manila@paris#epsilon | nova              |
| 195e3ba2-9342-446a-bc93-a584551de0ac | Share2  | 1    | NFS         | available | True      | default         | manila@london#LONDON | nova              |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+</screen>
          <para>Check the share status and see the share export locations. After <literal>creating</literal>
status share should have status <literal>available</literal>:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila show Share2
+----------------------+----------------------------------------------------------------------+
| Property             | Value                                                                |
+----------------------+----------------------------------------------------------------------+
| status               | available                                                            |
| share_type_name      | default                                                              |
| description          | My second share                                                      |
| availability_zone    | nova                                                                 |
| share_network_id     | c895fe26-92be-4152-9e6c-f2ad230efb13                                 |
| export_locations     |                                                                      |
|                      | path = 10.254.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965 |
|                      | preferred = False                                                    |
|                      | is_admin_only = False                                                |
|                      | id = de6d4012-6158-46f0-8b28-4167baca51a7                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
|                      | path = 10.0.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965   |
|                      | preferred = False                                                    |
|                      | is_admin_only = True                                                 |
|                      | id = 602d0f5c-921b-4e45-bfdb-5eec8a89165a                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
| share_server_id      | 2e9d2d02-883f-47b5-bb98-e053b8d1e683                                 |
| host                 | manila@london#LONDON                                                 |
| access_rules_status  | active                                                               |
| snapshot_id          | None                                                                 |
| is_public            | True                                                                 |
| task_state           | None                                                                 |
| snapshot_support     | True                                                                 |
| id                   | 195e3ba2-9342-446a-bc93-a584551de0ac                                 |
| size                 | 1                                                                    |
| name                 | Share2                                                               |
| share_type           | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf                                 |
| has_replicas         | False                                                                |
| replication_type     | None                                                                 |
| created_at           | 2016-03-25T12:13:40.000000                                           |
| share_proto          | NFS                                                                  |
| consistency_group_id | None                                                                 |
| project_id           | 907004508ef4447397ce6741a8f037c1                                     |
| metadata             | {u'aim': u'testing'}                                                 |
+----------------------+----------------------------------------------------------------------+</screen>
          <para><literal>is_public</literal> defines the level of visibility for the share: whether other
projects can or cannot see the share. By default, the share is private.</para>
        </sect3>
        <sect3>
          <title>Update share</title>
          <para>Update the name, or description, or level of visibility for all projects for
the share if you need:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila update Share2 --description "My second share. Updated" --is-public False

$ manila show Share2
+----------------------+----------------------------------------------------------------------+
| Property             | Value                                                                |
+----------------------+----------------------------------------------------------------------+
| status               | available                                                            |
| share_type_name      | default                                                              |
| description          | My second share. Updated                                             |
| availability_zone    | nova                                                                 |
| share_network_id     | c895fe26-92be-4152-9e6c-f2ad230efb13                                 |
| export_locations     |                                                                      |
|                      | path = 10.254.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965 |
|                      | preferred = False                                                    |
|                      | is_admin_only = False                                                |
|                      | id = de6d4012-6158-46f0-8b28-4167baca51a7                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
|                      | path = 10.0.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965   |
|                      | preferred = False                                                    |
|                      | is_admin_only = True                                                 |
|                      | id = 602d0f5c-921b-4e45-bfdb-5eec8a89165a                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
| share_server_id      | 2e9d2d02-883f-47b5-bb98-e053b8d1e683                                 |
| host                 | manila@london#LONDON                                                 |
| access_rules_status  | active                                                               |
| snapshot_id          | None                                                                 |
| is_public            | False                                                                |
| task_state           | None                                                                 |
| snapshot_support     | True                                                                 |
| id                   | 195e3ba2-9342-446a-bc93-a584551de0ac                                 |
| size                 | 1                                                                    |
| name                 | Share2                                                               |
| share_type           | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf                                 |
| has_replicas         | False                                                                |
| replication_type     | None                                                                 |
| created_at           | 2016-03-25T12:13:40.000000                                           |
| share_proto          | NFS                                                                  |
| consistency_group_id | None                                                                 |
| project_id           | 907004508ef4447397ce6741a8f037c1                                     |
| metadata             | {u'aim': u'testing'}                                                 |
+----------------------+----------------------------------------------------------------------+</screen>
          <para>A share can have one of these status values:</para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="46.1*"/>
              <colspec colname="c2" colwidth="53.9*"/>
              <thead>
                <row>
                  <entry>
                    <para>Status</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>creating</para>
                  </entry>
                  <entry>
                    <para>The share is being created.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>deleting</para>
                  </entry>
                  <entry>
                    <para>The share is being deleted.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>error</para>
                  </entry>
                  <entry>
                    <para>An error occurred during share creation.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>error_deleting</para>
                  </entry>
                  <entry>
                    <para>An error occurred during share deletion.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>available</para>
                  </entry>
                  <entry>
                    <para>The share is ready to use.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>manage_starting</para>
                  </entry>
                  <entry>
                    <para>Share manage started.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>manage_error</para>
                  </entry>
                  <entry>
                    <para>Share manage failed.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>unmanage_starting</para>
                  </entry>
                  <entry>
                    <para>Share unmanage started.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>unmanage_error</para>
                  </entry>
                  <entry>
                    <para>Share cannot be unmanaged.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>unmanaged</para>
                  </entry>
                  <entry>
                    <para>Share was unmanaged.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>extending</para>
                  </entry>
                  <entry>
                    <para>The extend, or increase, share size
request was issued successfully.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>extending_error</para>
                  </entry>
                  <entry>
                    <para>Extend share failed.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>shrinking</para>
                  </entry>
                  <entry>
                    <para>Share is being shrunk.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>shrinking_error</para>
                  </entry>
                  <entry>
                    <para>Failed to update quota on share
shrinking.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>shrinking_possible_data_loss_error</para>
                  </entry>
                  <entry>
                    <para>Shrink share failed due to possible data
loss.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>migrating</para>
                  </entry>
                  <entry>
                    <para>Share migration is in progress.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
        </sect3>
        <sect3>
          <title>Share metadata</title>
          <para>If you want to set the metadata key-value pairs on the share, run:</para>
          <screen language="console">$ manila metadata Share2 set project=my_abc deadline=01/20/16</screen>
          <para>Get all metadata key-value pairs of the share:</para>
          <screen language="console">$ manila metadata-show Share2
+----------+----------+
| Property | Value    |
+----------+----------+
| aim      | testing  |
| project  | my_abc   |
| deadline | 01/20/16 |
+----------+----------+</screen>
          <para>You can update the metadata:</para>
          <screen language="console">$ manila metadata-update-all Share2 deadline=01/30/16
+----------+----------+
| Property | Value    |
+----------+----------+
| deadline | 01/30/16 |
+----------+----------+</screen>
          <para>You also can unset the metadata using
<emphasis role="bold">manila metadata &lt;share_name&gt; unset &lt;metadata_key(s)&gt;</emphasis>.</para>
        </sect3>
        <sect3>
          <title>Reset share state</title>
          <para>As administrator, you can reset the state of a share.</para>
          <para>Use <emphasis role="bold">manila reset-state [--state &lt;state&gt;] &lt;share&gt;</emphasis> command to reset share
state, where <literal>state</literal> indicates which state to assign the share. Options
include <literal>available</literal>, <literal>error</literal>, <literal>creating</literal>, <literal>deleting</literal>,
<literal>error_deleting</literal> states.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila reset-state Share2 --state deleting

$ manila show Share2
+----------------------+----------------------------------------------------------------------+
| Property             | Value                                                                |
+----------------------+----------------------------------------------------------------------+
| status               | deleting                                                             |
| share_type_name      | default                                                              |
| description          | My second share. Updated                                             |
| availability_zone    | nova                                                                 |
| share_network_id     | c895fe26-92be-4152-9e6c-f2ad230efb13                                 |
| export_locations     |                                                                      |
|                      | path = 10.254.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965 |
|                      | preferred = False                                                    |
|                      | is_admin_only = False                                                |
|                      | id = de6d4012-6158-46f0-8b28-4167baca51a7                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
|                      | path = 10.0.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965   |
|                      | preferred = False                                                    |
|                      | is_admin_only = True                                                 |
|                      | id = 602d0f5c-921b-4e45-bfdb-5eec8a89165a                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
| share_server_id      | 2e9d2d02-883f-47b5-bb98-e053b8d1e683                                 |
| host                 | manila@london#LONDON                                                 |
| access_rules_status  | active                                                               |
| snapshot_id          | None                                                                 |
| is_public            | False                                                                |
| task_state           | None                                                                 |
| snapshot_support     | True                                                                 |
| id                   | 195e3ba2-9342-446a-bc93-a584551de0ac                                 |
| size                 | 1                                                                    |
| name                 | Share2                                                               |
| share_type           | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf                                 |
| has_replicas         | False                                                                |
| replication_type     | None                                                                 |
| created_at           | 2016-03-25T12:13:40.000000                                           |
| share_proto          | NFS                                                                  |
| consistency_group_id | None                                                                 |
| project_id           | 907004508ef4447397ce6741a8f037c1                                     |
| metadata             | {u'deadline': u'01/30/16'}                                           |
+----------------------+----------------------------------------------------------------------+</screen>
        </sect3>
        <sect3>
          <title>Delete and force-delete share</title>
          <para>You also can force-delete a share.
The shares cannot be deleted in transitional states. The transitional
states are <literal>creating</literal>, <literal>deleting</literal>, <literal>managing</literal>, <literal>unmanaging</literal>,
<literal>migrating</literal>, <literal>extending</literal>, and <literal>shrinking</literal> statuses for the shares.
Force-deletion deletes an object in any state. Use the <literal>policy.json</literal> file
to grant permissions for this action to other roles.</para>
          <tip>
            <para>The configuration file <literal>policy.json</literal> may be used from different places.
The path <literal>/etc/manila/policy.json</literal> is one of expected paths by default.</para>
          </tip>
          <para>Use <emphasis role="bold">manila delete &lt;share_name_or_ID&gt;</emphasis> command to delete a specified share:</para>
          <screen language="console">$ manila delete %share_name_or_id%</screen>
          <note>
            <para>If you specified <xref linkend="shared-file-systems-cgroups"/>
while creating a share, you should provide the <literal>--consistency-group</literal>
parameter to delete the share:</para>
          </note>
          <screen language="console">$ manila delete %share_name_or_id% --consistency-group %consistency-group-id%</screen>
          <para>If you try to delete the share in one of the transitional
state using soft-deletion you'll get an error:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila delete Share2
Delete for share 195e3ba2-9342-446a-bc93-a584551de0ac failed: Invalid share: Share status must be one of ('available', 'error', 'inactive'). (HTTP 403) (Request-ID: req-9a77b9a0-17d2-4d97-8a7a-b7e23c27f1fe)
ERROR: Unable to delete any of the specified shares.</screen>
          <para>A share cannot be deleted in a transitional status, that it why an error from
<literal>python-manilaclient</literal> appeared.</para>
          <para>Print the list of all shares for all projects:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila list --all-tenants
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| ID                                   | Name    | Size | Share Proto | Status    | Is Public | Share Type Name | Host                 | Availability Zone |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 | Share1  | 1    | NFS         | available | False     | my_type         | manila@paris#epsilon | nova              |
| 195e3ba2-9342-446a-bc93-a584551de0ac | Share2  | 1    | NFS         | available | False     | default         | manila@london#LONDON | nova              |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+</screen>
          <para>Force-delete Share2 and check that it is absent in the list of shares,
run:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila force-delete Share2

$ manila list
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| ID                                   | Name    | Size | Share Proto | Status    | Is Public | Share Type Name | Host                 | Availability Zone |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 | Share1  | 1    | NFS         | available | False     | my_type         | manila@paris#epsilon | nova              |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+</screen>
        </sect3>
        <sect3 xml:id="access-to-share">
          <title>Manage access to share</title>
          <para>The Shared File Systems service allows to grant or deny access to a specified
share, and list the permissions for a specified share.</para>
          <para>To grant or deny access to a share, specify one of these supported share
access levels:</para>
          <itemizedlist>
            <listitem>
              <para><emphasis role="bold">rw</emphasis>. Read and write (RW) access. This is the default value.</para>
            </listitem>
            <listitem>
              <para><emphasis role="bold">ro</emphasis>. Read-only (RO) access.</para>
            </listitem>
          </itemizedlist>
          <para>You must also specify one of these supported authentication methods:</para>
          <itemizedlist>
            <listitem>
              <para><emphasis role="bold">ip</emphasis>. Authenticates an instance through its IP address. A valid
format is <literal>XX.XX.XX.XX</literal> or <literal>XX.XX.XX.XX/XX</literal>. For example <literal>0.0.0.0/0</literal>.</para>
            </listitem>
            <listitem>
              <para><emphasis role="bold">user</emphasis>. Authenticates by a specified user or group name. A valid value is
an alphanumeric string that can contain some special characters and is from
4 to 32 characters long.</para>
            </listitem>
            <listitem>
              <para><emphasis role="bold">cert</emphasis>. Authenticates an instance through a TLS certificate. Specify the
TLS identity as the IDENTKEY. A valid value is any string up to 64 characters
long in the common name (CN) of the certificate. The meaning of a string
depends on its interpretation.</para>
            </listitem>
            <listitem>
              <para><emphasis role="bold">cephx</emphasis>. Ceph authentication system. Specify the Ceph auth ID that needs
to be authenticated and authorized for share access by the Ceph back end. A
valid value must be non-empty, consist of ASCII printable characters, and not
contain periods.</para>
            </listitem>
          </itemizedlist>
          <para>Try to mount NFS share with export path
<literal>10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9</literal> on the
node with IP address <literal>10.0.0.13</literal>:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ sudo mount -v -t nfs 10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9 /mnt/
mount.nfs: timeout set for Tue Oct  6 10:37:23 2015
mount.nfs: trying text-based options 'vers=4,addr=10.0.0.4,clientaddr=10.0.0.13'
mount.nfs: mount(2): Permission denied
mount.nfs: access denied by server while mounting 10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9</screen>
          <para>An error message "Permission denied" appeared, so you are not allowed to mount
a share without an access rule. Allow access to the share with <literal>ip</literal> access
type and <literal>10.0.0.13</literal> IP address:</para>
          <screen language="console">$ manila access-allow Share1 ip 10.0.0.13 --access-level rw
+--------------+--------------------------------------+
| Property     | Value                                |
+--------------+--------------------------------------+
| share_id     | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 |
| access_type  | ip                                   |
| access_to    | 10.0.0.13                            |
| access_level | rw                                   |
| state        | new                                  |
| id           | de715226-da00-4cfc-b1ab-c11f3393745e |
+--------------+--------------------------------------+</screen>
          <para>Try to mount a share again. This time it is mounted successfully:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ sudo mount -v -t nfs 10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9 /mnt/</screen>
          <para>Since it is allowed node on 10.0.0.13 read and write access, try to create
a file on a mounted share:</para>
          <screen language="console">$ cd /mnt
$ ls
lost+found
$ touch my_file.txt</screen>
          <para>Connect via SSH to the <literal>10.0.0.4</literal> node and check new file <literal>my_file.txt</literal>
in the <literal>/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9</literal> directory:</para>
          <screen language="console">$ ssh 10.0.0.4
$ cd /shares
$ ls
manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9
$ cd manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9
$ ls
lost+found  my_file.txt</screen>
          <para>You have successfully created a file from instance that was given access by
its IP address.</para>
          <para>Allow access to the share with <literal>user</literal> access type:</para>
          <screen language="console">$ manila access-allow Share1 user demo --access-level rw
+--------------+--------------------------------------+
| Property     | Value                                |
+--------------+--------------------------------------+
| share_id     | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 |
| access_type  | user                                 |
| access_to    | demo                                 |
| access_level | rw                                   |
| state        | new                                  |
| id           | 4f391c6b-fb4f-47f5-8b4b-88c5ec9d568a |
+--------------+--------------------------------------+</screen>
          <note>
            <para>Different share features are supported by different share drivers.
For the example, the Generic driver with the Block Storage service as a
back-end doesn't support <literal>user</literal> and <literal>cert</literal> authentications methods. For
details of supporting of features by different drivers, see <link xlink:href="http://docs.openstack.org/developer/manila/devref/share_back_ends_feature_support_mapping.html">Manila share
features support mapping</link>.</para>
          </note>
          <para>To verify that the access rules (ACL) were configured correctly for a share,
you list permissions for a share:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila access-list Share1
+--------------------------------------+-------------+------------+--------------+--------+
| id                                   | access type | access to  | access level | state  |
+--------------------------------------+-------------+------------+--------------+--------+
| 4f391c6b-fb4f-47f5-8b4b-88c5ec9d568a | user        | demo       | rw           | error  |
| de715226-da00-4cfc-b1ab-c11f3393745e | ip          | 10.0.0.13  | rw           | active |
+--------------------------------------+-------------+------------+--------------+--------+</screen>
          <para>Deny access to the share and check that deleted access rule is absent in the
access rule list:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila access-deny Share1 de715226-da00-4cfc-b1ab-c11f3393745e

$ manila access-list Share1
+--------------------------------------+-------------+-----------+--------------+-------+
| id                                   | access type | access to | access level | state |
+--------------------------------------+-------------+-----------+--------------+-------+
| 4f391c6b-fb4f-47f5-8b4b-88c5ec9d568a | user        | demo      | rw           | error |
+--------------------------------------+-------------+-----------+--------------+-------+</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Manage and unmanage share</title>
        <para>To <literal>manage</literal> a share means that an administrator, rather than a share
driver, manages the storage lifecycle. This approach is appropriate when an
administrator already has the custom non-manila share with its size, shared
file system protocol, and export path, and an administrator wants to
register it in the Shared File System service.</para>
        <para>To <literal>unmanage</literal> a share means to unregister a specified share from the Shared
File Systems service. Administrators can revert an unmanaged share to managed
status if needed.</para>
        <sect3>
          <title>Unmanage a share</title>
          <para>The <literal>unmanage</literal> operation is not supported for shares that were
created on top of share servers and created with share networks.
The Share service should have the
option <literal>driver_handles_share_servers = False</literal>
set in the <literal>manila.conf</literal> file. You can unmanage a share that has
no dependent snapshots.</para>
          <para>To unmanage managed share, run the <command>manila unmanage &lt;share&gt;</command>
command. Then try to print the information about the share. The
returned result should indicate that Shared File Systems service won't
find the share:</para>
          <screen language="console">$ manila unmanage share_for_docs
$ manila show share_for_docs
ERROR: No share with a name or ID of 'share_for_docs' exists.</screen>
        </sect3>
        <sect3>
          <title>Manage a share</title>
          <para>To register the non-managed share in the File System service, run the
<command>manila manage</command> command:</para>
          <screen language="console">manila manage [--name &lt;name&gt;] [--description &lt;description&gt;]
              [--share_type &lt;share-type&gt;]
              [--driver_options [&lt;key=value&gt; [&lt;key=value&gt; ...]]]
              &lt;service_host&gt; &lt;protocol&gt; &lt;export_path&gt;</screen>
          <para>The positional arguments are:</para>
          <itemizedlist>
            <listitem>
              <para>service_host. The manage-share service host in
<literal>host@backend#POOL</literal> format, which consists of the host name for
the back end, the name of the back end, and the pool name for the
back end.</para>
            </listitem>
            <listitem>
              <para>protocol. The Shared File Systems protocol of the share to manage. Valid
values are NFS, CIFS, GlusterFS, or HDFS.</para>
            </listitem>
            <listitem>
              <para>export_path. The share export path in the format appropriate for the
protocol:</para>
              <itemizedlist>
                <listitem>
                  <para>NFS protocol. 10.0.0.1:/foo_path.</para>
                </listitem>
                <listitem>
                  <para>CIFS protocol. \\10.0.0.1\foo_name_of_cifs_share.</para>
                </listitem>
                <listitem>
                  <para>HDFS protocol. hdfs://10.0.0.1:foo_port/foo_share_name.</para>
                </listitem>
                <listitem>
                  <para>GlusterFS. 10.0.0.1:/foo_volume.</para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
          <para>The <literal>driver_options</literal> is an optional set of one or more key and value pairs
that describe driver options. Note that the share type must have the
<literal>driver_handles_share_servers = False</literal> option. As a result, a special share
type named <literal>for_managing</literal> was used in example.</para>
          <para>To manage share, run:</para>
          <screen language="console">$ manila manage \
    manila@paris#shares \
    nfs \
    1.0.0.4:/shares/manila_share_6d2142d8_2b9b_4405_867f_8a48094c893f \
    --name share_for_docs \
    --description "We manage share." \
    --share_type for_managing
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | manage_starting                      |
| share_type_name             | for_managing                         |
| description                 | We manage share.                     |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| share_server_id             | None                                 |
| host                        | manila@paris#shares                  |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | ddfb1240-ed5e-4071-a031-b842035a834a |
| size                        | None                                 |
| name                        | share_for_docs                       |
| share_type                  | 14ee8575-aac2-44af-8392-d9c9d344f392 |
| has_replicas                | False                                |
| replication_type            | None                                 |
| created_at                  | 2016-03-25T15:22:43.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 907004508ef4447397ce6741a8f037c1     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</screen>
          <para>Check that the share is available:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila show share_for_docs
+----------------------+--------------------------------------------------------------------------+
| Property             | Value                                                                    |
+----------------------+--------------------------------------------------------------------------+
| status               | available                                                                |
| share_type_name      | for_managing                                                             |
| description          | We manage share.                                                         |
| availability_zone    | None                                                                     |
| share_network_id     | None                                                                     |
| export_locations     |                                                                          |
|                      | path = 1.0.0.4:/shares/manila_share_6d2142d8_2b9b_4405_867f_8a48094c893f |
|                      | preferred = False                                                        |
|                      | is_admin_only = False                                                    |
|                      | id = d4d048bf-4159-4a94-8027-e567192b8d30                                |
|                      | share_instance_id = 4c8e3887-4f9a-4775-bab4-e5840a09c34e                 |
|                      | path = 2.0.0.3:/shares/manila_share_6d2142d8_2b9b_4405_867f_8a48094c893f |
|                      | preferred = False                                                        |
|                      | is_admin_only = True                                                     |
|                      | id = 1dd4f0a3-778d-486a-a851-b522f6e7cf5f                                |
|                      | share_instance_id = 4c8e3887-4f9a-4775-bab4-e5840a09c34e                 |
| share_server_id      | None                                                                     |
| host                 | manila@paris#shares                                                      |
| access_rules_status  | active                                                                   |
| snapshot_id          | None                                                                     |
| is_public            | False                                                                    |
| task_state           | None                                                                     |
| snapshot_support     | True                                                                     |
| id                   | ddfb1240-ed5e-4071-a031-b842035a834a                                     |
| size                 | 1                                                                        |
| name                 | share_for_docs                                                           |
| share_type           | 14ee8575-aac2-44af-8392-d9c9d344f392                                     |
| has_replicas         | False                                                                    |
| replication_type     | None                                                                     |
| created_at           | 2016-03-25T15:22:43.000000                                               |
| share_proto          | NFS                                                                      |
| consistency_group_id | None                                                                     |
| project_id           | 907004508ef4447397ce6741a8f037c1                                         |
| metadata             | {}                                                                       |
+----------------------+--------------------------------------------------------------------------+</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Manage and unmanage share snapshot</title>
        <para>To <literal>manage</literal> a share snapshot means that an administrator, rather than a
share driver, manages the storage lifecycle. This approach is appropriate
when an administrator manages share snapshots outside of the Shared File
Systems service and wants to register it with the service.</para>
        <para>To <literal>unmanage</literal> a share snapshot means to unregister a specified share
snapshot from the Shared File Systems service. Administrators can revert an
unmanaged share snapshot to managed status if needed.</para>
        <sect3>
          <title>Unmanage a share snapshot</title>
          <para>The <literal>unmanage</literal> operation is not supported for shares that were
created on top of share servers and created with share networks.
The Share service should have the option
<literal>driver_handles_share_servers = False</literal> set in the <literal>manila.conf</literal> file.</para>
          <para>To unmanage managed share snapshot, run the :command:
<literal>manila snapshot-unmanage &lt;share_snapshot&gt;</literal> command. Then try to print the
information about the share snapshot. The returned result should indicate that
Shared File Systems service won't find the share snapshot:</para>
          <screen language="console">$ manila snapshot-unmanage my_test_share_snapshot
$ manila snapshot-show my_test_share_snapshot
ERROR: No sharesnapshot with a name or ID of 'my_test_share_snapshot'
exists.</screen>
        </sect3>
        <sect3>
          <title>Manage a share snapshot</title>
          <para>To register the non-managed share snapshot in the File System service, run the
<command>manila snapshot-manage</command> command:</para>
          <screen language="console">manila snapshot-manage [--name &lt;name&gt;] [--description &lt;description&gt;]
              [--driver_options [&lt;key=value&gt; [&lt;key=value&gt; ...]]]
              &lt;share&gt; &lt;provider_location&gt;</screen>
          <para>The positional arguments are:</para>
          <itemizedlist>
            <listitem>
              <para>share. Name or ID of the share.</para>
            </listitem>
            <listitem>
              <para>provider_location. Provider location of the share snapshot on the backend.</para>
            </listitem>
          </itemizedlist>
          <para>The <literal>driver_options</literal> is an optional set of one or more key and value pairs
that describe driver options.</para>
          <para>To manage share snapshot, run:</para>
          <screen language="console">$ manila snapshot-manage \
    9ba52cc6-c97e-4b40-8653-4bcbaaf9628d \
    4d1e2863-33dd-4243-bf39-f7354752097d \
    --name my_test_share_snapshot \
    --description "My test share snapshot" \
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | manage_starting                      |
| share_id          | 9ba52cc6-c97e-4b40-8653-4bcbaaf9628d |
| user_id           | d9f4003655c94db5b16c591920be1f91     |
| description       | My test share snapshot               |
| created_at        | 2016-07-25T04:49:42.600980           |
| size              | None                                 |
| share_proto       | NFS                                  |
| provider_location | 4d1e2863-33dd-4243-bf39-f7354752097d |
| id                | 89c663b5-026d-45c7-a43b-56ef0ba0faab |
| project_id        | aaa33a0ca4324965a3e65ae47e864e94     |
| share_size        | 1                                    |
| name              | my_test_share_snapshot               |
+-------------------+--------------------------------------+</screen>
          <para>Check that the share snapshot is available:</para>
          <screen language="console">$ manila snapshot-show my_test_share_snapshot
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | available                            |
| share_id          | 9ba52cc6-c97e-4b40-8653-4bcbaaf9628d |
| user_id           | d9f4003655c94db5b16c591920be1f91     |
| description       | My test share snapshot               |
| created_at        | 2016-07-25T04:49:42.000000           |
| size              | 1                                    |
| share_proto       | NFS                                  |
| provider_location | 4d1e2863-33dd-4243-bf39-f7354752097d |
| id                | 89c663b5-026d-45c7-a43b-56ef0ba0faab |
| project_id        | aaa33a0ca4324965a3e65ae47e864e94     |
| share_size        | 1                                    |
| name              | my_test_share_snapshot               |
+-------------------+--------------------------------------+</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Resize share</title>
        <para>To change file share size, use the <command>manila extend</command> command and
the <command>manila shrink</command> command. For most drivers it is safe
operation. If you want to be sure that your data is safe, you can make
a share back up by creating a snapshot of it.</para>
        <para>You can extend and shrink the share with the <command>manila extend</command> and
<command>manila shrink</command> commands respectively, and specify the share
with the new size that does not exceed the quota. For details, see
<xref linkend="shared-file-systems-quotas"/>. You also cannot shrink
share size to 0 or to a greater value than the current share size.</para>
        <para>While extending, the share has an <literal>extending</literal> status. This means that
the increase share size request was issued successfully.</para>
        <para>To extend the share and check the result, run:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila extend docs_resize 2
$ manila show docs_resize
+----------------------+--------------------------------------------------------------------------+
| Property             | Value                                                                    |
+----------------------+--------------------------------------------------------------------------+
| status               | available                                                                |
| share_type_name      | my_type                                                                  |
| description          | None                                                                     |
| availability_zone    | nova                                                                     |
| share_network_id     | None                                                                     |
| export_locations     |                                                                          |
|                      | path = 1.0.0.4:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = False                                                    |
|                      | id = 3ffb76f4-92b9-4639-83fd-025bc3e302ff                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
|                      | path = 2.0.0.3:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = True                                                     |
|                      | id = 1f0e263f-370d-47d3-95f6-1be64088b9da                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
| share_server_id      | None                                                                     |
| host                 | manila@paris#shares                                                      |
| access_rules_status  | active                                                                   |
| snapshot_id          | None                                                                     |
| is_public            | False                                                                    |
| task_state           | None                                                                     |
| snapshot_support     | True                                                                     |
| id                   | b07dbebe-a328-403c-b402-c8871c89e3d1                                     |
| size                 | 2                                                                        |
| name                 | docs_resize                                                              |
| share_type           | 14ee8575-aac2-44af-8392-d9c9d344f392                                     |
| has_replicas         | False                                                                    |
| replication_type     | None                                                                     |
| created_at           | 2016-03-25T15:33:18.000000                                               |
| share_proto          | NFS                                                                      |
| consistency_group_id | None                                                                     |
| project_id           | 907004508ef4447397ce6741a8f037c1                                         |
| metadata             | {}                                                                       |
+----------------------+--------------------------------------------------------------------------+</screen>
        <para>While shrinking, the share has a <literal>shrinking</literal> status. This means that the
decrease share size request was issued successfully. To shrink the share and
check the result, run:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila shrink docs_resize 1
$ manila show docs_resize
+----------------------+--------------------------------------------------------------------------+
| Property             | Value                                                                    |
+----------------------+--------------------------------------------------------------------------+
| status               | available                                                                |
| share_type_name      | my_type                                                                  |
| description          | None                                                                     |
| availability_zone    | nova                                                                     |
| share_network_id     | None                                                                     |
| export_locations     |                                                                          |
|                      | path = 1.0.0.4:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = False                                                    |
|                      | id = 3ffb76f4-92b9-4639-83fd-025bc3e302ff                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
|                      | path = 2.0.0.3:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = True                                                     |
|                      | id = 1f0e263f-370d-47d3-95f6-1be64088b9da                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
| share_server_id      | None                                                                     |
| host                 | manila@paris#shares                                                      |
| access_rules_status  | active                                                                   |
| snapshot_id          | None                                                                     |
| is_public            | False                                                                    |
| task_state           | None                                                                     |
| snapshot_support     | True                                                                     |
| id                   | b07dbebe-a328-403c-b402-c8871c89e3d1                                     |
| size                 | 1                                                                        |
| name                 | docs_resize                                                              |
| share_type           | 14ee8575-aac2-44af-8392-d9c9d344f392                                     |
| has_replicas         | False                                                                    |
| replication_type     | None                                                                     |
| created_at           | 2016-03-25T15:33:18.000000                                               |
| share_proto          | NFS                                                                      |
| consistency_group_id | None                                                                     |
| project_id           | 907004508ef4447397ce6741a8f037c1                                         |
| metadata             | {}                                                                       |
+----------------------+--------------------------------------------------------------------------+</screen>
      </sect2>
      <sect2 xml:id="shared-file-systems-quotas">
        <title>Quotas and limits</title>
        <sect3>
          <title>Limits</title>
          <para>Limits are the resource limitations that are allowed for each project.
An administrator can configure limits in the <literal>manila.conf</literal> file.</para>
          <para>Users can query their rate and absolute limits.</para>
          <para>To see the absolute limits, run:</para>
          <screen language="console">$ manila absolute-limits
+----------------------------+-------+
| Name                       | Value |
+----------------------------+-------+
| maxTotalShareGigabytes     | 1000  |
| maxTotalShareNetworks      | 10    |
| maxTotalShareSnapshots     | 50    |
| maxTotalShares             | 50    |
| maxTotalSnapshotGigabytes  | 1000  |
| totalShareGigabytesUsed    | 1     |
| totalShareNetworksUsed     | 2     |
| totalShareSnapshotsUsed    | 1     |
| totalSharesUsed            | 1     |
| totalSnapshotGigabytesUsed | 1     |
+----------------------------+-------+</screen>
          <para>Rate limits control the frequency at which users can issue specific API
requests. Administrators use rate limiting to configure limits on the type and
number of API calls that can be made in a specific time interval. For example,
a rate limit can control the number of <literal>GET</literal> requests processed
during a one-minute period.</para>
          <para>To set the API rate limits, modify the
<literal>etc/manila/api-paste.ini</literal> file, which is a part of the WSGI pipeline and
defines the actual limits. You need to restart <literal>manila-api</literal> service after
you edit the <literal>etc/manila/api-paste.ini</literal> file.</para>
          <screen language="ini"><?dbsuse-fo font-size="8pt"?>[filter:ratelimit]
paste.filter_factory = manila.api.v1.limits:RateLimitingMiddleware.factory
limits = (POST, "*/shares", ^/shares, 120, MINUTE);(PUT, "*/shares", .*, 120, MINUTE);(DELETE, "*", .*, 120, MINUTE)</screen>
          <para>Also, add the <literal>ratelimit</literal> to <literal>noauth</literal>, <literal>keystone</literal>, <literal>keystone_nolimit</literal>
parameters in the <literal>[composite:openstack_share_api]</literal> and
<literal>[composite:openstack_share_api_v2]</literal> groups.</para>
          <screen language="ini"><?dbsuse-fo font-size="8pt"?>[composite:openstack_share_api]
use = call:manila.api.middleware.auth:pipeline_factory
noauth = cors faultwrap ssl ratelimit sizelimit noauth api
keystone = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext api
keystone_nolimit = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext api

[composite:openstack_share_api_v2]
use = call:manila.api.middleware.auth:pipeline_factory
noauth = cors faultwrap ssl ratelimit sizelimit noauth apiv2
keystone = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext apiv2
keystone_nolimit = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext apiv2</screen>
          <para>To see the rate limits, run:</para>
          <screen language="console">$ manila rate-limits
+--------+------------+-------+--------+--------+----------------------+
| Verb   | URI        | Value | Remain | Unit   | Next_Available       |
+--------+------------+-------+--------+--------+----------------------+
| DELETE | "*"        | 120   | 120    | MINUTE | 2015-10-20T15:17:20Z |
| POST   | "*/shares" | 120   | 120    | MINUTE | 2015-10-20T15:17:20Z |
| PUT    | "*/shares" | 120   | 120    | MINUTE | 2015-10-20T15:17:20Z |
+--------+------------+-------+--------+--------+----------------------+</screen>
        </sect3>
        <sect3>
          <title>Quotas</title>
          <para>Quota sets provide quota management support.</para>
          <para>To list the quotas for a project or user, use the <command>manila quota-show</command>
command. If you specify the optional <literal>--user</literal> parameter, you get the
quotas for this user in the specified project. If you omit this parameter,
you get the quotas for the specified project.</para>
          <note>
            <para>The Shared File Systems service does not perform mapping of usernames and
project names to IDs. Provide only ID values to get correct setup
of quotas. Setting it by names you set quota for nonexistent project/user.
In case quota is not set explicitly by project/user ID,
The Shared File Systems service just applies default quotas.</para>
          </note>
          <screen language="console">$ manila quota-show --tenant %project_id% --user %user_id%
+--------------------+-------+
| Property           | Value |
+--------------------+-------+
| gigabytes          | 1000  |
| snapshot_gigabytes | 1000  |
| snapshots          | 50    |
| shares             | 50    |
| share_networks     | 10    |
+--------------------+-------+</screen>
          <para>There are default quotas for a project that are set from the
<literal>manila.conf</literal> file. To list the default quotas for a project, use
the <command>manila quota-defaults</command> command:</para>
          <screen language="console">$ manila quota-defaults --tenant %project_id%
+--------------------+-------+
| Property           | Value |
+--------------------+-------+
| gigabytes          | 1000  |
| snapshot_gigabytes | 1000  |
| snapshots          | 50    |
| shares             | 50    |
| share_networks     | 10    |
+--------------------+-------+</screen>
          <para>The administrator can update the quotas for a specific project, or for a
specific user by providing both the <literal>--tenant</literal> and <literal>--user</literal> optional
arguments. It is possible to update the <literal>shares</literal>, <literal>snapshots</literal>,
<literal>gigabytes</literal>, <literal>snapshot-gigabytes</literal>, and <literal>share-networks</literal> quotas.</para>
          <screen language="console">$ manila quota-update %project_id% --user %user_id% --shares 49 --snapshots 49</screen>
          <para>As administrator, you can also permit or deny the force-update of a quota that
is already used, or if the requested value exceeds the configured quota limit.
To force-update a quota, use <literal>force</literal> optional key.</para>
          <screen language="console">$ manila quota-update %project_id% --shares 51 --snapshots 51 --force</screen>
          <para>To revert quotas to default for a project or for a user, delete quotas:</para>
          <screen language="console">$ manila quota-delete --tenant %project_id% --user %user_id%</screen>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Migrate shares</title>
      <para>As an administrator, you can migrate a share with its data from one
location to another in a manner that is transparent to users and
workloads. You can use <literal>manila</literal> client commands to complete a share
migration.</para>
      <para>Possible use cases for data migration include:</para>
      <itemizedlist>
        <listitem>
          <para>Bring down a physical storage device for maintenance without
disrupting workloads.</para>
        </listitem>
        <listitem>
          <para>Modify the properties of a share.</para>
        </listitem>
        <listitem>
          <para>Free up space in a thinly-provisioned back end.</para>
        </listitem>
      </itemizedlist>
      <para>Migrate a share with the <command>manila migrate</command> command, as shown in the
following example:</para>
      <screen language="console">$ manila migrate shareID destinationHost --force-host-copy True|False</screen>
      <para>In this example, <literal>--force-host-copy True</literal> forces the generic
host-based migration mechanism and bypasses any driver optimizations.
<literal>destinationHost</literal> is in this format <literal>host#pool</literal> which includes
destination host and pool.</para>
      <note>
        <para>If the user is not an administrator, the migration fails.</para>
      </note>
    </sect1>
    <sect1 xml:id="shared-file-systems-share-types">
      <title>Share types</title>
      <para>A share type enables you to filter or choose back ends before you create a
share and to set data for the share driver. A share type behaves in the same
way as a Block Storage volume type behaves.</para>
      <para>In the Shared File Systems configuration file <literal>manila.conf</literal>, the
administrator can set the share type used by default for the share creation
and then create a default share type.</para>
      <para>To create a share type, use <command>manila type-create</command> command as:</para>
      <screen language="console">manila type-create [--snapshot_support &lt;snapshot_support&gt;]
                   [--is_public &lt;is_public&gt;]
                   &lt;name&gt; &lt;spec_driver_handles_share_servers&gt;</screen>
      <para>where the <literal>name</literal> is the share type name, <literal>--is_public</literal> defines the level of
the visibility for the share type, <literal>snapshot_support</literal> and
<literal>spec_driver_handles_share_servers</literal> are the extra specifications used to
filter back ends. Administrators can create share types with these extra
specifications for the back ends filtering:</para>
      <itemizedlist>
        <listitem>
          <para><literal>driver_handles_share_servers</literal>. Required. Defines the driver mode for share
server lifecycle management. Valid values are <literal>true</literal>/<literal>1</literal> and
<literal>false</literal>/<literal>0</literal>.
Set to True when the share driver can manage, or handle, the share server
lifecycle.
Set to False when an administrator, rather than a share driver, manages
the bare metal storage with some net interface instead of the presence
of the share servers.</para>
        </listitem>
        <listitem>
          <para><literal>snapshot_support</literal>. Filters back ends by whether they do or do not support
share snapshots. Default is <literal>True</literal>.
Set to True to find back ends that support share snapshots.
Set to False to find back ends that do not support share snapshots.</para>
        </listitem>
      </itemizedlist>
      <note>
        <para>The extra specifications set in the share types are operated in the
<xref linkend="shared-file-systems-scheduling"/>.</para>
      </note>
      <para>Administrators can also set additional extra specifications for a share type
for the following purposes:</para>
      <itemizedlist>
        <listitem>
          <para><emphasis>Filter back ends</emphasis>. Unqualified extra specifications written in
this format: <literal>extra_spec=value</literal>. For example, <emphasis role="bold">netapp_raid_type=raid4</emphasis>.</para>
        </listitem>
        <listitem>
          <para><emphasis>Set data for the driver</emphasis>. Qualified extra specifications always written
with the prefix with a colon, except for the special <literal>capabilities</literal>
prefix, in this format: <literal>vendor:extra_spec=value</literal>. For example,
<emphasis role="bold">netapp:thin_provisioned=true</emphasis>.</para>
        </listitem>
      </itemizedlist>
      <para>The scheduler uses the special capabilities prefix for filtering. The scheduler
can only create a share on a back end that reports capabilities matching the
un-scoped extra-spec keys for the share type. For details, see <link xlink:href="http://docs.openstack.org/developer/manila/devref/capabilities_and_extra_specs.html">Capabilities
and Extra-Specs</link>.</para>
      <para>Each driver implementation determines which extra specification keys it uses.
For details, see the documentation for the driver.</para>
      <para>An administrator can use the <literal>policy.json</literal> file to grant permissions for
share type creation with extra specifications to other roles.</para>
      <para>You set a share type to private or public and
<xref linkend="share-type-access"/> to the private share types. By
default a share type is created as publicly accessible. Set
<literal>--is_public</literal> to <literal>False</literal> to make the share type private.</para>
      <sect2>
        <title>Share type operations</title>
        <para>To create a new share type you need to specify the name of the new share
type. You also require an extra spec <literal>driver_handles_share_servers</literal>.
The new share type can also be public.</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila type-create netapp1 False --is_public True

$ manila type-list
+-----+--------+-----------+-----------+-----------------------------------+-----------------------+
| ID  | Name   | Visibility| is_default| required_extra_specs              | optional_extra_specs  |
+-----+--------+-----------+-----------+-----------------------------------+-----------------------+
| c0..| netapp1| public    | -         | driver_handles_share_servers:False| snapshot_support:True |
+-----+--------+-----------+-----------+-----------------------------------+-----------------------+</screen>
        <para>You can set or unset extra specifications for a share type
using <emphasis role="bold">manila type-key &lt;share_type&gt; set &lt;key=value&gt;</emphasis> command. Since it is up
to each driver what extra specification keys it uses, see the documentation
for the specified driver.</para>
        <screen language="console">$ manila type-key netapp1 set thin_provisioned=True</screen>
        <para>It is also possible to view a list of current share types and extra
specifications:</para>
        <screen language="console">$ manila extra-specs-list
+-------------+---------+-------------------------------------+
| ID          | Name    | all_extra_specs                     |
+-------------+---------+-------------------------------------+
| c0086582-...| netapp1 | snapshot_support : True             |
|             |         | thin_provisioned : True             |
|             |         | driver_handles_share_servers : True |
+-------------+---------+-------------------------------------+</screen>
        <para>Use <command>manila type-key &lt;share_type&gt; unset &lt;key&gt;</command> to unset an extra
specification.</para>
        <para>The public or private share type can be deleted with the
<command>manila type-delete &lt;share_type&gt;</command> command.</para>
      </sect2>
      <sect2 xml:id="share-type-access">
        <title>Share type access</title>
        <para>You can manage access to a private share type for different projects.
Administrators can provide access, remove access, and retrieve
information about access for a specified private share.</para>
        <para>Create a private type:</para>
        <screen language="console">$ manila type-create my_type1 True --is_public False
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| required_extra_specs | driver_handles_share_servers : True  |
| Name                 | my_type1                             |
| Visibility           | private                              |
| is_default           | -                                    |
| ID                   | 06793be5-9a79-4516-89fe-61188cad4d6c |
| optional_extra_specs | snapshot_support : True              |
+----------------------+--------------------------------------+</screen>
        <note>
          <para>If you run <command>manila type-list</command> only public share types appear.
To see private share types, run <command>manila type-list</command> with
<literal>--all</literal> optional argument.</para>
        </note>
        <para>Grant access to created private type for a demo and alt_demo projects
by providing their IDs:</para>
        <screen language="console">$ manila type-access-add my_type1 d8f9af6915404114ae4f30668a4f5ba7
$ manila type-access-add my_type1 e4970f57f1824faab2701db61ee7efdf</screen>
        <para>To view information about access for a private share, type <literal>my_type1</literal>:</para>
        <screen language="console">$ manila type-access-list my_type1
+----------------------------------+
| Project_ID                       |
+----------------------------------+
| d8f9af6915404114ae4f30668a4f5ba7 |
| e4970f57f1824faab2701db61ee7efdf |
+----------------------------------+</screen>
        <para>After granting access to the share, the target project
can see the share type in the list, and create private
shares.</para>
        <para>To deny access for a specified project, use
<command>manila type-access-remove &lt;share_type&gt; &lt;project_id&gt;</command> command.</para>
      </sect2>
    </sect1>
    <sect1 xml:id="shared-file-systems-snapshots">
      <title>Share snapshots</title>
      <para>The Shared File Systems service provides a snapshot mechanism to help users
restore data by running the <command>manila snapshot-create</command> command.</para>
      <para>To export a snapshot, create a share from it, then mount the new share
to an instance. Copy files from the attached share into the archive.</para>
      <para>To import a snapshot, create a new share with appropriate size, attach it to
instance, and then copy a file from the archive to the attached file
system.</para>
      <note>
        <para>You cannot delete a share while it has saved dependent snapshots.</para>
      </note>
      <para>Create a snapshot from the share:</para>
      <screen language="console">$ manila snapshot-create Share1 --name Snapshot1 --description "Snapshot of Share1"
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | creating                             |
| share_id    | aca648eb-8c03-4394-a5cc-755066b7eb66 |
| name        | Snapshot1                            |
| created_at  | 2015-09-25T05:27:38.862040           |
| share_proto | NFS                                  |
| id          | 962e8126-35c3-47bb-8c00-f0ee37f42ddd |
| size        | 1                                    |
| share_size  | 1                                    |
| description | Snapshot of Share1                   |
+-------------+--------------------------------------+</screen>
      <para>Update snapshot name or description if needed:</para>
      <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila snapshot-rename Snapshot1 Snapshot_1 --description "Snapshot of Share1. Updated."</screen>
      <para>Check that status of a snapshot is <literal>available</literal>:</para>
      <screen language="console">$ manila snapshot-show Snapshot1
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | available                            |
| share_id    | aca648eb-8c03-4394-a5cc-755066b7eb66 |
| name        | Snapshot1                            |
| created_at  | 2015-09-25T05:27:38.000000           |
| share_proto | NFS                                  |
| id          | 962e8126-35c3-47bb-8c00-f0ee37f42ddd |
| size        | 1                                    |
| share_size  | 1                                    |
| description | Snapshot of Share1                   |
+-------------+--------------------------------------+</screen>
      <para>To restore your data from a snapshot, use <command>manila create</command> with
key <literal>--snapshot-id</literal>. This creates a new share from an
existing snapshot. Create a share from a snapshot and check whether
it is available:</para>
      <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila create nfs 1 --name Share2 --metadata source=snapshot --description "Share from a snapshot." --snapshot-id 962e8126-35c3-47bb-8c00-f0ee37f42ddd
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | None                                 |
| share_type_name             | default                              |
| description                 | Share from a snapshot.               |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| export_locations            | []                                   |
| share_server_id             | None                                 |
| host                        | None                                 |
| snapshot_id                 | 962e8126-35c3-47bb-8c00-f0ee37f42ddd |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | b6b0617c-ea51-4450-848e-e7cff69238c7 |
| size                        | 1                                    |
| name                        | Share2                               |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86 |
| created_at                  | 2015-09-25T06:25:50.240417           |
| export_location             | None                                 |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 20787a7ba11946adad976463b57d8a2f     |
| metadata                    | {u'source': u'snapshot'}             |
+-----------------------------+--------------------------------------+

$ manila show Share2
+-----------------------------+-------------------------------------------+
| Property                    | Value                                     |
+-----------------------------+-------------------------------------------+
| status                      | available                                 |
| share_type_name             | default                                   |
| description                 | Share from a snapshot.                    |
| availability_zone           | nova                                      |
| share_network_id            | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a      |
| export_locations            | 10.254.0.3:/shares/share-1dc2a471-3d47-...|
| share_server_id             | 41b7829d-7f6b-4c96-aea5-d106c2959961      |
| host                        | manila@generic1#GENERIC1                  |
| snapshot_id                 | 962e8126-35c3-47bb-8c00-f0ee37f42ddd      |
| is_public                   | False                                     |
| task_state                  | None                                      |
| snapshot_support            | True                                      |
| id                          | b6b0617c-ea51-4450-848e-e7cff69238c7      |
| size                        | 1                                         |
| name                        | Share2                                    |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86      |
| created_at                  | 2015-09-25T06:25:50.000000                |
| share_proto                 | NFS                                       |
| consistency_group_id        | None                                      |
| source_cgsnapshot_member_id | None                                      |
| project_id                  | 20787a7ba11946adad976463b57d8a2f          |
| metadata                    | {u'source': u'snapshot'}                  |
+-----------------------------+-------------------------------------------+</screen>
      <para>You can soft-delete a snapshot using <command>manila snapshot-delete
&lt;snapshot_name_or_ID&gt;</command>. If a snapshot is in busy state, and during
the delete an <literal>error_deleting</literal> status appeared, administrator can
force-delete it or explicitly reset the state.</para>
      <para>Use <command>snapshot-reset-state [--state &lt;state&gt;] &lt;snapshot&gt;</command> to update
the state of a snapshot explicitly. A valid value of a status are
<literal>available</literal>, <literal>error</literal>, <literal>creating</literal>, <literal>deleting</literal>, <literal>error_deleting</literal>.
If no state is provided, the <literal>available</literal> state will be used.</para>
      <para>Use <command>manila snapshot-force-delete &lt;snapshot&gt;</command> to force-delete
a specified share snapshot in any state.</para>
    </sect1>
    <sect1 xml:id="shared-file-systems-security-services">
      <title>Security services</title>
      <para>A security service stores client configuration information used for
authentication and authorization (AuthN/AuthZ). For example, a share server
will be the client for an existing service such as LDAP, Kerberos, or
Microsoft Active Directory.</para>
      <para>You can associate a share with one to three security service types:</para>
      <itemizedlist>
        <listitem>
          <para><literal>ldap</literal>: LDAP.</para>
        </listitem>
        <listitem>
          <para><literal>kerberos</literal>: Kerberos.</para>
        </listitem>
        <listitem>
          <para><literal>active_directory</literal>: Microsoft Active Directory.</para>
        </listitem>
      </itemizedlist>
      <para>You can configure a security service with these options:</para>
      <itemizedlist>
        <listitem>
          <para>A DNS IP address.</para>
        </listitem>
        <listitem>
          <para>An IP address or host name.</para>
        </listitem>
        <listitem>
          <para>A domain.</para>
        </listitem>
        <listitem>
          <para>A user or group name.</para>
        </listitem>
        <listitem>
          <para>The password for the user, if you specify a user name.</para>
        </listitem>
      </itemizedlist>
      <para>You can add the security service to the
<xref linkend="shared-file-systems-share-networks"/>.</para>
      <para>To create a security service, specify the security service type, a
description of a security service, DNS IP address used inside project's
network, security service IP address or host name, domain, security
service user or group used by project, and a password for the user. The
share name is optional.</para>
      <para>Create a <literal>ldap</literal> security service:</para>
      <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila security-service-create ldap --dns-ip 8.8.8.8 --server 10.254.0.3 --name my_ldap_security_service
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | new                                  |
| domain      | None                                 |
| password    | None                                 |
| name        | my_ldap_security_service             |
| dns_ip      | 8.8.8.8                              |
| created_at  | 2015-09-25T10:19:06.019527           |
| updated_at  | None                                 |
| server      | 10.254.0.3                           |
| user        | None                                 |
| project_id  | 20787a7ba11946adad976463b57d8a2f     |
| type        | ldap                                 |
| id          | 413479b2-0d20-4c58-a9d3-b129fa592d8e |
| description | None                                 |
+-------------+--------------------------------------+</screen>
      <para>To create <literal>kerberos</literal> security service, run:</para>
      <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila security-service-create kerberos --server 10.254.0.3 --user demo --password secret --name my_kerberos_security_service --description "Kerberos security service"
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | new                                  |
| domain      | None                                 |
| password    | secret                               |
| name        | my_kerberos_security_service         |
| dns_ip      | None                                 |
| created_at  | 2015-09-25T10:26:03.211849           |
| updated_at  | None                                 |
| server      | 10.254.0.3                           |
| user        | demo                                 |
| project_id  | 20787a7ba11946adad976463b57d8a2f     |
| type        | kerberos                             |
| id          | 7f46a447-2534-453d-924d-bd7c8e63bbec |
| description | Kerberos security service            |
+-------------+--------------------------------------+</screen>
      <para>To see the list of created security service use
<command>manila security-service-list</command>:</para>
      <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila security-service-list
+--------------------------------------+------------------------------+--------+----------+
| id                                   | name                         | status | type     |
+--------------------------------------+------------------------------+--------+----------+
| 413479b2-0d20-4c58-a9d3-b129fa592d8e | my_ldap_security_service     | new    | ldap     |
| 7f46a447-2534-453d-924d-bd7c8e63bbec | my_kerberos_security_service | new    | kerberos |
+--------------------------------------+------------------------------+--------+----------+</screen>
      <para>You can add a security service to the existing
<xref linkend="shared-file-systems-share-networks"/>, which is not
yet used (a <literal>share network</literal> not associated with a share).</para>
      <para>Add a security service to the share network with
<literal>share-network-security-service-add</literal> specifying share network and
security service. The command returns information about the
security service. You can see view new attributes and <literal>share_networks</literal>
using the associated share network ID.</para>
      <screen language="console">$ manila share-network-security-service-add share_net2 my_ldap_security_service

$ manila security-service-show my_ldap_security_service
+----------------+-------------------------------------------+
| Property       | Value                                     |
+----------------+-------------------------------------------+
| status         | new                                       |
| domain         | None                                      |
| password       | None                                      |
| name           | my_ldap_security_service                  |
| dns_ip         | 8.8.8.8                                   |
| created_at     | 2015-09-25T10:19:06.000000                |
| updated_at     | None                                      |
| server         | 10.254.0.3                                |
| share_networks | [u'6d36c41f-d310-4aff-a0c2-ffd870e91cab'] |
| user           | None                                      |
| project_id     | 20787a7ba11946adad976463b57d8a2f          |
| type           | ldap                                      |
| id             | 413479b2-0d20-4c58-a9d3-b129fa592d8e      |
| description    | None                                      |
+----------------+-------------------------------------------+</screen>
      <para>It is possible to see the list of security services associated
with a given share network. List security services for <literal>share_net2</literal>
share network with:</para>
      <screen language="console">$ manila share-network-security-service-list share_net2
+--------------------------------------+--------------------------+--------+------+
| id                                   | name                     | status | type |
+--------------------------------------+--------------------------+--------+------+
| 413479b2-0d20-4c58-a9d3-b129fa592d8e | my_ldap_security_service | new    | ldap |
+--------------------------------------+--------------------------+--------+------+</screen>
      <para>You also can dissociate a security service from the share network
and confirm that the security service now has an empty list of
share networks:</para>
      <screen language="console">$ manila share-network-security-service-remove share_net2 my_ldap_security_service

$ manila security-service-show my_ldap_security_service
+----------------+--------------------------------------+
| Property       | Value                                |
+----------------+--------------------------------------+
| status         | new                                  |
| domain         | None                                 |
| password       | None                                 |
| name           | my_ldap_security_service             |
| dns_ip         | 8.8.8.8                              |
| created_at     | 2015-09-25T10:19:06.000000           |
| updated_at     | None                                 |
| server         | 10.254.0.3                           |
| share_networks | []                                   |
| user           | None                                 |
| project_id     | 20787a7ba11946adad976463b57d8a2f     |
| type           | ldap                                 |
| id             | 413479b2-0d20-4c58-a9d3-b129fa592d8e |
| description    | None                                 |
+----------------+--------------------------------------+</screen>
      <para>The Shared File Systems service allows you to update a security service field
using <command>manila security-service-update</command> command with optional
arguments such as <literal>--dns-ip</literal>, <literal>--server</literal>, <literal>--domain</literal>,
<literal>--user</literal>, <literal>--password</literal>, <literal>--name</literal>, or
<literal>--description</literal>.</para>
      <para>To remove a security service not associated with any share networks
run:</para>
      <screen language="console">$ manila security-service-delete my_ldap_security_service</screen>
    </sect1>
    <sect1 xml:id="shared-file-systems-cgroups">
      <title>Consistency groups</title>
      <para>Consistency groups enable you to create snapshots from multiple file system
shares at the same point in time. For example, a database might place its
tables, logs, and configurations on separate shares. Store logs, tables,
and configurations at the same point in time to effectively restore a
database.</para>
      <para>The Shared File System service allows you to create a snapshot of the
consistency group and restore all shares that were associated with a
consistency group.</para>
      <important>
        <para>The <emphasis role="bold">consistency groups and snapshots</emphasis> are an <emphasis role="bold">experimental</emphasis>
Shared File Systems API in the Liberty release.
Contributors can change or remove the experimental part of the
Shared File Systems API in further releases without maintaining
backward compatibility. Experimental APIs have an
<literal>X-OpenStack-Manila-API-Experimental: true</literal> header in
their HTTP requests.</para>
      </important>
      <sect2>
        <title>Consistency groups</title>
        <note>
          <para>Before using consistency groups, make sure the Shared File System driver
that you are running has consistency group support. You can check it in the
<literal>manila-scheduler</literal> service reports. The <literal>consistency_group_support</literal> can
have the following values:</para>
          <itemizedlist>
            <listitem>
              <para><literal>pool</literal> or <literal>host</literal>. Consistency groups are supported. Specifies the
level of consistency groups support.</para>
            </listitem>
            <listitem>
              <para><literal>false</literal>. Consistency groups are not supported.</para>
            </listitem>
          </itemizedlist>
        </note>
        <para>The <command>manila cg-create</command> command creates a new consistency group.
With this command, you can specify a share network, and one or more share
types. In the example a consistency group <literal>cgroup1</literal> was created by
specifying two comma-separated share types:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila cg-create --name cgroup1 --description "My first CG." --share-types my_type1,default --share-network my_share_net
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | creating                             |
| description          | My first CG.                         |
| source_cgsnapshot_id | None                                 |
| created_at           | 2015-09-29T15:01:12.102472           |
| share_network_id     | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a |
| share_server_id      | None                                 |
| host                 | None                                 |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| share_types          | a4218aa5-f16a-42b3-945d-113496d40558 |
|                      | c0086582-30a6-4060-b096-a42ec9d66b86 |
| id                   | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| name                 | cgroup1                              |
+----------------------+--------------------------------------+</screen>
        <para>Check that consistency group status is <literal>available</literal>:</para>
        <screen language="console">$ manila cg-show cgroup1
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | available                            |
| description          | My first CG.                         |
| source_cgsnapshot_id | None                                 |
| created_at           | 2015-09-29T15:05:40.000000           |
| share_network_id     | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a |
| share_server_id      | None                                 |
| host                 | manila@generic1#GENERIC1             |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| share_types          | c0086582-30a6-4060-b096-a42ec9d66b86 |
|                      | a4218aa5-f16a-42b3-945d-113496d40558 |
| id                   | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| name                 | cgroup1                              |
+----------------------+--------------------------------------+</screen>
        <para>To add a share to the consistency group, create a share by adding the
<literal>--consistency-group</literal> option where you specify the ID of the consistency
group in <literal>available</literal> status:</para>
        <screen language="console">$ manila create nfs 1 --name "Share2" --description "My second share" \
--share-type default --share-network my_share_net --consistency-group cgroup1
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | None                                 |
| share_type_name             | default                              |
| description                 | My second share                      |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| export_locations            | []                                   |
| share_server_id             | None                                 |
| host                        | None                                 |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | 7bcd888b-681b-4836-ac9c-c3add4e62537 |
| size                        | 1                                    |
| name                        | Share2                               |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86 |
| created_at                  | 2015-09-29T15:09:24.156387           |
| export_location             | None                                 |
| share_proto                 | NFS                                  |
| consistency_group_id        | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 20787a7ba11946adad976463b57d8a2f     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</screen>
        <para>Administrators can rename the consistency group, or change its
description using the <command>manila cg-update</command> command. Delete the group
with the <command>manila cg-delete</command> command.</para>
        <para>As an administrator, you can also reset the state of a consistency group and
force delete a specified consistency group in any state. Use the
<literal>policy.json</literal> file to grant permissions for these actions to other roles.</para>
        <para>Use <command>manila cg-reset-state [--state &lt;state&gt;] &lt;consistency_group&gt;</command>
to update the state of a consistency group explicitly. A valid value of a
status are <literal>available</literal>, <literal>error</literal>, <literal>creating</literal>, <literal>deleting</literal>,
<literal>error_deleting</literal>. If no state is provided, <literal>available</literal> will be used.</para>
        <screen language="console">$ manila cg-reset-state cgroup1 --state error</screen>
        <para>Use <command>manila cg-delete &lt;consistency_group&gt; [&lt;consistency_group&gt; ...]</command>
to soft-delete one or more consistency groups.</para>
        <note>
          <para>A consistency group can be deleted only if it has no dependent
<xref linkend="shared-file-systems-cgsnapshots"/>.</para>
        </note>
        <screen language="console">$ manila cg-delete cgroup1</screen>
        <para>Use <command>manila cg-delete --force &lt;consistency_group&gt;
[&lt;consistency_group&gt; ...]</command>
to force-delete a specified consistency group in any state.</para>
        <screen language="console">$ manila cg-delete --force cgroup1</screen>
      </sect2>
      <sect2 xml:id="shared-file-systems-cgsnapshots">
        <title>Consistency group snapshots</title>
        <para>To create a snapshot, specify the ID or name of the consistency group.
After creating a consistency group snapshot, it is possible to generate
a new consistency group.</para>
        <para>Create a snapshot of consistency group <literal>cgroup1</literal>:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila cg-snapshot-create cgroup1 --name CG_snapshot1 --description "A snapshot of the first CG."
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | creating                             |
| name                 | CG_snapshot1                         |
| created_at           | 2015-09-29T15:26:16.839704           |
| consistency_group_id | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| id                   | 876ad24c-1efd-4607-a2b1-6a2c90034fa5 |
| description          | A snapshot of the first CG.          |
+----------------------+--------------------------------------+</screen>
        <para>Check the status of created consistency group snapshot:</para>
        <screen language="console">$ manila cg-snapshot-show CG_snapshot1
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | available                            |
| name                 | CG_snapshot1                         |
| created_at           | 2015-09-29T15:26:22.000000           |
| consistency_group_id | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| id                   | 876ad24c-1efd-4607-a2b1-6a2c90034fa5 |
| description          | A snapshot of the first CG.          |
+----------------------+--------------------------------------+</screen>
        <para>Administrators can rename a consistency group snapshot, change its
description using the <command>cg-snapshot-update</command> command, or delete
it with the <command>cg-snapshot-delete</command> command.</para>
        <para>A consistency group snapshot can have <literal>members</literal>. To add a member,
include the <literal>--consistency-group</literal> optional parameter in the
create share command. This ID must match the ID of the consistency group from
which the consistency group snapshot was created. Then, while restoring data,
and operating with consistency group snapshots, you can quickly
find which shares belong to a specified consistency group.</para>
        <para>You created the share <literal>Share2</literal> in <literal>cgroup1</literal> consistency group. Since
you made a snapshot of it, you can see that the only member of the consistency
group snapshot is <literal>Share2</literal> share:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila cg-snapshot-members CG_snapshot1
+--------------+------+----------------------------+----------------+--------------+--------------+
| Id           | Size | Created_at                 | Share_protocol | Share_id     | Share_type_id|
+--------------+------+----------------------------+----------------+--------------+--------------+
| 5c62af2b-... | 1    | 2015-09-29T15:26:22.000000 | NFS            | 7bcd888b-... | c0086582-... |
+--------------+------+----------------------------+----------------+--------------+--------------+</screen>
        <para>After you create a consistency group snapshot, you can create a consistency
group from the new snapshot:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila cg-create --source-cgsnapshot-id 876ad24c-1efd-4607-a2b1-6a2c90034fa5 --name cgroup2 --description "A consistency group from a CG snapshot."
+----------------------+-----------------------------------------+
| Property             | Value                                   |
+----------------------+-----------------------------------------+
| status               | creating                                |
| description          | A consistency group from a CG snapshot. |
| source_cgsnapshot_id | 876ad24c-1efd-4607-a2b1-6a2c90034fa5    |
| created_at           | 2015-09-29T15:47:47.937991              |
| share_network_id     | None                                    |
| share_server_id      | None                                    |
| host                 | manila@generic1#GENERIC1                |
| project_id           | 20787a7ba11946adad976463b57d8a2f        |
| share_types          | c0086582-30a6-4060-b096-a42ec9d66b86    |
|                      | a4218aa5-f16a-42b3-945d-113496d40558    |
| id                   | ffee08d9-c86c-45e5-861e-175c731daca2    |
| name                 | cgroup2                                 |
+----------------------+-----------------------------------------+</screen>
        <para>Check the consistency group list. Two groups now appear:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila cg-list
+-------------------+---------+-----------------------------------------+-----------+
| id                | name    | description                             | status    |
+-------------------+---------+-----------------------------------------+-----------+
| 6fdd91bc-7a48-... | cgroup1 | My first CG.                            | available |
| ffee08d9-c86c-... | cgroup2 | A consistency group from a CG snapshot. | available |
+-------------------+---------+-----------------------------------------+-----------+</screen>
        <para>Check a list of the shares. New share with
<literal>ba52454e-2ea3-47fa-a683-3176a01295e6</literal> ID appeared after the
consistency group <literal>cgroup2</literal> was built from a snapshot with a member.</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila list
+------+-------+-----+------------+----------+----------+-----------+--------------------------+
| ID   | Name  | Size| Share Proto| Status   | Is Public| Share Type| Host                     |
+------+-------+-----+------------+----------+----------+-----------+--------------------------+
| 7bc..| Share2| 1   | NFS        | available| False    | c008658...| manila@generic1#GENERIC1 |
| ba5..| None  | 1   | NFS        | available| False    | c008658...| manila@generic1#GENERIC1 |
+------+-------+-----+------------+----------+----------+-----------+--------------------------+</screen>
        <para>Print detailed information about new share:</para>
        <note>
          <para>Pay attention on the <literal>source_cgsnapshot_member_id</literal> and
<literal>consistency_group_id</literal> fields in a new share. It has
<literal>source_cgsnapshot_member_id</literal> that is equal to the ID of the consistency
group snapshot and <literal>consistency_group_id</literal> that is equal to the ID of
<literal>cgroup2</literal> created from a snapshot.</para>
        </note>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila show ba52454e-2ea3-47fa-a683-3176a01295e6
+-----------------------------+---------------------------------------------------------------+
| Property                    | Value                                                         |
+-----------------------------+---------------------------------------------------------------+
| status                      | available                                                     |
| share_type_name             | default                                                       |
| description                 | None                                                          |
| availability_zone           | None                                                          |
| share_network_id            | None                                                          |
| export_locations            | 10.254.0.5:/shares/share-5acadf4d-f81a-4515-b5ce-3ab641ab4d1e |
| share_server_id             | None                                                          |
| host                        | manila@generic1#GENERIC1                                      |
| snapshot_id                 | None                                                          |
| is_public                   | False                                                         |
| task_state                  | None                                                          |
| snapshot_support            | True                                                          |
| id                          | ba52454e-2ea3-47fa-a683-3176a01295e6                          |
| size                        | 1                                                             |
| name                        | None                                                          |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86                          |
| created_at                  | 2015-09-29T15:47:48.000000                                    |
| share_proto                 | NFS                                                           |
| consistency_group_id        | ffee08d9-c86c-45e5-861e-175c731daca2                          |
| source_cgsnapshot_member_id | 5c62af2b-0870-4d00-b3fa-174831eb15ca                          |
| project_id                  | 20787a7ba11946adad976463b57d8a2f                              |
| metadata                    | {}                                                            |
+-----------------------------+---------------------------------------------------------------+</screen>
        <para>As an administrator, you can also reset the state of a consistency group
snapshot with the <command>cg-snapshot-reset-state</command> command, and force delete a specified
consistency group snapshot in any state using the <command>cg-snapshot-delete</command> command
with the <literal>--force</literal> key. Use the <literal>policy.json</literal> file to grant permissions for
these actions to other roles.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Share replication</title>
      <para>Replication of data has a number of use cases in the cloud. One use case is
High Availability of the data in a shared file system, used for example, to
support a production database. Another use case is ensuring Data Protection;
i.e being prepared for a disaster by having a replication location that will be
ready to back up your primary data source.</para>
      <para>The Shared File System service supports user facing APIs that allow users to
create shares that support replication, add and remove share replicas and
manage their snapshots and access rules. Three replication types are currently
supported and they vary in the semantics associated with the primary share and
the secondary copies.</para>
      <important>
        <para><emphasis role="bold">Share replication</emphasis> is an <emphasis role="bold">experimental</emphasis> Shared File Systems API in
the Mitaka release. Contributors can change or remove the experimental
part of the Shared File Systems API in further releases without maintaining
backward compatibility. Experimental APIs have an
<literal>X-OpenStack-Manila-API-Experimental: true</literal> header in their HTTP requests.</para>
      </important>
      <sect2>
        <title>Replication types supported</title>
        <para>Before using share replication, make sure the Shared File System driver that
you are running supports this feature. You can check it in the
<literal>manila-scheduler</literal> service reports. The <literal>replication_type</literal> capability
reported can have one of the following values:</para>
        <variablelist>
          <varlistentry>
            <term>writable</term>
            <listitem>
              <para>The driver supports creating <literal>writable</literal> share replicas. All share replicas
can be accorded read/write access and would be synchronously mirrored.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>readable</term>
            <listitem>
              <para>The driver supports creating <literal>read-only</literal> share replicas. All secondary
share replicas can be accorded read access. Only the primary (or <literal>active</literal>
share replica) can be written into.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>dr</term>
            <listitem>
              <para>The driver supports creating <literal>dr</literal> (abbreviated from Disaster Recovery)
share replicas. A secondary share replica is inaccessible until after a
<literal>promotion</literal>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>None</term>
            <listitem>
              <para>The driver does not support Share Replication.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <note>
          <para>The term <literal>active</literal> share replica refers to the <literal>primary</literal> share. In
<literal>writable</literal> style of replication, all share replicas are <literal>active</literal>, and
there could be no distinction of a <literal>primary</literal> share. In <literal>readable</literal> and
<literal>dr</literal> styles of replication, a <literal>secondary</literal> share replica may be referred
to as <literal>passive</literal>, <literal>non-active</literal> or simply, <literal>replica</literal>.</para>
        </note>
      </sect2>
      <sect2>
        <title>Configuration</title>
        <para>Two new configuration options have been introduced to support Share
Replication.</para>
        <variablelist>
          <varlistentry>
            <term>replica_state_update_interval</term>
            <listitem>
              <para>Specify this option in the <literal>DEFAULT</literal> section of your <literal>manila.conf</literal>.
The Shared File Systems service requests periodic update of the
<literal>replica_state</literal> of all <literal>non-active</literal> share replicas. The update occurs with
respect to an interval corresponding to this option. If it is not specified,
it defaults to 300 seconds.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>replication_domain</term>
            <listitem>
              <para>Specify this option in the backend stanza when using a multi-backend style
configuration. The value can be any ASCII string. Two backends that can
replicate between each other would have the same <literal>replication_domain</literal>.
This comes from the premise that the Shared File Systems service expects
Share Replication to be performed between symmetric backends. This option
is <emphasis>required</emphasis> for using the Share Replication feature.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Health of a share replica</title>
        <para>Apart from the <literal>status</literal> attribute, share replicas have the
<literal>replica_state</literal> attribute to denote the state of data replication on the
storage backend. The <literal>primary</literal> share replica will have it's <literal>replica_state</literal>
attribute set to <literal>active</literal>. The <literal>secondary</literal> share replicas may have one of
the following as their <literal>replica_state</literal>:</para>
        <variablelist>
          <varlistentry>
            <term>in_sync</term>
            <listitem>
              <para>The share replica is up to date with the <literal>active</literal> share replica (possibly
within a backend-specific <literal>recovery point objective</literal>).</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>out_of_sync</term>
            <listitem>
              <para>The share replica is out of date (all new share replicas start out in
this <literal>replica_state</literal>).</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>error</term>
            <listitem>
              <para>When the scheduler fails to schedule this share replica or some potentially
irrecoverable error occurred with regard to updating data for this replica.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Promotion or failover</title>
        <para>For <literal>readable</literal> and <literal>dr</literal> types of replication, we refer to the task
of switching a <literal>non-active</literal> share replica with the <literal>active</literal> replica as
<literal>promotion</literal>. For the <literal>writable</literal> style of replication, promotion does
not make sense since all share replicas are <literal>active</literal> (or writable) at all
times.</para>
        <para>The <literal>status</literal> attribute of the non-active replica being promoted will be
set to <literal>replication_change</literal> during its promotion. This has been classified as
a <literal>busy</literal> state and thus API interactions with the share are restricted
while one of its share replicas is in this state.</para>
      </sect2>
      <sect2>
        <title>Share replication workflows</title>
        <para>The following examples have been implemented with the ZFSonLinux driver that
is a reference implementation in the Shared File Systems service. It operates
in <literal>driver_handles_share_servers=False</literal> mode and supports the <literal>readable</literal>
type of replication. In the example, we assume a configuration of two
Availability Zones (configuration option: <literal>storage_availability_zone</literal>),
called <literal>availability_zone_1</literal> and <literal>availability_zone_2</literal>.</para>
        <para>Multiple availability zones are not necessary to use the replication feature.
However, the use of an availability zone as a <literal>failure domain</literal> is encouraged.</para>
        <para>Pay attention to the network configuration for the ZFS driver. Here, we assume
a configuration of <literal>zfs_service_ip</literal> and <literal>zfs_share_export_ip</literal> from two
separate networks. The service network is reachable from the host where the
<literal>manila-share</literal> service is running. The share export IP is from a network that
allows user access.</para>
        <para>See <link xlink:href="http://docs.openstack.org/newton/config-reference/shared-file-systems/drivers/zfs-on-linux-driver.html">Configuring the ZFSonLinux driver</link>
for information on how to set up the ZFSonLinux driver.</para>
        <sect3>
          <title>Creating a share that supports replication</title>
          <para>Create a new share type and specify the <literal>replication_type</literal> as an extra-spec
within the share-type being used.</para>
          <para>Use the <command>manila type-create</command> command to create a new share type.
Specify the name and the value for the extra-spec
<literal>driver_handles_share_servers</literal>.</para>
          <screen language="console">$ manila type-create readable_type_replication False
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| required_extra_specs | driver_handles_share_servers : False |
| Name                 | readable_type_replication            |
| Visibility           | public                               |
| is_default           | -                                    |
| ID                   | 3b3ee3f7-6e43-4aa1-859d-0b0511c43074 |
| optional_extra_specs | snapshot_support : True              |
+----------------------+--------------------------------------+</screen>
          <para>Use the <command>manila type-key</command> command to set an extra-spec to the
share type.</para>
          <screen language="console">$ manila type-key readable_type_replication set replication_type=readable</screen>
          <note>
            <para>This command has no output. To verify the extra-spec, use the
<command>manila extra-specs-list</command> command and specify the share type's name
or ID as a parameter.</para>
          </note>
          <para>Create a share with the share type</para>
          <para>Use the <command>manila create</command> command to create a share. Specify the share
protocol, size and the availability zone.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila create NFS 1 --share_type readable_type_replication --name my_share --description "This share will have replicas" --az availability_zone_1
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | creating                             |
| share_type_name             | readable_type_replication            |
| description                 | This share will have replicas        |
| availability_zone           | availability_zone_1                  |
| share_network_id            | None                                 |
| share_server_id             | None                                 |
| host                        |                                      |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| size                        | 1                                    |
| name                        | my_share                             |
| share_type                  | 3b3ee3f7-6e43-4aa1-859d-0b0511c43074 |
| has_replicas                | False                                |
| replication_type            | readable                             |
| created_at                  | 2016-03-29T20:22:18.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 48a5ca76ac69405e99dc1c13c5195186     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</screen>
          <para>Use the <command>manila show</command> command to retrieve details of the share.
Specify the share ID or name as a parameter.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila show my_share
+-----------------------------+--------------------------------------------------------------------+
| Property                    | Value                                                              |
+-----------------------------+--------------------------------------------------------------------+
| status                      | available                                                          |
| share_type_name             | readable_type_replication                                          |
| description                 | This share will have replicas                                      |
| availability_zone           | availability_zone_1                                                |
| share_network_id            | None                                                               |
| export_locations            |                                                                    |
|                             | path =                                                             |
|                             |10.32.62.26:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28|
|                             | preferred = False                                                  |
|                             | is_admin_only = False                                              |
|                             | id = e1d754b5-ec06-42d2-afff-3e98c0013faf                          |
|                             | share_instance_id = 38efc042-50c2-4825-a6d8-cba2a8277b28           |
|                             | path =                                                             |
|                             |172.21.0.23:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28|
|                             | preferred = False                                                  |
|                             | is_admin_only = True                                               |
|                             | id = 6f843ecd-a7ea-4939-86de-e1e01d9e8672                          |
|                             | share_instance_id = 38efc042-50c2-4825-a6d8-cba2a8277b28           |
| share_server_id             | None                                                               |
| host                        | openstack4@zfsonlinux_1#alpha                                      |
| access_rules_status         | active                                                             |
| snapshot_id                 | None                                                               |
| is_public                   | False                                                              |
| task_state                  | None                                                               |
| snapshot_support            | True                                                               |
| id                          | e496ed61-8f2e-436b-b299-32c3e90991cc                               |
| size                        | 1                                                                  |
| name                        | my_share                                                           |
| share_type                  | 3b3ee3f7-6e43-4aa1-859d-0b0511c43074                               |
| has_replicas                | False                                                              |
| replication_type            | readable                                                           |
| created_at                  | 2016-03-29T20:22:18.000000                                         |
| share_proto                 | NFS                                                                |
| consistency_group_id        | None                                                               |
| source_cgsnapshot_member_id | None                                                               |
| project_id                  | 48a5ca76ac69405e99dc1c13c5195186                                   |
| metadata                    | {}                                                                 |
+-----------------------------+--------------------------------------------------------------------+</screen>
          <note>
            <para>When you create a share that supports replication, an <literal>active</literal> replica is
created for you. You can verify this with the
<command>manila share-replica-list</command> command.</para>
          </note>
        </sect3>
        <sect3>
          <title>Creating and promoting share replicas</title>
          <para>Create a share replica</para>
          <para>Use the <command>manila share-replica-create</command> command to create a share
replica. Specify the share ID or name as a parameter. You may
optionally provide the <literal>availability_zone</literal> and <literal>share_network_id</literal>. In the
example below, <literal>share_network_id</literal> is not used since the ZFSonLinux driver
does not support it.</para>
          <screen language="console">$ manila share-replica-create my_share --az availability_zone_2
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | creating                             |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| availability_zone | availability_zone_2                  |
| created_at        | 2016-03-29T20:24:53.148992           |
| updated_at        | None                                 |
| share_network_id  | None                                 |
| share_server_id   | None                                 |
| host              |                                      |
| replica_state     | None                                 |
| id                | 78a5ef96-6c36-42e0-b50b-44efe7c1807e |
+-------------------+--------------------------------------+</screen>
          <para>See details of the newly created share replica</para>
          <para>Use the <command>manila share-replica-show</command> command to see details
of the newly created share replica. Specify the share replica's ID as a
parameter.</para>
          <screen language="console">$ manila share-replica-show 78a5ef96-6c36-42e0-b50b-44efe7c1807e
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | available                            |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| availability_zone | availability_zone_2                  |
| created_at        | 2016-03-29T20:24:53.000000           |
| updated_at        | 2016-03-29T20:24:58.000000           |
| share_network_id  | None                                 |
| share_server_id   | None                                 |
| host              | openstack4@zfsonlinux_2#beta         |
| replica_state     | in_sync                              |
| id                | 78a5ef96-6c36-42e0-b50b-44efe7c1807e |
+-------------------+--------------------------------------+</screen>
          <para>See all replicas of the share</para>
          <para>Use the <command>manila share-replica-list</command> command to see all the replicas
of the share. Specify the share ID or name as an optional parameter.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila share-replica-list --share-id my_share
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| ID                                   | Status    | Replica State | Share ID                             | Host                          | Availability Zone   | Updated At                 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| 38efc042-50c2-4825-a6d8-cba2a8277b28 | available | active        | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_1#alpha | availability_zone_1 | 2016-03-29T20:22:19.000000 |
| 78a5ef96-6c36-42e0-b50b-44efe7c1807e | available | in_sync       | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_2#beta  | availability_zone_2 | 2016-03-29T20:24:58.000000 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+</screen>
          <para>Promote the secondary share replica to be the new active replica</para>
          <para>Use the <command>manila share-replica-promote</command> command to promote a
non-active share replica to become the <literal>active</literal> replica. Specify the
non-active replica's ID as a parameter.</para>
          <screen language="console">$ manila share-replica-promote 78a5ef96-6c36-42e0-b50b-44efe7c1807e</screen>
          <note>
            <para>This command has no output.</para>
          </note>
          <para>The promotion may take time. During the promotion, the <literal>replica_state</literal>
attribute of the share replica being promoted will be set to
<literal>replication_change</literal>.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila share-replica-list --share-id my_share
+--------------------------------------+-----------+--------------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| ID                                   | Status    |    Replica State   | Share ID                             | Host                          | Availability Zone   | Updated At                 |
+--------------------------------------+-----------+--------------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| 38efc042-50c2-4825-a6d8-cba2a8277b28 | available |       active       | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_1#alpha | availability_zone_1 | 2016-03-29T20:32:19.000000 |
| 78a5ef96-6c36-42e0-b50b-44efe7c1807e | available | replication_change | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_2#beta  | availability_zone_2 | 2016-03-29T20:32:19.000000 |
+--------------------------------------+-----------+--------------------+--------------------------------------+-------------------------------+---------------------+----------------------------+</screen>
          <para>Once the promotion is complete, the <literal>replica_state</literal> will be set to
<literal>active</literal>.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila share-replica-list --share-id my_share
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| ID                                   | Status    | Replica State | Share ID                             | Host                          | Availability Zone   | Updated At                 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| 38efc042-50c2-4825-a6d8-cba2a8277b28 | available | in_sync       | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_1#alpha | availability_zone_1 | 2016-03-29T20:32:19.000000 |
| 78a5ef96-6c36-42e0-b50b-44efe7c1807e | available | active        | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_2#beta  | availability_zone_2 | 2016-03-29T20:32:19.000000 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+</screen>
        </sect3>
        <sect3>
          <title>Access rules</title>
          <para>Create an IP access rule for the share</para>
          <para>Use the <command>manila access-allow</command> command to add an access rule.
Specify the share ID or name, protocol and the target as parameters.</para>
          <screen language="console">$ manila access-allow my_share ip 0.0.0.0/0 --access-level rw
+--------------+--------------------------------------+
| Property     | Value                                |
+--------------+--------------------------------------+
| share_id     | e496ed61-8f2e-436b-b299-32c3e90991cc |
| access_type  | ip                                   |
| access_to    | 0.0.0.0/0                            |
| access_level | rw                                   |
| state        | new                                  |
| id           | 8b339cdc-c1e0-448f-bf6d-f068ee6e8f45 |
+--------------+--------------------------------------+</screen>
          <note>
            <para>Access rules are not meant to be different across the replicas of the share.
However, as per the type of replication, drivers may choose to modify the
access level prescribed. In the above example, even though read/write access
was requested for the share, the driver will provide read-only access to
the non-active replica to the same target, because of the semantics of
the replication type: <literal>readable</literal>. However, the target will have read/write
access to the (currently) non-active replica when it is promoted to
become the <literal>active</literal> replica.</para>
          </note>
          <para>The <command>manila access-deny</command> command can be used to remove a previously
applied access rule.</para>
          <para>List the export locations of the share</para>
          <para>Use the <command>manila share-export-locations-list</command> command to list the
export locations of a share.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila share-export-location-list my_share
+--------------------------------------+---------------------------------------------------------------------------+-----------+
| ID                                   | Path                                                                      | Preferred |
+--------------------------------------+---------------------------------------------------------------------------+-----------+
| 3ed3fbf5-2fa1-4dc0-8440-a0af72398cb6 | 10.32.62.21:/beta/subdir/manila_share_78a5ef96_6c36_42e0_b50b_44efe7c1807e| False     |
| 6f843ecd-a7ea-4939-86de-e1e01d9e8672 | 172.21.0.23:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28      | False     |
| e1d754b5-ec06-42d2-afff-3e98c0013faf | 10.32.62.26:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28      | False     |
| f3c5585f-c2f7-4264-91a7-a4a1e754e686 | 172.21.0.29:/beta/subdir/manila_share_78a5ef96_6c36_42e0_b50b_44efe7c1807e| False     |
+--------------------------------------+---------------------------------------------------------------------------+-----------+</screen>
          <para>Identify the export location corresponding to the share replica on the user
accessible network and you may mount it on the target node.</para>
          <note>
            <para>As an administrator, you can list the export locations for a particular
share replica by using the
<command>manila share-instance-export-location-list</command> command and
specifying the share replica's ID as a parameter.</para>
          </note>
        </sect3>
        <sect3>
          <title>Snapshots</title>
          <para>Create a snapshot of the share</para>
          <para>Use the <command>manila snapshot-create</command> command to create a snapshot
of the share. Specify the share ID or name as a parameter.</para>
          <screen language="console">$ manila snapshot-create my_share --name "my_snapshot"
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | creating                             |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| description       | None                                 |
| created_at        | 2016-03-29T21:14:03.000000           |
| share_proto       | NFS                                  |
| provider_location | None                                 |
| id                | 06cdccaf-93a0-4e57-9a39-79fb1929c649 |
| size              | 1                                    |
| share_size        | 1                                    |
| name              | my_snapshot                          |
+-------------------+--------------------------------------+</screen>
          <para>Show the details of the snapshot</para>
          <para>Use the <command>manila snapshot-show</command> to view details of a snapshot.
Specify the snapshot ID or name as a parameter.</para>
          <screen language="console">$ manila snapshot-show my_snapshot
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | available                            |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| description       | None                                 |
| created_at        | 2016-03-29T21:14:03.000000           |
| share_proto       | NFS                                  |
| provider_location | None                                 |
| id                | 06cdccaf-93a0-4e57-9a39-79fb1929c649 |
| size              | 1                                    |
| share_size        | 1                                    |
| name              | my_snapshot                          |
+-------------------+--------------------------------------+</screen>
          <note>
            <para>The <literal>status</literal> attribute of a snapshot will transition from <literal>creating</literal>
to <literal>available</literal> only when it is present on all the share replicas that have
their <literal>replica_state</literal> attribute set to <literal>active</literal> or <literal>in_sync</literal>.</para>
            <para>Likewise, the <literal>replica_state</literal> attribute of a share replica will
transition from <literal>out_of_sync</literal> to <literal>in_sync</literal> only when all <literal>available</literal>
snapshots are present on it.</para>
          </note>
        </sect3>
        <sect3>
          <title>Planned failovers</title>
          <para>As an administrator, you can use the <command>manila share-replica-resync</command>
command to attempt to sync data between <literal>active</literal> and <literal>non-active</literal> share
replicas of a share before promotion. This will ensure that share replicas have
the most up-to-date data and their relationships can be safely switched.</para>
          <screen language="console">$ manila share-replica-resync 38efc042-50c2-4825-a6d8-cba2a8277b28</screen>
          <note>
            <para>This command has no output.</para>
          </note>
        </sect3>
        <sect3>
          <title>Updating attributes</title>
          <para>If an error occurs while updating data or replication relationships (during
a <literal>promotion</literal>), the Shared File Systems service may not be able to determine
the consistency or health of a share replica. It may require administrator
intervention to make any fixes on the storage backend as necessary. In such a
situation, state correction within the Shared File Systems service is possible.</para>
          <para>As an administrator, you can:</para>
          <para>Reset the <literal>status</literal> attribute of a share replica</para>
          <para>Use the <command>manila share-replica-reset-state</command> command to reset
the <literal>status</literal> attribute. Specify the share replica's ID as a parameter
and use the <literal>--state</literal> option to specify the state intended.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila share-replica-reset-state 38efc042-50c2-4825-a6d8-cba2a8277b28 --state=available</screen>
          <note>
            <para>This command has no output.</para>
          </note>
          <para>Reset the <literal>replica_state</literal> attribute</para>
          <para>Use the <command>manila share-replica-reset-replica-state</command> command to
reset the <literal>replica_state</literal> attribute. Specify the share replica's ID
and use the <literal>--state</literal> option to specify the state intended.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila share-replica-reset-replica-state 38efc042-50c2-4825-a6d8-cba2a8277b28 --state=out_of_sync</screen>
          <note>
            <para>This command has no output.</para>
          </note>
          <para>Force delete a specified share replica in any state</para>
          <para>Use the <command>manila share-replica-delete</command> command with the
'--force' key to remove the share replica, regardless of the state it is in.</para>
          <screen language="console">$ manila share-replica-show 9513de5d-0384-4528-89fb-957dd9b57680
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | error                                |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| availability_zone | availability_zone_1                  |
| created_at        | 2016-03-30T01:32:47.000000           |
| updated_at        | 2016-03-30T01:34:25.000000           |
| share_network_id  | None                                 |
| share_server_id   | None                                 |
| host              | openstack4@zfsonlinux_1#alpha        |
| replica_state     | out_of_sync                          |
| id                | 38efc042-50c2-4825-a6d8-cba2a8277b28 |
+-------------------+--------------------------------------+

$ manila share-replica-delete --force 38efc042-50c2-4825-a6d8-cba2a8277b28</screen>
          <note>
            <para>This command has no output.</para>
          </note>
          <para>Use the <literal>policy.json</literal> file to grant permissions for these actions to other
roles.</para>
        </sect3>
        <sect3>
          <title>Deleting share replicas</title>
          <para>Use the <command>manila share-replica-delete</command> command with the share
replica's ID to delete a share replica.</para>
          <screen language="console">$ manila share-replica-delete 38efc042-50c2-4825-a6d8-cba2a8277b28</screen>
          <note>
            <para>This command has no output.</para>
          </note>
          <note>
            <para>You cannot delete the last <literal>active</literal> replica with this command. You should
use the <command>manila delete</command> command to remove the share.</para>
          </note>
        </sect3>
      </sect2>
    </sect1>
    <sect1 xml:id="shared-file-systems-multi-backend">
      <title>Multi-storage configuration</title>
      <para>The Shared File Systems service can provide access to multiple file storage
back ends. In general, the workflow with multiple back ends looks similar
to the Block Storage service one, see <xref linkend="multi-backend"/>.</para>
      <para>Using <literal>manila.conf</literal>, you can spawn multiple share services. To do it, you
should set the <literal>enabled_share_backends</literal> flag in the <literal>manila.conf</literal> file. This
flag defines the comma-separated names of the configuration stanzas for the
different back ends. One name is associated to one configuration group for a
back end.</para>
      <para>The following example runs three configured share services:</para>
      <screen language="ini">[DEFAULT]
enabled_share_backends=backendEMC2,backendGeneric1,backendNetApp

[backendGeneric1]
share_driver=manila.share.drivers.generic.GenericShareDriver
share_backend_name=one_name_for_two_backends
service_instance_user=ubuntu_user
service_instance_password=ubuntu_user_password
service_image_name=ubuntu_image_name
path_to_private_key=/home/foouser/.ssh/id_rsa
path_to_public_key=/home/foouser/.ssh/id_rsa.pub

[backendEMC2]
share_driver=manila.share.drivers.emc.driver.EMCShareDriver
share_backend_name=backendEMC2
emc_share_backend=vnx
emc_nas_server=1.1.1.1
emc_nas_password=password
emc_nas_login=user
emc_nas_server_container=server_3
emc_nas_pool_name="Pool 2"

[backendNetApp]
share_driver = manila.share.drivers.netapp.common.NetAppDriver
driver_handles_share_servers = True
share_backend_name=backendNetApp
netapp_login=user
netapp_password=password
netapp_server_hostname=1.1.1.1
netapp_root_volume_aggregate=aggr01</screen>
      <para>To spawn separate groups of share services, you can use separate configuration
files. If it is necessary to control each back end in a separate way, you
should provide a single configuration file per each back end.</para>
      <sect2 xml:id="shared-file-systems-scheduling">
        <title>Scheduling</title>
        <para>The Shared File Systems service uses a scheduler to provide unified
access for a variety of different types of shared file systems. The
scheduler collects information from the active shared services, and
makes decisions such as what shared services will be used to create
a new share. To manage this process, the Shared File Systems service
provides Share types API.</para>
        <para>A share type is a list from key-value pairs called extra-specs. The
scheduler uses required and un-scoped extra-specs to look up
the shared service most suitable for a new share with the specified share type.
For more information about extra-specs and their type, see <link xlink:href="http://docs.openstack.org/developer/manila/devref/capabilities_and_extra_specs.html">Capabilities
and Extra-Specs</link> section in developer documentation.</para>
        <para>The general scheduler workflow:</para>
        <procedure>
          <step>
            <para>Share services report information about their existing pool number, their
capacities, and their capabilities.</para>
          </step>
          <step>
            <para>When a request on share creation arrives, the scheduler picks a service
and pool that best serves the request, using share type
filters and back end capabilities. If back end capabilities pass through,
all filters request the selected back end where the target pool resides.</para>
          </step>
          <step>
            <para>The share driver receives a reply on the request status, and lets the
target pool serve the request as the scheduler instructs. The scoped
and un-scoped share types are available for the driver implementation
to use as needed.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Manage shares services</title>
        <para>The Shared File Systems service provides API that allows to manage running
share services (<link xlink:href="http://developer.openstack.org/api-ref/shared-file-systems/">Share services API</link>).
Using the <command>manila service-list</command> command, it is possible to get a list
of all kinds of running services. To select only share services, you can pick
items that have field <literal>binary</literal> equal to <literal>manila-share</literal>. Also, you can
enable or disable share services using raw API requests. Disabling means that
share services are excluded from the scheduler cycle and new shares will not
be placed on the disabled back end. However, shares from this service stay
available.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Networking</title>
      <para>Unlike the OpenStack Block Storage service, the Shared File Systems service
must connect to the Networking service. The share service requires the
option to self-manage share servers. For client authentication and
authorization, you can configure the Shared File Systems service to
work with different network authentication services, like LDAP, Kerberos
protocols, or Microsoft Active Directory.</para>
      <sect2 xml:id="shared-file-systems-share-networks">
        <title>Share networks</title>
        <para>Share network is an entity that encapsulates interaction with the OpenStack
Networking service. If the share driver that you selected runs in a mode
requiring Networking service interaction, specify the share network when
creating a new share network.</para>
        <sect3>
          <title>How to create share network</title>
          <para>To list networks in a project, run:</para>
          <screen language="console">$ openstack network list
+--------------+---------+--------------------+
| ID           | Name    | Subnets            |
+--------------+---------+--------------------+
| bee7411d-... | public  | 884a6564-0f11-...  |
|              |         | e6da81fa-5d5f-...  |
| 5ed5a854-... | private | 74dcfb5a-b4d7-...  |
|              |         | cc297be2-5213-...  |
+--------------+---------+--------------------+</screen>
          <para>A share network stores network information that share servers can use where
shares are hosted. You can associate a share with a single share network.
When you create or update a share, you can optionally specify the ID of a share
network through which instances can access the share.</para>
          <para>When you create a share network, you can specify only one type of network:</para>
          <itemizedlist>
            <listitem>
              <para>OpenStack Networking (neutron). Specify a network ID and subnet ID.
In this case <literal>manila.network.nova_network_plugin.NeutronNetworkPlugin</literal>
will be used.</para>
            </listitem>
            <listitem>
              <para>Legacy networking (nova-network). Specify a network ID.
In this case <literal>manila.network.nova_network_plugin.NoveNetworkPlugin</literal>
will be used.</para>
            </listitem>
          </itemizedlist>
          <para>For more information about supported plug-ins for share networks, see
<xref linkend="shared-file-systems-network-plugins"/>.</para>
          <para>A share network has these attributes:</para>
          <itemizedlist>
            <listitem>
              <para>The IP block in Classless Inter-Domain Routing (CIDR) notation from which to
allocate the network.</para>
            </listitem>
            <listitem>
              <para>The IP version of the network.</para>
            </listitem>
            <listitem>
              <para>The network type, which is <literal>vlan</literal>, <literal>vxlan</literal>, <literal>gre</literal>, or <literal>flat</literal>.</para>
            </listitem>
          </itemizedlist>
          <para>If the network uses segmentation, a segmentation identifier. For example, VLAN,
VXLAN, and GRE networks use segmentation.</para>
          <para>To create a share network with private network and subnetwork, run:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ manila share-network-create --neutron-net-id 5ed5a854-21dc-4ed3-870a-117b7064eb21 \
--neutron-subnet-id 74dcfb5a-b4d7-4855-86f5-a669729428dc --name my_share_net --description "My first share network"
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| name              | my_share_net                         |
| segmentation_id   | None                                 |
| created_at        | 2015-09-24T12:06:32.602174           |
| neutron_subnet_id | 74dcfb5a-b4d7-4855-86f5-a669729428dc |
| updated_at        | None                                 |
| network_type      | None                                 |
| neutron_net_id    | 5ed5a854-21dc-4ed3-870a-117b7064eb21 |
| ip_version        | None                                 |
| nova_net_id       | None                                 |
| cidr              | None                                 |
| project_id        | 20787a7ba11946adad976463b57d8a2f     |
| id                | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a |
| description       | My first share network               |
+-------------------+--------------------------------------+</screen>
          <para>The <literal>segmentation_id</literal>, <literal>cidr</literal>, <literal>ip_version</literal>, and <literal>network_type</literal>
share network attributes are automatically set to the values determined by the
network provider.</para>
          <para>To check the network list, run:</para>
          <screen language="console">$ manila share-network-list
+--------------------------------------+--------------+
| id                                   | name         |
+--------------------------------------+--------------+
| 5c3cbabb-f4da-465f-bc7f-fadbe047b85a | my_share_net |
+--------------------------------------+--------------+</screen>
          <para>If you configured the generic driver with <literal>driver_handles_share_servers =
True</literal> (with the share servers) and already had previous operations in the Shared
File Systems service, you can see <literal>manila_service_network</literal> in the neutron
list of networks. This network was created by the generic driver for internal
use.</para>
          <screen language="console">$ openstack network list
+--------------+------------------------+--------------------+
| ID           | Name                   | Subnets            |
+--------------+------------------------+--------------------+
| 3b5a629a-e...| manila_service_network | 4f366100-50...     |
| bee7411d-... | public                 | 884a6564-0f11-...  |
|              |                        | e6da81fa-5d5f-...  |
| 5ed5a854-... | private                | 74dcfb5a-b4d7-...  |
|              |                        | cc297be2-5213-...  |
+--------------+------------------------+--------------------+</screen>
          <para>You also can see detailed information about the share network including
<literal>network_type</literal>, and <literal>segmentation_id</literal> fields:</para>
          <screen language="console">$ openstack network show manila_service_network
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | UP                                   |
| availability_zone_hints   |                                      |
| availability_zones        | nova                                 |
| created_at                | 2016-12-13T09:31:30Z                 |
| description               |                                      |
| id                        | 3b5a629a-e7a1-46a3-afb2-ab666fb884bc |
| ipv4_address_scope        | None                                 |
| ipv6_address_scope        | None                                 |
| mtu                       | 1450                                 |
| name                      | manila_service_network               |
| port_security_enabled     | True                                 |
| project_id                | f6ac448a469b45e888050cf837b6e628     |
| provider:network_type     | vxlan                                |
| provider:physical_network | None                                 |
| provider:segmentation_id  | 73                                   |
| revision_number           | 7                                    |
| router:external           | Internal                             |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   | 682e3329-60b0-440f-8749-83ef53dd8544 |
| tags                      | []                                   |
| updated_at                | 2016-12-13T09:31:36Z                 |
+---------------------------+--------------------------------------+</screen>
          <para>You also can add and remove the security services from the share network.
For more detail, see <xref linkend="shared-file-systems-security-services"/>.</para>
        </sect3>
      </sect2>
      <sect2 xml:id="shared-file-systems-network-plugins">
        <title>Network plug-ins</title>
        <para>The Shared File Systems service architecture defines an abstraction layer for
network resource provisioning and allowing administrators to choose from a
different options for how network resources are assigned to their projects’
networked storage. There are a set of network plug-ins that provide a variety
of integration approaches with the network services that are available with
OpenStack.</para>
        <para>The Shared File Systems service may need a network resource provisioning if
share service with specified driver works in mode, when a share driver manages
lifecycle of share servers on its own. This behavior is defined by a flag
<literal>driver_handles_share_servers</literal> in share service configuration.  When
<literal>driver_handles_share_servers</literal> is set to <literal>True</literal>, a share driver will be
called to create share servers for shares using information provided within a
share network. This information will be provided to one of the enabled network
plug-ins that will handle reservation, creation and deletion of network
resources including IP addresses and network interfaces.</para>
        <sect3>
          <title>What network plug-ins are available?</title>
          <para>There are three different network plug-ins and five python classes in the
Shared File Systems service:</para>
          <procedure>
            <step>
              <para>Network plug-in for using the OpenStack Networking service. It allows to use
any network segmentation that the Networking service supports. It is up to
each share driver to support at least one network segmentation type.</para>
              <substeps>
                <step>
                  <para><literal>manila.network.neutron.neutron_network_plugin.NeutronNetworkPlugin</literal>.
This is a default network plug-in. It requires the <literal>neutron_net_id</literal> and
the <literal>neutron_subnet_id</literal> to be provided when defining the share network
that will be used for the creation of share servers. The user may define
any number of share networks corresponding to the various physical
network segments in a project environment.</para>
                </step>
                <step>
                  <para><literal>manila.network.neutron.neutron_network_plugin.
NeutronSingleNetworkPlugin</literal>. This is a simplification of the previous
case. It accepts values for <literal>neutron_net_id</literal> and <literal>neutron_subnet_id</literal>
from the <literal>manila.conf</literal> configuration file and uses one network for all
shares.</para>
                </step>
              </substeps>
              <para>When only a single network is needed, the NeutronSingleNetworkPlugin (1.b)
is a simple solution. Otherwise NeutronNetworkPlugin (1.a) should be chosen.</para>
            </step>
            <step>
              <para>Network plug-in for working with OpenStack Networking from the Compute
service. It supports either flat networks or VLAN-segmented networks.</para>
              <substeps>
                <step>
                  <para><literal>manila.network.nova_network_plugin.NovaNetworkPlugin</literal>. This plug-in
serves the networking needs when <literal>Nova networking</literal> is configured in
the cloud instead of Neutron. It requires a single parameter,
<literal>nova_net_id</literal>.</para>
                </step>
                <step>
                  <para><literal>manila.network.nova_network_plugin.NovaSingleNetworkPlugin</literal>. This
plug-in works the same way as
<literal>manila.network.nova_network_plugin.NovaNetworkPlugin</literal>, except it takes
<literal>nova_net_id</literal> from the Shared File Systems service configuration
file and creates the share servers using only one network.</para>
                </step>
              </substeps>
              <para>When only a single network is needed, the NovaSingleNetworkPlugin (2.b) is a
simple solution. Otherwise NovaNetworkPlugin (2.a) should be chosen.</para>
            </step>
            <step>
              <para>Network plug-in for specifying networks independently from OpenStack
networking services.</para>
              <substeps>
                <step>
                  <para><literal>manila.network.standalone_network_plugin.StandaloneNetworkPlugin</literal>.
This plug-in uses a pre-existing network that is available to the
manila-share host. This network may be handled either by OpenStack or be
created independently by any other means. The plug-in supports any type
of network - flat and segmented. As above, it is completely up to the
share driver to support the network type for which the network plug-in is
configured.</para>
                </step>
              </substeps>
            </step>
          </procedure>
          <note>
            <para>These network plug-ins were introduced in the OpenStack Kilo release. In
the OpenStack Juno version, only NeutronNetworkPlugin is available.</para>
          </note>
          <para>More information about network plug-ins can be found in <link xlink:href="http://docs.openstack.org/developer/manila/adminref/network_plugins.html">Manila developer documentation</link></para>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Troubleshoot Shared File Systems service</title>
      <sect2>
        <title>Failures in Share File Systems service during a share creation</title>
        <sect3>
          <title>Problem</title>
          <para>New shares can enter <literal>error</literal> state during the creation process.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <procedure>
            <step>
              <para>Make sure, that share services are running in debug mode. If the debug mode
is not set, you will not get any tips from logs how to fix your issue.</para>
            </step>
            <step>
              <para>Find what share service holds a specified share. To do that, run command
<command>manila show &lt;share_id_or_name&gt;</command> and find a share host in the
output. Host uniquely identifies what share service holds the broken share.</para>
            </step>
            <step>
              <para>Look thought logs of this share service. Usually, it can be found at
<literal>/etc/var/log/manila-share.log</literal>. This log should contain kind of
traceback with extra information to help you to find the origin of issues.</para>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2>
        <title>No valid host was found</title>
        <sect3>
          <title>Problem</title>
          <para>If a share type contains invalid extra specs, the scheduler will not be
able to locate a valid host for the shares.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To diagnose this issue, make sure that scheduler service is running in
debug mode. Try to create a new share and look for message <literal>Failed to
schedule create_share: No valid host was found.</literal> in
<literal>/etc/var/log/manila-scheduler.log</literal>.</para>
          <para>To solve this issue look carefully through the list of extra specs in
the share type, and the list of share services reported capabilities.
Make sure that extra specs are pointed in the right way.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Created share is unreachable</title>
        <sect3>
          <title>Problem</title>
          <para>By default, a new share does not have any active access rules.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>To provide access to new share, you need to create
appropriate access rule with the right value.
The value must defines access.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Service becomes unavailable after upgrade</title>
        <sect3>
          <title>Problem</title>
          <para>After upgrading the Shared File Systems service from version v1 to version
v2.x, you must update the service endpoint in the OpenStack Identity service.
Otherwise, the service may become unavailable.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <procedure>
            <step>
              <para>To get the service type related to the Shared File Systems service, run:</para>
              <screen language="console"># openstack endpoint list

# openstack endpoint show &lt;share-service-type&gt;</screen>
              <para>You will get the endpoints expected from running the Shared File Systems
service.</para>
            </step>
            <step>
              <para>Make sure that these endpoints are updated. Otherwise, delete the outdated
endpoints and create new ones.</para>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2>
        <title>Failures during management of internal resources</title>
        <sect3>
          <title>Problem</title>
          <para>The Shared File System service manages internal resources effectively.
Administrators may need to manually adjust internal resources to
handle failures.</para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>Some drivers in the Shared File Systems service can create service entities,
like servers and networks. If it is necessary, you can log in to
project <literal>service</literal> and take manual control over it.</para>
        </sect3>
      </sect2>
    </sect1>
  </chapter>
  <chapter xml:id="networking">
    <title>Networking</title>
    <info/>
    <para>Learn OpenStack Networking concepts, architecture, and basic and
advanced <literal>neutron</literal> and <literal>nova</literal> command-line interface (CLI) commands.</para>
    <sect1>
      <title>Introduction to Networking</title>
      <para>The Networking service, code-named neutron, provides an API that lets
you define network connectivity and addressing in the cloud. The
Networking service enables operators to leverage different networking
technologies to power their cloud networking. The Networking service
also provides an API to configure and manage a variety of network
services ranging from L3 forwarding and NAT to load balancing, edge
firewalls, and IPsec VPN.</para>
      <para>For a detailed description of the Networking API abstractions and their
attributes, see the <link xlink:href="http://developer.openstack.org/api-ref/networking/v2/">OpenStack Networking API v2.0
Reference</link>.</para>
      <note>
        <para>If you use the Networking service, do not run the Compute
<literal>nova-network</literal> service (like you do in traditional Compute deployments).
When you configure networking, see the Compute-related topics in this
Networking section.</para>
      </note>
      <sect2>
        <title>Networking API</title>
        <para>Networking is a virtual network service that provides a powerful API to
define the network connectivity and IP addressing that devices from
other services, such as Compute, use.</para>
        <para>The Compute API has a virtual server abstraction to describe computing
resources. Similarly, the Networking API has virtual network, subnet,
and port abstractions to describe networking resources.</para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="19.7*"/>
            <colspec colname="c2" colwidth="80.3*"/>
            <thead>
              <row>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Network</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>An isolated L2 segment, analogous to VLAN in the physical
networking world.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Subnet</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>A block of v4 or v6 IP addresses and associated
configuration state.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Port</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>A connection point for attaching a single device, such as
the NIC of a virtual server, to a virtual network. Also
describes the associated network configuration, such as
the MAC and IP addresses to be used on that port.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          <emphasis role="bold">Networking resources</emphasis>
        </para>
        <para>To configure rich network topologies, you can create and configure
networks and subnets and instruct other OpenStack services like Compute
to attach virtual devices to ports on these networks.</para>
        <para>In particular, Networking supports each project having multiple private
networks and enables projects to choose their own IP addressing scheme,
even if those IP addresses overlap with those that other projects use.</para>
        <para>The Networking service:</para>
        <itemizedlist>
          <listitem>
            <para>Enables advanced cloud networking use cases, such as building
multi-tiered web applications and enabling migration of applications
to the cloud without changing IP addresses.</para>
          </listitem>
          <listitem>
            <para>Offers flexibility for administrators to customize network
offerings.</para>
          </listitem>
          <listitem>
            <para>Enables developers to extend the Networking API. Over time, the
extended functionality becomes part of the core Networking API.</para>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>Configure SSL support for networking API</title>
        <para>OpenStack Networking supports SSL for the Networking API server. By
default, SSL is disabled but you can enable it in the <literal>neutron.conf</literal>
file.</para>
        <para>Set these options to configure SSL:</para>
        <variablelist>
          <varlistentry>
            <term>
              <literal>use_ssl = True</literal>
            </term>
            <listitem>
              <para>Enables SSL on the networking API server.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>ssl_cert_file = PATH_TO_CERTFILE</literal>
            </term>
            <listitem>
              <para>Certificate file that is used when you securely start the Networking
API server.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>ssl_key_file = PATH_TO_KEYFILE</literal>
            </term>
            <listitem>
              <para>Private key file that is used when you securely start the Networking
API server.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>ssl_ca_file = PATH_TO_CAFILE</literal>
            </term>
            <listitem>
              <para>Optional. CA certificate file that is used when you securely start
the Networking API server. This file verifies connecting clients.
Set this option when API clients must authenticate to the API server
by using SSL certificates that are signed by a trusted CA.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>tcp_keepidle = 600</literal>
            </term>
            <listitem>
              <para>The value of TCP_KEEPIDLE, in seconds, for each server socket when
starting the API server. Not supported on OS X.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>retry_until_window = 30</literal>
            </term>
            <listitem>
              <para>Number of seconds to keep retrying to listen.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>backlog = 4096</literal>
            </term>
            <listitem>
              <para>Number of backlog requests with which to configure the socket.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Load-Balancer-as-a-Service (LBaaS) overview</title>
        <para>Load-Balancer-as-a-Service (LBaaS) enables Networking to distribute
incoming requests evenly among designated instances. This distribution
ensures that the workload is shared predictably among instances and
enables more effective use of system resources. Use one of these load
balancing methods to distribute incoming requests:</para>
        <variablelist>
          <varlistentry>
            <term>Round robin</term>
            <listitem>
              <para>Rotates requests evenly between multiple instances.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Source IP</term>
            <listitem>
              <para>Requests from a unique source IP address are consistently directed
to the same instance.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>Least connections</term>
            <listitem>
              <para>Allocates requests to the instance with the least number of active
connections.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="32.9*"/>
            <colspec colname="c2" colwidth="67.1*"/>
            <thead>
              <row>
                <entry>
                  <para>Feature</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Monitors</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>LBaaS provides availability monitoring with the
<literal>ping</literal>, TCP, HTTP and HTTPS GET methods.
Monitors are implemented to determine whether
pool members are available to handle requests.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Management</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>LBaaS is managed using a variety of tool sets.
The REST API is available for programmatic
administration and scripting. Users perform
administrative management of load balancers
through either the CLI (<literal>neutron</literal>) or the
OpenStack Dashboard.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Connection limits</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>Ingress traffic can be shaped with <emphasis>connection
limits</emphasis>. This feature allows workload control,
and can also assist with mitigating DoS (Denial
of Service) attacks.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Session persistence</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>LBaaS supports session persistence by ensuring
incoming requests are routed to the same instance
within a pool of multiple instances. LBaaS
supports routing decisions based on cookies and
source IP address.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Firewall-as-a-Service (FWaaS) overview</title>
        <para>For information on Firewall-as-a-Service (FWaaS), please consult the <link xlink:href="http://docs.openstack.org/newton/networking-guide/fwaas.html">Networking Guide</link>.</para>
      </sect2>
      <sect2>
        <title>Allowed-address-pairs</title>
        <para><literal>Allowed-address-pairs</literal> enables you to specify
mac_address and ip_address(cidr) pairs that pass through a port regardless
of subnet. This enables the use of protocols such as VRRP, which floats
an IP address between two instances to enable fast data plane failover.</para>
        <note>
          <para>Currently, only the ML2, Open vSwitch, and VMware NSX plug-ins
support the allowed-address-pairs extension.</para>
        </note>
        <para>
          <emphasis role="bold">Basic allowed-address-pairs operations.</emphasis>
        </para>
        <itemizedlist>
          <listitem>
            <para>Create a port with a specified allowed address pair:</para>
            <screen language="console">$ neutron port-create net1 --allowed-address-pairs type=dict \
  list=true mac_address=MAC_ADDRESS,ip_address=IP_CIDR</screen>
          </listitem>
          <listitem>
            <para>Update a port by adding allowed address pairs:</para>
            <screen language="console">$ neutron port-update PORT_UUID --allowed-address-pairs type=dict \
list=true mac_address=MAC_ADDRESS,ip_address=IP_CIDR</screen>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>Virtual-Private-Network-as-a-Service (VPNaaS)</title>
        <para>The VPNaaS extension enables OpenStack projects to extend private networks
across the internet.</para>
        <para>VPNaas is a <xref linkend="term-service"/>. It is a parent object that associates a VPN
with a specific subnet and router. Only one VPN service object can be
created for each router and each subnet. However, each VPN service object
can have any number of IP security connections.</para>
        <para>The Internet Key Exchange (IKE) policy specifies the authentication and
encryption algorithms to use during phase one and two negotiation of a VPN
connection. The IP security policy specifies the authentication and encryption
algorithm and encapsulation mode to use for the established VPN connection.
Note that you cannot update the IKE and IPSec parameters for live tunnels.</para>
        <para>You can set parameters for site-to-site IPsec connections, including peer
CIDRs, MTU, authentication mode, peer address, DPD settings, and status.</para>
        <para>The current implementation of the VPNaaS extension provides:</para>
        <itemizedlist>
          <listitem>
            <para>Site-to-site VPN that connects two private networks.</para>
          </listitem>
          <listitem>
            <para>Multiple VPN connections per project.</para>
          </listitem>
          <listitem>
            <para>IKEv1 policy support with 3des, aes-128, aes-256, or aes-192 encryption.</para>
          </listitem>
          <listitem>
            <para>IPSec policy support with 3des, aes-128, aes-192, or aes-256 encryption,
sha1 authentication, ESP, AH, or AH-ESP transform protocol, and tunnel or
transport mode encapsulation.</para>
          </listitem>
          <listitem>
            <para>Dead Peer Detection (DPD) with hold, clear, restart, disabled, or
restart-by-peer actions.</para>
          </listitem>
        </itemizedlist>
        <para>The VPNaaS driver plugin can be configured in the neutron configuration file.
You can then enable the service.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Networking architecture</title>
      <para>Before you deploy Networking, it is useful to understand the Networking
services and how they interact with the OpenStack components.</para>
      <sect2>
        <title>Overview</title>
        <para>Networking is a standalone component in the OpenStack modular
architecture. It is positioned alongside OpenStack components such as
Compute, Image service, Identity, or Dashboard. Like those
components, a deployment of Networking often involves deploying several
services to a variety of hosts.</para>
        <para>The Networking server uses the neutron-server daemon to expose the
Networking API and enable administration of the configured Networking
plug-in. Typically, the plug-in requires access to a database for
persistent storage (also similar to other OpenStack services).</para>
        <para>If your deployment uses a controller host to run centralized Compute
components, you can deploy the Networking server to that same host.
However, Networking is entirely standalone and can be deployed to a
dedicated host. Depending on your configuration, Networking can also
include the following agents:</para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="38.4*"/>
            <colspec colname="c2" colwidth="61.6*"/>
            <thead>
              <row>
                <entry>
                  <para>Agent</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para><emphasis role="bold">plug-in agent</emphasis>
(<literal>neutron-*-agent</literal>)</para>
                </entry>
                <entry>
                  <para>Runs on each hypervisor to perform
local vSwitch configuration. The agent that
runs, depends on the plug-in that you use.
Certain plug-ins do not require an agent.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para><emphasis role="bold">dhcp agent</emphasis>
(<literal>neutron-dhcp-agent</literal>)</para>
                </entry>
                <entry>
                  <para>Provides DHCP services to project networks.
Required by certain plug-ins.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para><emphasis role="bold">l3 agent</emphasis>
(<literal>neutron-l3-agent</literal>)</para>
                </entry>
                <entry>
                  <para>Provides L3/NAT forwarding to provide
external network access for VMs on project
networks. Required by certain plug-ins.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para><emphasis role="bold">metering agent</emphasis>
(<literal>neutron-metering-agent</literal>)</para>
                </entry>
                <entry>
                  <para>Provides L3 traffic metering for project
networks.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>These agents interact with the main neutron process through RPC (for
example, RabbitMQ or Qpid) or through the standard Networking API. In
addition, Networking integrates with OpenStack components in a number of
ways:</para>
        <itemizedlist>
          <listitem>
            <para>Networking relies on the Identity service (keystone) for the
authentication and authorization of all API requests.</para>
          </listitem>
          <listitem>
            <para>Compute (nova) interacts with Networking through calls to its
standard API. As part of creating a VM, the <literal>nova-compute</literal> service
communicates with the Networking API to plug each virtual NIC on the
VM into a particular network.</para>
          </listitem>
          <listitem>
            <para>The dashboard (horizon) integrates with the Networking API, enabling
administrators and project users to create and manage network services
through a web-based GUI.</para>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>VMware NSX integration</title>
        <para>OpenStack Networking uses the NSX plug-in to integrate with an existing
VMware vCenter deployment. When installed on the network nodes, the NSX
plug-in enables a NSX controller to centrally manage configuration
settings and push them to managed network nodes. Network nodes are
considered managed when they are added as hypervisors to the NSX
controller.</para>
        <para>The diagrams below depict some VMware NSX deployment examples. The first
diagram illustrates the traffic flow between VMs on separate Compute
nodes, and the second diagram between two VMs on a single compute node.
Note the placement of the VMware NSX plug-in and the neutron-server
service on the network node. The green arrow indicates the management
relationship between the NSX controller and the network node.</para>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="vmware_nsx_ex1.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="vmware_nsx_ex1.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
        <figure>
          <title/>
          <mediaobject>
            <imageobject role="fo">
              <imagedata fileref="vmware_nsx_ex2.png" width="99%"/>
            </imageobject>
            <imageobject role="html">
              <imagedata fileref="vmware_nsx_ex2.png" width="99%"/>
            </imageobject>
          </mediaobject>
        </figure>
      </sect2>
    </sect1>
    <sect1>
      <title>Plug-in configurations</title>
      <para>For configurations options, see <link xlink:href="http://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html">Networking configuration
options</link>
in Configuration Reference. These sections explain how to configure
specific plug-ins.</para>
      <sect2>
        <title>Configure Big Switch (Floodlight REST Proxy) plug-in</title>
        <procedure>
          <step>
            <para>Edit the <literal>/etc/neutron/neutron.conf</literal> file and add this line:</para>
            <screen language="ini">core_plugin = bigswitch</screen>
          </step>
          <step>
            <para>In the <literal>/etc/neutron/neutron.conf</literal> file, set the <literal>service_plugins</literal>
option:</para>
            <screen language="ini">service_plugins = neutron.plugins.bigswitch.l3_router_plugin.L3RestProxy</screen>
          </step>
          <step>
            <para>Edit the <literal>/etc/neutron/plugins/bigswitch/restproxy.ini</literal> file for the
plug-in and specify a comma-separated list of controller_ip:port pairs:</para>
            <screen language="ini">server = CONTROLLER_IP:PORT</screen>
            <para>For database configuration, see <link xlink:href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html">Install Networking
Services</link>
in the Installation Tutorials and Guides. (The link defaults to the Ubuntu
version.)</para>
          </step>
          <step>
            <para>Restart the <literal>neutron-server</literal> to apply the settings:</para>
            <screen language="console"># service neutron-server restart</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Configure Brocade plug-in</title>
        <procedure>
          <step>
            <para>Install the Brocade-modified Python netconf client (ncclient) library,
which is available at <link xlink:href="https://github.com/brocade/ncclient">https://github.com/brocade/ncclient</link>:</para>
            <screen language="console">$ git clone https://github.com/brocade/ncclient</screen>
          </step>
          <step>
            <para>As root, run this command:</para>
            <screen language="console"># cd ncclient;python setup.py install</screen>
          </step>
          <step>
            <para>Edit the <literal>/etc/neutron/neutron.conf</literal> file and set the following
option:</para>
            <screen language="ini">core_plugin = brocade</screen>
          </step>
          <step>
            <para>Edit the <literal>/etc/neutron/plugins/brocade/brocade.ini</literal> file for the
Brocade plug-in and specify the admin user name, password, and IP
address of the Brocade switch:</para>
            <screen language="ini">[SWITCH]
username = ADMIN
password = PASSWORD
address  = SWITCH_MGMT_IP_ADDRESS
ostype   = NOS</screen>
            <para>For database configuration, see <link xlink:href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html">Install Networking
Services</link>
in any of the Installation Tutorials and Guides in the <link xlink:href="http://docs.openstack.org">OpenStack Documentation
index</link>. (The link defaults to the Ubuntu
version.)</para>
          </step>
          <step>
            <para>Restart the <literal>neutron-server</literal> service to apply the settings:</para>
            <screen language="console"># service neutron-server restart</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Configure NSX-mh plug-in</title>
        <para>The instructions in this section refer to the VMware NSX-mh platform,
formerly known as Nicira NVP.</para>
        <procedure>
          <step>
            <para>Install the NSX plug-in:</para>
            <screen language="console"># apt-get install neutron-plugin-vmware</screen>
          </step>
          <step>
            <para>Edit the <literal>/etc/neutron/neutron.conf</literal> file and set this line:</para>
            <screen language="ini">core_plugin = vmware</screen>
            <para>Example <literal>neutron.conf</literal> file for NSX-mh integration:</para>
            <screen language="ini">core_plugin = vmware
rabbit_host = 192.168.203.10
allow_overlapping_ips = True</screen>
          </step>
          <step>
            <para>To configure the NSX-mh controller cluster for OpenStack Networking,
locate the <literal>[default]</literal> section in the
<literal>/etc/neutron/plugins/vmware/nsx.ini</literal> file and add the following
entries:</para>
            <itemizedlist>
              <listitem>
                <para>To establish and configure the connection with the controller cluster
you must set some parameters, including NSX-mh API endpoints, access
credentials, and optionally specify settings for HTTP timeouts,
redirects and retries in case of connection failures:</para>
                <screen language="ini">nsx_user = ADMIN_USER_NAME
nsx_password = NSX_USER_PASSWORD
http_timeout = HTTP_REQUEST_TIMEOUT # (seconds) default 75 seconds
retries = HTTP_REQUEST_RETRIES # default 2
redirects = HTTP_REQUEST_MAX_REDIRECTS # default 2
nsx_controllers = API_ENDPOINT_LIST # comma-separated list</screen>
                <para>To ensure correct operations, the <literal>nsx_user</literal> user must have
administrator credentials on the NSX-mh platform.</para>
                <para>A controller API endpoint consists of the IP address and port for the
controller; if you omit the port, port 443 is used. If multiple API
endpoints are specified, it is up to the user to ensure that all
these endpoints belong to the same controller cluster. The OpenStack
Networking VMware NSX-mh plug-in does not perform this check, and
results might be unpredictable.</para>
                <para>When you specify multiple API endpoints, the plug-in takes care of
load balancing requests on the various API endpoints.</para>
              </listitem>
              <listitem>
                <para>The UUID of the NSX-mh transport zone that should be used by default
when a project creates a network. You can get this value from the
Transport Zones page for the NSX-mh manager:</para>
                <para>Alternatively the transport zone identifier can be retrieved by query
the NSX-mh API: <literal>/ws.v1/transport-zone</literal></para>
                <screen language="ini">default_tz_uuid = TRANSPORT_ZONE_UUID</screen>
              </listitem>
              <listitem>
                <screen language="ini">default_l3_gw_service_uuid = GATEWAY_SERVICE_UUID</screen>
                <warning>
                  <para>Ubuntu packaging currently does not update the neutron init
script to point to the NSX-mh configuration file. Instead, you
must manually update <literal>/etc/default/neutron-server</literal> to add this
line:</para>
                  <screen language="ini">NEUTRON_PLUGIN_CONFIG = /etc/neutron/plugins/vmware/nsx.ini</screen>
                </warning>
                <para>For database configuration, see <link xlink:href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html">Install Networking
Services</link>
in the Installation Tutorials and Guides.</para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>Restart <literal>neutron-server</literal> to apply settings:</para>
            <screen language="console"># service neutron-server restart</screen>
            <warning>
              <para>The neutron NSX-mh plug-in does not implement initial
re-synchronization of Neutron resources. Therefore resources that
might already exist in the database when Neutron is switched to the
NSX-mh plug-in will not be created on the NSX-mh backend upon
restart.</para>
            </warning>
          </step>
        </procedure>
        <para>Example <literal>nsx.ini</literal> file:</para>
        <screen language="ini">[DEFAULT]
default_tz_uuid = d3afb164-b263-4aaa-a3e4-48e0e09bb33c
default_l3_gw_service_uuid=5c8622cc-240a-40a1-9693-e6a5fca4e3cf
nsx_user=admin
nsx_password=changeme
nsx_controllers=10.127.0.100,10.127.0.200:8888</screen>
        <note>
          <para>To debug <literal>nsx.ini</literal> configuration issues, run this command from the
host that runs neutron-server:</para>
        </note>
        <screen language="console"># neutron-check-nsx-config PATH_TO_NSX.INI</screen>
        <para>This command tests whether <literal>neutron-server</literal> can log into all of the
NSX-mh controllers and the SQL server, and whether all UUID values
are correct.</para>
      </sect2>
      <sect2>
        <title>Configure PLUMgrid plug-in</title>
        <procedure>
          <step>
            <para>Edit the <literal>/etc/neutron/neutron.conf</literal> file and set this line:</para>
            <screen language="ini">core_plugin = plumgrid</screen>
          </step>
          <step>
            <para>Edit the [PLUMgridDirector] section in the
<literal>/etc/neutron/plugins/plumgrid/plumgrid.ini</literal> file and specify the IP
address, port, admin user name, and password of the PLUMgrid Director:</para>
            <screen language="ini">[PLUMgridDirector]
director_server = "PLUMgrid-director-ip-address"
director_server_port = "PLUMgrid-director-port"
username = "PLUMgrid-director-admin-username"
password = "PLUMgrid-director-admin-password"</screen>
            <para>For database configuration, see <link xlink:href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html">Install Networking
Services</link>
in the Installation Tutorials and Guides.</para>
          </step>
          <step>
            <para>Restart the <literal>neutron-server</literal> service to apply the settings:</para>
            <screen language="console"># service neutron-server restart</screen>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Configure neutron agents</title>
      <para>Plug-ins typically have requirements for particular software that must
be run on each node that handles data packets. This includes any node
that runs nova-compute and nodes that run dedicated OpenStack Networking
service agents such as <literal>neutron-dhcp-agent</literal>, <literal>neutron-l3-agent</literal>,
<literal>neutron-metering-agent</literal> or <literal>neutron-lbaasv2-agent</literal>.</para>
      <para>A data-forwarding node typically has a network interface with an IP
address on the management network and another interface on the data
network.</para>
      <para>This section shows you how to install and configure a subset of the
available plug-ins, which might include the installation of switching
software (for example, <literal>Open vSwitch</literal>) and as agents used to communicate
with the <literal>neutron-server</literal> process running elsewhere in the data center.</para>
      <sect2>
        <title>Configure data-forwarding nodes</title>
        <sect3>
          <title>Node set up: NSX plug-in</title>
          <para>If you use the NSX plug-in, you must also install Open vSwitch on each
data-forwarding node. However, you do not need to install an additional
agent on each node.</para>
          <warning>
            <para>It is critical that you run an Open vSwitch version that is
compatible with the current version of the NSX Controller software.
Do not use the Open vSwitch version that is installed by default on
Ubuntu. Instead, use the Open vSwitch version that is provided on
the VMware support portal for your NSX Controller version.</para>
          </warning>
          <para>
            <emphasis role="bold">To set up each node for the NSX plug-in</emphasis>
          </para>
          <procedure>
            <step>
              <para>Ensure that each data-forwarding node has an IP address on the
management network, and an IP address on the data network that is used
for tunneling data traffic. For full details on configuring your
forwarding node, see the <link xlink:href="http://pubs.vmware.com/NSX-62/index.jsp#com.vmware.nsx.admin.doc/GUID-B5C70003-8194-4EC3-AB36-54C848508818.html">NSX Administration Guide</link>.</para>
            </step>
            <step>
              <para>Use the NSX Administrator Guide to add the node as a Hypervisor
by using the NSX Manager GUI. Even if your forwarding node has no
VMs and is only used for services agents like <literal>neutron-dhcp-agent</literal>
or <literal>neutron-lbaas-agent</literal>, it should still be added to NSX as a
Hypervisor.</para>
            </step>
            <step>
              <para>After following the NSX Administrator Guide, use the page for this
Hypervisor in the NSX Manager GUI to confirm that the node is properly
connected to the NSX Controller Cluster and that the NSX Controller
Cluster can see the <literal>br-int</literal> integration bridge.</para>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2>
        <title>Configure DHCP agent</title>
        <para>The DHCP service agent is compatible with all existing plug-ins and is
required for all deployments where VMs should automatically receive IP
addresses through DHCP.</para>
        <para>
          <emphasis role="bold">To install and configure the DHCP agent</emphasis>
        </para>
        <procedure>
          <step>
            <para>You must configure the host running the neutron-dhcp-agent as a data
forwarding node according to the requirements for your plug-in.</para>
          </step>
          <step>
            <para>Install the DHCP agent:</para>
            <screen language="console"># apt-get install neutron-dhcp-agent</screen>
          </step>
          <step>
            <para>Update any options in the <literal>/etc/neutron/dhcp_agent.ini</literal> file
that depend on the plug-in in use. See the sub-sections.</para>
            <important>
              <para>If you reboot a node that runs the DHCP agent, you must run the
<command>neutron-ovs-cleanup</command> command before the <literal>neutron-dhcp-agent</literal>
service starts.</para>
              <para>On Red Hat, SUSE, and Ubuntu based systems, the
<literal>neutron-ovs-cleanup</literal> service runs the <command>neutron-ovs-cleanup</command>
command automatically. However, on Debian-based systems, you
must manually run this command or write your own system script
that runs on boot before the <literal>neutron-dhcp-agent</literal> service starts.</para>
            </important>
          </step>
        </procedure>
        <para>Networking dhcp-agent can use
<link xlink:href="http://www.thekelleys.org.uk/dnsmasq/doc.html">dnsmasq</link> driver which
supports stateful and stateless DHCPv6 for subnets created with
<literal>--ipv6_address_mode</literal> set to <literal>dhcpv6-stateful</literal> or
<literal>dhcpv6-stateless</literal>.</para>
        <para>For example:</para>
        <screen language="console">$ openstack subnet create --ip-version 6 --ipv6-ra-mode dhcpv6-stateful \
  --ipv6-address-mode dhcpv6-stateful --network NETWORK --subnet-range \
  CIDR SUBNET_NAME</screen>
        <screen language="console">$ openstack subnet create --ip-version 6 --ipv6-ra-mode dhcpv6-stateless \
  --ipv6-address-mode dhcpv6-stateless --network NETWORK --subnet-range \
  CIDR SUBNET_NAME</screen>
        <para>If no dnsmasq process for subnet's network is launched, Networking will
launch a new one on subnet's dhcp port in <literal>qdhcp-XXX</literal> namespace. If
previous dnsmasq process is already launched, restart dnsmasq with a new
configuration.</para>
        <para>Networking will update dnsmasq process and restart it when subnet gets
updated.</para>
        <note>
          <para>For dhcp-agent to operate in IPv6 mode use at least dnsmasq v2.63.</para>
        </note>
        <para>After a certain, configured timeframe, networks uncouple from DHCP
agents when the agents are no longer in use. You can configure the DHCP
agent to automatically detach from a network when the agent is out of
service, or no longer needed.</para>
        <para>This feature applies to all plug-ins that support DHCP scaling. For more
information, see the <link xlink:href="http://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#dhcp-agent">DHCP agent configuration
options</link>
listed in the OpenStack Configuration Reference.</para>
        <sect3>
          <title>DHCP agent setup: OVS plug-in</title>
          <para>These DHCP agent options are required in the
<literal>/etc/neutron/dhcp_agent.ini</literal> file for the OVS plug-in:</para>
          <screen language="bash">[DEFAULT]
enable_isolated_metadata = True
interface_driver = openvswitch</screen>
        </sect3>
        <sect3>
          <title>DHCP agent setup: NSX plug-in</title>
          <para>These DHCP agent options are required in the
<literal>/etc/neutron/dhcp_agent.ini</literal> file for the NSX plug-in:</para>
          <screen language="bash">[DEFAULT]
enable_metadata_network = True
enable_isolated_metadata = True
interface_driver = openvswitch</screen>
        </sect3>
        <sect3>
          <title>DHCP agent setup: Linux-bridge plug-in</title>
          <para>These DHCP agent options are required in the
<literal>/etc/neutron/dhcp_agent.ini</literal> file for the Linux-bridge plug-in:</para>
          <screen language="bash">[DEFAULT]
enabled_isolated_metadata = True
interface_driver = linuxbridge</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Configure L3 agent</title>
        <para>The OpenStack Networking service has a widely used API extension to
allow administrators and projects to create routers to interconnect L2
networks, and floating IPs to make ports on private networks publicly
accessible.</para>
        <para>Many plug-ins rely on the L3 service agent to implement the L3
functionality. However, the following plug-ins already have built-in L3
capabilities:</para>
        <itemizedlist>
          <listitem>
            <para>Big Switch/Floodlight plug-in, which supports both the open source
<link xlink:href="http://www.projectfloodlight.org/floodlight/">Floodlight</link>
controller and the proprietary Big Switch controller.</para>
            <note>
              <para>Only the proprietary BigSwitch controller implements L3
functionality. When using Floodlight as your OpenFlow controller,
L3 functionality is not available.</para>
            </note>
          </listitem>
          <listitem>
            <para>IBM SDN-VE plug-in</para>
          </listitem>
          <listitem>
            <para>MidoNet plug-in</para>
          </listitem>
          <listitem>
            <para>NSX plug-in</para>
          </listitem>
          <listitem>
            <para>PLUMgrid plug-in</para>
          </listitem>
        </itemizedlist>
        <warning>
          <para>Do not configure or use <literal>neutron-l3-agent</literal> if you use one of these
plug-ins.</para>
        </warning>
        <para>
          <emphasis role="bold">To install the L3 agent for all other plug-ins</emphasis>
        </para>
        <procedure>
          <step>
            <para>Install the <literal>neutron-l3-agent</literal> binary on the network node:</para>
            <screen language="console"># apt-get install neutron-l3-agent</screen>
          </step>
          <step>
            <para>To uplink the node that runs <literal>neutron-l3-agent</literal> to the external network,
create a bridge named <literal>br-ex</literal> and attach the NIC for the external
network to this bridge.</para>
            <para>For example, with Open vSwitch and NIC eth1 connected to the external
network, run:</para>
            <screen language="console"># ovs-vsctl add-br br-ex
# ovs-vsctl add-port br-ex eth1</screen>
            <para>When the <literal>br-ex</literal> port is added to the <literal>eth1</literal> interface, external
communication is interrupted. To avoid this, edit the
<literal>/etc/network/interfaces</literal> file to contain the following information:</para>
            <screen language="ini">## External bridge
auto br-ex
iface br-ex inet static
address 192.27.117.101
netmask 255.255.240.0
gateway 192.27.127.254
dns-nameservers 8.8.8.8

## External network interface
auto eth1
iface eth1 inet manual
up ifconfig $IFACE 0.0.0.0 up
up ip link set $IFACE promisc on
down ip link set $IFACE promisc off
down ifconfig $IFACE down</screen>
            <note>
              <para>The external bridge configuration address is the external IP address.
This address and gateway should be configured in
<literal>/etc/network/interfaces</literal>.</para>
            </note>
            <para>After editing the configuration, restart <literal>br-ex</literal>:</para>
            <screen language="console"># ifdown br-ex &amp;&amp; ifup br-ex</screen>
            <para>Do not manually configure an IP address on the NIC connected to the
external network for the node running <literal>neutron-l3-agent</literal>. Rather, you
must have a range of IP addresses from the external network that can be
used by OpenStack Networking for routers that uplink to the external
network. This range must be large enough to have an IP address for each
router in the deployment, as well as each floating IP.</para>
          </step>
          <step>
            <para>The <literal>neutron-l3-agent</literal> uses the Linux IP stack and iptables to perform L3
forwarding and NAT. In order to support multiple routers with
potentially overlapping IP addresses, <literal>neutron-l3-agent</literal> defaults to
using Linux network namespaces to provide isolated forwarding contexts.
As a result, the IP addresses of routers are not visible simply by running
the <command>ip addr list</command> or <command>ifconfig</command> command on the node.
Similarly, you cannot directly <command>ping</command> fixed IPs.</para>
            <para>To do either of these things, you must run the command within a
particular network namespace for the router. The namespace has the name
<literal>qrouter-ROUTER_UUID</literal>. These example commands run in the router
namespace with UUID 47af3868-0fa8-4447-85f6-1304de32153b:</para>
            <screen language="console"># ip netns exec qrouter-47af3868-0fa8-4447-85f6-1304de32153b ip addr list</screen>
            <screen language="console"># ip netns exec qrouter-47af3868-0fa8-4447-85f6-1304de32153b ping FIXED_IP</screen>
            <important>
              <para>If you reboot a node that runs the L3 agent, you must run the
<command>neutron-ovs-cleanup</command> command before the <literal>neutron-l3-agent</literal>
service starts.</para>
              <para>On Red Hat, SUSE and Ubuntu based systems, the neutron-ovs-cleanup
service runs the <command>neutron-ovs-cleanup</command> command
automatically. However, on Debian-based systems, you must manually
run this command or write your own system script that runs on boot
before the neutron-l3-agent service starts.</para>
            </important>
          </step>
        </procedure>
        <para><emphasis role="bold">How routers are assigned to L3 agents</emphasis>
By default, a router is assigned to the L3 agent with the least number
of routers (LeastRoutersScheduler). This can be changed by altering the
<literal>router_scheduler_driver</literal> setting in the configuration file.</para>
      </sect2>
      <sect2>
        <title>Configure metering agent</title>
        <para>The Neutron Metering agent resides beside neutron-l3-agent.</para>
        <para>
          <emphasis role="bold">To install the metering agent and configure the node</emphasis>
        </para>
        <procedure>
          <step>
            <para>Install the agent by running:</para>
            <screen language="console"># apt-get install neutron-metering-agent</screen>
          </step>
          <step>
            <para>If you use one of the following plug-ins, you need to configure the
metering agent with these lines as well:</para>
            <itemizedlist>
              <listitem>
                <para>An OVS-based plug-in such as OVS, NSX, NEC, BigSwitch/Floodlight:</para>
                <screen language="ini">interface_driver = openvswitch</screen>
              </listitem>
              <listitem>
                <para>A plug-in that uses LinuxBridge:</para>
                <screen language="ini">interface_driver = linuxbridge</screen>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>To use the reference implementation, you must set:</para>
            <screen language="ini">driver = neutron.services.metering.drivers.iptables.iptables_driver
.IptablesMeteringDriver</screen>
          </step>
          <step>
            <para>Set the <literal>service_plugins</literal> option in the <literal>/etc/neutron/neutron.conf</literal>
file on the host that runs <literal>neutron-server</literal>:</para>
            <screen language="ini">service_plugins = metering</screen>
            <para>If this option is already defined, add <literal>metering</literal> to the list, using a
comma as separator. For example:</para>
            <screen language="ini">service_plugins = router,metering</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Configure Load-Balancer-as-a-Service (LBaaS v2)</title>
        <para>For the back end, use either <xref linkend="term-octavia"/> or <xref linkend="term-haproxy"/>.
This example uses Octavia.</para>
        <para>
          <emphasis role="bold">To configure LBaaS V2</emphasis>
        </para>
        <procedure>
          <step>
            <para>Install Octavia using your distribution's package manager.</para>
          </step>
          <step>
            <para>Edit the <literal>/etc/neutron/neutron_lbaas.conf</literal> file and change
the <literal>service_provider</literal> parameter to enable Octavia:</para>
            <screen language="ini">service_provider = LOADBALANCERV2:Octavia:neutron_lbaas.
drivers.octavia.driver.OctaviaDriver:default</screen>
          </step>
          <step>
            <para>Edit the <literal>/etc/neutron/neutron.conf</literal> file and add the
<literal>service_plugins</literal> parameter to enable the load-balancing plug-in:</para>
            <screen language="ini">service_plugins = neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2</screen>
            <para>If this option is already defined, add the load-balancing plug-in to
the list using a comma as a separator. For example:</para>
            <screen language="ini"><?dbsuse-fo font-size="8pt"?>service_plugins = [already defined plugins],neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2</screen>
          </step>
          <step>
            <para>Create the required tables in the database:</para>
            <screen language="console"># neutron-db-manage --subproject neutron-lbaas upgrade head</screen>
          </step>
          <step>
            <para>Restart the <literal>neutron-server</literal> service.</para>
          </step>
          <step>
            <para>Enable load balancing in the Project section of the dashboard.</para>
            <warning>
              <para>Horizon panels are enabled only for LBaaSV1. LBaaSV2 panels are still
being developed.</para>
            </warning>
            <para>By default, the <literal>enable_lb</literal> option is <literal>True</literal> in the <literal>local_settings.py</literal>
file.</para>
            <screen language="python">OPENSTACK_NEUTRON_NETWORK = {
    'enable_lb': True,
    ...
}</screen>
            <para>Apply the settings by restarting the web server. You can now view the
Load Balancer management options in the Project view in the dashboard.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Configure Hyper-V L2 agent</title>
        <para>Before you install the OpenStack Networking Hyper-V L2 agent on a
Hyper-V compute node, ensure the compute node has been configured
correctly using these
<link xlink:href="http://docs.openstack.org/newton/config-reference/compute/hypervisor-hyper-v.html">instructions</link>.</para>
        <para>
          <emphasis role="bold">To install the OpenStack Networking Hyper-V agent and configure the node</emphasis>
        </para>
        <procedure>
          <step>
            <para>Download the OpenStack Networking code from the repository:</para>
            <screen language="console">&gt; cd C:\OpenStack\
&gt; git clone https://git.openstack.org/openstack/neutron</screen>
          </step>
          <step>
            <para>Install the OpenStack Networking Hyper-V Agent:</para>
            <screen language="console">&gt; cd C:\OpenStack\neutron\
&gt; python setup.py install</screen>
          </step>
          <step>
            <para>Copy the <literal>policy.json</literal> file:</para>
            <screen language="console">&gt; xcopy C:\OpenStack\neutron\etc\policy.json C:\etc\</screen>
          </step>
          <step>
            <para>Create the <literal>C:\etc\neutron-hyperv-agent.conf</literal> file and add the proper
configuration options and the <link xlink:href="http://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#cloudbase-hyper-v-agent-configuration-options">Hyper-V related
options</link>. Here is a sample config file:</para>
            <screen language="ini">[DEFAULT]
control_exchange = neutron
policy_file = C:\etc\policy.json
rpc_backend = neutron.openstack.common.rpc.impl_kombu
rabbit_host = IP_ADDRESS
rabbit_port = 5672
rabbit_userid = guest
rabbit_password = &lt;password&gt;
logdir = C:\OpenStack\Log
logfile = neutron-hyperv-agent.log

[AGENT]
polling_interval = 2
physical_network_vswitch_mappings = *:YOUR_BRIDGE_NAME
enable_metrics_collection = true

[SECURITYGROUP]
firewall_driver = hyperv.neutron.security_groups_driver.
HyperVSecurityGroupsDriver
enable_security_group = true</screen>
          </step>
          <step>
            <para>Start the OpenStack Networking Hyper-V agent:</para>
            <screen language="console">&gt; C:\Python27\Scripts\neutron-hyperv-agent.exe --config-file
C:\etc\neutron-hyperv-agent.conf</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Basic operations on agents</title>
        <para>This table shows examples of Networking commands that enable you to
complete basic operations on agents.</para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="50.0*"/>
            <colspec colname="c2" colwidth="50.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Operation</para>
                </entry>
                <entry>
                  <para>Command</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>List all available agents.</para>
                </entry>
                <entry>
                  <para>
                    <literal>$ openstack network agent list</literal>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Show information of a given agent.</para>
                </entry>
                <entry>
                  <para>
                    <literal>$ openstack network agent show AGENT_ID</literal>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Update the admin status and description for a specified agent. The
command can be used to enable and disable agents by using
<literal>--admin-state-up</literal> parameter set to <literal>False</literal> or <literal>True</literal>.</para>
                </entry>
                <entry>
                  <para>
                    <literal>$ neutron agent-update --admin-state-up False AGENT_ID</literal>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Delete a given agent. Consider disabling the agent before deletion.</para>
                </entry>
                <entry>
                  <para>
                    <literal>$ openstack network agent delete AGENT_ID</literal>
                  </para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          <emphasis role="bold">Basic operations on Networking agents</emphasis>
        </para>
        <para>See the <link xlink:href="http://docs.openstack.org/cli-reference/neutron.html">OpenStack Command-Line Interface
Reference</link>
for more information on Networking commands.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Configure Identity service for Networking</title>
      <para>
        <emphasis role="bold">To configure the Identity service for use with Networking</emphasis>
      </para>
      <procedure>
        <step>
          <para>Create the <literal>get_id()</literal> function</para>
          <para>The <literal>get_id()</literal> function stores the ID of created objects, and removes
the need to copy and paste object IDs in later steps:</para>
          <substeps>
            <step>
              <para>Add the following function to your <literal>.bashrc</literal> file:</para>
              <screen language="ini">function get_id () {
echo `"$@" | awk '/ id / { print $4 }'`
}</screen>
            </step>
            <step>
              <para>Source the <literal>.bashrc</literal> file:</para>
              <screen language="console">$ source .bashrc</screen>
            </step>
          </substeps>
        </step>
        <step>
          <para>Create the Networking service entry</para>
          <para>Networking must be available in the Compute service catalog. Create the
service:</para>
          <screen language="console">$ NEUTRON_SERVICE_ID=$(get_id openstack service create network \
  --name neutron --description 'OpenStack Networking Service')</screen>
        </step>
        <step>
          <para>Create the Networking service endpoint entry</para>
          <para>The way that you create a Networking endpoint entry depends on whether
you are using the SQL or the template catalog driver:</para>
          <itemizedlist>
            <listitem>
              <para>If you are using the <literal>SQL driver</literal>, run the following command with the
specified region (<literal>$REGION</literal>), IP address of the Networking server
(<literal>$IP</literal>), and service ID (<literal>$NEUTRON_SERVICE_ID</literal>, obtained in the
previous step).</para>
              <screen language="console">$ openstack endpoint create $NEUTRON_SERVICE_ID --region $REGION \
  --publicurl 'http://$IP:9696/' --adminurl 'http://$IP:9696/' \
  --internalurl 'http://$IP:9696/'</screen>
              <para>For example:</para>
              <screen language="console">$ openstack endpoint create $NEUTRON_SERVICE_ID --region myregion \
  --publicurl "http://10.211.55.17:9696/" \
  --adminurl "http://10.211.55.17:9696/" \
  --internalurl "http://10.211.55.17:9696/"</screen>
            </listitem>
            <listitem>
              <para>If you are using the <literal>template driver</literal>, specify the following
parameters in your Compute catalog template file
(<literal>default_catalog.templates</literal>), along with the region (<literal>$REGION</literal>)
and IP address of the Networking server (<literal>$IP</literal>).</para>
              <screen language="bash">catalog.$REGION.network.publicURL = http://$IP:9696
catalog.$REGION.network.adminURL = http://$IP:9696
catalog.$REGION.network.internalURL = http://$IP:9696
catalog.$REGION.network.name = Network Service</screen>
              <para>For example:</para>
              <screen language="bash">catalog.$Region.network.publicURL = http://10.211.55.17:9696
catalog.$Region.network.adminURL = http://10.211.55.17:9696
catalog.$Region.network.internalURL = http://10.211.55.17:9696
catalog.$Region.network.name = Network Service</screen>
            </listitem>
          </itemizedlist>
        </step>
        <step>
          <para>Create the Networking service user</para>
          <para>You must provide admin user credentials that Compute and some internal
Networking components can use to access the Networking API. Create a
special <literal>service</literal> project and a <literal>neutron</literal> user within this project,
and assign an <literal>admin</literal> role to this role.</para>
          <substeps>
            <step>
              <para>Create the <literal>admin</literal> role:</para>
              <screen language="console">$ ADMIN_ROLE=$(get_id openstack role create admin)</screen>
            </step>
            <step>
              <para>Create the <literal>neutron</literal> user:</para>
              <screen language="console">$ NEUTRON_USER=$(get_id openstack user create neutron \
  --password "$NEUTRON_PASSWORD" --email demo@example.com \
  --project service)</screen>
            </step>
            <step>
              <para>Create the <literal>service</literal> project:</para>
              <screen language="console">$ SERVICE_TENANT=$(get_id openstack project create service \
  --description "Services project" --domain default)</screen>
            </step>
            <step>
              <para>Establish the relationship among the project, user, and role:</para>
              <screen language="console">$ openstack role add $ADMIN_ROLE --user $NEUTRON_USER \
  --project $SERVICE_TENANT</screen>
            </step>
          </substeps>
        </step>
      </procedure>
      <para>For information about how to create service entries and users, see the <link xlink:href="http://docs.openstack.org/project-install-guide/newton/">Newton Installation
Tutorials and Guides</link>
for your distribution.</para>
      <sect2>
        <title>Compute</title>
        <para>If you use Networking, do not run the Compute <literal>nova-network</literal> service (like
you do in traditional Compute deployments). Instead, Compute delegates
most network-related decisions to Networking.</para>
        <note>
          <para>Uninstall <literal>nova-network</literal> and reboot any physical nodes that have been
running <literal>nova-network</literal> before using them to run Networking.
Inadvertently running the <literal>nova-network</literal> process while using
Networking can cause problems, as can stale iptables rules pushed
down by previously running <literal>nova-network</literal>.</para>
        </note>
        <para>Compute proxies project-facing API calls to manage security groups and
floating IPs to Networking APIs. However, operator-facing tools such
as <literal>nova-manage</literal>, are not proxied and should not be used.</para>
        <warning>
          <para>When you configure networking, you must use this guide. Do not rely
on Compute networking documentation or past experience with Compute.
If a <command>nova</command> command or configuration option related to networking
is not mentioned in this guide, the command is probably not
supported for use with Networking. In particular, you cannot use CLI
tools like <literal>nova-manage</literal> and <literal>nova</literal> to manage networks or IP
addressing, including both fixed and floating IPs, with Networking.</para>
        </warning>
        <para>To ensure that Compute works properly with Networking (rather than the
legacy <literal>nova-network</literal> mechanism), you must adjust settings in the
<literal>nova.conf</literal> configuration file.</para>
      </sect2>
      <sect2>
        <title>Networking API and credential configuration</title>
        <para>Each time you provision or de-provision a VM in Compute, <literal>nova-\*</literal>
services communicate with Networking using the standard API. For this to
happen, you must configure the following items in the <literal>nova.conf</literal> file
(used by each <literal>nova-compute</literal> and <literal>nova-api</literal> instance).</para>
        <table>
          <title>nova.conf API and credential settings prior to Mitaka</title>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="28.6*"/>
            <colspec colname="c2" colwidth="71.4*"/>
            <thead>
              <row>
                <entry>
                  <para>Attribute name</para>
                </entry>
                <entry>
                  <para>Required</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <literal>[DEFAULT] use_neutron</literal>
                  </para>
                </entry>
                <entry>
                  <para>Modify from the default to <literal>True</literal> to
indicate that Networking should be used rather than the traditional
nova-network networking model.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] url</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the host name/IP and port of the neutron-server instance
for this deployment.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] auth_strategy</literal>
                  </para>
                </entry>
                <entry>
                  <para>Keep the default <literal>keystone</literal> value for all production deployments.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] admin_project_name</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the name of the service tenant created in the above section on
Identity configuration.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] admin_username</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the name of the user created in the above section on Identity
configuration.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] admin_password</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the password of the user created in the above section on
Identity configuration.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] admin_auth_url</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the Identity server IP and port. This is the Identity
(keystone) admin API server IP and port value, and not the Identity
service API IP and port.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <table>
          <title>nova.conf API and credential settings in Newton</title>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="28.6*"/>
            <colspec colname="c2" colwidth="71.4*"/>
            <thead>
              <row>
                <entry>
                  <para>Attribute name</para>
                </entry>
                <entry>
                  <para>Required</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <literal>[DEFAULT] use_neutron</literal>
                  </para>
                </entry>
                <entry>
                  <para>Modify from the default to <literal>True</literal> to
indicate that Networking should be used rather than the traditional
nova-network networking model.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] url</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the host name/IP and port of the neutron-server instance
for this deployment.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] auth_strategy</literal>
                  </para>
                </entry>
                <entry>
                  <para>Keep the default <literal>keystone</literal> value for all production deployments.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] project_name</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the name of the service tenant created in the above section on
Identity configuration.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] username</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the name of the user created in the above section on Identity
configuration.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] password</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the password of the user created in the above section on
Identity configuration.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>[neutron] auth_url</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to the Identity server IP and port. This is the Identity
(keystone) admin API server IP and port value, and not the Identity
service API IP and port.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </sect2>
      <sect2>
        <title>Configure security groups</title>
        <para>The Networking service provides security group functionality using a
mechanism that is more flexible and powerful than the security group
capabilities built into Compute. Therefore, if you use Networking, you
should always disable built-in security groups and proxy all security
group calls to the Networking API. If you do not, security policies
will conflict by being simultaneously applied by both services.</para>
        <para>To proxy security groups to Networking, use the following configuration
values in the <literal>nova.conf</literal> file:</para>
        <para>
          <emphasis role="bold">nova.conf security group settings</emphasis>
        </para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="30.3*"/>
            <colspec colname="c2" colwidth="69.7*"/>
            <thead>
              <row>
                <entry>
                  <para>Item</para>
                </entry>
                <entry>
                  <para>Configuration</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <literal>firewall_driver</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to <literal>nova.virt.firewall.NoopFirewallDriver</literal>,
so that nova-compute does not perform
iptables-based filtering itself.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Configure metadata</title>
        <para>The Compute service allows VMs to query metadata associated with a VM by
making a web request to a special 169.254.169.254 address. Networking
supports proxying those requests to nova-api, even when the requests are
made from isolated networks, or from multiple networks that use
overlapping IP addresses.</para>
        <para>To enable proxying the requests, you must update the following fields in
<literal>[neutron]</literal> section in the <literal>nova.conf</literal>.</para>
        <para>
          <emphasis role="bold">nova.conf metadata settings</emphasis>
        </para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="44.0*"/>
            <colspec colname="c2" colwidth="56.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Item</para>
                </entry>
                <entry>
                  <para>Configuration</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <literal>service_metadata_proxy</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to <literal>true</literal>, otherwise nova-api
will not properly respond to requests
from the neutron-metadata-agent.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <literal>metadata_proxy_shared_secret</literal>
                  </para>
                </entry>
                <entry>
                  <para>Update to a string "password" value.
You must also configure the same value in
the <literal>metadata_agent.ini</literal> file, to
authenticate requests made for metadata.</para>
                  <para>The default value of an empty string in
both files will allow metadata to
function, but will not be secure if any
non-trusted entities have access to the
metadata APIs exposed by nova-api.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <para>As a precaution, even when using <literal>metadata_proxy_shared_secret</literal>,
we recommend that you do not expose metadata using the same
nova-api instances that are used for projects. Instead, you should
run a dedicated set of nova-api instances for metadata that are
available only on your management network. Whether a given nova-api
instance exposes metadata APIs is determined by the value of
<literal>enabled_apis</literal> in its <literal>nova.conf</literal>.</para>
        </note>
      </sect2>
      <sect2>
        <title>Example nova.conf (for nova-compute and nova-api)</title>
        <para>Example values for the above settings, assuming a cloud controller node
running Compute and Networking with an IP address of 192.168.1.2:</para>
        <screen language="ini">[DEFAULT]
use_neutron = True
firewall_driver=nova.virt.firewall.NoopFirewallDriver

[neutron]
url=http://192.168.1.2:9696
auth_strategy=keystone
admin_tenant_name=service
admin_username=neutron
admin_password=password
admin_auth_url=http://192.168.1.2:35357/v2.0
service_metadata_proxy=true
metadata_proxy_shared_secret=foo</screen>
      </sect2>
    </sect1>
    <sect1>
      <title>Advanced configuration options</title>
      <para>This section describes advanced configuration options for various system
components. For example, configuration options where the default works
but that the user wants to customize options. After installing from
packages, <literal>$NEUTRON_CONF_DIR</literal> is <literal>/etc/neutron</literal>.</para>
      <sect2>
        <title>L3 metering agent</title>
        <para>You can run an L3 metering agent that enables layer-3 traffic metering.
In general, you should launch the metering agent on all nodes that run
the L3 agent:</para>
        <screen language="console">$ neutron-metering-agent --config-file NEUTRON_CONFIG_FILE \
  --config-file L3_METERING_CONFIG_FILE</screen>
        <para>You must configure a driver that matches the plug-in that runs on the
service. The driver adds metering to the routing interface.</para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="56.0*"/>
            <colspec colname="c2" colwidth="44.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Option</para>
                </entry>
                <entry>
                  <para>Value</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Open vSwitch</emphasis>
                  </para>
                </entry>
                <entry/>
              </row>
              <row>
                <entry>
                  <para>interface_driver
($NEUTRON_CONF_DIR/metering_agent.ini)</para>
                </entry>
                <entry>
                  <para>openvswitch</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Linux Bridge</emphasis>
                  </para>
                </entry>
                <entry/>
              </row>
              <row>
                <entry>
                  <para>interface_driver
($NEUTRON_CONF_DIR/metering_agent.ini)</para>
                </entry>
                <entry>
                  <para>linuxbridge</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <sect3>
          <title>L3 metering driver</title>
          <para>You must configure any driver that implements the metering abstraction.
Currently the only available implementation uses iptables for metering.</para>
          <screen language="ini">driver = neutron.services.metering.drivers.
iptables.iptables_driver.IptablesMeteringDriver</screen>
        </sect3>
        <sect3>
          <title>L3 metering service driver</title>
          <para>To enable L3 metering, you must set the following option in the
<literal>neutron.conf</literal> file on the host that runs <literal>neutron-server</literal>:</para>
          <screen language="ini">service_plugins = metering</screen>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Scalable and highly available DHCP agents</title>
      <para>This section is fully described at the <link xlink:href="http://docs.openstack.org/newton/networking-guide/config-dhcp-ha.html">High-availability for DHCP</link>
in the Networking Guide.</para>
    </sect1>
    <sect1>
      <title>Use Networking</title>
      <para>You can manage OpenStack Networking services by using the service
command. For example:</para>
      <screen language="console"># service neutron-server stop
# service neutron-server status
# service neutron-server start
# service neutron-server restart</screen>
      <para>Log files are in the <literal>/var/log/neutron</literal> directory.</para>
      <para>Configuration files are in the <literal>/etc/neutron</literal> directory.</para>
      <para>Administrators and projects can use OpenStack Networking to build
rich network topologies. Administrators can create network
connectivity on behalf of projects.</para>
      <sect2>
        <title>Core Networking API features</title>
        <para>After installing and configuring Networking (neutron), projects and
administrators can perform create-read-update-delete (CRUD) API networking
operations. This is performed using the Networking API directly with either
the <command>neutron</command> command-line interface (CLI) or the <command>openstack</command>
CLI. The <command>neutron</command> CLI is a wrapper around the Networking API. Every
Networking API call has a corresponding <command>neutron</command> command.</para>
        <para>The <command>openstack</command> CLI is a common interface for all OpenStack
projects, however, not every API operation has been implemented. For the
list of available commands, see <link xlink:href="http://docs.openstack.org/developer/python-openstackclient/command-list.html">Command List</link>.</para>
        <para>The <command>neutron</command> CLI includes a number of options. For details, see
<link xlink:href="http://docs.openstack.org/user-guide/cli-create-and-manage-networks.html">Create and manage networks</link>.</para>
        <sect3>
          <title>Basic Networking operations</title>
          <para>To learn about advanced capabilities available through the <command>neutron</command>
command-line interface (CLI), read the networking section <link xlink:href="http://docs.openstack.org/user-guide/cli-create-and-manage-networks.html">Create and manage
networks</link>
in the OpenStack End User Guide.</para>
          <para>This table shows example <command>openstack</command> commands that enable you to
complete basic network operations:</para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="33.8*"/>
              <colspec colname="c2" colwidth="66.2*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operation</para>
                  </entry>
                  <entry>
                    <para>Command</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Creates a network.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack network create net1</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a subnet that is
associated with net1.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack subnet create subnet1</literal>
                      <literal>--subnet-range 10.0.0.0/24</literal>
                      <literal>--network net1</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists ports for a
specified project.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack port list</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists ports for a
specified project
and displays the <literal>ID</literal>,
<literal>Fixed IP Addresses</literal></para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack port list -c ID</literal>
                      <literal>-c "Fixed IP Addresses</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Shows information for a
specified port.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack port show PORT_ID</literal>
                    </para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>
            <emphasis role="bold">Basic Networking operations</emphasis>
          </para>
          <note>
            <para>The <literal>device_owner</literal> field describes who owns the port. A port whose
<literal>device_owner</literal> begins with:</para>
            <itemizedlist>
              <listitem>
                <para><literal>network</literal> is created by Networking.</para>
              </listitem>
              <listitem>
                <para><literal>compute</literal> is created by Compute.</para>
              </listitem>
            </itemizedlist>
          </note>
        </sect3>
        <sect3>
          <title>Administrative operations</title>
          <para>The administrator can run any <command>openstack</command> command on behalf of
projects by specifying an Identity <literal>project</literal> in the command, as
follows:</para>
          <screen language="console">$ openstack network create --project PROJECT_ID NETWORK_NAME</screen>
          <para>For example:</para>
          <screen language="console">$ openstack network create --project 5e4bbe24b67a4410bc4d9fae29ec394e net1</screen>
          <note>
            <para>To view all project IDs in Identity, run the following command as an
Identity service admin user:</para>
            <screen language="console">$ openstack project list</screen>
          </note>
        </sect3>
        <sect3>
          <title>Advanced Networking operations</title>
          <para>This table shows example CLI commands that enable you to complete
advanced network operations:</para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="41.3*"/>
              <colspec colname="c2" colwidth="58.7*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operation</para>
                  </entry>
                  <entry>
                    <para>Command</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Creates a network that
all projects can use.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack network create</literal>
                      <literal>--share public-net</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a subnet with a
specified gateway IP address.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack subnet create subnet1</literal>
                      <literal>--gateway 10.0.0.254 --network net1</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a subnet that has
no gateway IP address.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack subnet create subnet1</literal>
                      <literal>--no-gateway --network net1</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a subnet with DHCP
disabled.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack subnet create subnet1</literal>
                      <literal>--network net1 --no-dhcp</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Specifies a set of host routes</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack subnet create subnet1</literal>
                      <literal>--network net1 --host-route</literal>
                      <literal>destination=40.0.1.0/24,</literal>
                      <literal>gateway=40.0.0.2</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a subnet with a
specified set of dns name
servers.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack subnet create subnet1</literal>
                      <literal>--network net1 --dns-nameserver</literal>
                      <literal>8.8.4.4</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Displays all ports and
IPs allocated on a network.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack port list --network NET_ID</literal>
                    </para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>
            <emphasis role="bold">Advanced Networking operations</emphasis>
          </para>
        </sect3>
      </sect2>
      <sect2>
        <title>Use Compute with Networking</title>
        <sect3>
          <title>Basic Compute and Networking operations</title>
          <para>This table shows example <command>openstack</command> commands that enable you to
complete basic VM networking operations:</para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="45.3*"/>
              <colspec colname="c2" colwidth="54.7*"/>
              <thead>
                <row>
                  <entry>
                    <para>Action</para>
                  </entry>
                  <entry>
                    <para>Command</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Checks available networks.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack network list</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Boots a VM with a single NIC on
a selected Networking network.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack server create --image</literal>
                      <literal>IMAGE --flavor FLAVOR --nic</literal>
                      <literal>net-id=NET_ID VM_NAME</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Searches for ports with a
<literal>device_id</literal> that matches the
Compute instance UUID. See :ref:
<literal>Create and delete VMs</literal></para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack port list --server VM_ID</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Searches for ports, but shows
only the <literal>mac_address</literal> of
the port.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack port list -c</literal>
                      <literal>"MAC Address" --server VM_ID</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Temporarily disables a port from
sending traffic.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack port set PORT_ID</literal>
                      <literal>--disable</literal>
                    </para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>
            <emphasis role="bold">Basic Compute and Networking operations</emphasis>
          </para>
          <note>
            <para>The <literal>device_id</literal> can also be a logical router ID.</para>
          </note>
          <note>
            <itemizedlist>
              <listitem>
                <para>When you boot a Compute VM, a port on the network that
corresponds to the VM NIC is automatically created and associated
with the default security group. You can configure <link xlink:href="#enable-ping-and-ssh-on-vms-security-groups">security
group rules</link> to enable
users to access the VM.</para>
              </listitem>
            </itemizedlist>
          </note>
        </sect3>
        <sect3>
          <title>Advanced VM creation operations</title>
          <para>This table shows example <command>openstack</command> commands that enable you to
complete advanced VM creation operations:</para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="49.3*"/>
              <colspec colname="c2" colwidth="50.7*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operation</para>
                  </entry>
                  <entry>
                    <para>Command</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Boots a VM with multiple
NICs.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack server create --image</literal>
                      <literal>IMAGE --flavor FLAVOR --nic</literal>
                      <literal>net-id=NET_ID VM_NAME</literal>
                      <literal>net-id=NET2-ID VM_NAME</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Boots a VM with a specific IP
address. Note that you cannot
use the <literal>--max</literal> or <literal>--min</literal>
parameters in this case.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack server create --image</literal>
                      <literal>IMAGE --flavor FLAVOR --nic</literal>
                      <literal>net-id=NET_ID VM_NAME</literal>
                      <literal>v4-fixed-ip=IP-ADDR VM_NAME</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Boots a VM that connects to all
networks that are accessible to the
project who submits the request
(without the <literal>--nic</literal> option).</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>$ openstack server create --image</literal>
                      <literal>IMAGE --flavor FLAVOR</literal>
                    </para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>
            <emphasis role="bold">Advanced VM creation operations</emphasis>
          </para>
          <note>
            <para>Cloud images that distribution vendors offer usually have only one
active NIC configured. When you boot with multiple NICs, you must
configure additional interfaces on the image or the NICs are not
reachable.</para>
            <para>The following Debian/Ubuntu-based example shows how to set up the
interfaces within the instance in the <literal>/etc/network/interfaces</literal>
file. You must apply this configuration to the image.</para>
            <screen language="bash"># The loopback network interface
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet dhcp

auto eth1
iface eth1 inet dhcp</screen>
          </note>
        </sect3>
        <sect3>
          <title>Enable ping and SSH on VMs (security groups)</title>
          <para>You must configure security group rules depending on the type of plug-in
you are using. If you are using a plug-in that:</para>
          <itemizedlist>
            <listitem>
              <para>Implements Networking security groups, you can configure security
group rules directly by using the <command>openstack security group rule create</command>
command. This example enables <literal>ping</literal> and <literal>ssh</literal> access to your VMs.</para>
              <screen language="console">$ openstack security group rule create --protocol icmp \
    --ingress</screen>
              <screen language="console">$ openstack security group rule create --protocol tcp \
    --egress --description "Sample Security Group"</screen>
            </listitem>
            <listitem>
              <para>Does not implement Networking security groups, you can configure
security group rules by using the <command>openstack security group rule
create</command> or <command>euca-authorize</command> command. These <command>openstack</command>
commands enable <literal>ping</literal> and <literal>ssh</literal> access to your VMs.</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule create default --protocol icmp --dst-port -1:-1 --remote-ip 0.0.0.0/0
$ openstack security group rule create default --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0</screen>
            </listitem>
          </itemizedlist>
          <note>
            <para>If your plug-in implements Networking security groups, you can also
leverage Compute security groups by setting
<literal>security_group_api = neutron</literal> in the <literal>nova.conf</literal> file. After
you set this option, all Compute security group commands are proxied
to Networking.</para>
          </note>
        </sect3>
      </sect2>
    </sect1>
    <sect1 xml:id="networking-adv-features">
      <title>Advanced features through API extensions</title>
      <para>Several plug-ins implement API extensions that provide capabilities
similar to what was available in <literal>nova-network</literal>. These plug-ins are likely
to be of interest to the OpenStack community.</para>
      <sect2>
        <title>Provider networks</title>
        <para>Networks can be categorized as either project networks or provider
networks. Project networks are created by normal users and details about
how they are physically realized are hidden from those users. Provider
networks are created with administrative credentials, specifying the
details of how the network is physically realized, usually to match some
existing network in the data center.</para>
        <para>Provider networks enable administrators to create networks that map
directly to the physical networks in the data center.
This is commonly used to give projects direct access to a public network
that can be used to reach the Internet. It might also be used to
integrate with VLANs in the network that already have a defined meaning
(for example, enable a VM from the marketing department to be placed
on the same VLAN as bare-metal marketing hosts in the same data center).</para>
        <para>The provider extension allows administrators to explicitly manage the
relationship between Networking virtual networks and underlying physical
mechanisms such as VLANs and tunnels. When this extension is supported,
Networking client users with administrative privileges see additional
provider attributes on all virtual networks and are able to specify
these attributes in order to create provider networks.</para>
        <para>The provider extension is supported by the Open vSwitch and Linux Bridge
plug-ins. Configuration of these plug-ins requires familiarity with this
extension.</para>
        <sect3>
          <title>Terminology</title>
          <para>A number of terms are used in the provider extension and in the
configuration of plug-ins supporting the provider extension:</para>
          <para>
            <emphasis role="bold">Provider extension terminology</emphasis>
          </para>
          <informaltable>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="29.3*"/>
              <colspec colname="c2" colwidth="70.7*"/>
              <thead>
                <row>
                  <entry>
                    <para>Term</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">virtual network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A Networking L2 network (identified by a UUID and
optional name) whose ports can be attached as vNICs
to Compute instances and to various Networking
agents. The Open vSwitch and Linux Bridge plug-ins
each support several different mechanisms to
realize virtual networks.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">physical network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A network connecting virtualization hosts (such as
compute nodes) with each other and with other
network resources. Each physical network might
support multiple virtual networks. The provider
extension and the plug-in configurations identify
physical networks using simple string names.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">project network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A virtual network that a project or an administrator
creates. The physical details of the network are not
exposed to the project.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">provider network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A virtual network administratively created to map to
a specific network in the data center, typically to
enable direct access to non-OpenStack resources on
that network. Project can be given access to
provider networks.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">VLAN network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A virtual network implemented as packets on a
specific physical network containing IEEE 802.1Q
headers with a specific VID field value. VLAN
networks sharing the same physical network are
isolated from each other at L2 and can even have
overlapping IP address spaces. Each distinct
physical network supporting VLAN networks is
treated as a separate VLAN trunk, with a distinct
space of VID values. Valid VID values are 1
through 4094.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">flat network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A virtual network implemented as packets on a
specific physical network containing no IEEE 802.1Q
header. Each physical network can realize at most
one flat network.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">local network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A virtual network that allows communication within
each host, but not across a network. Local networks
are intended mainly for single-node test scenarios,
but can have other uses.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">GRE network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>A virtual network implemented as network packets
encapsulated using GRE. GRE networks are also
referred to as <emphasis>tunnels</emphasis>. GRE tunnel packets are
routed by the IP routing table for the host, so
GRE networks are not associated by Networking with
specific physical networks.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <emphasis role="bold">Virtual Extensible
LAN (VXLAN) network</emphasis>
                    </para>
                  </entry>
                  <entry>
                    <para>VXLAN is a proposed encapsulation protocol for
running an overlay network on existing Layer 3
infrastructure. An overlay network is a virtual
network that is built on top of existing network
Layer 2 and Layer 3 technologies to support elastic
compute architectures.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>The ML2, Open vSwitch, and Linux Bridge plug-ins support VLAN networks,
flat networks, and local networks. Only the ML2 and Open vSwitch
plug-ins currently support GRE and VXLAN networks, provided that the
required features exist in the hosts Linux kernel, Open vSwitch, and
iproute2 packages.</para>
        </sect3>
        <sect3>
          <title>Provider attributes</title>
          <para>The provider extension extends the Networking network resource with
these attributes:</para>
          <table>
            <title>Provider network attributes</title>
            <tgroup cols="4">
              <colspec colname="c1" colwidth="12.7*"/>
              <colspec colname="c2" colwidth="12.7*"/>
              <colspec colname="c3" colwidth="12.7*"/>
              <colspec colname="c4" colwidth="62.0*"/>
              <thead>
                <row>
                  <entry>
                    <para>Attribute name</para>
                  </entry>
                  <entry>
                    <para>Type</para>
                  </entry>
                  <entry>
                    <para>Default Value</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>provider: network_type</para>
                  </entry>
                  <entry>
                    <para>String</para>
                  </entry>
                  <entry>
                    <para>N/A</para>
                  </entry>
                  <entry>
                    <para>The physical mechanism by which the virtual network is implemented.
Possible values are <literal>flat</literal>, <literal>vlan</literal>, <literal>local</literal>, <literal>gre</literal>, and
<literal>vxlan</literal>, corresponding to flat networks, VLAN networks, local
networks, GRE networks, and VXLAN networks as defined above.
All types of provider networks can be created by administrators,
while project networks can be implemented as <literal>vlan</literal>, <literal>gre</literal>,
<literal>vxlan</literal>, or <literal>local</literal> network types depending on plug-in
configuration.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>provider: physical_network</para>
                  </entry>
                  <entry>
                    <para>String</para>
                  </entry>
                  <entry>
                    <para>If a physical network named "default" has been configured and
if provider:network_type is <literal>flat</literal> or <literal>vlan</literal>, then "default"
is used.</para>
                  </entry>
                  <entry>
                    <para>The name of the physical network over which the virtual network
is implemented for flat and VLAN networks. Not applicable to the
<literal>local</literal> or <literal>gre</literal> network types.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>provider:segmentation_id</para>
                  </entry>
                  <entry>
                    <para>Integer</para>
                  </entry>
                  <entry>
                    <para>N/A</para>
                  </entry>
                  <entry>
                    <para>For VLAN networks, the VLAN VID on the physical network that
realizes the virtual network. Valid VLAN VIDs are 1 through 4094.
For GRE networks, the tunnel ID. Valid tunnel IDs are any 32 bit
unsigned integer. Not applicable to the <literal>flat</literal> or <literal>local</literal>
network types.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
          <para>To view or set provider extended attributes, a client must be authorized
for the <literal>extension:provider_network:view</literal> and
<literal>extension:provider_network:set</literal> actions in the Networking policy
configuration. The default Networking configuration authorizes both
actions for users with the admin role. An authorized client or an
administrative user can view and set the provider extended attributes
through Networking API calls. See the section called
<xref linkend="authentication-and-authorization"/> for details on policy configuration.</para>
        </sect3>
      </sect2>
      <sect2 xml:id="l3-routing-and-nat">
        <title>L3 routing and NAT</title>
        <para>The Networking API provides abstract L2 network segments that are
decoupled from the technology used to implement the L2 network.
Networking includes an API extension that provides abstract L3 routers
that API users can dynamically provision and configure. These Networking
routers can connect multiple L2 Networking networks and can also provide
a gateway that connects one or more private L2 networks to a shared
external network. For example, a public network for access to the
Internet. See the <link xlink:href="http://docs.openstack.org/newton/config-reference/">OpenStack Configuration Reference</link> for details on common
models of deploying Networking L3 routers.</para>
        <para>The L3 router provides basic NAT capabilities on gateway ports that
uplink the router to external networks. This router SNATs all traffic by
default and supports floating IPs, which creates a static one-to-one
mapping from a public IP on the external network to a private IP on one
of the other subnets attached to the router. This allows a project to
selectively expose VMs on private networks to other hosts on the
external network (and often to all hosts on the Internet). You can
allocate and map floating IPs from one port to another, as needed.</para>
        <sect3>
          <title>Basic L3 operations</title>
          <para>External networks are visible to all users. However, the default policy
settings enable only administrative users to create, update, and delete
external networks.</para>
          <para>This table shows example neutron commands that enable you to complete
basic L3 operations:</para>
          <table>
            <title>Basic L3 Operations</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="37.5*"/>
              <colspec colname="c2" colwidth="62.5*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operation</para>
                  </entry>
                  <entry>
                    <para>Command</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Creates external networks.</para>
                  </entry>
                  <entry>
                    <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack network create public --external
$ openstack subnet create --network public --subnet-range 172.16.1.0/24 public-subnet</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists external networks.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network list --external</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates an internal-only router that connects to multiple L2 networks privately.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network create net1
$ openstack subnet create --network net1 --subnet-range 10.0.0.0/24 subnet1
$ openstack network create net2
$ openstack subnet create --network net2 --subnet-range 10.0.1.0/24 subnet2
$ openstack router create router1
$ openstack router add subnet router1 SUBNET1_UUID
$ openstack router add subnet router1 SUBNET2_UUID</screen>
                    <para>An internal router port can have only one IPv4 subnet and multiple IPv6 subnets
that belong to the same network ID. When you call <literal>router-interface-add</literal> with an IPv6
subnet, this operation adds the interface to an existing internal port with the same
network ID. If a port with the same network ID does not exist, a new port is created.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Connects a router to an external network, which enables that router to
act as a NAT gateway for external connectivity.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack router set router1 --external-gateway EXT_NET_ID</screen>
                    <para>The router obtains an interface with the gateway_ip address of the
subnet and this interface is attached to a port on the L2 Networking
network associated with the subnet. The router also gets a gateway
interface to the specified external network. This provides SNAT
connectivity to the external network as well as support for floating
IPs allocated on that external networks. Commonly an external network
maps to a network in the provider.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists routers.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack router list</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Shows information for a specified router.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack router show ROUTER_ID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Shows all internal interfaces for a router.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack port list --router  ROUTER_ID
$ openstack port list --router  ROUTER_NAME</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Identifies the PORT_ID that represents the VM NIC to which the floating
IP should map.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack port list -c ID -c "Fixed IP Addresses" --server INSTANCE_ID</screen>
                    <para>This port must be on a Networking subnet that is attached to
a router uplinked to the external network used to create the floating
IP. Conceptually, this is because the router must be able to perform the
Destination NAT (DNAT) rewriting of packets from the floating IP address
(chosen from a subnet on the external network) to the internal fixed
IP (chosen from a private subnet that is behind the router).</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a floating IP address and associates it with a port.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack floating ip create EXT_NET_ID
$ openstack floating ip add port FLOATING_IP_ID --port-id INTERNAL_VM_PORT_ID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a floating IP on a specific subnet in the external network.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack floating ip create EXT_NET_ID --subnet SUBNET_ID</screen>
                    <para>If there are multiple subnets in the external network, you can choose a specific
subnet based on quality and costs.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a floating IP address and associates it with a port, in a single step.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack floating ip create --port INTERNAL_VM_PORT_ID EXT_NET_ID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists floating IPs</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack floating ip list</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Finds floating IP for a specified VM port.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack floating ip list --port INTERNAL_VM_PORT_ID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Disassociates a floating IP address.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack floating ip remove port FLOATING_IP_ID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Deletes the floating IP address.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack floating ip delete FLOATING_IP_ID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Clears the gateway.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack router unset --external-gateway router1</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Removes the interfaces from the router.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack router remove subnet router1 SUBNET_ID</screen>
                    <para>If this subnet ID is the last subnet on the port, this operation deletes the port itself.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Deletes the router.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack router delete router1</screen>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
        </sect3>
      </sect2>
      <sect2>
        <title>Security groups</title>
        <para>Security groups and security group rules allow administrators and
projects to specify the type of traffic and direction
(ingress/egress) that is allowed to pass through a port. A security
group is a container for security group rules.</para>
        <para>When a port is created in Networking it is associated with a security
group. If a security group is not specified the port is associated with
a 'default' security group. By default, this group drops all ingress
traffic and allows all egress. Rules can be added to this group in order
to change the behavior.</para>
        <para>To use the Compute security group APIs or use Compute to orchestrate the
creation of ports for instances on specific security groups, you must
complete additional configuration. You must configure the
<literal>/etc/nova/nova.conf</literal> file and set the <literal>security_group_api=neutron</literal>
option on every node that runs nova-compute and nova-api. After you make
this change, restart nova-api and nova-compute to pick up this change.
Then, you can use both the Compute and OpenStack Network security group
APIs at the same time.</para>
        <note>
          <itemizedlist>
            <listitem>
              <para>To use the Compute security group API with Networking, the
Networking plug-in must implement the security group API. The
following plug-ins currently implement this: ML2, Open vSwitch,
Linux Bridge, NEC, and VMware NSX.</para>
            </listitem>
            <listitem>
              <para>You must configure the correct firewall driver in the
<literal>securitygroup</literal> section of the plug-in/agent configuration
file. Some plug-ins and agents, such as Linux Bridge Agent and
Open vSwitch Agent, use the no-operation driver as the default,
which results in non-working security groups.</para>
            </listitem>
            <listitem>
              <para>When using the security group API through Compute, security
groups are applied to all ports on an instance. The reason for
this is that Compute security group APIs are instances based and
not port based as Networking.</para>
            </listitem>
          </itemizedlist>
        </note>
        <sect3>
          <title>Basic security group operations</title>
          <para>This table shows example neutron commands that enable you to complete
basic security group operations:</para>
          <table>
            <title>Basic security group operations</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="37.5*"/>
              <colspec colname="c2" colwidth="62.5*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operation</para>
                  </entry>
                  <entry>
                    <para>Command</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Creates a security group for our web servers.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack security group create webservers \
 --description "security group for webservers"</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists security groups.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack security group list</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a security group rule to allow port 80 ingress.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack security group rule create --ingress \
  --protocol tcp SECURITY_GROUP_UUID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists security group rules.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack security group rule list</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Deletes a security group rule.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack security group rule delete SECURITY_GROUP_RULE_UUID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Deletes a security group.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack security group delete SECURITY_GROUP_UUID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a port and associates two security groups.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack port create port1 --security-group SECURITY_GROUP_ID1 \
  --security-group SECURITY_GROUP_ID2 --network NETWORK_ID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Removes security groups from a port.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack port set --no-security-group PORT_ID</screen>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
        </sect3>
      </sect2>
      <sect2>
        <title>Basic Load-Balancer-as-a-Service operations</title>
        <note>
          <para>The Load-Balancer-as-a-Service (LBaaS) API provisions and configures
load balancers. The reference implementation is based on the HAProxy
software load balancer.</para>
        </note>
        <para>This list shows example neutron commands that enable you to complete
basic LBaaS operations:</para>
        <itemizedlist>
          <listitem>
            <para>Creates a load balancer pool by using specific provider.</para>
            <para><literal>--provider</literal> is an optional argument. If not used, the pool is
created with default provider for LBaaS service. You should configure
the default provider in the <literal>[service_providers]</literal> section of the
<literal>neutron.conf</literal> file. If no default provider is specified for LBaaS,
the <literal>--provider</literal> parameter is required for pool creation.</para>
            <screen language="console">$ neutron lb-pool-create --lb-method ROUND_ROBIN --name mypool \
  --protocol HTTP --subnet-id SUBNET_UUID --provider PROVIDER_NAME</screen>
          </listitem>
          <listitem>
            <para>Associates two web servers with pool.</para>
            <screen language="console">$ neutron lb-member-create --address  WEBSERVER1_IP --protocol-port 80 mypool
$ neutron lb-member-create --address  WEBSERVER2_IP --protocol-port 80 mypool</screen>
          </listitem>
          <listitem>
            <para>Creates a health monitor that checks to make sure our instances are
still running on the specified protocol-port.</para>
            <screen language="console">$ neutron lb-healthmonitor-create --delay 3 --type HTTP --max-retries 3 \
  --timeout 3</screen>
          </listitem>
          <listitem>
            <para>Associates a health monitor with pool.</para>
            <screen language="console">$ neutron lb-healthmonitor-associate  HEALTHMONITOR_UUID mypool</screen>
          </listitem>
          <listitem>
            <para>Creates a virtual IP (VIP) address that, when accessed through the
load balancer, directs the requests to one of the pool members.</para>
            <screen language="console">$ neutron lb-vip-create --name myvip --protocol-port 80 --protocol \
  HTTP --subnet-id SUBNET_UUID mypool</screen>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>Plug-in specific extensions</title>
        <para>Each vendor can choose to implement additional API extensions to the
core API. This section describes the extensions for each plug-in.</para>
        <sect3>
          <title>VMware NSX extensions</title>
          <para>These sections explain NSX plug-in extensions.</para>
          <sect4>
            <title>VMware NSX QoS extension</title>
            <para>The VMware NSX QoS extension rate-limits network ports to guarantee a
specific amount of bandwidth for each port. This extension, by default,
is only accessible by a project with an admin role but is configurable
through the <literal>policy.json</literal> file. To use this extension, create a queue
and specify the min/max bandwidth rates (kbps) and optionally set the
QoS Marking and DSCP value (if your network fabric uses these values to
make forwarding decisions). Once created, you can associate a queue with
a network. Then, when ports are created on that network they are
automatically created and associated with the specific queue size that
was associated with the network. Because one size queue for a every port
on a network might not be optimal, a scaling factor from the nova flavor
<literal>rxtx_factor</literal> is passed in from Compute when creating the port to scale
the queue.</para>
            <para>Lastly, if you want to set a specific baseline QoS policy for the amount
of bandwidth a single port can use (unless a network queue is specified
with the network a port is created on) a default queue can be created in
Networking which then causes ports created to be associated with a queue
of that size times the rxtx scaling factor. Note that after a network or
default queue is specified, queues are added to ports that are
subsequently created but are not added to existing ports.</para>
            <sect5>
              <title>Basic VMware NSX QoS operations</title>
              <para>This table shows example neutron commands that enable you to complete
basic queue operations:</para>
              <table>
                <title>Basic VMware NSX QoS operations</title>
                <tgroup cols="2">
                  <colspec colname="c1" colwidth="37.5*"/>
                  <colspec colname="c2" colwidth="62.5*"/>
                  <thead>
                    <row>
                      <entry>
                        <para>Operation</para>
                      </entry>
                      <entry>
                        <para>Command</para>
                      </entry>
                    </row>
                  </thead>
                  <tbody>
                    <row>
                      <entry>
                        <para>Creates QoS queue (admin-only).</para>
                      </entry>
                      <entry>
                        <screen language="console">$ neutron queue-create --min 10 --max 1000 myqueue</screen>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>Associates a queue with a network.</para>
                      </entry>
                      <entry>
                        <screen language="console">$ neutron net-create network --queue_id QUEUE_ID</screen>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>Creates a default system queue.</para>
                      </entry>
                      <entry>
                        <screen language="console">$ neutron queue-create --default True --min 10 --max 2000 default</screen>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>Lists QoS queues.</para>
                      </entry>
                      <entry>
                        <screen language="console">$ neutron queue-list</screen>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>Deletes a QoS queue.</para>
                      </entry>
                      <entry>
                        <screen language="console">$ neutron queue-delete QUEUE_ID_OR_NAME</screen>
                      </entry>
                    </row>
                  </tbody>
                </tgroup>
              </table>
            </sect5>
          </sect4>
          <sect4>
            <title>VMware NSX provider networks extension</title>
            <para>Provider networks can be implemented in different ways by the underlying
NSX platform.</para>
            <para>The <emphasis>FLAT</emphasis> and <emphasis>VLAN</emphasis> network types use bridged transport connectors.
These network types enable the attachment of large number of ports. To
handle the increased scale, the NSX plug-in can back a single OpenStack
Network with a chain of NSX logical switches. You can specify the
maximum number of ports on each logical switch in this chain on the
<literal>max_lp_per_bridged_ls</literal> parameter, which has a default value of 5,000.</para>
            <para>The recommended value for this parameter varies with the NSX version
running in the back-end, as shown in the following table.</para>
            <para>
              <emphasis role="bold">Recommended values for max_lp_per_bridged_ls</emphasis>
            </para>
            <informaltable>
              <tgroup cols="2">
                <colspec colname="c1" colwidth="41.7*"/>
                <colspec colname="c2" colwidth="58.3*"/>
                <thead>
                  <row>
                    <entry>
                      <para>NSX version</para>
                    </entry>
                    <entry>
                      <para>Recommended Value</para>
                    </entry>
                  </row>
                </thead>
                <tbody>
                  <row>
                    <entry>
                      <para>2.x</para>
                    </entry>
                    <entry>
                      <para>64</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>3.0.x</para>
                    </entry>
                    <entry>
                      <para>5,000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>3.1.x</para>
                    </entry>
                    <entry>
                      <para>5,000</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>3.2.x</para>
                    </entry>
                    <entry>
                      <para>10,000</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </informaltable>
            <para>In addition to these network types, the NSX plug-in also supports a
special <emphasis>l3_ext</emphasis> network type, which maps external networks to specific
NSX gateway services as discussed in the next section.</para>
          </sect4>
          <sect4>
            <title>VMware NSX L3 extension</title>
            <para>NSX exposes its L3 capabilities through gateway services which are
usually configured out of band from OpenStack. To use NSX with L3
capabilities, first create an L3 gateway service in the NSX Manager.
Next, in <literal>/etc/neutron/plugins/vmware/nsx.ini</literal> set
<literal>default_l3_gw_service_uuid</literal> to this value. By default, routers are
mapped to this gateway service.</para>
            <sect5>
              <title>VMware NSX L3 extension operations</title>
              <para>Create external network and map it to a specific NSX gateway service:</para>
              <screen language="console">$ openstack network create public --external --provider-network-type l3_ext \
--provider-physical-network L3_GATEWAY_SERVICE_UUID</screen>
              <para>Terminate traffic on a specific VLAN from a NSX gateway service:</para>
              <screen language="console">$ openstack network create public --external --provider-network-type l3_ext \
--provider-physical-network L3_GATEWAY_SERVICE_UUID --provider-segment VLAN_ID</screen>
            </sect5>
          </sect4>
          <sect4>
            <title>Operational status synchronization in the VMware NSX plug-in</title>
            <para>Starting with the Havana release, the VMware NSX plug-in provides an
asynchronous mechanism for retrieving the operational status for neutron
resources from the NSX back-end; this applies to <emphasis>network</emphasis>, <emphasis>port</emphasis>, and
<emphasis>router</emphasis> resources.</para>
            <para>The back-end is polled periodically and the status for every resource is
retrieved; then the status in the Networking database is updated only
for the resources for which a status change occurred. As operational
status is now retrieved asynchronously, performance for <literal>GET</literal>
operations is consistently improved.</para>
            <para>Data to retrieve from the back-end are divided in chunks in order to
avoid expensive API requests; this is achieved leveraging NSX APIs
response paging capabilities. The minimum chunk size can be specified
using a configuration option; the actual chunk size is then determined
dynamically according to: total number of resources to retrieve,
interval between two synchronization task runs, minimum delay between
two subsequent requests to the NSX back-end.</para>
            <para>The operational status synchronization can be tuned or disabled using
the configuration options reported in this table; it is however worth
noting that the default values work fine in most cases.</para>
            <table>
              <title>Configuration options for tuning operational status synchronization in the NSX plug-in</title>
              <tgroup cols="5">
                <colspec colname="c1" colwidth="13.3*"/>
                <colspec colname="c2" colwidth="13.3*"/>
                <colspec colname="c3" colwidth="13.3*"/>
                <colspec colname="c4" colwidth="13.3*"/>
                <colspec colname="c5" colwidth="46.7*"/>
                <thead>
                  <row>
                    <entry>
                      <para>Option name</para>
                    </entry>
                    <entry>
                      <para>Group</para>
                    </entry>
                    <entry>
                      <para>Default value</para>
                    </entry>
                    <entry>
                      <para>Type and constraints</para>
                    </entry>
                    <entry>
                      <para>Notes</para>
                    </entry>
                  </row>
                </thead>
                <tbody>
                  <row>
                    <entry>
                      <para>
                        <literal>state_sync_interval</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>
                        <literal>nsx_sync</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>10 seconds</para>
                    </entry>
                    <entry>
                      <para>Integer; no constraint.</para>
                    </entry>
                    <entry>
                      <para>Interval in seconds between two run of the synchronization task. If the
synchronization task takes more than <literal>state_sync_interval</literal> seconds to
execute, a new instance of the task is started as soon as the other is
completed. Setting the value for this option to 0 will disable the
synchronization task.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>max_random_sync_delay</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>
                        <literal>nsx_sync</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>0 seconds</para>
                    </entry>
                    <entry>
                      <para>Integer. Must not exceed <literal>min_sync_req_delay</literal></para>
                    </entry>
                    <entry>
                      <para>When different from zero, a random delay between 0 and
<literal>max_random_sync_delay</literal> will be added before processing the next
chunk.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>min_sync_req_delay</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>
                        <literal>nsx_sync</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>1 second</para>
                    </entry>
                    <entry>
                      <para>Integer. Must not exceed <literal>state_sync_interval</literal>.</para>
                    </entry>
                    <entry>
                      <para>The value of this option can be tuned according to the observed
load on the NSX controllers. Lower values will result in faster
synchronization, but might increase the load on the controller cluster.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>min_chunk_size</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>
                        <literal>nsx_sync</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>500 resources</para>
                    </entry>
                    <entry>
                      <para>Integer; no constraint.</para>
                    </entry>
                    <entry>
                      <para>Minimum number of resources to retrieve from the back-end for each
synchronization chunk. The expected number of synchronization chunks
is given by the ratio between <literal>state_sync_interval</literal> and
<literal>min_sync_req_delay</literal>. This size of a chunk might increase if the
total number of resources is such that more than <literal>min_chunk_size</literal>
resources must be fetched in one chunk with the current number of
chunks.</para>
                    </entry>
                  </row>
                  <row>
                    <entry>
                      <para>
                        <literal>always_read_status</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>
                        <literal>nsx_sync</literal>
                      </para>
                    </entry>
                    <entry>
                      <para>False</para>
                    </entry>
                    <entry>
                      <para>Boolean; no constraint.</para>
                    </entry>
                    <entry>
                      <para>When this option is enabled, the operational status will always be
retrieved from the NSX back-end ad every <literal>GET</literal> request. In this
case it is advisable to disable the synchronization task.</para>
                    </entry>
                  </row>
                </tbody>
              </tgroup>
            </table>
            <para>When running multiple OpenStack Networking server instances, the status
synchronization task should not run on every node; doing so sends
unnecessary traffic to the NSX back-end and performs unnecessary DB
operations. Set the <literal>state_sync_interval</literal> configuration option to a
non-zero value exclusively on a node designated for back-end status
synchronization.</para>
            <para>The <literal>fields=status</literal> parameter in Networking API requests always
triggers an explicit query to the NSX back end, even when you enable
asynchronous state synchronization. For example, <literal>GET
/v2.0/networks/NET_ID?fields=status&amp;fields=name</literal>.</para>
          </sect4>
        </sect3>
        <sect3>
          <title>Big Switch plug-in extensions</title>
          <para>This section explains the Big Switch neutron plug-in-specific extension.</para>
          <sect4>
            <title>Big Switch router rules</title>
            <para>Big Switch allows router rules to be added to each project router. These
rules can be used to enforce routing policies such as denying traffic
between subnets or traffic to external networks. By enforcing these at
the router level, network segmentation policies can be enforced across
many VMs that have differing security groups.</para>
            <sect5>
              <title>Router rule attributes</title>
              <para>Each project router has a set of router rules associated with it. Each
router rule has the attributes in this table. Router rules and their
attributes can be set using the <command>openstack router set</command> command,
through the horizon interface or the Networking API.</para>
              <table>
                <title>Big Switch Router rule attributes</title>
                <tgroup cols="4">
                  <colspec colname="c1" colwidth="15.4*"/>
                  <colspec colname="c2" colwidth="15.4*"/>
                  <colspec colname="c3" colwidth="15.4*"/>
                  <colspec colname="c4" colwidth="53.8*"/>
                  <thead>
                    <row>
                      <entry>
                        <para>Attribute name</para>
                      </entry>
                      <entry>
                        <para>Required</para>
                      </entry>
                      <entry>
                        <para>Input type</para>
                      </entry>
                      <entry>
                        <para>Description</para>
                      </entry>
                    </row>
                  </thead>
                  <tbody>
                    <row>
                      <entry>
                        <para>source</para>
                      </entry>
                      <entry>
                        <para>Yes</para>
                      </entry>
                      <entry>
                        <para>A valid CIDR or one of the keywords 'any' or 'external'</para>
                      </entry>
                      <entry>
                        <para>The network that a packet's source IP must match for the
rule to be applied.</para>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>destination</para>
                      </entry>
                      <entry>
                        <para>Yes</para>
                      </entry>
                      <entry>
                        <para>A valid CIDR or one of the keywords 'any' or 'external'</para>
                      </entry>
                      <entry>
                        <para>The network that a packet's destination IP must match for the rule to
be applied.</para>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>action</para>
                      </entry>
                      <entry>
                        <para>Yes</para>
                      </entry>
                      <entry>
                        <para>'permit' or 'deny'</para>
                      </entry>
                      <entry>
                        <para>Determines whether or not the matched packets will allowed to cross the
router.</para>
                      </entry>
                    </row>
                    <row>
                      <entry>
                        <para>nexthop</para>
                      </entry>
                      <entry>
                        <para>No</para>
                      </entry>
                      <entry>
                        <para>A plus-separated (+) list of next-hop IP addresses. For example,
<literal>1.1.1.1+1.1.1.2</literal>.</para>
                      </entry>
                      <entry>
                        <para>Overrides the default virtual router used to handle traffic for packets
that match the rule.</para>
                      </entry>
                    </row>
                  </tbody>
                </tgroup>
              </table>
            </sect5>
            <sect5>
              <title>Order of rule processing</title>
              <para>The order of router rules has no effect. Overlapping rules are evaluated
using longest prefix matching on the source and destination fields. The
source field is matched first so it always takes higher precedence over
the destination field. In other words, longest prefix matching is used
on the destination field only if there are multiple matching rules with
the same source.</para>
            </sect5>
            <sect5>
              <title>Big Switch router rules operations</title>
              <para>Router rules are configured with a router update operation in OpenStack
Networking. The update overrides any previous rules so all rules must be
provided at the same time.</para>
              <para>Update a router with rules to permit traffic by default but block
traffic from external networks to the 10.10.10.0/24 subnet:</para>
              <screen language="console">$ neutron router-update ROUTER_UUID --router_rules type=dict list=true \
  source=any,destination=any,action=permit \
  source=external,destination=10.10.10.0/24,action=deny</screen>
              <para>Specify alternate next-hop addresses for a specific subnet:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ neutron router-update ROUTER_UUID --router_rules type=dict list=true  \
  source=any,destination=any,action=permit \
  source=10.10.10.0/24,destination=any,action=permit,nexthops=10.10.10.254+10.10.10.253</screen>
              <para>Block traffic between two subnets while allowing everything else:</para>
              <screen language="console">$ neutron router-update ROUTER_UUID --router_rules type=dict list=true \
  source=any,destination=any,action=permit \
  source=10.10.10.0/24,destination=10.20.20.20/24,action=deny</screen>
            </sect5>
          </sect4>
        </sect3>
      </sect2>
      <sect2>
        <title>L3 metering</title>
        <para>The L3 metering API extension enables administrators to configure IP
ranges and assign a specified label to them to be able to measure
traffic that goes through a virtual router.</para>
        <para>The L3 metering extension is decoupled from the technology that
implements the measurement. Two abstractions have been added: One is the
metering label that can contain metering rules. Because a metering label
is associated with a project, all virtual routers in this project are
associated with this label.</para>
        <sect3>
          <title>Basic L3 metering operations</title>
          <para>Only administrators can manage the L3 metering labels and rules.</para>
          <para>This table shows example <command>neutron</command> commands that enable you to
complete basic L3 metering operations:</para>
          <table>
            <title>Basic L3 operations</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="28.6*"/>
              <colspec colname="c2" colwidth="71.4*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operation</para>
                  </entry>
                  <entry>
                    <para>Command</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Creates a metering label.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label create LABEL1 \
  --description "DESCRIPTION_LABEL1"</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists metering labels.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label list</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Shows information for a specified label.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label show LABEL_UUID
$ openstack network meter label show LABEL1</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Deletes a metering label.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label delete LABEL_UUID
$ openstack network meter label delete LABEL1</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Creates a metering rule.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label rule create LABEL_UUID \
  --remote-ip-prefix CIDR \
  --direction DIRECTION --exclude</screen>
                    <para>For example:</para>
                    <screen language="console">$ openstack network meter label rule create label1 \
  --remote-ip-prefix 10.0.0.0/24 --direction ingress
$ openstack network meter label rule create label1 \
  --remote-ip-prefix 20.0.0.0/24 --exclude</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists metering all label rules.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label rule list</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Shows information for a specified label rule.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label rule show RULE_UUID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Deletes a metering label rule.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ openstack network meter label rule delete RULE_UUID</screen>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>Lists the value of created metering label rules.</para>
                  </entry>
                  <entry>
                    <screen language="console">$ ceilometer sample-list -m bandwidth -q resource=LABEL_UUID</screen>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Advanced operational features</title>
      <sect2>
        <title>Logging settings</title>
        <para>Networking components use Python logging module to do logging. Logging
configuration can be provided in <literal>neutron.conf</literal> or as command-line
options. Command options override ones in <literal>neutron.conf</literal>.</para>
        <para>To configure logging for Networking components, use one of these
methods:</para>
        <itemizedlist>
          <listitem>
            <para>Provide logging settings in a logging configuration file.</para>
            <para>See <link xlink:href="http://docs.python.org/howto/logging.html">Python logging
how-to</link> to learn more
about logging.</para>
          </listitem>
          <listitem>
            <para>Provide logging setting in <literal>neutron.conf</literal>.</para>
            <screen language="ini">[DEFAULT]
# Default log level is WARNING
# Show debugging output in logs (sets DEBUG log level output)
# debug = False

# log_date_format = %Y-%m-%d %H:%M:%S

# use_syslog = False
# syslog_log_facility = LOG_USER

# if use_syslog is False, we can set log_file and log_dir.
# if use_syslog is False and we do not set log_file,
# the log will be printed to stdout.
# log_file =
# log_dir =</screen>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>Notifications</title>
        <para>Notifications can be sent when Networking resources such as network,
subnet and port are created, updated or deleted.</para>
        <sect3>
          <title>Notification options</title>
          <para>To support DHCP agent, <literal>rpc_notifier</literal> driver must be set. To set up the
notification, edit notification options in <literal>neutron.conf</literal>:</para>
          <screen language="ini"># Driver or drivers to handle sending notifications. (multi
# valued)
# notification_driver=messagingv2

# AMQP topic used for OpenStack notifications. (list value)
# Deprecated group/name - [rpc_notifier2]/topics
notification_topics = notifications</screen>
        </sect3>
        <sect3>
          <title>Setting cases</title>
          <sect4>
            <title>Logging and RPC</title>
            <para>These options configure the Networking server to send notifications
through logging and RPC. The logging options are described in OpenStack
Configuration Reference. RPC notifications go to <literal>notifications.info</literal>
queue bound to a topic exchange defined by <literal>control_exchange</literal> in
<literal>neutron.conf</literal>.</para>
            <para>
              <emphasis role="bold">Notification System Options</emphasis>
            </para>
            <para>A notification can be sent when a network, subnet, or port is created,
updated or deleted. The notification system options are:</para>
            <itemizedlist>
              <listitem>
                <variablelist>
                  <varlistentry>
                    <term>
                      <literal>notification_driver</literal>
                    </term>
                    <listitem>
                      <para>Defines the driver or drivers to handle the sending of a notification.
The six available options are:</para>
                      <itemizedlist>
                        <listitem>
                          <variablelist>
                            <varlistentry>
                              <term>
                                <literal>messaging</literal>
                              </term>
                              <listitem>
                                <para>Send notifications using the 1.0 message format.</para>
                              </listitem>
                            </varlistentry>
                          </variablelist>
                        </listitem>
                        <listitem>
                          <variablelist>
                            <varlistentry>
                              <term>
                                <literal>messagingv2</literal>
                              </term>
                              <listitem>
                                <para>Send notifications using the 2.0 message format (with a message
envelope).</para>
                              </listitem>
                            </varlistentry>
                          </variablelist>
                        </listitem>
                        <listitem>
                          <variablelist>
                            <varlistentry>
                              <term>
                                <literal>routing</literal>
                              </term>
                              <listitem>
                                <para>Configurable routing notifier (by priority or event_type).</para>
                              </listitem>
                            </varlistentry>
                          </variablelist>
                        </listitem>
                        <listitem>
                          <variablelist>
                            <varlistentry>
                              <term>
                                <literal>log</literal>
                              </term>
                              <listitem>
                                <para>Publish notifications using Python logging infrastructure.</para>
                              </listitem>
                            </varlistentry>
                          </variablelist>
                        </listitem>
                        <listitem>
                          <variablelist>
                            <varlistentry>
                              <term>
                                <literal>test</literal>
                              </term>
                              <listitem>
                                <para>Store notifications in memory for test verification.</para>
                              </listitem>
                            </varlistentry>
                          </variablelist>
                        </listitem>
                        <listitem>
                          <variablelist>
                            <varlistentry>
                              <term>
                                <literal>noop</literal>
                              </term>
                              <listitem>
                                <para>Disable sending notifications entirely.</para>
                              </listitem>
                            </varlistentry>
                          </variablelist>
                        </listitem>
                      </itemizedlist>
                    </listitem>
                  </varlistentry>
                </variablelist>
              </listitem>
              <listitem>
                <variablelist>
                  <varlistentry>
                    <term>
                      <literal>default_notification_level</literal>
                    </term>
                    <listitem>
                      <para>Is used to form topic names or to set a logging level.</para>
                    </listitem>
                  </varlistentry>
                </variablelist>
              </listitem>
              <listitem>
                <variablelist>
                  <varlistentry>
                    <term>
                      <literal>default_publisher_id</literal>
                    </term>
                    <listitem>
                      <para>Is a part of the notification payload.</para>
                    </listitem>
                  </varlistentry>
                </variablelist>
              </listitem>
              <listitem>
                <variablelist>
                  <varlistentry>
                    <term>
                      <literal>notification_topics</literal>
                    </term>
                    <listitem>
                      <para>AMQP topic used for OpenStack notifications. They can be comma-separated
values. The actual topic names will be the values of
<literal>default_notification_level</literal>.</para>
                    </listitem>
                  </varlistentry>
                </variablelist>
              </listitem>
              <listitem>
                <variablelist>
                  <varlistentry>
                    <term>
                      <literal>control_exchange</literal>
                    </term>
                    <listitem>
                      <para>This is an option defined in oslo.messaging. It is the default exchange
under which topics are scoped. May be overridden by an exchange name
specified in the <literal>transport_url</literal> option. It is a string value.</para>
                    </listitem>
                  </varlistentry>
                </variablelist>
              </listitem>
            </itemizedlist>
            <para>Below is a sample <literal>neutron.conf</literal> configuration file:</para>
            <screen language="ini">notification_driver = messagingv2

default_notification_level = INFO

host = myhost.com
default_publisher_id = $host

notification_topics = notifications

control_exchange = openstack</screen>
          </sect4>
        </sect3>
      </sect2>
    </sect1>
    <sect1 xml:id="authentication-and-authorization">
      <title>Authentication and authorization</title>
      <para>Networking uses the Identity service as the default authentication
service. When the Identity service is enabled, users who submit requests
to the Networking service must provide an authentication token in
<literal>X-Auth-Token</literal> request header. Users obtain this token by
authenticating with the Identity service endpoint. For more information
about authentication with the Identity service, see <link xlink:href="http://developer.openstack.org/api-ref/identity/v2/">OpenStack Identity
service API v2.0
Reference</link>.
When the Identity service is enabled, it is not mandatory to specify the
project ID for resources in create requests because the project ID is
derived from the authentication token.</para>
      <para>The default authorization settings only allow administrative users
to create resources on behalf of a different project. Networking uses
information received from Identity to authorize user requests.
Networking handles two kind of authorization policies:</para>
      <itemizedlist>
        <listitem>
          <para><emphasis role="bold">Operation-based</emphasis> policies specify access criteria for specific
operations, possibly with fine-grained control over specific
attributes.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Resource-based</emphasis> policies specify whether access to specific
resource is granted or not according to the permissions configured
for the resource (currently available only for the network resource).
The actual authorization policies enforced in Networking might vary
from deployment to deployment.</para>
        </listitem>
      </itemizedlist>
      <para>The policy engine reads entries from the <literal>policy.json</literal> file. The
actual location of this file might vary from distribution to
distribution. Entries can be updated while the system is running, and no
service restart is required. Every time the policy file is updated, the
policies are automatically reloaded. Currently the only way of updating
such policies is to edit the policy file. In this section, the terms
<emphasis>policy</emphasis> and <emphasis>rule</emphasis> refer to objects that are specified in the same way
in the policy file. There are no syntax differences between a rule and a
policy. A policy is something that is matched directly from the
Networking policy engine. A rule is an element in a policy, which is
evaluated. For instance in <literal>"create_subnet":
"rule:admin_or_network_owner"</literal>, <emphasis>create_subnet</emphasis> is a
policy, and <emphasis>admin_or_network_owner</emphasis> is a rule.</para>
      <para>Policies are triggered by the Networking policy engine whenever one of
them matches a Networking API operation or a specific attribute being
used in a given operation. For instance the <literal>create_subnet</literal> policy is
triggered every time a <literal>POST /v2.0/subnets</literal> request is sent to the
Networking server; on the other hand <literal>create_network:shared</literal> is
triggered every time the <emphasis>shared</emphasis> attribute is explicitly specified (and
set to a value different from its default) in a <literal>POST /v2.0/networks</literal>
request. It is also worth mentioning that policies can also be related
to specific API extensions; for instance
<literal>extension:provider_network:set</literal> is triggered if the attributes
defined by the Provider Network extensions are specified in an API
request.</para>
      <para>An authorization policy can be composed by one or more rules. If more
rules are specified then the evaluation policy succeeds if any of the
rules evaluates successfully; if an API operation matches multiple
policies, then all the policies must evaluate successfully. Also,
authorization rules are recursive. Once a rule is matched, the rule(s)
can be resolved to another rule, until a terminal rule is reached.</para>
      <para>The Networking policy engine currently defines the following kinds of
terminal rules:</para>
      <itemizedlist>
        <listitem>
          <para><emphasis role="bold">Role-based rules</emphasis> evaluate successfully if the user who submits
the request has the specified role. For instance <literal>"role:admin"</literal> is
successful if the user who submits the request is an administrator.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Field-based rules</emphasis> evaluate successfully if a field of the
resource specified in the current request matches a specific value.
For instance <literal>"field:networks:shared=True"</literal> is successful if the
<literal>shared</literal> attribute of the <literal>network</literal> resource is set to true.</para>
        </listitem>
        <listitem>
          <para><emphasis role="bold">Generic rules</emphasis> compare an attribute in the resource with an
attribute extracted from the user's security credentials and
evaluates successfully if the comparison is successful. For instance
<literal>"tenant_id:%(tenant_id)s"</literal> is successful if the project identifier
in the resource is equal to the project identifier of the user
submitting the request.</para>
        </listitem>
      </itemizedlist>
      <para>This extract is from the default <literal>policy.json</literal> file:</para>
      <itemizedlist>
        <listitem>
          <para>A rule that evaluates successfully if the current user is an
administrator or the owner of the resource specified in the request
(project identifier is equal).</para>
          <screen language="json">{
 "admin_or_owner": [
     [
         "role:admin"
     ],
     [
         "tenant_id:%(tenant_id)s"
     ]
 ],
 "admin_or_network_owner": [
     [
         "role:admin"
     ],
     [
         "tenant_id:%(network_tenant_id)s"
     ]
 ],
 "admin_only": [
     [
         "role:admin"
 ]
 ],
 "regular_user": [],
 "shared": [
     [
         "field:networks:shared=True"
     ]
 ],
 "default": [
     [</screen>
        </listitem>
        <listitem>
          <para>The default policy that is always evaluated if an API operation does
not match any of the policies in <literal>policy.json</literal>.</para>
          <screen language="json">        "rule:admin_or_owner"
    ]
],
"create_subnet": [
    [
        "rule:admin_or_network_owner"
    ]
],
"get_subnet": [
    [
        "rule:admin_or_owner"
    ],
    [
        "rule:shared"
    ]
],
"update_subnet": [
    [
        "rule:admin_or_network_owner"
    ]
],
"delete_subnet": [
    [
        "rule:admin_or_network_owner"
    ]
],
"create_network": [],
"get_network": [
    [
        "rule:admin_or_owner"
    ],</screen>
        </listitem>
        <listitem>
          <para>This policy evaluates successfully if either <emphasis>admin_or_owner</emphasis>, or
<emphasis>shared</emphasis> evaluates successfully.</para>
          <screen language="json">    [
        "rule:shared"
    ]
],
"create_network:shared": [
    [
        "rule:admin_only"
    ]</screen>
        </listitem>
        <listitem>
          <para>This policy restricts the ability to manipulate the <emphasis>shared</emphasis>
attribute for a network to administrators only.</para>
          <screen language="json">],
"update_network": [
    [
        "rule:admin_or_owner"
    ]
],
"delete_network": [
    [
        "rule:admin_or_owner"
    ]
],
"create_port": [],
"create_port:mac_address": [
    [
        "rule:admin_or_network_owner"
    ]
],
"create_port:fixed_ips": [</screen>
        </listitem>
        <listitem>
          <para>This policy restricts the ability to manipulate the <emphasis>mac_address</emphasis>
attribute for a port only to administrators and the owner of the
network where the port is attached.</para>
          <screen language="json">     [
         "rule:admin_or_network_owner"
     ]
 ],
 "get_port": [
     [
         "rule:admin_or_owner"
     ]
 ],
 "update_port": [
     [
         "rule:admin_or_owner"
     ]
 ],
  "delete_port": [
     [
         "rule:admin_or_owner"
     ]
 ]
}</screen>
        </listitem>
      </itemizedlist>
      <para>In some cases, some operations are restricted to administrators only.
This example shows you how to modify a policy file to permit project to
define networks, see their resources, and permit administrative users to
perform all other operations:</para>
      <screen language="ini">{
        "admin_or_owner": [["role:admin"], ["tenant_id:%(tenant_id)s"]],
        "admin_only": [["role:admin"]], "regular_user": [],
        "default": [["rule:admin_only"]],
        "create_subnet": [["rule:admin_only"]],
        "get_subnet": [["rule:admin_or_owner"]],
        "update_subnet": [["rule:admin_only"]],
        "delete_subnet": [["rule:admin_only"]],
        "create_network": [],
        "get_network": [["rule:admin_or_owner"]],
        "create_network:shared": [["rule:admin_only"]],
        "update_network": [["rule:admin_or_owner"]],
        "delete_network": [["rule:admin_or_owner"]],
        "create_port": [["rule:admin_only"]],
        "get_port": [["rule:admin_or_owner"]],
        "update_port": [["rule:admin_only"]],
        "delete_port": [["rule:admin_only"]]
}</screen>
    </sect1>
  </chapter>
  <chapter>
    <title>Telemetry</title>
    <info/>
    <para>Even in the cloud industry, providers must use a multi-step process
for billing. The required steps to bill for usage in a cloud
environment are metering, rating, and billing. Because the provider's
requirements may be far too specific for a shared solution, rating
and billing solutions cannot be designed in a common module that
satisfies all. Providing users with measurements on cloud services is
required to meet the <literal>measured service</literal> definition of cloud computing.</para>
    <para>The Telemetry service was originally designed to support billing
systems for OpenStack cloud resources. This project only covers the
metering portion of the required processing for billing. This service
collects information about the system and stores it in the form of
samples in order to provide data about anything that can be billed.</para>
    <para>In addition to system measurements, the Telemetry service also
captures event notifications triggered when various actions are
executed in the OpenStack system. This data is captured as Events and
stored alongside metering data.</para>
    <para>The list of meters is continuously growing, which makes it possible
to use the data collected by Telemetry for different purposes, other
than billing. For example, the autoscaling feature in the
Orchestration service can be triggered by alarms this module sets and
then gets notified within Telemetry.</para>
    <para>The sections in this document contain information about the
architecture and usage of Telemetry. The first section contains a
brief summary about the system architecture used in a typical
OpenStack deployment. The second section describes the data
collection mechanisms. You can also read about alarming to understand
how alarm definitions can be posted to Telemetry and what actions can
happen if an alarm is raised. The last section contains a
troubleshooting guide, which mentions error situations and possible
solutions to the problems.</para>
    <para>You can retrieve the collected samples in three different ways: with
the REST API, with the command-line interface, or with the Metering
tab on an OpenStack dashboard.</para>
    <sect1 xml:id="telemetry-system-architecture">
      <title>System architecture</title>
      <para>The Telemetry service uses an agent-based architecture. Several modules
combine their responsibilities to collect data, store samples in a
database, or provide an API service for handling incoming requests.</para>
      <para>The Telemetry service is built from the following agents and services:</para>
      <variablelist>
        <varlistentry>
          <term>ceilometer-api</term>
          <listitem>
            <para>Presents aggregated metering data to consumers (such as billing
engines and analytics tools).</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-polling</term>
          <listitem>
            <para>Polls for different kinds of meter data by using the polling
plug-ins (pollsters) registered in different namespaces. It provides a
single polling interface across different namespaces.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-agent-central</term>
          <listitem>
            <para>Polls the public RESTful APIs of other OpenStack services such as
Compute service and Image service, in order to keep tabs on resource
existence, by using the polling plug-ins (pollsters) registered in
the central polling namespace.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-agent-compute</term>
          <listitem>
            <para>Polls the local hypervisor or libvirt daemon to acquire performance
data for the local instances, messages and emits the data as AMQP
messages, by using the polling plug-ins (pollsters) registered in
the compute polling namespace.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-agent-ipmi</term>
          <listitem>
            <para>Polls the local node with IPMI support, in order to acquire IPMI
sensor data and Intel Node Manager data, by using the polling
plug-ins (pollsters) registered in the IPMI polling namespace.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-agent-notification</term>
          <listitem>
            <para>Consumes AMQP messages from other OpenStack services.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-collector</term>
          <listitem>
            <para>Consumes AMQP notifications from the agents, then dispatches these
data to the appropriate data store.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-alarm-evaluator</term>
          <listitem>
            <para>Determines when alarms fire due to the associated statistic trend
crossing a threshold over a sliding time window.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ceilometer-alarm-notifier</term>
          <listitem>
            <para>Initiates alarm actions, for example calling out to a webhook with a
description of the alarm state transition.</para>
            <note>
              <procedure>
                <step>
                  <para>The <literal>ceilometer-polling</literal> service is available since the Kilo release.
It is intended to replace <literal>ceilometer-agent-central</literal>,
<literal>ceilometer-agent-compute</literal>, and <literal>ceilometer-agent-ipmi</literal>.</para>
                </step>
                <!--<step>
                  <para>The <literal>ceilometer-api</literal> and <literal>ceilometer-collector</literal> are no longer
supported since the Ocata release.</para>
                </step>-->
                <step>
                  <para>The <literal>ceilometer-alarm-evaluator</literal> and <literal>ceilometer-alarm-notifier</literal>
services are removed in Mitaka release.</para>
                </step>
              </procedure>
            </note>
          </listitem>
        </varlistentry>
      </variablelist>
      <para>Except for the <literal>ceilometer-agent-compute</literal> and the <literal>ceilometer-agent-ipmi</literal>
services, all the other services are placed on one or more controller
nodes.</para>
      <para>The Telemetry architecture highly depends on the AMQP service both for
consuming notifications coming from OpenStack services and internal
communication.</para>
      <sect2 xml:id="telemetry-supported-databases">
        <title>Supported databases</title>
        <para>The other key external component of Telemetry is the database, where
events, samples, alarm definitions, and alarms are stored.</para>
        <note>
          <para>Multiple database back ends can be configured in order to store
events, samples, and alarms separately. We recommend Gnocchi for
time-series storage.</para>
        </note>
        <para>The list of supported database back ends:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="http://gnocchi.xyz/">Gnocchi</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://www.elastic.co/">ElasticSearch (events only)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://www.mongodb.org/">MongoDB</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://www.mysql.com/">MySQL</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://www.postgresql.org/">PostgreSQL</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://hbase.apache.org/">HBase</link>
            </para>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2 xml:id="telemetry-supported-hypervisors">
        <title>Supported hypervisors</title>
        <para>The Telemetry service collects information about the virtual machines,
which requires close connection to the hypervisor that runs on the
compute hosts.</para>
        <para>The following is a list of supported hypervisors.</para>
        <itemizedlist>
          <listitem>
            <para>The following hypervisors are supported via <link xlink:href="http://libvirt.org/">libvirt</link></para>
            <itemizedlist>
              <listitem>
                <para>
                  <link xlink:href="http://www.linux-kvm.org/page/Main_Page">Kernel-based Virtual Machine (KVM)</link>
                </para>
              </listitem>
              <listitem>
                <para>
                  <link xlink:href="http://wiki.qemu.org/Main_Page">Quick Emulator (QEMU)</link>
                </para>
              </listitem>
              <listitem>
                <para>
                  <link xlink:href="https://linuxcontainers.org/">Linux Containers (LXC)</link>
                </para>
              </listitem>
              <listitem>
                <para>
                  <link xlink:href="http://user-mode-linux.sourceforge.net/">User-mode Linux (UML)</link>
                </para>
              </listitem>
            </itemizedlist>
            <note>
              <para>For details about hypervisor support in libvirt please check the
<link xlink:href="http://libvirt.org/hvsupport.html">Libvirt API support matrix</link>.</para>
            </note>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://www.microsoft.com/en-us/server-cloud/hyper-v-server/default.aspx">Hyper-V</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://www.xenproject.org/help/documentation.html">XEN</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://www.vmware.com/products/vsphere-hypervisor/support.html">VMware vSphere</link>
            </para>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>Supported networking services</title>
        <para>Telemetry is able to retrieve information from OpenStack Networking and
external networking services:</para>
        <itemizedlist>
          <listitem>
            <para>OpenStack Networking:</para>
            <itemizedlist>
              <listitem>
                <para>Basic network meters</para>
              </listitem>
              <listitem>
                <para>Firewall-as-a-Service (FWaaS) meters</para>
              </listitem>
              <listitem>
                <para>Load-Balancer-as-a-Service (LBaaS) meters</para>
              </listitem>
              <listitem>
                <para>VPN-as-a-Service (VPNaaS) meters</para>
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem>
            <para>SDN controller meters:</para>
            <itemizedlist>
              <listitem>
                <para>
                  <link xlink:href="https://www.opendaylight.org/">OpenDaylight</link>
                </para>
              </listitem>
              <listitem>
                <para>
                  <link xlink:href="http://www.opencontrail.org/">OpenContrail</link>
                </para>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2 xml:id="telemetry-users-roles-projects">
        <title>Users, roles, and projects</title>
        <para>This service of OpenStack uses OpenStack Identity for authenticating and
authorizing users. The required configuration options are listed in the
<link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry.html">Telemetry
section</link>
in the OpenStack Configuration Reference.</para>
        <para>The system uses two roles:<literal>admin</literal> and <literal>non-admin</literal>. The authorization
happens before processing each API request. The amount of returned data
depends on the role the requestor owns.</para>
        <para>The creation of alarm definitions also highly depends on the role of the
user, who initiated the action. Further details about <xref linkend="telemetry-alarms"/>
handling can be found in this guide.</para>
      </sect2>
    </sect1>
    <sect1 xml:id="telemetry-data-collection">
      <title>Data collection</title>
      <para>The main responsibility of Telemetry in OpenStack is to collect
information about the system that can be used by billing systems or
interpreted by analytic tooling. Telemetry in OpenStack originally focused
on the counters used for billing, and the recorded range is
continuously growing wider.</para>
      <para>Collected data can be stored in the form of samples or events in the
supported databases, which are listed
in <xref linkend="telemetry-supported-databases"/>.</para>
      <para>Samples can have various sources. Sample sources depend on, and adapt to,
the needs and configuration of Telemetry. The Telemetry service requires
multiple methods to collect data samples.</para>
      <para>The available data collection mechanisms are:</para>
      <variablelist>
        <varlistentry>
          <term>Notifications</term>
          <listitem>
            <para>Processing notifications from other OpenStack services, by consuming
messages from the configured message queue system.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Polling</term>
          <listitem>
            <para>Retrieve information directly from the hypervisor or from the host
machine using SNMP, or by using the APIs of other OpenStack
services.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>RESTful API</term>
          <listitem>
            <para>Pushing samples via the RESTful API of Telemetry.</para>
          </listitem>
        </varlistentry>
      </variablelist>
      <sect2>
        <title>Notifications</title>
        <para>All OpenStack services send notifications about the executed operations
or system state. Several notifications carry information that can be
metered. For example, CPU time of a VM instance created by OpenStack
Compute service.</para>
        <para>The notification agent works alongside, but separately, from the
Telemetry service. The agent is responsible for consuming notifications.
This component is responsible for consuming from the message bus and
transforming notifications into events and measurement samples.</para>
        <para>Since the Liberty release, the notification agent is responsible
for all data processing such as transformations and publishing. After
processing, the data is sent via AMQP to the collector service or any
external service. These external services persist the data in
configured databases.</para>
        <para>The different OpenStack services emit several notifications about the
various types of events that happen in the system during normal
operation. Not all these notifications are consumed by the Telemetry
service, as the intention is only to capture the billable events and
notifications that can be used for monitoring or profiling purposes. The
notification agent filters by the event type. Each notification
message contains the event type. The following table contains the event
types by each OpenStack service that Telemetry transforms into samples.</para>
        <informaltable>
          <tgroup cols="3">
            <colspec colname="c1" colwidth="18.2*"/>
            <colspec colname="c2" colwidth="27.3*"/>
            <colspec colname="c3" colwidth="54.5*"/>
            <thead>
              <row>
                <entry>
                  <para>OpenStack service</para>
                </entry>
                <entry>
                  <para>Event types</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>OpenStack Compute</para>
                </entry>
                <entry>
                  <para>scheduler.run_instance.scheduled</para>
                  <para>scheduler.select_destinations</para>
                  <para>compute.instance.*</para>
                </entry>
                <entry>
                  <para>For a more detailed list of Compute notifications please
check the <link xlink:href="https://wiki.openstack.org/wiki/SystemUsageData">System Usage Data wiki page</link>.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Bare metal service</para>
                </entry>
                <entry>
                  <para>hardware.ipmi.*</para>
                </entry>
                <entry/>
              </row>
              <row>
                <entry>
                  <para>OpenStack Image</para>
                </entry>
                <entry>
                  <para>image.update</para>
                  <para>image.upload</para>
                  <para>image.delete</para>
                  <para>image.send</para>
                </entry>
                <entry>
                  <para>The required configuration for Image service can be  * - service found in
<link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton">Configure the Image service for Telemetry</link>
section in the Installation Tutorials and Guides.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>OpenStack Networking</para>
                </entry>
                <entry>
                  <para>floatingip.create.end</para>
                  <para>floatingip.update.*</para>
                  <para>floatingip.exists</para>
                  <para>network.create.end</para>
                  <para>network.update.*</para>
                  <para>network.exists</para>
                  <para>port.create.end</para>
                  <para>port.update.*</para>
                  <para>port.exists</para>
                  <para>router.create.end</para>
                  <para>router.update.*</para>
                  <para>router.exists</para>
                  <para>subnet.create.end</para>
                  <para>subnet.update.*</para>
                  <para>subnet.exists</para>
                  <para>l3.meter</para>
                </entry>
                <entry/>
              </row>
              <row>
                <entry>
                  <para>Orchestration service</para>
                </entry>
                <entry>
                  <para>orchestration.stack.create.end</para>
                  <para>orchestration.stack.update.end</para>
                  <para>orchestration.stack.delete.end</para>
                  <para>orchestration.stack.resume.end</para>
                  <para>orchestration.stack.suspend.end</para>
                </entry>
                <entry/>
              </row>
              <row>
                <entry>
                  <para>OpenStack Block Storage</para>
                </entry>
                <entry>
                  <para>volume.exists</para>
                  <para>volume.create.*</para>
                  <para>volume.delete.*</para>
                  <para>volume.update.*</para>
                  <para>volume.resize.*</para>
                  <para>volume.attach.*</para>
                  <para>volume.detach.*</para>
                  <para>snapshot.exists</para>
                  <para>snapshot.create.*</para>
                  <para>snapshot.delete.*</para>
                  <para>snapshot.update.*</para>
                  <para>volume.backup.create.*</para>
                  <para>volume.backup.delete.*</para>
                  <para>volume.backup.restore.*</para>
                </entry>
                <entry>
                  <para>The required configuration for Block Storage service can be found in the
<link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/cinder/install-cinder-ubuntu.html">Add the Block Storage service agent for Telemetry section</link>
in the Installation Tutorials and Guides.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <para>Some services require additional configuration to emit the
notifications using the correct control exchange on the message
queue and so forth. These configuration needs are referred in the
above table for each OpenStack service that needs it.</para>
        </note>
        <para>Specific notifications from the Compute service are important for
administrators and users. Configuring <literal>nova_notifications</literal> in the
<literal>nova.conf</literal> file allows administrators to respond to events
rapidly. For more information on configuring notifications for the
compute service, see
<link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/nova/install-nova-ubuntu.html">Telemetry services</link> in the
Installation Tutorials and Guides.</para>
        <note>
          <para>When the <literal>store_events</literal> option is set to <literal>True</literal> in
<literal>ceilometer.conf</literal>, Prior to the Kilo release, the notification agent
needed database access in order to work properly.</para>
        </note>
        <sect3>
          <title>Compute agent</title>
          <para>This agent is responsible for collecting resource usage data of VM
instances on individual compute nodes within an OpenStack deployment.
This mechanism requires a closer interaction with the hypervisor,
therefore a separate agent type fulfills the collection of the related
meters, which is placed on the host machines to retrieve this
information locally.</para>
          <para>A Compute agent instance has to be installed on each and every compute
node, installation instructions can be found in the <link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/nova/install-nova-ubuntu.html">Install the Compute
agent for Telemetry</link>
section in the Installation Tutorials and Guides.</para>
          <para>Just like the central agent, this component also does not need a direct
database connection. The samples are sent via AMQP to the notification agent.</para>
          <para>The list of supported hypervisors can be found in
<xref linkend="telemetry-supported-hypervisors"/>. The Compute agent uses the API of the
hypervisor installed on the compute hosts. Therefore, the supported meters may
be different in case of each virtualization back end, as each inspection tool
provides a different set of meters.</para>
          <para>The list of collected meters can be found in <xref linkend="telemetry-compute-meters"/>.
The support column provides the information about which meter is available for
each hypervisor supported by the Telemetry service.</para>
          <note>
            <para>Telemetry supports Libvirt, which hides the hypervisor under it.</para>
          </note>
        </sect3>
        <sect3>
          <title>Middleware for the OpenStack Object Storage service</title>
          <para>A subset of Object Store statistics requires additional middleware to
be installed behind the proxy of Object Store. This additional component
emits notifications containing data-flow-oriented meters, namely the
<literal>storage.objects.(incoming|outgoing).bytes values</literal>. The list of these
meters are listed in <xref linkend="telemetry-object-storage-meter"/>, marked with
<literal>notification</literal> as origin.</para>
          <para>The instructions on how to install this middleware can be found in
<link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/swift/install-swift-ubuntu.html">Configure the Object Storage service for Telemetry</link>
section in the Installation Tutorials and Guides.</para>
        </sect3>
        <sect3>
          <title>Telemetry middleware</title>
          <para>Telemetry provides HTTP request and API endpoint counting
capability in OpenStack. This is achieved by
storing a sample for each event marked as <literal>audit.http.request</literal>,
<literal>audit.http.response</literal>, <literal>http.request</literal> or <literal>http.response</literal>.</para>
          <para>It is recommended that these notifications be consumed as events rather
than samples to better index the appropriate values and avoid massive
load on the Metering database. If preferred, Telemetry can consume these
events as samples if the services are configured to emit <literal>http.*</literal>
notifications.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Polling</title>
        <para>The Telemetry service is intended to store a complex picture of the
infrastructure. This goal requires additional information than what is
provided by the events and notifications published by each service. Some
information is not emitted directly, like resource usage of the VM
instances.</para>
        <para>Therefore Telemetry uses another method to gather this data by polling
the infrastructure including the APIs of the different OpenStack
services and other assets, like hypervisors. The latter case requires
closer interaction with the compute hosts. To solve this issue,
Telemetry uses an agent based architecture to fulfill the requirements
against the data collection.</para>
        <para>There are three types of agents supporting the polling mechanism, the
<literal>compute agent</literal>, the <literal>central agent</literal>, and the <literal>IPMI agent</literal>. Under
the hood, all the types of polling agents are the same
<literal>ceilometer-polling</literal> agent, except that they load different polling
plug-ins (pollsters) from different namespaces to gather data. The following
subsections give further information regarding the architectural and
configuration details of these components.</para>
        <para>Running <command>ceilometer-agent-compute</command> is exactly the same as:</para>
        <screen language="console">$ ceilometer-polling --polling-namespaces compute</screen>
        <para>Running <command>ceilometer-agent-central</command> is exactly the same as:</para>
        <screen language="console">$ ceilometer-polling --polling-namespaces central</screen>
        <para>Running <command>ceilometer-agent-ipmi</command> is exactly the same as:</para>
        <screen language="console">$ ceilometer-polling --polling-namespaces ipmi</screen>
        <para>In addition to loading all the polling plug-ins registered in the
specified namespaces, the <literal>ceilometer-polling</literal> agent can also specify the
polling plug-ins to be loaded by using the <literal>pollster-list</literal> option:</para>
        <screen language="console">$ ceilometer-polling --polling-namespaces central \
        --pollster-list image image.size storage.*</screen>
        <note>
          <para>HA deployment is NOT supported if the <literal>pollster-list</literal> option is
used.</para>
        </note>
        <note>
          <para>The <literal>ceilometer-polling</literal> service is available since Kilo release.</para>
        </note>
        <sect3>
          <title>Central agent</title>
          <para>This agent is responsible for polling public REST APIs to retrieve additional
information on OpenStack resources not already surfaced via notifications,
and also for polling hardware resources over SNMP.</para>
          <para>The following services can be polled with this agent:</para>
          <itemizedlist>
            <listitem>
              <para>OpenStack Networking</para>
            </listitem>
            <listitem>
              <para>OpenStack Object Storage</para>
            </listitem>
            <listitem>
              <para>OpenStack Block Storage</para>
            </listitem>
            <listitem>
              <para>Hardware resources via SNMP</para>
            </listitem>
            <listitem>
              <para>Energy consumption meters via <link xlink:href="https://launchpad.net/kwapi">Kwapi</link>
framework</para>
            </listitem>
          </itemizedlist>
          <para>To install and configure this service use the <link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton/install-base-ubuntu.html">Add the Telemetry service</link>
section in the Installation Tutorials and Guides.</para>
          <para>The central agent does not need direct database connection. The samples
collected by this agent are sent via AMQP to the notification agent to be
processed.</para>
          <note>
            <para>Prior to the Liberty release, data from the polling agents was processed
locally and published accordingly rather than by the notification agent.</para>
          </note>
        </sect3>
        <sect3 xml:id="telemetry-ipmi-agent">
          <title>IPMI agent</title>
          <para>This agent is responsible for collecting IPMI sensor data and Intel Node
Manager data on individual compute nodes within an OpenStack deployment.
This agent requires an IPMI capable node with the ipmitool utility installed,
which is commonly used for IPMI control on various Linux distributions.</para>
          <para>An IPMI agent instance could be installed on each and every compute node
with IPMI support, except when the node is managed by the Bare metal
service and the <literal>conductor.send_sensor_data</literal> option is set to <literal>true</literal>
in the Bare metal service. It is no harm to install this agent on a
compute node without IPMI or Intel Node Manager support, as the agent
checks for the hardware and if none is available, returns empty data. It
is suggested that you install the IPMI agent only on an IPMI capable
node for performance reasons.</para>
          <para>Just like the central agent, this component also does not need direct
database access. The samples are sent via AMQP to the notification agent.</para>
          <para>The list of collected meters can be found in
<xref linkend="telemetry-bare-metal-service"/>.</para>
          <note>
            <para>Do not deploy both the IPMI agent and the Bare metal service on one
compute node. If <literal>conductor.send_sensor_data</literal> is set, this
misconfiguration causes duplicated IPMI sensor samples.</para>
          </note>
        </sect3>
      </sect2>
      <sect2 xml:id="ha-deploy-services">
        <title>Support for HA deployment</title>
        <para>Both the polling agents and notification agents can run in an HA deployment,
which means that multiple instances of these services can run in
parallel with workload partitioning among these running instances.</para>
        <para>The <link xlink:href="https://pypi.python.org/pypi/tooz">Tooz</link> library provides the
coordination within the groups of service instances. It provides an API
above several back ends that can be used for building distributed
applications.</para>
        <para>Tooz supports <link xlink:href="http://docs.openstack.org/developer/tooz/drivers.html">various
drivers</link>
including the following back end solutions:</para>
        <itemizedlist>
          <listitem>
            <para><link xlink:href="http://zookeeper.apache.org/">Zookeeper</link>. Recommended solution by
the Tooz project.</para>
          </listitem>
          <listitem>
            <para><link xlink:href="http://redis.io/">Redis</link>. Recommended solution by the Tooz
project.</para>
          </listitem>
          <listitem>
            <para><link xlink:href="http://memcached.org/">Memcached</link>. Recommended for testing.</para>
          </listitem>
        </itemizedlist>
        <para>You must configure a supported Tooz driver for the HA deployment of the
Telemetry services.</para>
        <para>For information about the required configuration options that have to be
set in the <literal>ceilometer.conf</literal> configuration file for both the central
and Compute agents, see the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">Coordination section</link>
in the OpenStack Configuration Reference.</para>
        <sect3>
          <title>Notification agent HA deployment</title>
          <para>In the Kilo release, workload partitioning support was added to the
notification agent. This is particularly useful as the pipeline processing
is handled exclusively by the notification agent now which may result
in a larger amount of load.</para>
          <para>To enable workload partitioning by notification agent, the <literal>backend_url</literal>
option must be set in the <literal>ceilometer.conf</literal> configuration file.
Additionally, <literal>workload_partitioning</literal> should be enabled in the
<link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">Notification section</link> in the OpenStack Configuration Reference.</para>
          <note>
            <para>In Liberty, the notification agent creates multiple queues to divide the
workload across all active agents. The number of queues can be controlled by
the <literal>pipeline_processing_queues</literal> option in the <literal>ceilometer.conf</literal>
configuration file. A larger value will result in better distribution of
tasks but will also require more memory and longer startup time. It is
recommended to have a value approximately three times the number of active
notification agents. At a minimum, the value should be equal to the number
of active agents.</para>
          </note>
        </sect3>
        <sect3>
          <title>Polling agent HA deployment</title>
          <note>
            <para>Without the <literal>backend_url</literal> option being set only one instance of
both the central and Compute agent service is able to run and
function correctly.</para>
          </note>
          <para>The availability check of the instances is provided by heartbeat
messages. When the connection with an instance is lost, the workload
will be reassigned within the remained instances in the next polling
cycle.</para>
          <note>
            <para><literal>Memcached</literal> uses a <literal>timeout</literal> value, which should always be set
to a value that is higher than the <literal>heartbeat</literal> value set for
Telemetry.</para>
          </note>
          <para>For backward compatibility and supporting existing deployments, the
central agent configuration also supports using different configuration
files for groups of service instances of this type that are running in
parallel. For enabling this configuration set a value for the
<literal>partitioning_group_prefix</literal> option in the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">polling section</link>
in the OpenStack Configuration Reference.</para>
          <warning>
            <para>For each sub-group of the central agent pool with the same
<literal>partitioning_group_prefix</literal> a disjoint subset of meters must be
polled, otherwise samples may be missing or duplicated. The list of
meters to poll can be set in the <literal>/etc/ceilometer/pipeline.yaml</literal>
configuration file. For more information about pipelines see
<xref linkend="data-collection-and-processing"/>.</para>
          </warning>
          <para>To enable the Compute agent to run multiple instances simultaneously
with workload partitioning, the <literal>workload_partitioning</literal> option has to
be set to <literal>True</literal> under the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">Compute section</link>
in the <literal>ceilometer.conf</literal> configuration file.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Send samples to Telemetry</title>
        <para>While most parts of the data collection in the Telemetry service are
automated, Telemetry provides the possibility to submit samples via the
REST API to allow users to send custom samples into this service.</para>
        <para>This option makes it possible to send any kind of samples without the
need of writing extra code lines or making configuration changes.</para>
        <para>The samples that can be sent to Telemetry are not limited to the actual
existing meters. There is a possibility to provide data for any new,
customer defined counter by filling out all the required fields of the
POST request.</para>
        <para>If the sample corresponds to an existing meter, then the fields like
<literal>meter-type</literal> and meter name should be matched accordingly.</para>
        <para>The required fields for sending a sample using the command-line client
are:</para>
        <itemizedlist>
          <listitem>
            <para>ID of the corresponding resource. (<literal>--resource-id</literal>)</para>
          </listitem>
          <listitem>
            <para>Name of meter. (<literal>--meter-name</literal>)</para>
          </listitem>
          <listitem>
            <para>Type of meter. (<literal>--meter-type</literal>)</para>
            <para>Predefined meter types:</para>
            <itemizedlist>
              <listitem>
                <para>Gauge</para>
              </listitem>
              <listitem>
                <para>Delta</para>
              </listitem>
              <listitem>
                <para>Cumulative</para>
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem>
            <para>Unit of meter. (<literal>--meter-unit</literal>)</para>
          </listitem>
          <listitem>
            <para>Volume of sample. (<literal>--sample-volume</literal>)</para>
          </listitem>
        </itemizedlist>
        <para>To send samples to Telemetry using the command-line client, the
following command should be invoked:</para>
        <screen language="console">$ ceilometer sample-create -r 37128ad6-daaa-4d22-9509-b7e1c6b08697 \
  -m memory.usage --meter-type gauge --meter-unit MB --sample-volume 48
+-------------------+--------------------------------------------+
| Property          | Value                                      |
+-------------------+--------------------------------------------+
| message_id        | 6118820c-2137-11e4-a429-08002715c7fb       |
| name              | memory.usage                               |
| project_id        | e34eaa91d52a4402b4cb8bc9bbd308c1           |
| resource_id       | 37128ad6-daaa-4d22-9509-b7e1c6b08697       |
| resource_metadata | {}                                         |
| source            | e34eaa91d52a4402b4cb8bc9bbd308c1:openstack |
| timestamp         | 2014-08-11T09:10:46.358926                 |
| type              | gauge                                      |
| unit              | MB                                         |
| user_id           | 679b0499e7a34ccb9d90b64208401f8e           |
| volume            | 48.0                                       |
+-------------------+--------------------------------------------+</screen>
        <sect3>
          <title>Meter definitions</title>
          <para>The Telemetry service collects a subset of the meters by filtering
notifications emitted by other OpenStack services. Starting with the Liberty
release, you can find the meter definitions in a separate configuration file,
called <literal>ceilometer/meter/data/meter.yaml</literal>. This enables
operators/administrators to add new meters to Telemetry project by updating
the <literal>meter.yaml</literal> file without any need for additional code changes.</para>
          <note>
            <para>The <literal>meter.yaml</literal> file should be modified with care. Unless intended
do not remove any existing meter definitions from the file. Also, the
collected meters can differ in some cases from what is referenced in the
documentation.</para>
          </note>
          <para>A standard meter definition looks like:</para>
          <screen language="yaml">---
metric:
  - name: 'meter name'
    event_type: 'event name'
    type: 'type of meter eg: gauge, cumulative or delta'
    unit: 'name of unit eg: MB'
    volume: 'path to a measurable value eg: $.payload.size'
    resource_id: 'path to resource id eg: $.payload.id'
    project_id: 'path to project id eg: $.payload.owner'</screen>
          <para>The definition above shows a simple meter definition with some fields,
from which <literal>name</literal>, <literal>event_type</literal>, <literal>type</literal>, <literal>unit</literal>, and <literal>volume</literal>
are required. If there is a match on the event type, samples are generated
for the meter.</para>
          <para>If you take a look at the <literal>meter.yaml</literal> file, it contains the sample
definitions for all the meters that Telemetry is collecting from
notifications. The value of each field is specified by using JSON path in
order to find the right value from the notification message. In order to be
able to specify the right field you need to be aware of the format of the
consumed notification. The values that need to be searched in the notification
message are set with a JSON path starting with <literal>$.</literal> For instance, if you need
the <literal>size</literal> information from the payload you can define it like
<literal>$.payload.size</literal>.</para>
          <para>A notification message may contain multiple meters. You can use <literal>*</literal> in
the meter definition to capture all the meters and generate samples
respectively. You can use wild cards as shown in the following example:</para>
          <screen language="yaml">---
metric:
  - name: $.payload.measurements.[*].metric.[*].name
    event_type: 'event_name.*'
    type: 'delta'
    unit: $.payload.measurements.[*].metric.[*].unit
    volume: payload.measurements.[*].result
    resource_id: $.payload.target
    user_id: $.payload.initiator.id
    project_id: $.payload.initiator.project_id</screen>
          <para>In the above example, the <literal>name</literal> field is a JSON path with matching
a list of meter names defined in the notification message.</para>
          <para>You can even use complex operations on JSON paths. In the following example,
<literal>volume</literal> and <literal>resource_id</literal> fields perform an arithmetic
and string concatenation:</para>
          <screen language="yaml">---
metric:
- name: 'compute.node.cpu.idle.percent'
  event_type: 'compute.metrics.update'
  type: 'gauge'
  unit: 'percent'
  volume: payload.metrics[?(@.name='cpu.idle.percent')].value * 100
  resource_id: $.payload.host + "_" + $.payload.nodename</screen>
          <para>You can use the <literal>timedelta</literal> plug-in to evaluate the difference in seconds
between two <literal>datetime</literal> fields from one notification.</para>
          <screen language="yaml">---
metric:
- name: 'compute.instance.booting.time'
  event_type: 'compute.instance.create.end'
 type: 'gauge'
 unit: 'sec'
 volume:
   fields: [$.payload.created_at, $.payload.launched_at]
   plugin: 'timedelta'
 project_id: $.payload.tenant_id
 resource_id: $.payload.instance_id</screen>
          <para>You will find some existence meters in the <literal>meter.yaml</literal>. These
meters have a <literal>volume</literal> as <literal>1</literal> and are at the bottom of the yaml file
with a note suggesting that these will be removed in Mitaka release.</para>
          <para>For example, the meter definition for existence meters is as follows:</para>
          <screen language="yaml">---
metric:
  - name: 'meter name'
    type: 'delta'
    unit: 'volume'
    volume: 1
    event_type:
        - 'event type'
    resource_id: $.payload.volume_id
    user_id: $.payload.user_id
    project_id: $.payload.tenant_id</screen>
          <para>These meters are not loaded by default. To load these meters, flip
the <literal>disable_non_metric_meters</literal> option in the <literal>ceilometer.conf</literal>
file.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Block Storage audit script setup to get notifications</title>
        <para>If you want to collect OpenStack Block Storage notification on demand,
you can use <command>cinder-volume-usage-audit</command> from OpenStack Block Storage.
This script becomes available when you install OpenStack Block Storage,
so you can use it without any specific settings and you don't need to
authenticate to access the data. To use it, you must run this command in
the following format:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ cinder-volume-usage-audit \
  --start_time='YYYY-MM-DD HH:MM:SS' --end_time='YYYY-MM-DD HH:MM:SS' --send_actions</screen>
        <para>This script outputs what volumes or snapshots were created, deleted, or
exists in a given period of time and some information about these
volumes or snapshots. Information about the existence and size of
volumes and snapshots is store in the Telemetry service. This data is
also stored as an event which is the recommended usage as it provides
better indexing of data.</para>
        <para>Using this script via cron you can get notifications periodically, for
example, every 5 minutes:</para>
        <screen>*/5 * * * * /path/to/cinder-volume-usage-audit --send_actions</screen>
      </sect2>
      <sect2 xml:id="telemetry-storing-samples">
        <title>Storing samples</title>
        <para>The Telemetry service has a separate service that is responsible for
persisting the data that comes from the pollsters or is received as
notifications. The data can be stored in a file or a database back end,
for which the list of supported databases can be found in
<xref linkend="telemetry-supported-databases"/>. The data can also be sent to an external
data store by using an HTTP dispatcher.</para>
        <para>The <literal>ceilometer-collector</literal> service receives the data as messages from the
message bus of the configured AMQP service. It sends these datapoints
without any modification to the configured target. The service has to
run on a host machine from which it has access to the configured
dispatcher.</para>
        <note>
          <para>Multiple dispatchers can be configured for Telemetry at one time.</para>
        </note>
        <para>Multiple <literal>ceilometer-collector</literal> processes can be run at a time. It is also
supported to start multiple worker threads per collector process. The
<literal>collector_workers</literal> configuration option has to be modified in the
<link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">Collector section</link>
of the <literal>ceilometer.conf</literal> configuration file.</para>
        <sect3>
          <title>Database dispatcher</title>
          <para>When the database dispatcher is configured as data store, you have the
option to set a <literal>time_to_live</literal> option (ttl) for samples. By default
the time to live value for samples is set to -1, which means that they
are kept in the database forever.</para>
          <para>The time to live value is specified in seconds. Each sample has a time
stamp, and the <literal>ttl</literal> value indicates that a sample will be deleted
from the database when the number of seconds has elapsed since that
sample reading was stamped. For example, if the time to live is set to
600, all samples older than 600 seconds will be purged from the
database.</para>
          <para>Certain databases support native TTL expiration. In cases where this is
not possible, a command-line script, which you can use for this purpose
is <literal>ceilometer-expirer</literal>. You can run it in a cron job, which helps to keep
your database in a consistent state.</para>
          <para>The level of support differs in case of the configured back end:</para>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="33.3*"/>
              <colspec colname="c2" colwidth="33.3*"/>
              <colspec colname="c3" colwidth="33.3*"/>
              <thead>
                <row>
                  <entry>
                    <para>Database</para>
                  </entry>
                  <entry>
                    <para>TTL value support</para>
                  </entry>
                  <entry>
                    <para>Note</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>MongoDB</para>
                  </entry>
                  <entry>
                    <para>Yes</para>
                  </entry>
                  <entry>
                    <para>MongoDB has native TTL support for deleting samples
that are older than the configured ttl value.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>SQL-based back ends</para>
                  </entry>
                  <entry>
                    <para>Yes</para>
                  </entry>
                  <entry>
                    <para><literal>ceilometer-expirer</literal> has to be used for deleting
samples and its related data from the database.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>HBase</para>
                  </entry>
                  <entry>
                    <para>No</para>
                  </entry>
                  <entry>
                    <para>Telemetry's HBase support does not include native TTL
nor <literal>ceilometer-expirer</literal> support.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>DB2 NoSQL</para>
                  </entry>
                  <entry>
                    <para>No</para>
                  </entry>
                  <entry>
                    <para>DB2 NoSQL does not have native TTL
nor <literal>ceilometer-expirer</literal> support.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
        </sect3>
        <sect3>
          <title>HTTP dispatcher</title>
          <para>The Telemetry service supports sending samples to an external HTTP
target. The samples are sent without any modification. To set this
option as the collector's target, the <literal>dispatcher</literal> has to be changed
to <literal>http</literal> in the <literal>ceilometer.conf</literal> configuration file. For the list
of options that you need to set, see the see the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">dispatcher_http
section</link>
in the OpenStack Configuration Reference.</para>
        </sect3>
        <sect3>
          <title>File dispatcher</title>
          <para>You can store samples in a file by setting the <literal>dispatcher</literal> option in the
<literal>ceilometer.conf</literal> file. For the list of configuration options,
see the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">dispatcher_file section</link>
in the OpenStack Configuration Reference.</para>
        </sect3>
      </sect2>
    </sect1>
    <sect1 xml:id="data-collection-and-processing">
      <title>Data collection, processing, and pipelines</title>
      <para>The mechanism by which data is collected and processed is called a
pipeline. Pipelines, at the configuration level, describe a coupling
between sources of data and the corresponding sinks for transformation
and publication of data.</para>
      <para>A source is a producer of data: <literal>samples</literal> or <literal>events</literal>. In effect, it is a
set of pollsters or notification handlers emitting datapoints for a set
of matching meters and event types.</para>
      <para>Each source configuration encapsulates name matching, polling interval
determination, optional resource enumeration or discovery, and mapping
to one or more sinks for publication.</para>
      <para>Data gathered can be used for different purposes, which can impact how
frequently it needs to be published. Typically, a meter published for
billing purposes needs to be updated every 30 minutes while the same
meter may be needed for performance tuning every minute.</para>
      <warning>
        <para>Rapid polling cadences should be avoided, as it results in a huge
amount of data in a short time frame, which may negatively affect
the performance of both Telemetry and the underlying database back
end. We strongly recommend you do not use small granularity
values like 10 seconds.</para>
      </warning>
      <para>A sink, on the other hand, is a consumer of data, providing logic for
the transformation and publication of data emitted from related sources.</para>
      <para>In effect, a sink describes a chain of handlers. The chain starts with
zero or more transformers and ends with one or more publishers. The
first transformer in the chain is passed data from the corresponding
source, takes some action such as deriving rate of change, performing
unit conversion, or aggregating, before passing the modified data to the
next step that is described in <xref linkend="telemetry-publishers"/>.</para>
      <sect2 xml:id="telemetry-pipeline-configuration">
        <title>Pipeline configuration</title>
        <para>The pipeline configuration is, by default stored in separate configuration
files called <literal>pipeline.yaml</literal> and <literal>event_pipeline.yaml</literal> next to
the <literal>ceilometer.conf</literal> file. The meter pipeline and event pipeline
configuration files can be set by the <literal>pipeline_cfg_file</literal> and
<literal>event_pipeline_cfg_file</literal> options listed in the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html">Description of
configuration options for api table</link>
section in the OpenStack Configuration Reference respectively. Multiple
pipelines can be defined in one pipeline configuration file.</para>
        <para>The meter pipeline definition looks like:</para>
        <screen language="yaml">---
sources:
  - name: 'source name'
    interval: 'how often should the samples be injected into the pipeline'
    meters:
      - 'meter filter'
    resources:
      - 'list of resource URLs'
    sinks
      - 'sink name'
sinks:
  - name: 'sink name'
    transformers: 'definition of transformers'
    publishers:
      - 'list of publishers'</screen>
        <para>The interval parameter in the sources section should be defined in
seconds. It determines the polling cadence of sample injection into the
pipeline, where samples are produced under the direct control of an
agent.</para>
        <para>There are several ways to define the list of meters for a pipeline
source. The list of valid meters can be found in <xref linkend="telemetry-measurements"/>.
There is a possibility to define all the meters, or just included or excluded
meters, with which a source should operate:</para>
        <itemizedlist>
          <listitem>
            <para>To include all meters, use the <literal>*</literal> wildcard symbol. It is highly
advisable to select only the meters that you intend on using to avoid
flooding the metering database with unused data.</para>
          </listitem>
          <listitem>
            <para>To define the list of meters, use either of the following:</para>
            <itemizedlist>
              <listitem>
                <para>To define the list of included meters, use the <literal>meter_name</literal>
syntax.</para>
              </listitem>
              <listitem>
                <para>To define the list of excluded meters, use the <literal>!meter_name</literal>
syntax.</para>
              </listitem>
              <listitem>
                <para>For meters, which have variants identified by a complex name
field, use the wildcard symbol to select all, for example,
for <literal>instance:m1.tiny</literal>, use <literal>instance:\*</literal>.</para>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
        <note>
          <para>The OpenStack Telemetry service does not have any duplication check
between pipelines, and if you add a meter to multiple pipelines then it is
assumed the duplication is intentional and may be stored multiple
times according to the specified sinks.</para>
        </note>
        <para>The above definition methods can be used in the following combinations:</para>
        <itemizedlist>
          <listitem>
            <para>Use only the wildcard symbol.</para>
          </listitem>
          <listitem>
            <para>Use the list of included meters.</para>
          </listitem>
          <listitem>
            <para>Use the list of excluded meters.</para>
          </listitem>
          <listitem>
            <para>Use wildcard symbol with the list of excluded meters.</para>
          </listitem>
        </itemizedlist>
        <note>
          <para>At least one of the above variations should be included in the
meters section. Included and excluded meters cannot co-exist in the
same pipeline. Wildcard and included meters cannot co-exist in the
same pipeline definition section.</para>
        </note>
        <para>The optional resources section of a pipeline source allows a static list
of resource URLs to be configured for polling.</para>
        <para>The transformers section of a pipeline sink provides the possibility to
add a list of transformer definitions. The available transformers are:</para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="50.0*"/>
            <colspec colname="c2" colwidth="50.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name of transformer</para>
                </entry>
                <entry>
                  <para>Reference name for configuration</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>Accumulator</para>
                </entry>
                <entry>
                  <para>accumulator</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Aggregator</para>
                </entry>
                <entry>
                  <para>aggregator</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Arithmetic</para>
                </entry>
                <entry>
                  <para>arithmetic</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Rate of change</para>
                </entry>
                <entry>
                  <para>rate_of_change</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Unit conversion</para>
                </entry>
                <entry>
                  <para>unit_conversion</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>delta</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>The publishers section contains the list of publishers, where the
samples data should be sent after the possible transformations.</para>
        <para>Similarly, the event pipeline definition looks like:</para>
        <screen language="yaml">---
sources:
  - name: 'source name'
    events:
      - 'event filter'
    sinks
      - 'sink name'
sinks:
  - name: 'sink name'
    publishers:
      - 'list of publishers'</screen>
        <para>The event filter uses the same filtering logic as the meter pipeline.</para>
        <sect3 xml:id="telemetry-transformers">
          <title>Transformers</title>
          <para>The definition of transformers can contain the following fields:</para>
          <variablelist>
            <varlistentry>
              <term>name</term>
              <listitem>
                <para>Name of the transformer.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>parameters</term>
              <listitem>
                <para>Parameters of the transformer.</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <para>The parameters section can contain transformer specific fields, like
source and target fields with different subfields in case of the rate of
change, which depends on the implementation of the transformer.</para>
          <para>In the case of the transformer that creates the <literal>cpu_util</literal> meter, the
definition looks like:</para>
          <screen language="yaml">transformers:
    - name: "rate_of_change"
      parameters:
          target:
              name: "cpu_util"
              unit: "%"
              type: "gauge"
              scale: "100.0 / (10**9 * (resource_metadata.cpu_number or 1))"</screen>
          <para>The rate of change the transformer generates is the <literal>cpu_util</literal> meter
from the sample values of the <literal>cpu</literal> counter, which represents
cumulative CPU time in nanoseconds. The transformer definition above
defines a scale factor (for nanoseconds and multiple CPUs), which is
applied before the transformation derives a sequence of gauge samples
with unit <literal>%</literal>, from sequential values of the <literal>cpu</literal> meter.</para>
          <para>The definition for the disk I/O rate, which is also generated by the
rate of change transformer:</para>
          <screen language="yaml">transformers:
    - name: "rate_of_change"
      parameters:
          source:
              map_from:
                  name: "disk\\.(read|write)\\.(bytes|requests)"
                  unit: "(B|request)"
          target:
              map_to:
                  name: "disk.\\1.\\2.rate"
                  unit: "\\1/s"
              type: "gauge"</screen>
        </sect3>
        <sect3>
          <title>Unit conversion transformer</title>
          <para>Transformer to apply a unit conversion. It takes the volume of the meter
and multiplies it with the given <literal>scale</literal> expression. Also supports
<literal>map_from</literal> and <literal>map_to</literal> like the rate of change transformer.</para>
          <para>Sample configuration:</para>
          <screen language="yaml">transformers:
    - name: "unit_conversion"
      parameters:
          target:
              name: "disk.kilobytes"
              unit: "KB"
              scale: "volume * 1.0 / 1024.0"</screen>
          <para>With <literal>map_from</literal> and <literal>map_to</literal>:</para>
          <screen language="yaml">transformers:
    - name: "unit_conversion"
      parameters:
          source:
              map_from:
                  name: "disk\\.(read|write)\\.bytes"
          target:
              map_to:
                  name: "disk.\\1.kilobytes"
              scale: "volume * 1.0 / 1024.0"
              unit: "KB"</screen>
        </sect3>
        <sect3>
          <title>Aggregator transformer</title>
          <para>A transformer that sums up the incoming samples until enough samples
have come in or a timeout has been reached.</para>
          <para>Timeout can be specified with the <literal>retention_time</literal> option. If you want
to flush the aggregation, after a set number of samples have been
aggregated, specify the size parameter.</para>
          <para>The volume of the created sample is the sum of the volumes of samples
that came into the transformer. Samples can be aggregated by the
attributes <literal>project_id</literal>, <literal>user_id</literal> and <literal>resource_metadata</literal>. To aggregate
by the chosen attributes, specify them in the configuration and set which
value of the attribute to take for the new sample (first to take the
first sample's attribute, last to take the last sample's attribute, and
drop to discard the attribute).</para>
          <para>To aggregate 60s worth of samples by <literal>resource_metadata</literal> and keep the
<literal>resource_metadata</literal> of the latest received sample:</para>
          <screen language="yaml">transformers:
    - name: "aggregator"
      parameters:
          retention_time: 60
          resource_metadata: last</screen>
          <para>To aggregate each 15 samples by <literal>user_id</literal> and <literal>resource_metadata</literal> and keep
the <literal>user_id</literal> of the first received sample and drop the
<literal>resource_metadata</literal>:</para>
          <screen language="yaml">transformers:
    - name: "aggregator"
      parameters:
          size: 15
          user_id: first
          resource_metadata: drop</screen>
        </sect3>
        <sect3>
          <title>Accumulator transformer</title>
          <para>This transformer simply caches the samples until enough samples have
arrived and then flushes them all down the pipeline at once:</para>
          <screen language="yaml">transformers:
    - name: "accumulator"
      parameters:
          size: 15</screen>
        </sect3>
        <sect3>
          <title>Multi meter arithmetic transformer</title>
          <para>This transformer enables us to perform arithmetic calculations over one
or more meters and/or their metadata, for example:</para>
          <screen language="json">memory_util = 100 * memory.usage / memory</screen>
          <para>A new sample is created with the properties described in the <literal>target</literal>
section of the transformer's configuration. The sample's
volume is the result of the provided expression. The calculation is
performed on samples from the same resource.</para>
          <note>
            <para>The calculation is limited to meters with the same interval.</para>
          </note>
          <para>Example configuration:</para>
          <screen language="yaml">transformers:
    - name: "arithmetic"
      parameters:
        target:
          name: "memory_util"
          unit: "%"
          type: "gauge"
          expr: "100 * $(memory.usage) / $(memory)"</screen>
          <para>To demonstrate the use of metadata, the following implementation of a
novel meter shows average CPU time per core:</para>
          <screen language="yaml">transformers:
    - name: "arithmetic"
      parameters:
        target:
          name: "avg_cpu_per_core"
          unit: "ns"
          type: "cumulative"
          expr: "$(cpu) / ($(cpu).resource_metadata.cpu_number or 1)"</screen>
          <note>
            <para>Expression evaluation gracefully handles NaNs and exceptions. In
such a case it does not create a new sample but only logs a warning.</para>
          </note>
        </sect3>
        <sect3>
          <title>Delta transformer</title>
          <para>This transformer calculates the change between two sample datapoints of a
resource. It can be configured to capture only the positive growth deltas.</para>
          <para>Example configuration:</para>
          <screen language="yaml">transformers:
    - name: "delta"
      parameters:
        target:
            name: "cpu.delta"
        growth_only: True</screen>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Data retrieval</title>
      <para>The Telemetry service offers several mechanisms from which the persisted
data can be accessed. As described in <xref linkend="telemetry-system-architecture"/> and
in <xref linkend="telemetry-data-collection"/>, the collected information can be stored in
one or more database back ends, which are hidden by the Telemetry RESTful API.</para>
      <note>
        <para>It is highly recommended not to access the database directly and
read or modify any data in it. The API layer hides all the changes
in the actual database schema and provides a standard interface to
expose the samples, alarms and so forth.</para>
      </note>
      <sect2>
        <title>Telemetry v2 API</title>
        <para>The Telemetry service provides a RESTful API, from which the collected
samples and all the related information can be retrieved, like the list
of meters, alarm definitions and so forth.</para>
        <para>The Telemetry API URL can be retrieved from the service catalog provided
by OpenStack Identity, which is populated during the installation
process. The API access needs a valid token and proper permission to
retrieve data, as described in <xref linkend="telemetry-users-roles-projects"/>.</para>
        <para>Further information about the available API endpoints can be found in
the <link xlink:href="http://developer.openstack.org/api-ref-telemetry-v2.html">Telemetry API Reference</link>.</para>
        <sect3 xml:id="sec.query">
          <title>Query</title>
          <para>The API provides some additional functionalities, like querying the
collected data set. For the samples and alarms API endpoints, both
simple and complex query styles are available, whereas for the other
endpoints only simple queries are supported.</para>
          <para>After validating the query parameters, the processing is done on the
database side in the case of most database back ends in order to achieve
better performance.</para>
          <para>
            <emphasis role="bold">Simple query</emphasis>
          </para>
          <para>Many of the API endpoints accept a query filter argument, which should
be a list of data structures that consist of the following items:</para>
          <itemizedlist>
            <listitem>
              <para>
                <literal>field</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>op</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>value</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>type</literal>
              </para>
            </listitem>
          </itemizedlist>
          <para>Regardless of the endpoint on which the filter is applied on, it will
always target the fields of the <link xlink:href="http://docs.openstack.org/developer/ceilometer/webapi/v2.html#Sample">Sample type</link>.</para>
          <para>Several fields of the API endpoints accept shorter names than the ones
defined in the reference. The API will do the transformation internally
and return the output with the fields that are listed in the <link xlink:href="http://docs.openstack.org/developer/ceilometer/webapi/v2.html">API reference</link>.
The fields are the following:</para>
          <itemizedlist>
            <listitem>
              <para><literal>project_id</literal>: project</para>
            </listitem>
            <listitem>
              <para><literal>resource_id</literal>: resource</para>
            </listitem>
            <listitem>
              <para><literal>user_id</literal>: user</para>
            </listitem>
          </itemizedlist>
          <para>When a filter argument contains multiple constraints of the above form,
a logical <literal>AND</literal> relation between them is implied.</para>
          <para>
            <emphasis role="bold">Complex query</emphasis>
          </para>
          <para>The filter expressions of the complex query feature operate on the
fields of <literal>Sample</literal>, <literal>Alarm</literal> and <literal>AlarmChange</literal> types. The following
comparison operators are supported:</para>
          <itemizedlist>
            <listitem>
              <para>
                <literal>=</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>!=</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>&lt;</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>&lt;=</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>&gt;</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>&gt;=</literal>
              </para>
            </listitem>
          </itemizedlist>
          <para>The following logical operators can be used:</para>
          <itemizedlist>
            <listitem>
              <para>
                <literal>and</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>or</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>not</literal>
              </para>
            </listitem>
          </itemizedlist>
          <note>
            <para>The <literal>not</literal> operator has different behavior in MongoDB and in the
SQLAlchemy-based database engines. If the <literal>not</literal> operator is
applied on a non existent metadata field then the result depends on
the database engine. In case of MongoDB, it will return every sample
as the <literal>not</literal> operator is evaluated true for every sample where the
given field does not exist. On the other hand the SQL-based database
engine will return an empty result because of the underlying
<literal>join</literal> operation.</para>
          </note>
          <para>Complex query supports specifying a list of <literal>orderby</literal> expressions.
This means that the result of the query can be ordered based on the
field names provided in this list. When multiple keys are defined for
the ordering, these will be applied sequentially in the order of the
specification. The second expression will be applied on the groups for
which the values of the first expression are the same. The ordering can
be ascending or descending.</para>
          <para>The number of returned items can be bounded using the <literal>limit</literal> option.</para>
          <para>The <literal>filter</literal>, <literal>orderby</literal> and <literal>limit</literal> fields are optional.</para>
          <note>
            <para>As opposed to the simple query, complex query is available via a
separate API endpoint. For more information see the <link xlink:href="http://docs.openstack.org/developer/ceilometer/webapi/v2.html#v2-web-api">Telemetry v2 Web API
Reference</link>.</para>
          </note>
        </sect3>
        <sect3>
          <title>Statistics</title>
          <para>The sample data can be used in various ways for several purposes, like
billing or profiling. In external systems the data is often used in the
form of aggregated statistics. The Telemetry API provides several
built-in functions to make some basic calculations available without any
additional coding.</para>
          <para>Telemetry supports the following statistics and aggregation functions:</para>
          <variablelist>
            <varlistentry>
              <term>
                <literal>avg</literal>
              </term>
              <listitem>
                <para>Average of the sample volumes over each period.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>cardinality</literal>
              </term>
              <listitem>
                <para>Count of distinct values in each period identified by a key
specified as the parameter of this aggregate function. The supported
parameter values are:</para>
                <itemizedlist>
                  <listitem>
                    <para>
                      <literal>project_id</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>resource_id</literal>
                    </para>
                  </listitem>
                  <listitem>
                    <para>
                      <literal>user_id</literal>
                    </para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </varlistentry>
          </variablelist>
          <note>
            <para>The <literal>aggregate.param</literal> option is required.</para>
          </note>
          <variablelist>
            <varlistentry>
              <term>
                <literal>count</literal>
              </term>
              <listitem>
                <para>Number of samples in each period.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>max</literal>
              </term>
              <listitem>
                <para>Maximum of the sample volumes in each period.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>min</literal>
              </term>
              <listitem>
                <para>Minimum of the sample volumes in each period.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>stddev</literal>
              </term>
              <listitem>
                <para>Standard deviation of the sample volumes in each period.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>sum</literal>
              </term>
              <listitem>
                <para>Sum of the sample volumes over each period.</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <para>The simple query and the statistics functionality can be used together
in a single API request.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Telemetry command-line client and SDK</title>
        <para>The Telemetry service provides a command-line client, with which the
collected data is available just as the alarm definition and retrieval
options. The client uses the Telemetry RESTful API in order to execute
the requested operations.</para>
        <para>To be able to use the <command>ceilometer</command> command, the
python-ceilometerclient package needs to be installed and configured
properly. For details about the installation process, see the <link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton/">Telemetry
chapter</link>
in the Installation Tutorials and Guides.</para>
        <note>
          <para>The Telemetry service captures the user-visible resource usage data.
Therefore the database will not contain any data without the
existence of these resources, like VM images in the OpenStack Image
service.</para>
        </note>
        <para>Similarly to other OpenStack command-line clients, the <literal>ceilometer</literal>
client uses OpenStack Identity for authentication. The proper
credentials and <literal>--auth_url</literal> parameter have to be defined via command
line parameters or environment variables.</para>
        <para>This section provides some examples without the aim of completeness.
These commands can be used for instance for validating an installation
of Telemetry.</para>
        <para>To retrieve the list of collected meters, the following command should
be used:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer meter-list
+------------------------+------------+------+------------------------------------------+----------------------------------+----------------------------------+
| Name                   | Type       | Unit | Resource ID                              | User ID                          | Project ID                       |
+------------------------+------------+------+------------------------------------------+----------------------------------+----------------------------------+
| cpu                    | cumulative | ns   | bb52e52b-1e42-4751-b3ac-45c52d83ba07     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu                    | cumulative | ns   | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_util               | gauge      | %    | bb52e52b-1e42-4751-b3ac-45c52d83ba07     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_util               | gauge      | %    | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | bb52e52b-1e42-4751-b3ac-45c52d83ba07-hdd | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | bb52e52b-1e42-4751-b3ac-45c52d83ba07-vda | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b-hdd | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b-vda | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| ...                                                                                                                                                         |
+------------------------+------------+------+------------------------------------------+----------------------------------+----------------------------------+</screen>
        <para>The <command>ceilometer</command> command was run with <literal>admin</literal> rights, which means
that all the data is accessible in the database. For more information
about access right see <xref linkend="telemetry-users-roles-projects"/>. As it can be seen
in the above example, there are two VM instances existing in the system, as
there are VM instance related meters on the top of the result list. The
existence of these meters does not indicate that these instances are running at
the time of the request. The result contains the currently collected meters per
resource, in an ascending order based on the name of the meter.</para>
        <para>Samples are collected for each meter that is present in the list of
meters, except in case of instances that are not running or deleted from
the OpenStack Compute database. If an instance no longer exists and
there is a <literal>time_to_live</literal> value set in the <literal>ceilometer.conf</literal>
configuration file, then a group of samples are deleted in each
expiration cycle. When the last sample is deleted for a meter, the
database can be cleaned up by running ceilometer-expirer and the meter
will not be present in the list above anymore. For more information
about the expiration procedure see <xref linkend="telemetry-storing-samples"/>.</para>
        <para>The Telemetry API supports simple query on the meter endpoint. The query
functionality has the following syntax:</para>
        <screen language="console">--query &lt;field1&gt;&lt;operator1&gt;&lt;value1&gt;;...;&lt;field_n&gt;&lt;operator_n&gt;&lt;value_n&gt;</screen>
        <para>The following command needs to be invoked to request the meters of one
VM instance:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer meter-list --query resource=bb52e52b-1e42-4751-b3ac-45c52d83ba07
+-------------------------+------------+-----------+--------------------------------------+----------------------------------+----------------------------------+
| Name                    | Type       | Unit      | Resource ID                          | User ID                          | Project ID                       |
+-------------------------+------------+-----------+--------------------------------------+----------------------------------+----------------------------------+
| cpu                     | cumulative | ns        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_util                | gauge      | %         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_l3_cache            | gauge      | B         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.ephemeral.size     | gauge      | GB        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.bytes         | cumulative | B         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.bytes.rate    | gauge      | B/s       | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.requests      | cumulative | request   | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.requests.rate | gauge      | request/s | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.root.size          | gauge      | GB        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.bytes        | cumulative | B         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.bytes.rate   | gauge      | B/s       | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.requests     | cumulative | request   | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.requests.rate| gauge      | request/s | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| instance                | gauge      | instance  | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| instance:m1.tiny        | gauge      | instance  | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| memory                  | gauge      | MB        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| vcpus                   | gauge      | vcpu      | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
+-------------------------+------------+-----------+--------------------------------------+----------------------------------+----------------------------------+</screen>
        <para>As it was described above, the whole set of samples can be retrieved
that are stored for a meter or filtering the result set by using one of
the available query types. The request for all the samples of the
<literal>cpu</literal> meter without any additional filtering looks like the following:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer sample-list --meter cpu
+--------------------------------------+-------+------------+------------+------+---------------------+
| Resource ID                          | Meter | Type       | Volume     | Unit | Timestamp           |
+--------------------------------------+-------+------------+------------+------+---------------------+
| c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b | cpu   | cumulative | 5.4863e+11 | ns   | 2014-08-31T11:17:03 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu   | cumulative | 5.7848e+11 | ns   | 2014-08-31T11:17:03 |
| c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b | cpu   | cumulative | 5.4811e+11 | ns   | 2014-08-31T11:07:05 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu   | cumulative | 5.7797e+11 | ns   | 2014-08-31T11:07:05 |
| c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b | cpu   | cumulative | 5.3589e+11 | ns   | 2014-08-31T10:27:19 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu   | cumulative | 5.6397e+11 | ns   | 2014-08-31T10:27:19 |
| ...                                                                                                 |
+--------------------------------------+-------+------------+------------+------+---------------------+</screen>
        <para>The result set of the request contains the samples for both instances
ordered by the timestamp field in the default descending order.</para>
        <para>The simple query makes it possible to retrieve only a subset of the
collected samples. The following command can be executed to request the
<literal>cpu</literal> samples of only one of the VM instances:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer sample-list --meter cpu --query resource=bb52e52b-1e42-4751-
  b3ac-45c52d83ba07
+--------------------------------------+------+------------+------------+------+---------------------+
| Resource ID                          | Name | Type       | Volume     | Unit | Timestamp           |
+--------------------------------------+------+------------+------------+------+---------------------+
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.7906e+11 | ns   | 2014-08-31T11:27:08 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.7848e+11 | ns   | 2014-08-31T11:17:03 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.7797e+11 | ns   | 2014-08-31T11:07:05 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.6397e+11 | ns   | 2014-08-31T10:27:19 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.6207e+11 | ns   | 2014-08-31T10:17:03 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.3831e+11 | ns   | 2014-08-31T08:41:57 |
| ...                                                                                                |
+--------------------------------------+------+------------+------------+------+---------------------+</screen>
        <para>As it can be seen on the output above, the result set contains samples
for only one instance of the two.</para>
        <para>The <command>ceilometer query-samples</command> command is used to execute rich
queries. This command accepts the following parameters:</para>
        <variablelist>
          <varlistentry>
            <term>
              <literal>--filter</literal>
            </term>
            <listitem>
              <para>Contains the filter expression for the query in the form of:
<literal>{complex_op: [{simple_op: {field_name: value}}]}</literal>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>--orderby</literal>
            </term>
            <listitem>
              <para>Contains the list of <literal>orderby</literal> expressions in the form of:
<literal>[{field_name: direction}, {field_name: direction}]</literal>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>--limit</literal>
            </term>
            <listitem>
              <para>Specifies the maximum number of samples to return.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>For more information about complex queries see
<xref linkend="sec.query"/>.</para>
        <para>As the complex query functionality provides the possibility of using
complex operators, it is possible to retrieve a subset of samples for a
given VM instance. To request for the first six samples for the <literal>cpu</literal>
and <literal>disk.read.bytes</literal> meters, the following command should be invoked:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer query-samples --filter '{"and": \
  [{"=":{"resource":"bb52e52b-1e42-4751-b3ac-45c52d83ba07"}},{"or":[{"=":{"counter_name":"cpu"}}, \
  {"=":{"counter_name":"disk.read.bytes"}}]}]}' --orderby '[{"timestamp":"asc"}]' --limit 6
+--------------------------------------+-----------------+------------+------------+------+---------------------+
| Resource ID                          | Meter           | Type       | Volume     | Unit | Timestamp           |
+--------------------------------------+-----------------+------------+------------+------+---------------------+
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | disk.read.bytes | cumulative | 385334.0   | B    | 2014-08-30T13:00:46 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu             | cumulative | 1.2132e+11 | ns   | 2014-08-30T13:00:47 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu             | cumulative | 1.4295e+11 | ns   | 2014-08-30T13:10:51 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | disk.read.bytes | cumulative | 601438.0   | B    | 2014-08-30T13:10:51 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | disk.read.bytes | cumulative | 601438.0   | B    | 2014-08-30T13:20:33 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu             | cumulative | 1.4795e+11 | ns   | 2014-08-30T13:20:34 |
+--------------------------------------+-----------------+------------+------------+------+---------------------+</screen>
        <para>Ceilometer also captures data as events, which represents the state of a
resource. Refer to <literal>/telemetry-events</literal> for more information regarding
Events.</para>
        <para>To retrieve a list of recent events that occurred in the system, the
following command can be executed:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer event-list
+--------------------------------------+---------------+----------------------------+-----------------------------------------------------------------+
| Message ID                           | Event Type    | Generated                  | Traits                                                          |
+--------------------------------------+---------------+----------------------------+-----------------------------------------------------------------+
| dfdb87b6-92c6-4d40-b9b5-ba308f304c13 | image.create  | 2015-09-24T22:17:39.498888 | +---------+--------+-----------------+                          |
|                                      |               |                            | |   name  |  type  |      value      |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
|                                      |               |                            | | service | string | image.localhost |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
| 84054bc6-2ae6-4b93-b5e7-06964f151cef | image.prepare | 2015-09-24T22:17:39.594192 | +---------+--------+-----------------+                          |
|                                      |               |                            | |   name  |  type  |      value      |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
|                                      |               |                            | | service | string | image.localhost |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
| 2ec99c2c-08ee-4079-bf80-27d4a073ded6 | image.update  | 2015-09-24T22:17:39.578336 | +-------------+--------+--------------------------------------+ |
|                                      |               |                            | |     name    |  type  |                value                 | |
|                                      |               |                            | +-------------+--------+--------------------------------------+ |
|                                      |               |                            | |  created_at | string |         2015-09-24T22:17:39Z         | |
|                                      |               |                            | |     name    | string |    cirros-0.3.4-x86_64-uec-kernel    | |
|                                      |               |                            | |  project_id | string |   56ffddea5b4f423496444ea36c31be23   | |
|                                      |               |                            | | resource_id | string | 86eb8273-edd7-4483-a07c-002ff1c5657d | |
|                                      |               |                            | |   service   | string |           image.localhost            | |
|                                      |               |                            | |    status   | string |                saving                | |
|                                      |               |                            | |   user_id   | string |   56ffddea5b4f423496444ea36c31be23   | |
|                                      |               |                            | +-------------+--------+--------------------------------------+ |
+--------------------------------------+---------------+----------------------------+-----------------------------------------------------------------+</screen>
        <note>
          <para>In Liberty, the data returned corresponds to the role and user. Non-admin
users will only return events that are scoped to them. Admin users will
return all events related to the project they administer as well as
all unscoped events.</para>
        </note>
        <para>Similar to querying meters, additional filter parameters can be given to
retrieve specific events:</para>
        <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer event-list -q 'event_type=compute.instance.exists; \
  instance_type=m1.tiny'
+--------------------------------------+-------------------------+----------------------------+----------------------------------------------------------------------------------+
| Message ID                           | Event Type              | Generated                  | Traits                                                                           |
+--------------------------------------+-------------------------+----------------------------+----------------------------------------------------------------------------------+
| 134a2ab3-6051-496c-b82f-10a3c367439a | compute.instance.exists | 2015-09-25T03:00:02.152041 | +------------------------+----------+------------------------------------------+ |
|                                      |                         |                            | |          name          |   type   |                  value                   | |
|                                      |                         |                            | +------------------------+----------+------------------------------------------+ |
|                                      |                         |                            | | audit_period_beginning | datetime |           2015-09-25T02:00:00            | |
|                                      |                         |                            | |  audit_period_ending   | datetime |           2015-09-25T03:00:00            | |
|                                      |                         |                            | |        disk_gb         | integer  |                    1                     | |
|                                      |                         |                            | |      ephemeral_gb      | integer  |                    0                     | |
|                                      |                         |                            | |          host          |  string  |          localhost.localdomain           | |
|                                      |                         |                            | |      instance_id       |  string  |   2115f189-c7f1-4228-97bc-d742600839f2   | |
|                                      |                         |                            | |     instance_type      |  string  |                 m1.tiny                  | |
|                                      |                         |                            | |    instance_type_id    | integer  |                    2                     | |
|                                      |                         |                            | |      launched_at       | datetime |           2015-09-24T22:24:56            | |
|                                      |                         |                            | |       memory_mb        | integer  |                   512                    | |
|                                      |                         |                            | |       project_id       |  string  |     56ffddea5b4f423496444ea36c31be23     | |
|                                      |                         |                            | |       request_id       |  string  | req-c6292b21-bf98-4a1d-b40c-cebba4d09a67 | |
|                                      |                         |                            | |        root_gb         | integer  |                    1                     | |
|                                      |                         |                            | |        service         |  string  |                 compute                  | |
|                                      |                         |                            | |         state          |  string  |                  active                  | |
|                                      |                         |                            | |       tenant_id        |  string  |     56ffddea5b4f423496444ea36c31be23     | |
|                                      |                         |                            | |        user_id         |  string  |     0b3d725756f94923b9d0c4db864d06a9     | |
|                                      |                         |                            | |         vcpus          | integer  |                    1                     | |
|                                      |                         |                            | +------------------------+----------+------------------------------------------+ |
+--------------------------------------+-------------------------+----------------------------+----------------------------------------------------------------------------------+</screen>
        <note>
          <para>As of the Liberty release, the number of items returned will be
restricted to the value defined by <literal>default_api_return_limit</literal> in the
<literal>ceilometer.conf</literal> configuration file. Alternatively, the value can
be set per query by passing the <literal>limit</literal> option in the request.</para>
        </note>
        <sect3>
          <title>Telemetry Python bindings</title>
          <para>The command-line client library provides python bindings in order to use
the Telemetry Python API directly from python programs.</para>
          <para>The first step in setting up the client is to create a client instance
with the proper credentials:</para>
          <screen language="python"><?dbsuse-fo font-size="8pt"?>&gt;&gt;&gt; import ceilometerclient.client
&gt;&gt;&gt; cclient = ceilometerclient.client.get_client(VERSION, username=USERNAME, password=PASSWORD, tenant_name=PROJECT_NAME, auth_url=AUTH_URL)</screen>
          <para>The <literal>VERSION</literal> parameter can be <literal>1</literal> or <literal>2</literal>, specifying the API
version to be used.</para>
          <para>The method calls look like the following:</para>
          <screen language="python">&gt;&gt;&gt; cclient.meters.list()
 [&lt;Meter ...&gt;, ...]

&gt;&gt;&gt; cclient.samples.list()
 [&lt;Sample ...&gt;, ...]</screen>
          <para>For further details about the python-ceilometerclient package, see the
<link xlink:href="http://docs.openstack.org/developer/python-ceilometerclient/">Python bindings to the OpenStack Ceilometer
API</link>
reference.</para>
        </sect3>
      </sect2>
      <sect2 xml:id="telemetry-publishers">
        <title>Publishers</title>
        <para>The Telemetry service provides several transport methods to forward the
data collected to the <literal>ceilometer-collector</literal> service or to an external
system. The consumers of this data are widely different, like monitoring
systems, for which data loss is acceptable and billing systems, which
require reliable data transportation. Telemetry provides methods to
fulfill the requirements of both kind of systems, as it is described
below.</para>
        <para>The publisher component makes it possible to persist the data into
storage through the message bus or to send it to one or more external
consumers. One chain can contain multiple publishers.</para>
        <para>To solve the above mentioned problem, the notion of multi-publisher can
be configured for each datapoint within the Telemetry service, allowing
the same technical meter or event to be published multiple times to
multiple destinations, each potentially using a different transport.</para>
        <para>Publishers can be specified in the <literal>publishers</literal> section for each
pipeline (for further details about pipelines see
<xref linkend="data-collection-and-processing"/>) that is defined in
the <link xlink:href="https://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/pipeline.yaml">pipeline.yaml</link>
file.</para>
        <para>The following publisher types are supported:</para>
        <variablelist>
          <varlistentry>
            <term>direct</term>
            <listitem>
              <para>It can be specified in the form of <literal>direct://?dispatcher=http</literal>. The
dispatcher's options include database, file, http, and gnocchi. For
more details on dispatcher, see <xref linkend="telemetry-storing-samples"/>.
It emits data in the configured dispatcher directly, default configuration
(the form is <literal>direct://</literal>) is database dispatcher.
In the Mitaka release, this method can only emit data to the database
dispatcher, and the form is <literal>direct://</literal>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>notifier</term>
            <listitem>
              <para>It can be specified in the form of
<literal>notifier://?option1=value1&amp;option2=value2</literal>. It emits data over
AMQP using oslo.messaging. This is the recommended method of
publishing.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>rpc</term>
            <listitem>
              <para>It can be specified in the form of
<literal>rpc://?option1=value1&amp;option2=value2</literal>. It emits metering data
over lossy AMQP. This method is synchronous and may experience
performance issues. This publisher is deprecated in Liberty in favor of
the notifier publisher.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>udp</term>
            <listitem>
              <para>It can be specified in the form of <literal>udp://&lt;host&gt;:&lt;port&gt;/</literal>. It emits
metering data for over UDP.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>file</term>
            <listitem>
              <para>It can be specified in the form of
<literal>file://path?option1=value1&amp;option2=value2</literal>. This publisher
records metering data into a file.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <note>
          <para>If a file name and location is not specified, this publisher
does not log any meters, instead it logs a warning message in
the configured log file for Telemetry.</para>
        </note>
        <variablelist>
          <varlistentry>
            <term>kafka</term>
            <listitem>
              <para>It can be specified in the form of:
<literal>kafka://kafka_broker_ip: kafka_broker_port?topic=kafka_topic
&amp;option1=value1</literal>.</para>
              <para>This publisher sends metering data to a kafka broker.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <note>
          <para>If the topic parameter is missing, this publisher brings out
metering data under a topic name, <literal>ceilometer</literal>. When the port
number is not specified, this publisher uses 9092 as the
broker's port.</para>
        </note>
        <para>The following options are available for <literal>rpc</literal> and <literal>notifier</literal>. The
policy option can be used by <literal>kafka</literal> publisher:</para>
        <variablelist>
          <varlistentry>
            <term>
              <literal>per_meter_topic</literal>
            </term>
            <listitem>
              <para>The value of it is 1. It is used for publishing the samples on
additional <literal>metering_topic.sample_name</literal> topic queue besides the
default <literal>metering_topic</literal> queue.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>policy</literal>
            </term>
            <listitem>
              <para>It is used for configuring the behavior for the case, when the
publisher fails to send the samples, where the possible predefined
values are the following:</para>
              <variablelist>
                <varlistentry>
                  <term>default</term>
                  <listitem>
                    <para>Used for waiting and blocking until the samples have been sent.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>drop</term>
                  <listitem>
                    <para>Used for dropping the samples which are failed to be sent.</para>
                  </listitem>
                </varlistentry>
                <varlistentry>
                  <term>queue</term>
                  <listitem>
                    <para>Used for creating an in-memory queue and retrying to send the
samples on the queue on the next samples publishing period (the
queue length can be configured with <literal>max_queue_length</literal>, where
1024 is the default value).</para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>The following option is additionally available for the <literal>notifier</literal> publisher:</para>
        <variablelist>
          <varlistentry>
            <term>
              <literal>topic</literal>
            </term>
            <listitem>
              <para>The topic name of queue to publish to. Setting this will override the
default topic defined by <literal>metering_topic</literal> and <literal>event_topic</literal> options.
This option can be used to support multiple consumers. Support for this
feature was added in Kilo.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>The following options are available for the <literal>file</literal> publisher:</para>
        <variablelist>
          <varlistentry>
            <term>
              <literal>max_bytes</literal>
            </term>
            <listitem>
              <para>When this option is greater than zero, it will cause a rollover.
When the size is about to be exceeded, the file is closed and a new
file is silently opened for output. If its value is zero, rollover
never occurs.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>
              <literal>backup_count</literal>
            </term>
            <listitem>
              <para>If this value is non-zero, an extension will be appended to the
filename of the old log, as '.1', '.2', and so forth until the
specified value is reached. The file that is written and contains
the newest data is always the one that is specified without any
extensions.</para>
            </listitem>
          </varlistentry>
        </variablelist>
        <para>The default publisher is <literal>notifier</literal>, without any additional options
specified. A sample <literal>publishers</literal> section in the
<literal>/etc/ceilometer/pipeline.yaml</literal> looks like the following:</para>
        <screen language="yaml">publishers:
    - udp://10.0.0.2:1234
    - rpc://?per_meter_topic=1 (deprecated in Liberty)
    - notifier://?policy=drop&amp;max_queue_length=512&amp;topic=custom_target
    - direct://?dispatcher=http</screen>
      </sect2>
    </sect1>
    <sect1 xml:id="telemetry-alarms">
      <title>Alarms</title>
      <para>Alarms provide user-oriented Monitoring-as-a-Service for resources
running on OpenStack. This type of monitoring ensures you can
automatically scale in or out a group of instances through the
Orchestration service, but you can also use alarms for general-purpose
awareness of your cloud resources' health.</para>
      <para>These alarms follow a tri-state model:</para>
      <variablelist>
        <varlistentry>
          <term>ok</term>
          <listitem>
            <para>The rule governing the alarm has been evaluated as <literal>False</literal>.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>alarm</term>
          <listitem>
            <para>The rule governing the alarm have been evaluated as <literal>True</literal>.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>insufficient data</term>
          <listitem>
            <para>There are not enough datapoints available in the evaluation periods
to meaningfully determine the alarm state.</para>
          </listitem>
        </varlistentry>
      </variablelist>
      <sect2>
        <title>Alarm definitions</title>
        <para>The definition of an alarm provides the rules that govern when a state
transition should occur, and the actions to be taken thereon. The
nature of these rules depend on the alarm type.</para>
        <sect3>
          <title>Threshold rule alarms</title>
          <para>For conventional threshold-oriented alarms, state transitions are
governed by:</para>
          <itemizedlist>
            <listitem>
              <para>A static threshold value with a comparison operator such as greater
than or less than.</para>
            </listitem>
            <listitem>
              <para>A statistic selection to aggregate the data.</para>
            </listitem>
            <listitem>
              <para>A sliding time window to indicate how far back into the recent past
you want to look.</para>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Combination rule alarms</title>
          <para>The Telemetry service also supports the concept of a meta-alarm, which
aggregates over the current state of a set of underlying basic alarms
combined via a logical operator (AND or OR).</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Alarm dimensioning</title>
        <para>A key associated concept is the notion of <emphasis>dimensioning</emphasis> which
defines the set of matching meters that feed into an alarm
evaluation. Recall that meters are per-resource-instance, so in the
simplest case an alarm might be defined over a particular meter
applied to all resources visible to a particular user. More useful
however would be the option to explicitly select which specific
resources you are interested in alarming on.</para>
        <para>At one extreme you might have narrowly dimensioned alarms where this
selection would have only a single target (identified by resource
ID). At the other extreme, you could have widely dimensioned alarms
where this selection identifies many resources over which the
statistic is aggregated. For example all instances booted from a
particular image or all instances with matching user metadata (the
latter is how the Orchestration service identifies autoscaling
groups).</para>
      </sect2>
      <sect2>
        <title>Alarm evaluation</title>
        <para>Alarms are evaluated by the <literal>alarm-evaluator</literal> service on a periodic
basis, defaulting to once every minute.</para>
        <sect3>
          <title>Alarm actions</title>
          <para>Any state transition of individual alarm (to <literal>ok</literal>, <literal>alarm</literal>, or
<literal>insufficient data</literal>) may have one or more actions associated with
it. These actions effectively send a signal to a consumer that the
state transition has occurred, and provide some additional context.
This includes the new and previous states, with some reason data
describing the disposition with respect to the threshold, the number
of datapoints involved and most recent of these. State transitions
are detected by the <literal>alarm-evaluator</literal>, whereas the
<literal>alarm-notifier</literal> effects the actual notification action.</para>
          <para>
            <emphasis role="bold">Webhooks</emphasis>
          </para>
          <para>These are the <emphasis>de facto</emphasis> notification type used by Telemetry alarming
and simply involve an HTTP POST request being sent to an endpoint,
with a request body containing a description of the state transition
encoded as a JSON fragment.</para>
          <para>
            <emphasis role="bold">Log actions</emphasis>
          </para>
          <para>These are a lightweight alternative to webhooks, whereby the state
transition is simply logged by the <literal>alarm-notifier</literal>, and are
intended primarily for testing purposes.</para>
        </sect3>
        <sect3>
          <title>Workload partitioning</title>
          <para>The alarm evaluation process uses the same mechanism for workload
partitioning as the central and compute agents. The
<link xlink:href="https://pypi.python.org/pypi/tooz">Tooz</link> library provides the
coordination within the groups of service instances. For further
information about this approach, see the section called
<xref linkend="ha-deploy-services"/>.</para>
          <para>To use this workload partitioning solution set the
<literal>evaluation_service</literal> option to <literal>default</literal>. For more
information, see the alarm section in the
<link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry.html">OpenStack Configuration Reference</link>.</para>
        </sect3>
      </sect2>
      <sect2>
        <title>Using alarms</title>
        <sect3>
          <title>Alarm creation</title>
          <para>An example of creating a threshold-oriented alarm, based on an upper
bound on the CPU utilization for a particular instance:</para>
          <screen language="console">$ ceilometer alarm-threshold-create --name cpu_hi \
  --description 'instance running hot' \
  --meter-name cpu_util --threshold 70.0 \
  --comparison-operator gt --statistic avg \
  --period 600 --evaluation-periods 3 \
  --alarm-action 'log://' \
  --query resource_id=INSTANCE_ID</screen>
          <para>This creates an alarm that will fire when the average CPU utilization
for an individual instance exceeds 70% for three consecutive 10
minute periods. The notification in this case is simply a log message,
though it could alternatively be a webhook URL.</para>
          <note>
            <para>Alarm names must be unique for the alarms associated with an
individual project. Administrator can limit the maximum
resulting actions for three different states, and the
ability for a normal user to create <literal>log://</literal> and <literal>test://</literal>
notifiers is disabled. This prevents unintentional
consumption of disk and memory resources by the
Telemetry service.</para>
          </note>
          <para>The sliding time window over which the alarm is evaluated is 30
minutes in this example. This window is not clamped to wall-clock
time boundaries, rather it's anchored on the current time for each
evaluation cycle, and continually creeps forward as each evaluation
cycle rolls around (by default, this occurs every minute).</para>
          <para>The period length is set to 600s in this case to reflect the
out-of-the-box default cadence for collection of the associated
meter. This period matching illustrates an important general
principal to keep in mind for alarms:</para>
          <note>
            <para>The alarm period should be a whole number multiple (1 or more)
of the interval configured in the pipeline corresponding to the
target meter.</para>
          </note>
          <para>Otherwise the alarm will tend to flit in and out of the
<literal>insufficient data</literal> state due to the mismatch between the actual
frequency of datapoints in the metering store and the statistics
queries used to compare against the alarm threshold. If a shorter
alarm period is needed, then the corresponding interval should be
adjusted in the <literal>pipeline.yaml</literal> file.</para>
          <para>Other notable alarm attributes that may be set on creation, or via a
subsequent update, include:</para>
          <variablelist>
            <varlistentry>
              <term>state</term>
              <listitem>
                <para>The initial alarm state (defaults to <literal>insufficient data</literal>).</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>description</term>
              <listitem>
                <para>A free-text description of the alarm (defaults to a synopsis of the
alarm rule).</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>enabled</term>
              <listitem>
                <para>True if evaluation and actioning is to be enabled for this alarm
(defaults to <literal>True</literal>).</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>repeat-actions</term>
              <listitem>
                <para>True if actions should be repeatedly notified while the alarm
remains in the target state (defaults to <literal>False</literal>).</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>ok-action</term>
              <listitem>
                <para>An action to invoke when the alarm state transitions to <literal>ok</literal>.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>insufficient-data-action</term>
              <listitem>
                <para>An action to invoke when the alarm state transitions to
<literal>insufficient data</literal>.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>time-constraint</term>
              <listitem>
                <para>Used to restrict evaluation of the alarm to certain times of the
day or days of the week (expressed as <literal>cron</literal> expression with an
optional timezone).</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <para>An example of creating a combination alarm, based on the combined
state of two underlying alarms:</para>
          <screen language="console">$ ceilometer alarm-combination-create --name meta \
  --alarm_ids ALARM_ID1 \
  --alarm_ids ALARM_ID2 \
  --operator or \
  --alarm-action 'http://example.org/notify'</screen>
          <para>This creates an alarm that will fire when either one of two underlying
alarms transition into the alarm state. The notification in this case
is a webhook call. Any number of underlying alarms can be combined in
this way, using either <literal>and</literal> or <literal>or</literal>.</para>
        </sect3>
        <sect3>
          <title>Alarm retrieval</title>
          <para>You can display all your alarms via (some attributes are omitted for
brevity):</para>
          <screen language="console">$ ceilometer alarm-list
+----------+--------+-------------------+---------------------------------+
| Alarm ID | Name   | State             | Alarm condition                 |
+----------+--------+-------------------+---------------------------------+
| ALARM_ID | cpu_hi | insufficient data | cpu_util &gt; 70.0 during 3 x 600s |
+----------+--------+-------------------+---------------------------------+</screen>
          <para>In this case, the state is reported as <literal>insufficient data</literal> which
could indicate that:</para>
          <itemizedlist>
            <listitem>
              <para>meters have not yet been gathered about this instance over the
evaluation window into the recent past (for example a brand-new
instance)</para>
            </listitem>
            <listitem>
              <para><emphasis>or</emphasis>, that the identified instance is not visible to the
user/project owning the alarm</para>
            </listitem>
            <listitem>
              <para><emphasis>or</emphasis>, simply that an alarm evaluation cycle hasn't kicked off since
the alarm was created (by default, alarms are evaluated once per
minute).</para>
            </listitem>
          </itemizedlist>
          <note>
            <para>The visibility of alarms depends on the role and project
associated with the user issuing the query:</para>
            <itemizedlist>
              <listitem>
                <para>admin users see <emphasis>all</emphasis> alarms, regardless of the owner</para>
              </listitem>
              <listitem>
                <para>non-admin users see only the alarms associated with their project
(as per the normal project segregation in OpenStack)</para>
              </listitem>
            </itemizedlist>
          </note>
        </sect3>
        <sect3>
          <title>Alarm update</title>
          <para>Once the state of the alarm has settled down, we might decide that we
set that bar too low with 70%, in which case the threshold (or most
any other alarm attribute) can be updated thusly:</para>
          <screen language="console">$ ceilometer alarm-update --threshold 75 ALARM_ID</screen>
          <para>The change will take effect from the next evaluation cycle, which by
default occurs every minute.</para>
          <para>Most alarm attributes can be changed in this way, but there is also
a convenient short-cut for getting and setting the alarm state:</para>
          <screen language="console">$ ceilometer alarm-state-get ALARM_ID
$ ceilometer alarm-state-set --state ok -a ALARM_ID</screen>
          <para>Over time the state of the alarm may change often, especially if the
threshold is chosen to be close to the trending value of the
statistic. You can follow the history of an alarm over its lifecycle
via the audit API:</para>
          <screen language="console">$ ceilometer alarm-history ALARM_ID
+------------------+-----------+---------------------------------------+
| Type             | Timestamp | Detail                                |
+------------------+-----------+---------------------------------------+
| creation         | time0     | name: cpu_hi                          |
|                  |           | description: instance running hot     |
|                  |           | type: threshold                       |
|                  |           | rule: cpu_util &gt; 70.0 during 3 x 600s |
| state transition | time1     | state: ok                             |
| rule change      | time2     | rule: cpu_util &gt; 75.0 during 3 x 600s |
+------------------+-----------+---------------------------------------+</screen>
        </sect3>
        <sect3>
          <title>Alarm deletion</title>
          <para>An alarm that is no longer required can be disabled so that it is no
longer actively evaluated:</para>
          <screen language="console">$ ceilometer alarm-update --enabled False -a ALARM_ID</screen>
          <para>or even deleted permanently (an irreversible step):</para>
          <screen language="console">$ ceilometer alarm-delete ALARM_ID</screen>
          <note>
            <para>By default, alarm history is retained for deleted alarms.</para>
          </note>
        </sect3>
      </sect2>
    </sect1>
    <sect1 xml:id="telemetry-measurements">
      <title>Measurements</title>
      <para>The Telemetry service collects meters within an OpenStack deployment.
This section provides a brief summary about meters format and origin and
also contains the list of available meters.</para>
      <para>Telemetry collects meters by polling the infrastructure elements and
also by consuming the notifications emitted by other OpenStack services.
For more information about the polling mechanism and notifications see
<xref linkend="telemetry-data-collection"/>. There are several meters which are collected
by polling and by consuming. The origin for each meter is listed in the tables
below.</para>
      <note>
        <para>You may need to configure Telemetry or other OpenStack services in
order to be able to collect all the samples you need. For further
information about configuration requirements see the <link xlink:href="http://docs.openstack.org/project-install-guide/telemetry/newton/">Telemetry chapter</link>
in the Installation Tutorials and Guides. Also check the <link xlink:href="http://docs.openstack.org/developer/ceilometer/install/manual.html">Telemetry manual
installation</link>
description.</para>
      </note>
      <para>Telemetry uses the following meter types:</para>
      <informaltable>
        <tgroup cols="2">
          <colspec colname="c1" colwidth="18.4*"/>
          <colspec colname="c2" colwidth="81.6*"/>
          <thead>
            <row>
              <entry>
                <para>Type</para>
              </entry>
              <entry>
                <para>Description</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>Cumulative</para>
              </entry>
              <entry>
                <para>Increasing over time (instance hours)</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Delta</para>
              </entry>
              <entry>
                <para>Changing over time (bandwidth)</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>Gauge</para>
              </entry>
              <entry>
                <para>Discrete items (floating IPs, image uploads) and fluctuating
values (disk I/O)</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
      <para>Telemetry provides the possibility to store metadata for samples. This
metadata can be extended for OpenStack Compute and OpenStack Object
Storage.</para>
      <para>In order to add additional metadata information to OpenStack Compute you
have two options to choose from. The first one is to specify them when
you boot up a new instance. The additional information will be stored
with the sample in the form of <literal>resource_metadata.user_metadata.*</literal>.
The new field should be defined by using the prefix <literal>metering.</literal>. The
modified boot command look like the following:</para>
      <screen language="console">$ openstack server create --property metering.custom_metadata=a_value my_vm</screen>
      <para>The other option is to set the <literal>reserved_metadata_keys</literal> to the list of
metadata keys that you would like to be included in
<literal>resource_metadata</literal> of the instance related samples that are collected
for OpenStack Compute. This option is included in the <literal>DEFAULT</literal>
section of the <literal>ceilometer.conf</literal> configuration file.</para>
      <para>You might also specify headers whose values will be stored along with
the sample data of OpenStack Object Storage. The additional information
is also stored under <literal>resource_metadata</literal>. The format of the new field
is <literal>resource_metadata.http_header_$name</literal>, where <literal>$name</literal> is the name of
the header with <literal>-</literal> replaced by <literal>_</literal>.</para>
      <para>For specifying the new header, you need to set <literal>metadata_headers</literal> option
under the <literal>[filter:ceilometer]</literal> section in <literal>proxy-server.conf</literal> under the
<literal>swift</literal> folder. You can use this additional data for instance to distinguish
external and internal users.</para>
      <para>Measurements are grouped by services which are polled by
Telemetry or emit notifications that this service consumes.</para>
      <note>
        <para>The Telemetry service supports storing notifications as events. This
functionality was added later, therefore the list of meters still
contains existence type and other event related items. The proper
way of using Telemetry is to configure it to use the event store and
turn off the collection of the event related meters. For further
information about events see <link xlink:href="http://docs.openstack.org/developer/ceilometer/events.html">Events section</link>
in the Telemetry documentation. For further information about how to
turn on and off meters see <xref linkend="telemetry-pipeline-configuration"/>. Please
also note that currently no migration is available to move the already
existing event type samples to the event store.</para>
      </note>
      <sect2 xml:id="telemetry-compute-meters">
        <title>OpenStack Compute</title>
        <para>The following meters are collected for OpenStack Compute:</para>
        <informaltable>
          <tgroup cols="7">
            <colspec colname="c1" colwidth="15.5*"/>
            <colspec colname="c2" colwidth="9.9*"/>
            <colspec colname="c3" colwidth="8.5*"/>
            <colspec colname="c4" colwidth="14.1*"/>
            <colspec colname="c5" colwidth="14.1*"/>
            <colspec colname="c6" colwidth="12.7*"/>
            <colspec colname="c7" colwidth="25.4*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Support</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c7">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>instance</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>instance</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification,
Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Existence of
instance</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>instance:&lt;type&gt;</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>instance</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification,
Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Existence of
instance &lt;type&gt;
(OpenStack types)</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>memory</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>MB</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Volume of RAM
allocated to the
instance</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>memory.usage</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>MB</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>vSphere</para>
                </entry>
                <entry>
                  <para>Volume of RAM
used by the
instance from the
amount of its
allocated memory</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cpu</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>ns</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>CPU time used</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cpu_util</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>vSphere</para>
                </entry>
                <entry>
                  <para>Average CPU
utilization</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>vcpus</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>vcpu</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of virtual
CPUs allocated to
the instance</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.read.requests</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>request</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of read
requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.read.requests.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>request/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
read requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.write.requests</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>request</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of write
requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.write.requests.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>request/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
write requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.read.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Volume of reads</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.read.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
reads</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.write.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Volume of writes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.write.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
writes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.root.size</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>GB</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Size of root disk</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.ephemeral.size</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>GB</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Size of ephemeral
disk</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.incoming.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of
incoming bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.incoming.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
incoming bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.outgoing.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of
outgoing bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.outgoing.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
outgoing bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.incoming.packets</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of
incoming packets</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.incoming.packets.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>packet/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
incoming packets</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.outgoing.packets</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of
outgoing packets</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.outgoing.packets.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>packet/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
outgoing packets</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c7">
                  <para>
                    <emphasis role="bold">Meters added or hypervisor support changed in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>instance</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>instance</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification,
Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Existence of
instance</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>instance:&lt;type&gt;</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>instance</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification,
Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Existence of
instance &lt;type&gt;
(OpenStack types)</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>memory.usage</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>MB</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Volume of RAM
used by the
instance from the
amount of its
allocated memory</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cpu_util</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Average CPU
utilization</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.read.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Average rate of
reads</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.write.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Average rate of
writes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.read.requests</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>request</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of read
requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.read.requests.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>request/s</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
read requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.write.requests</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>request</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Number of write
requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.write.requests.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>request/s</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
write requests</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.read.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Volume of reads</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.read.bytes
.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
reads</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.write.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>Volume of writes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.write.bytes
.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere</para>
                </entry>
                <entry>
                  <para>Average rate of
writes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.incoming.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Average rate of
incoming bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.outgoing.bytes.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Average rate of
outgoing bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.incoming.packets.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>packet/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Average rate of
incoming packets</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.outgoing.packets.rate</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>packet/s</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Average rate of
outgoing packets</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c7">
                  <para>
                    <emphasis role="bold">Meters added or hypervisor support changed in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>memory.usage</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>MB</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Volume of RAM
used by the instance from the
amount of its
allocated memory</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>memory.resident</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>MB</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>Volume of RAM used by the instance on the physical machine</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.latency</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>ms</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Hyper-V</para>
                </entry>
                <entry>
                  <para>Average disk latency</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.iops</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>count/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Hyper-V</para>
                </entry>
                <entry>
                  <para>Average disk iops</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.latency</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>ms</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Hyper-V</para>
                </entry>
                <entry>
                  <para>Average disk latency per device</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.iops</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>count/s</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Hyper-V</para>
                </entry>
                <entry>
                  <para>Average disk iops per device</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.capacity</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>The amount of disk that the instance can see</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.allocation</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>The amount of disk occupied by
the instance on the host machine</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.usage</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>The physical size in bytes of
the image container on the host</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.capacity</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>The amount of disk per device
that the instance can see</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.allocation</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>The amount of disk per device
occupied by the
instance on the host machine</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>disk.device.usage</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>The physical size in bytes of
the image container on the host per device</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c7">
                  <para>
                    <emphasis role="bold">Meters deprecated in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>instance:&lt;type&gt;</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>instance</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Notification,
Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V,
vSphere,
XenAPI</para>
                </entry>
                <entry>
                  <para>Existence of
instance &lt;type&gt;
(OpenStack types)</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c7">
                  <para>
                    <emphasis role="bold">Meters added in the Liberty release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cpu.delta</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ns</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt,
Hyper-V</para>
                </entry>
                <entry>
                  <para>CPU time used since previous datapoint</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c7">
                  <para>
                    <emphasis role="bold">Meters added in the Newton release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cpu_l3_cache</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>L3 cache used by the instance</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>memory.bandwidth.total</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>Total system bandwidth from one level of cache</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>memory.bandwidth.local</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B/s</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>Bandwidth of memory traffic for a memory controller</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>perf.cpu.cycles</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>cycle</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>the number of cpu cycles one instruction needs</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>perf.instructions</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>instruction</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>the count of instructions</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>perf.cache.references</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>count</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>the count of cache hits</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>perf.cache.misses</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>count</para>
                </entry>
                <entry>
                  <para>instance
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Libvirt</para>
                </entry>
                <entry>
                  <para>the count of cache misses</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <procedure>
           <!-- <step>
              <para>In the Ocata release, the <literal>instance</literal> meter is no longer supported..</para>
            </step>-->
            <step>
              <para>The <literal>instance:&lt;type&gt;</literal> meter can be replaced by using extra parameters in
both the samples and statistics queries. Sample queries look like:</para>
            </step>
          </procedure>
          <screen language="console">statistics:

  ceilometer statistics -m instance -g resource_metadata.instance_type

samples:

  ceilometer sample-list -m instance -q metadata.instance_type=&lt;value&gt;</screen>
        </note>
        <para>The Telemetry service supports to create new meters by using
transformers. For more details about transformers see
<xref linkend="telemetry-transformers"/>. Among the meters gathered from libvirt and
Hyper-V there are a few ones which are generated from other meters. The list of
meters that are created by using the <literal>rate_of_change</literal> transformer from the
above table is the following:</para>
        <itemizedlist>
          <listitem>
            <para>cpu_util</para>
          </listitem>
          <listitem>
            <para>disk.read.requests.rate</para>
          </listitem>
          <listitem>
            <para>disk.write.requests.rate</para>
          </listitem>
          <listitem>
            <para>disk.read.bytes.rate</para>
          </listitem>
          <listitem>
            <para>disk.write.bytes.rate</para>
          </listitem>
          <listitem>
            <para>disk.device.read.requests.rate</para>
          </listitem>
          <listitem>
            <para>disk.device.write.requests.rate</para>
          </listitem>
          <listitem>
            <para>disk.device.read.bytes.rate</para>
          </listitem>
          <listitem>
            <para>disk.device.write.bytes.rate</para>
          </listitem>
          <listitem>
            <para>network.incoming.bytes.rate</para>
          </listitem>
          <listitem>
            <para>network.outgoing.bytes.rate</para>
          </listitem>
          <listitem>
            <para>network.incoming.packets.rate</para>
          </listitem>
          <listitem>
            <para>network.outgoing.packets.rate</para>
          </listitem>
        </itemizedlist>
        <note>
          <para>To enable the libvirt <literal>memory.usage</literal> support, you need to install
libvirt version 1.1.1+, QEMU version 1.5+, and you also need to
prepare suitable balloon driver in the image. It is applicable
particularly for Windows guests, most modern Linux distributions
already have it built in. Telemetry is not able to fetch the
<literal>memory.usage</literal> samples without the image balloon driver.</para>
        </note>
        <para>OpenStack Compute is capable of collecting <literal>CPU</literal> related meters from
the compute host machines. In order to use that you need to set the
<literal>compute_monitors</literal> option to <literal>ComputeDriverCPUMonitor</literal> in the
<literal>nova.conf</literal> configuration file. For further information see the
Compute configuration section in the <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/config-options.html">Compute chapter</link>
of the OpenStack Configuration Reference.</para>
        <para>The following host machine related meters are collected for OpenStack
Compute:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="29.2*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="8.3*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="18.1*"/>
            <colspec colname="c6" colwidth="20.8*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.frequency</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>MHz</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU frequency</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.kernel.time</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>ns</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU kernel
time</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.idle.time</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>ns</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU idle time</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.user.time</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>ns</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU user mode
time</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.iowait.time</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>ns</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU I/O wait
time</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.kernel.percent</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU kernel
percentage</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.idle.percent</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU idle
percentage</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.user.percent</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU user mode
percentage</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.iowait.percent</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU I/O wait
percentage</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>compute.node.cpu.percent</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>CPU
utilization</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2 xml:id="telemetry-bare-metal-service">
        <title>Bare metal service</title>
        <para>Telemetry captures notifications that are emitted by the Bare metal
service. The source of the notifications are IPMI sensors that collect
data from the host machine.</para>
        <note>
          <para>The sensor data is not available in the Bare metal service by
default. To enable the meters and configure this module to emit
notifications about the measured values see the <link xlink:href="http://docs.openstack.org/project-install-guide/baremetal/newton">Installation
Guide</link>
for the Bare metal service.</para>
        </note>
        <para>The following meters are recorded for the Bare metal service:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="25.0*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="8.3*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="18.1*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.fan</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>RPM</para>
                </entry>
                <entry>
                  <para>fan
sensor</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Fan rounds per
minute (RPM)</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.temperature</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>C</para>
                </entry>
                <entry>
                  <para>temperature
sensor</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Temperature reading from sensor</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.current</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>W</para>
                </entry>
                <entry>
                  <para>current
sensor</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Current reading
from sensor</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.voltage</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>V</para>
                </entry>
                <entry>
                  <para>voltage
sensor</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Voltage reading
from sensor</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>IPMI based meters</title>
        <para>Another way of gathering IPMI based data is to use IPMI sensors
independently from the Bare metal service's components. Same meters as
<xref linkend="telemetry-bare-metal-service"/> could be fetched except that origin is
<literal>Pollster</literal> instead of <literal>Notification</literal>.</para>
        <para>You need to deploy the ceilometer-agent-ipmi on each IPMI-capable node
in order to poll local sensor data. For further information about the
IPMI agent see <xref linkend="telemetry-ipmi-agent"/>.</para>
        <warning>
          <para>To avoid duplication of metering data and unnecessary load on the
IPMI interface, do not deploy the IPMI agent on nodes that are
managed by the Bare metal service and keep the
<literal>conductor.send_sensor_data</literal> option set to <literal>False</literal> in the
<literal>ironic.conf</literal> configuration file.</para>
        </warning>
        <para>Besides generic IPMI sensor data, the following Intel Node Manager
meters are recorded from capable platform:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="29.2*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="8.3*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="13.9*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.power</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>W</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Current power
of the system</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.temperature</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>C</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Current temperature of the
system</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.inlet_temperature</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>C</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Inlet temperature of the system</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.outlet_temperature</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>C</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Outlet temperature of the system</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.airflow</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>CFM</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Volumetric airflow of the system, expressed as
1/10th of CFM</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.cups</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>CUPS</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>CUPS(Compute Usage Per Second)
index data of the
system</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.cpu_util</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>CPU CUPS utilization of the
system</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.mem_util</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Memory CUPS
utilization of
the system</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.io_util</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>IO CUPS
utilization of
the system</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="47.4*"/>
            <colspec colname="c2" colwidth="52.6*"/>
            <thead>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>Meters renamed in the Kilo release</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>
                    <emphasis role="bold">Original Name</emphasis>
                  </para>
                </entry>
                <entry>
                  <para>
                    <emphasis role="bold">New Name</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.temperature</para>
                </entry>
                <entry>
                  <para>hardware.ipmi.node.inlet_temperature</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.ipmi.node.inlet_temperature</para>
                </entry>
                <entry>
                  <para>hardware.ipmi.node.temperature</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>SNMP based meters</title>
        <para>Telemetry supports gathering SNMP based generic host meters. In order to
be able to collect this data you need to run snmpd on each target host.</para>
        <para>The following meters are available about the host machines by using
SNMP:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="29.2*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="8.3*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="13.9*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.cpu.load.1min</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>process</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>CPU load in the
past 1 minute</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.cpu.load.5min</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>process</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>CPU load in the
past 5 minutes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.cpu.load.15min</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>process</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>CPU load in the
past 15 minutes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.disk.size.total</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total disk size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.disk.size.used</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>disk ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Used disk size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.memory.total</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total physical
memory size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.memory.used</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Used physical memory size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.memory.buffer</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Physical memory
buffer size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.memory.cached</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Cached physical
memory size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.memory.swap.total</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total swap space
size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.memory.swap.avail</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>KB</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Available swap
space size</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.network.incoming.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Bytes received
by network interface</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.network.outgoing.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Bytes sent by network interface</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.network.outgoing.errors</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>interface
ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Sending error of network interface</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.network.ip.incoming.datagrams</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>datagrams</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of received datagrams</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.network.ip.outgoing.datagrams</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>datagrams</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of sent
datagrams</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.system_stats.io.incoming.blocks</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>blocks</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Aggregated number of blocks received to block
device</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.system_stats.io.outgoing.blocks</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>blocks</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Aggregated number of blocks sent to block device</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.system_stats.cpu.idle</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>CPU idle percentage</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Mitaka release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>hardware.cpu.util</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>%</para>
                </entry>
                <entry>
                  <para>host ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>cpu usage
percentage</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>OpenStack Image service</title>
        <para>The following meters are collected for OpenStack Image service:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="27.8*"/>
            <colspec colname="c2" colwidth="11.1*"/>
            <colspec colname="c3" colwidth="8.3*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="13.9*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>image</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>image</para>
                </entry>
                <entry>
                  <para>image ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of the
image</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>image.size</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>image</para>
                </entry>
                <entry>
                  <para>image ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Size of the uploaded image</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>image.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>image</para>
                </entry>
                <entry>
                  <para>image ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of updates on the image</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>image.upload</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>image</para>
                </entry>
                <entry>
                  <para>image ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of uploads on the image</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>image.delete</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>image</para>
                </entry>
                <entry>
                  <para>image ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of deletes on the image</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>image.download</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>image ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Image is downloaded</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>image.serve</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>image ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Image is served
out</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>OpenStack Block Storage</title>
        <para>The following meters are collected for OpenStack Block Storage:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="27.8*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="11.1*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="13.9*"/>
            <colspec colname="c6" colwidth="23.6*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Existence of the
volume</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.size</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>GB</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Size of the volume</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>snapshot</para>
                </entry>
                <entry>
                  <para>snapshot
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Existence of the
snapshot</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot.size</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>GB</para>
                </entry>
                <entry>
                  <para>snapshot
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Size of the snapshot</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.create.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation of the
volume</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.delete.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Deletion of the
volume</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.update.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Update the name
or description
of the volume</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.resize.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Update the size
of the volume</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.attach.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Attaching the volume to an instance</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.detach.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>volume ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Detaching the volume from an instance</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot.create.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>snapshot</para>
                </entry>
                <entry>
                  <para>snapshot
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation of the
snapshot</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshot.delete.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>snapshot</para>
                </entry>
                <entry>
                  <para>snapshot
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Deletion of the
snapshot</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.backup.create.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>backup ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation of the
volume backup</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.backup.delete.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>backup ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Deletion of the
volume backup</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volume.backup.restore.(start|end)</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>volume</para>
                </entry>
                <entry>
                  <para>backup ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Restoration of
the volume backup</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2 xml:id="telemetry-object-storage-meter">
        <title>OpenStack Object Storage</title>
        <para>The following meters are collected for OpenStack Object Storage:</para>
        <informaltable>
          <tgroup cols="11">
            <colspec colname="c1" colwidth="26.9*"/>
            <colspec colname="c2" colwidth="1.5*"/>
            <colspec colname="c3" colwidth="7.5*"/>
            <colspec colname="c4" colwidth="1.5*"/>
            <colspec colname="c5" colwidth="6.0*"/>
            <colspec colname="c6" colwidth="3.0*"/>
            <colspec colname="c7" colwidth="10.4*"/>
            <colspec colname="c8" colwidth="6.0*"/>
            <colspec colname="c9" colwidth="11.9*"/>
            <colspec colname="c10" colwidth="0.0*"/>
            <colspec colname="c11" colwidth="25.4*"/>
            <thead>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>Name</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Type</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Unit</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Resource</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c11">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.objects</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Gauge</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>object</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of objects</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.objects.size</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Gauge</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>B</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total size of stored objects</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.objects.containers</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Gauge</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>container</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of containers</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.objects.incoming.bytes</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>B</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of incoming bytes</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.objects.outgoing.bytes</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>B</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of outgoing bytes</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.api.request</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>request</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of API requests against
OpenStack Object Storage</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.containers.objects</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Gauge</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>object</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID/container</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of objects in container</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.containers.objects.size</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Gauge</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>B</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID/container</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total size of stored objects in container</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11">
                  <para>
                    <emphasis role="bold">meters deprecated in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11">
                  <para>storage.objects.in| Delta | B     | storage ID | Notific| Number of incomcoming.bytes       |       |       |            | ation   | ing bytes</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.objects.outgoing.bytes</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>B</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of outgoing bytes</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>storage.api.request</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>request</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>storage ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of API requests against
OpenStack Object Storage</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Ceph Object Storage</title>
        <para>In order to gather meters from Ceph, you have to install and configure
the Ceph Object Gateway (radosgw) as it is described in the <link xlink:href="http://docs.ceph.com/docs/master/radosgw/">Installation
Manual</link>. You have to enable
<link xlink:href="http://ceph.com/docs/master/man/8/radosgw/#usage-logging">usage logging</link> in
order to get the related meters from Ceph. You will also need an
<literal>admin</literal> user with <literal>users</literal>, <literal>buckets</literal>, <literal>metadata</literal> and <literal>usage</literal><literal>caps</literal> configured.</para>
        <para>In order to access Ceph from Telemetry, you need to specify a
<literal>service group</literal> for <literal>radosgw</literal> in the <literal>ceilometer.conf</literal>
configuration file along with <literal>access_key</literal> and <literal>secret_key</literal> of the
<literal>admin</literal> user mentioned above.</para>
        <para>The following meters are collected for Ceph Object Storage:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="25.0*"/>
            <colspec colname="c2" colwidth="8.3*"/>
            <colspec colname="c3" colwidth="11.1*"/>
            <colspec colname="c4" colwidth="16.7*"/>
            <colspec colname="c5" colwidth="13.9*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>radosgw.objects</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>object</para>
                </entry>
                <entry>
                  <para>storage ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of objects</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>radosgw.objects.size</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>storage ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total size of stored objects</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>radosgw.objects.containers</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>container</para>
                </entry>
                <entry>
                  <para>storage ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of containers</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>radosgw.api.request</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>request</para>
                </entry>
                <entry>
                  <para>storage ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of API requests against
Ceph Object Gateway (radosgw)</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>radosgw.containers.objects</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>object</para>
                </entry>
                <entry>
                  <para>storage ID/container</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of objects in container</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>radosgw.containers.objects.size</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>storage ID/container</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total size of stored objects in
container</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <para>The <literal>usage</literal> related information may not be updated right after an
upload or download, because the Ceph Object Gateway needs time to
update the usage properties. For instance, the default configuration
needs approximately 30 minutes to generate the usage logs.</para>
        </note>
      </sect2>
      <sect2>
        <title>OpenStack Identity</title>
        <para>The following meters are collected for OpenStack Identity:</para>
        <informaltable>
          <tgroup cols="10">
            <colspec colname="c1" colwidth="26.5*"/>
            <colspec colname="c2" colwidth="0.0*"/>
            <colspec colname="c3" colwidth="8.8*"/>
            <colspec colname="c4" colwidth="8.8*"/>
            <colspec colname="c5" colwidth="1.5*"/>
            <colspec colname="c6" colwidth="11.8*"/>
            <colspec colname="c7" colwidth="2.9*"/>
            <colspec colname="c8" colwidth="14.7*"/>
            <colspec colname="c9" colwidth="0.0*"/>
            <colspec colname="c10" colwidth="25.0*"/>
            <thead>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Unit</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Resource</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c10">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.authenticate.success</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>User successfully authenticated</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.authenticate.pending</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>User pending authentication</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.authenticate.failure</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>User failed to
authenticate</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.user.created</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>User is created</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.user.deleted</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>User is deleted</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.user.updated</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>user ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>User is updated</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.group.created</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>group</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>group ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Group is created</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.group.deleted</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>group</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>group ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Group is deleted</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.group.updated</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>group</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>group ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Group is updated</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.role.created</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Role is created</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.role.deleted</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Role is deleted</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.role.updated</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Role is updated</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.project.created</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>project</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>project ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Project is created</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.project.deleted</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>project</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>project ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Project is deleted</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.project.updated</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>project</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>project ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Project is updated</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.trust.created</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>trust</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>trust ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Trust is created</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.trust.deleted</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>trust</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>trust ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Trust is deleted</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c10">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.role_assignment.created</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role_assignment</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Role is added to
an actor on a
target</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c2">
                  <para>identity.role_assignment.deleted</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role_assignment</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>role ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Role is removed
from an actor
on a target</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c10">
                  <para>
                    <emphasis role="bold">All meters thoroughly deprecated in the liberty release</emphasis>
                  </para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>OpenStack Networking</title>
        <para>The following meters are collected for OpenStack Networking:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="23.6*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="11.1*"/>
            <colspec colname="c4" colwidth="15.3*"/>
            <colspec colname="c5" colwidth="15.3*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>network</para>
                </entry>
                <entry>
                  <para>network ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Existence of network</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>network</para>
                </entry>
                <entry>
                  <para>network ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation requests for this network</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>network</para>
                </entry>
                <entry>
                  <para>network ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Update requests
for this network</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>subnet</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>subnet</para>
                </entry>
                <entry>
                  <para>subnet ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Existence of subnet</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>subnet.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>subnet</para>
                </entry>
                <entry>
                  <para>subnet ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation requests for this subnet</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>subnet.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>subnet</para>
                </entry>
                <entry>
                  <para>subnet ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Update requests
for this subnet</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>port</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>port</para>
                </entry>
                <entry>
                  <para>port ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Existence of port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>port.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>port</para>
                </entry>
                <entry>
                  <para>port ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation requests for this port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>port.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>port</para>
                </entry>
                <entry>
                  <para>port ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Update requests
for this port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>router</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>router</para>
                </entry>
                <entry>
                  <para>router ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Existence of router</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>router.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>router</para>
                </entry>
                <entry>
                  <para>router ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation requests for this router</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>router.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>router</para>
                </entry>
                <entry>
                  <para>router ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Update requests
for this router</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>ip.floating</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>ip</para>
                </entry>
                <entry>
                  <para>ip ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of IP</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>ip.floating.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ip</para>
                </entry>
                <entry>
                  <para>ip ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Creation requests for this IP</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>ip.floating.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ip</para>
                </entry>
                <entry>
                  <para>ip ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Update requests
for this IP</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>bandwidth</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>label ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Bytes through this l3 metering
label</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>SDN controllers</title>
        <para>The following meters are collected for SDN:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="23.6*"/>
            <colspec colname="c2" colwidth="12.5*"/>
            <colspec colname="c3" colwidth="11.1*"/>
            <colspec colname="c4" colwidth="15.3*"/>
            <colspec colname="c5" colwidth="13.9*"/>
            <colspec colname="c6" colwidth="23.6*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>switch</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Existence of switch</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>port</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Existence of port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.receive.packets</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Packets received on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.transmit.packets</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Packets transmitted on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.receive.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Bytes received
on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.transmit.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Bytes transmitted on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.receive.drops</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Drops received
on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.transmit.drops</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Drops transmitted on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.receive.errors</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Errors received
on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.transmit.errors</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Errors transmitted on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.receive.frame_error</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Frame alignment
errors received on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.receive.overrun_error</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Overrun errors
received on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.receive.crc_error</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>CRC errors received on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.port.collision.count</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>count</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Collisions on port</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.table</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>table</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Duration of table</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.table.active.entries</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>entry</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Active entries
in table</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.table.lookup.packets</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Lookup packets
for table</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.table.matched.packets</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Packets matches
for table</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.flow</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>flow</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Duration of flow</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.flow.duration.seconds</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>s</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Duration of flow
in seconds</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.flow.duration.nanoseconds</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>ns</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Duration of flow
in nanoseconds</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.flow.packets</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>packet</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Packets received</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>switch.flow.bytes</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>switch ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Bytes received</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>These meters are available for OpenFlow based switches. In order to
enable these meters, each driver needs to be properly configured.</para>
      </sect2>
      <sect2>
        <title>Load-Balancer-as-a-Service (LBaaS v1)</title>
        <para>The following meters are collected for LBaaS v1:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="20.8*"/>
            <colspec colname="c2" colwidth="12.5*"/>
            <colspec colname="c3" colwidth="12.5*"/>
            <colspec colname="c4" colwidth="15.3*"/>
            <colspec colname="c5" colwidth="15.3*"/>
            <colspec colname="c6" colwidth="23.6*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.pool</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>pool</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB pool</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.vip</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>vip</para>
                </entry>
                <entry>
                  <para>vip ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB VIP</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.member</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>member</para>
                </entry>
                <entry>
                  <para>member ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB member</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.health_monitor</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>health_monitor</para>
                </entry>
                <entry>
                  <para>monitor ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB health probe</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.total.connections</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>connection</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total connections on a LB</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.active.connections</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>connection</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Active connections on a LB</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.incoming.bytes</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of incoming Bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.outgoing.bytes</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of outgoing Bytes</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.pool.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>pool</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB pool was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.pool.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>pool</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB pool was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.vip.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>vip</para>
                </entry>
                <entry>
                  <para>vip ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB VIP was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.vip.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>vip</para>
                </entry>
                <entry>
                  <para>vip ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB VIP was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.member.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>member</para>
                </entry>
                <entry>
                  <para>member ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB member was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.member.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>member</para>
                </entry>
                <entry>
                  <para>member ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB member was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.health_monitor.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>health_monitor</para>
                </entry>
                <entry>
                  <para>monitor ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB health probe
was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.health_monitor.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>health_monitor</para>
                </entry>
                <entry>
                  <para>monitor ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB health probe
was updated</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Load-Balancer-as-a-Service (LBaaS v2)</title>
        <para>The following meters are collected for LBaaS v2. They are added in Mitaka
release:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="20.8*"/>
            <colspec colname="c2" colwidth="12.5*"/>
            <colspec colname="c3" colwidth="12.5*"/>
            <colspec colname="c4" colwidth="15.3*"/>
            <colspec colname="c5" colwidth="15.3*"/>
            <colspec colname="c6" colwidth="23.6*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>network.services.lb.pool</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>pool</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB pool</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.listener</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>listener</para>
                </entry>
                <entry>
                  <para>listener
ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB listener</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.member</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>member</para>
                </entry>
                <entry>
                  <para>member ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB member</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.health_monitor</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>health_monitor</para>
                </entry>
                <entry>
                  <para>monitor ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB health probe</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.loadbalancer</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>loadbalancer</para>
                </entry>
                <entry>
                  <para>loadbalancer ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
LB loadbalancer</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.total.connections</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>connection</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Total connections on a LB</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.active.connections</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>connection</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Active connections on a LB</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.incoming.bytes</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of incoming Bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.outgoing.bytes</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>B</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Number of outgoing Bytes</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.pool.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>pool</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB pool was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.pool.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>pool</para>
                </entry>
                <entry>
                  <para>pool ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB pool was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.listener.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>listener</para>
                </entry>
                <entry>
                  <para>listener
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB listener was
created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.listener.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>listener</para>
                </entry>
                <entry>
                  <para>listener
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB listener was
updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.member.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>member</para>
                </entry>
                <entry>
                  <para>member ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB member was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.member.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>member</para>
                </entry>
                <entry>
                  <para>member ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB member was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.healthmonitor.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>health_monitor</para>
                </entry>
                <entry>
                  <para>monitor ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB health probe
was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.healthmonitor.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>health_monitor</para>
                </entry>
                <entry>
                  <para>monitor ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB health probe
was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.loadbalancer.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>loadbalancer</para>
                </entry>
                <entry>
                  <para>loadbalancer ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB loadbalancer
was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.lb.loadbalancer.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>loadbalancer</para>
                </entry>
                <entry>
                  <para>loadbalancer ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>LB loadbalancer
was updated</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <para>The above meters are experimental and may generate a large load against the
Neutron APIs. The future enhancement will be implemented when Neutron
supports the new APIs.</para>
        </note>
      </sect2>
      <sect2>
        <title>VPN-as-a-Service (VPNaaS)</title>
        <para>The following meters are collected for VPNaaS:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="20.8*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="12.5*"/>
            <colspec colname="c4" colwidth="16.7*"/>
            <colspec colname="c5" colwidth="15.3*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>vpnservice</para>
                </entry>
                <entry>
                  <para>vpn ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
VPN</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.connections</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>ipsec_site_connection</para>
                </entry>
                <entry>
                  <para>connection
ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of an
IPSec connection</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>vpnservice</para>
                </entry>
                <entry>
                  <para>vpn ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>VPN was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>vpnservice</para>
                </entry>
                <entry>
                  <para>vpn ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>VPN was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.connections.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ipsec_site_connection</para>
                </entry>
                <entry>
                  <para>connection
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>IPSec connection
was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.connections.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ipsec_site_connection</para>
                </entry>
                <entry>
                  <para>connection
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>IPSec connection
was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.ipsecpolicy</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>ipsecpolicy</para>
                </entry>
                <entry>
                  <para>ipsecpolicy
ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of an
IPSec policy</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.ipsecpolicy.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ipsecpolicy</para>
                </entry>
                <entry>
                  <para>ipsecpolicy
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>IPSec policy was
created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.ipsecpolicy.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ipsecpolicy</para>
                </entry>
                <entry>
                  <para>ipsecpolicy
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>IPSec policy was
updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.ikepolicy</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>ikepolicy</para>
                </entry>
                <entry>
                  <para>ikepolicy
ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of an
Ike policy</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.ikepolicy.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ikepolicy</para>
                </entry>
                <entry>
                  <para>ikepolicy
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Ike policy was
created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.vpn.ikepolicy.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>ikepolicy</para>
                </entry>
                <entry>
                  <para>ikepolicy
ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Ike policy was
updated</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Firewall-as-a-Service (FWaaS)</title>
        <para>The following meters are collected for FWaaS:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="20.8*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="12.5*"/>
            <colspec colname="c4" colwidth="16.7*"/>
            <colspec colname="c5" colwidth="15.3*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>firewall</para>
                </entry>
                <entry>
                  <para>firewall ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
firewall</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.policy</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>firewall_policy</para>
                </entry>
                <entry>
                  <para>firewall ID</para>
                </entry>
                <entry>
                  <para>Notification, Pollster</para>
                </entry>
                <entry>
                  <para>Existence of a
firewall policy</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>firewall</para>
                </entry>
                <entry>
                  <para>firewall ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Firewall was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>firewall</para>
                </entry>
                <entry>
                  <para>firewall ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Firewall was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.policy.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>firewall_policy</para>
                </entry>
                <entry>
                  <para>policy ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Firewall policy
was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.policy.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>firewall_policy</para>
                </entry>
                <entry>
                  <para>policy ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Firewall policy
was updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.rule</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>firewall_rule</para>
                </entry>
                <entry>
                  <para>rule ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Existence of a
firewall rule</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.rule.create</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>firewall_rule</para>
                </entry>
                <entry>
                  <para>rule ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Firewall rule was created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>network.services.firewall.rule.update</para>
                </entry>
                <entry>
                  <para>Delta</para>
                </entry>
                <entry>
                  <para>firewall_rule</para>
                </entry>
                <entry>
                  <para>rule ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Firewall rule was updated</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Orchestration service</title>
        <para>The following meters are collected for the Orchestration service:</para>
        <informaltable>
          <tgroup cols="11">
            <colspec colname="c1" colwidth="23.9*"/>
            <colspec colname="c2" colwidth="1.5*"/>
            <colspec colname="c3" colwidth="7.5*"/>
            <colspec colname="c4" colwidth="1.5*"/>
            <colspec colname="c5" colwidth="6.0*"/>
            <colspec colname="c6" colwidth="1.5*"/>
            <colspec colname="c7" colwidth="11.9*"/>
            <colspec colname="c8" colwidth="1.5*"/>
            <colspec colname="c9" colwidth="17.9*"/>
            <colspec colname="c10" colwidth="0.0*"/>
            <colspec colname="c11" colwidth="26.9*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Type</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Unit</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Resource</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Origin</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c11">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>stack.create</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Stack was successfully created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>stack.update</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Stack was successfully updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>stack.delete</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Stack was successfully deleted</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>stack.resume</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Stack was successfully resumed</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>stack.suspend</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>stack ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Stack was successfully suspended</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11">
                  <para>
                    <emphasis role="bold">All meters thoroughly deprecated in the Liberty release</emphasis>
                  </para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Data processing service for OpenStack</title>
        <para>The following meters are collected for the Data processing service for
OpenStack:</para>
        <informaltable>
          <tgroup cols="11">
            <colspec colname="c1" colwidth="23.9*"/>
            <colspec colname="c2" colwidth="1.5*"/>
            <colspec colname="c3" colwidth="7.5*"/>
            <colspec colname="c4" colwidth="1.5*"/>
            <colspec colname="c5" colwidth="9.0*"/>
            <colspec colname="c6" colwidth="0.0*"/>
            <colspec colname="c7" colwidth="13.4*"/>
            <colspec colname="c8" colwidth="1.5*"/>
            <colspec colname="c9" colwidth="16.4*"/>
            <colspec colname="c10" colwidth="1.5*"/>
            <colspec colname="c11" colwidth="23.9*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Type</para>
                </entry>
                <entry namest="c1" nameend="c3">
                  <para>Unit</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Resource</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c11">
                  <para>
                    <emphasis role="bold">Meters added in the Juno release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cluster.create</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c3">
                  <para>cluster</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>cluster ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Cluster was
successfully
created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cluster.update</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c3">
                  <para>cluster</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>cluster ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Cluster was
successfully
updated</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>cluster.delete</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Delta</para>
                </entry>
                <entry namest="c1" nameend="c3">
                  <para>cluster</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>cluster ID</para>
                </entry>
                <entry namest="c1" nameend="c2">
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Cluster was
successfully
deleted</para>
                </entry>
              </row>
              <row>
                <entry namest="c1" nameend="c11">
                  <para>
                    <emphasis role="bold">All meters thoroughly deprecated in the Liberty release</emphasis>
                  </para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Key Value Store module</title>
        <para>The following meters are collected for the Key Value Store module:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="25.0*"/>
            <colspec colname="c2" colwidth="9.7*"/>
            <colspec colname="c3" colwidth="8.3*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="18.1*"/>
            <colspec colname="c6" colwidth="25.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Kilo release</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>magnetodb.table.create</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>table</para>
                </entry>
                <entry>
                  <para>table ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Table was successfully created</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>magnetodb.table.delete</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>table</para>
                </entry>
                <entry>
                  <para>table ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Table was successfully deleted</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>magnetodb.table.index.count</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>index</para>
                </entry>
                <entry>
                  <para>table ID</para>
                </entry>
                <entry>
                  <para>Notification</para>
                </entry>
                <entry>
                  <para>Number of indices
created in a
table</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <para>The the Key Value Store meters are not supported in the Newton release and
later.</para>
        </note>
      </sect2>
      <sect2>
        <title>Energy</title>
        <para>The following energy related meters are available:</para>
        <informaltable>
          <tgroup cols="6">
            <colspec colname="c1" colwidth="20.8*"/>
            <colspec colname="c2" colwidth="16.7*"/>
            <colspec colname="c3" colwidth="8.3*"/>
            <colspec colname="c4" colwidth="13.9*"/>
            <colspec colname="c5" colwidth="13.9*"/>
            <colspec colname="c6" colwidth="26.4*"/>
            <thead>
              <row>
                <entry>
                  <para>Name</para>
                </entry>
                <entry>
                  <para>Type</para>
                </entry>
                <entry>
                  <para>Unit</para>
                </entry>
                <entry>
                  <para>Resource</para>
                </entry>
                <entry>
                  <para>Origin</para>
                </entry>
                <entry>
                  <para>Note</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry namest="c1" nameend="c6">
                  <para>
                    <emphasis role="bold">Meters added in the Icehouse release or earlier</emphasis>
                  </para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>energy</para>
                </entry>
                <entry>
                  <para>Cumulative</para>
                </entry>
                <entry>
                  <para>kWh</para>
                </entry>
                <entry>
                  <para>probe ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Amount of energy</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>power</para>
                </entry>
                <entry>
                  <para>Gauge</para>
                </entry>
                <entry>
                  <para>W</para>
                </entry>
                <entry>
                  <para>probe ID</para>
                </entry>
                <entry>
                  <para>Pollster</para>
                </entry>
                <entry>
                  <para>Power consumption</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
    </sect1>
    <sect1>
      <title>Events</title>
      <para>In addition to meters, the Telemetry service collects events triggered
within an OpenStack environment. This section provides a brief summary
of the events format in the Telemetry service.</para>
      <para>While a sample represents a single, numeric datapoint within a
time-series, an event is a broader concept that represents the state of
a resource at a point in time. The state may be described using various
data types including non-numeric data such as an instance's flavor. In
general, events represent any action made in the OpenStack system.</para>
      <sect2>
        <title>Event configuration</title>
        <para>To enable the creation and storage of events in the Telemetry service
<literal>store_events</literal> option needs to be set to <literal>True</literal>. For further configuration
options, see the event section in the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry.html">OpenStack Configuration Reference</link>.</para>
        <note>
          <para>It is advisable to set <literal>disable_non_metric_meters</literal> to <literal>True</literal>
when enabling events in the Telemetry service. The Telemetry service
historically represented events as metering data, which may create
duplication of data if both events and non-metric meters are
enabled.</para>
        </note>
      </sect2>
      <sect2>
        <title>Event structure</title>
        <para>Events captured by the Telemetry service are represented by five key
attributes:</para>
        <variablelist>
          <varlistentry>
            <term>event_type</term>
            <listitem>
              <para>A dotted string defining what event occurred such as
<literal>"compute.instance.resize.start"</literal>.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>message_id</term>
            <listitem>
              <para>A UUID for the event.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>generated</term>
            <listitem>
              <para>A timestamp of when the event occurred in the system.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>traits</term>
            <listitem>
              <para>A flat mapping of key-value pairs which describe the event. The
event's traits contain most of the details of the event. Traits are
typed, and can be strings, integers, floats, or datetimes.</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term>raw</term>
            <listitem>
              <para>Mainly for auditing purpose, the full event message can be stored
(unindexed) for future evaluation.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </sect2>
      <sect2>
        <title>Event indexing</title>
        <para>The general philosophy of notifications in OpenStack is to emit any and
all data someone might need, and let the consumer filter out what they
are not interested in. In order to make processing simpler and more
efficient, the notifications are stored and processed within Ceilometer
as events. The notification payload, which can be an arbitrarily complex
JSON data structure, is converted to a flat set of key-value pairs. This
conversion is specified by a config file.</para>
        <note>
          <para>The event format is meant for efficient processing and querying.
Storage of complete notifications for auditing purposes can be
enabled by configuring <literal>store_raw</literal> option.</para>
        </note>
        <sect3>
          <title>Event conversion</title>
          <para>The conversion from notifications to events is driven by a configuration
file defined by the <literal>definitions_cfg_file</literal> in the <literal>ceilometer.conf</literal>
configuration file.</para>
          <para>This includes descriptions of how to map fields in the notification body
to Traits, and optional plug-ins for doing any programmatic translations
(splitting a string, forcing case).</para>
          <para>The mapping of notifications to events is defined per event_type, which
can be wildcarded. Traits are added to events if the corresponding
fields in the notification exist and are non-null.</para>
          <note>
            <para>The default definition file included with the Telemetry service
contains a list of known notifications and useful traits. The
mappings provided can be modified to include more or less data
according to user requirements.</para>
          </note>
          <para>If the definitions file is not present, a warning will be logged, but an
empty set of definitions will be assumed. By default, any notifications
that do not have a corresponding event definition in the definitions
file will be converted to events with a set of minimal traits. This can
be changed by setting the option <literal>drop_unmatched_notifications</literal> in the
<literal>ceilometer.conf</literal> file. If this is set to <literal>True</literal>, any unmapped
notifications will be dropped.</para>
          <para>The basic set of traits (all are TEXT type) that will be added to all
events if the notification has the relevant data are: service
(notification's publisher), tenant_id, and request_id. These do not
have to be specified in the event definition, they are automatically
added, but their definitions can be overridden for a given event_type.</para>
        </sect3>
        <sect3>
          <title>Event definitions format</title>
          <para>The event definitions file is in YAML format. It consists of a list of
event definitions, which are mappings. Order is significant, the list of
definitions is scanned in reverse order to find a definition which
matches the notification's event_type. That definition will be used to
generate the event. The reverse ordering is done because it is common to
want to have a more general wildcarded definition (such as
<literal>compute.instance.*</literal>) with a set of traits common to all of those
events, with a few more specific event definitions afterwards that have
all of the above traits, plus a few more.</para>
          <para>Each event definition is a mapping with two keys:</para>
          <variablelist>
            <varlistentry>
              <term>event_type</term>
              <listitem>
                <para>This is a list (or a string, which will be taken as a 1 element
list) of event_types this definition will handle. These can be
wildcarded with unix shell glob syntax. An exclusion listing
(starting with a <literal>!</literal>) will exclude any types listed from matching.
If only exclusions are listed, the definition will match anything
not matching the exclusions.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>traits</term>
              <listitem>
                <para>This is a mapping, the keys are the trait names, and the values are
trait definitions.</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <para>Each trait definition is a mapping with the following keys:</para>
          <variablelist>
            <varlistentry>
              <term>fields</term>
              <listitem>
                <para>A path specification for the field(s) in the notification you wish
to extract for this trait. Specifications can be written to match
multiple possible fields. By default the value will be the first
such field. The paths can be specified with a dot syntax
(<literal>payload.host</literal>). Square bracket syntax (<literal>payload[host]</literal>) is
also supported. In either case, if the key for the field you are
looking for contains special characters, like <literal>.</literal>, it will need to
be quoted (with double or single quotes):
<literal>payload.image_meta.’org.openstack__1__architecture’</literal>. The syntax
used for the field specification is a variant of
<link xlink:href="https://github.com/kennknowles/python-jsonpath-rw">JSONPath</link></para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>type</term>
              <listitem>
                <para>(Optional) The data type for this trait. Valid options are:
<literal>text</literal>, <literal>int</literal>, <literal>float</literal>, and <literal>datetime</literal>. Defaults to <literal>text</literal>
if not specified.</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>plugin</term>
              <listitem>
                <para>(Optional) Used to execute simple programmatic conversions on the
value in a notification field.</para>
              </listitem>
            </varlistentry>
          </variablelist>
        </sect3>
        <sect3>
          <title>Event delivery to external sinks</title>
          <para>You can configure the Telemetry service to deliver the events
into external sinks. These sinks are configurable in the
<literal>/etc/ceilometer/event_pipeline.yaml</literal> file.</para>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Troubleshoot Telemetry</title>
      <sect2>
        <title>Logging in Telemetry</title>
        <para>The Telemetry service has similar log settings as the other OpenStack
services. Multiple options are available to change the target of
logging, the format of the log entries and the log levels.</para>
        <para>The log settings can be changed in <literal>ceilometer.conf</literal>. The list of
configuration options are listed in the logging configuration options
table in the <link xlink:href="http://docs.openstack.org/newton/config-reference/telemetry.html">Telemetry
section</link>
in the OpenStack Configuration Reference.</para>
        <para>By default <literal>stderr</literal> is used as standard output for the log messages.
It can be changed to either a log file or syslog. The <literal>debug</literal> and
<literal>verbose</literal> options are also set to false in the default settings, the
default log levels of the corresponding modules can be found in the
table referred above.</para>
      </sect2>
      <sect2>
        <title>Recommended order of starting services</title>
        <para>As it can be seen in <link xlink:href="https://bugs.launchpad.net/devstack/+bug/1355809">Bug
1355809</link>, the wrong
ordering of service startup can result in data loss.</para>
        <para>When the services are started for the first time or in line with the
message queue service restart, it takes time while the
<literal>ceilometer-collector</literal> service establishes the connection and joins or
rejoins to the configured exchanges. Therefore, if the
<literal>ceilometer-agent-compute</literal>, <literal>ceilometer-agent-central</literal>, and the
<literal>ceilometer-agent-notification</literal> services are started before
the <literal>ceilometer-collector</literal> service, the <literal>ceilometer-collector</literal> service
may lose some messages while connecting to the message queue service.</para>
        <para>The possibility of this issue to happen is higher, when the polling
interval is set to a relatively short period. In order to avoid this
situation, the recommended order of service startup is to start or
restart the <literal>ceilometer-collector</literal> service after the message queue. All
the other Telemetry services should be started or restarted after and
the <literal>ceilometer-agent-compute</literal> should be the last in the sequence, as this
component emits metering messages in order to send the samples to the
collector.</para>
      </sect2>
      <sect2>
        <title>Notification agent</title>
        <para>In the Icehouse release of OpenStack a new service was introduced to be
responsible for consuming notifications that are coming from other
OpenStack services.</para>
        <para>If the <literal>ceilometer-agent-notification</literal> service is not installed and
started, samples originating from notifications will not be generated.
In case of the lack of notification based samples, the state of this
service and the log file of Telemetry should be checked first.</para>
        <para>For the list of meters that are originated from notifications, see the
<link xlink:href="http://docs.openstack.org/developer/ceilometer/measurements.html">Telemetry Measurements
Reference</link>.</para>
      </sect2>
      <sect2>
        <title>Recommended auth_url to be used</title>
        <para>When using the Telemetry command-line client, the credentials and the
<literal>os_auth_url</literal> have to be set in order for the client to authenticate
against OpenStack Identity. For further details
about the credentials that have to be provided see the <link xlink:href="http://docs.openstack.org/developer/python-ceilometerclient/">Telemetry Python
API</link>.</para>
        <para>The service catalog provided by OpenStack Identity contains the
URLs that are available for authentication. The URLs have
different <literal>port</literal>s, based on whether the type of the given URL is
<literal>public</literal>, <literal>internal</literal> or <literal>admin</literal>.</para>
        <para>OpenStack Identity is about to change API version from v2 to v3. The
<literal>adminURL</literal> endpoint (which is available via the port: <literal>35357</literal>)
supports only the v3 version, while the other two supports both.</para>
        <para>The Telemetry command line client is not adapted to the v3 version of
the OpenStack Identity API. If the <literal>adminURL</literal> is used as
<literal>os_auth_url</literal>, the <command>ceilometer</command> command results in the following
error message:</para>
        <screen language="console">$ ceilometer meter-list
  Unable to determine the Keystone version to authenticate with \
  using the given auth_url: http://10.0.2.15:35357/v2.0</screen>
        <para>Therefore when specifying the <literal>os_auth_url</literal> parameter on the command
line or by using environment variable, use the <literal>internalURL</literal> or
<literal>publicURL</literal>.</para>
        <para>For more details check the bug report <link xlink:href="https://bugs.launchpad.net/python-ceilometerclient/+bug/1351841">Bug
1351841</link>.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Telemetry best practices</title>
      <para>The following are some suggested best practices to follow when deploying
and configuring the Telemetry service. The best practices are divided
into data collection and storage.</para>
      <sect2>
        <title>Data collection</title>
        <procedure>
          <step>
            <para>The Telemetry service collects a continuously growing set of data. Not
all the data will be relevant for an administrator to monitor.</para>
            <itemizedlist>
              <listitem>
                <para>Based on your needs, you can edit the <literal>pipeline.yaml</literal> configuration
file to include a selected number of meters while disregarding the
rest.</para>
              </listitem>
              <listitem>
                <para>By default, Telemetry service polls the service APIs every 10
minutes. You can change the polling interval on a per meter basis by
editing the <literal>pipeline.yaml</literal> configuration file.</para>
                <warning>
                  <para>If the polling interval is too short, it will likely cause
increase of stored data and the stress on the service APIs.</para>
                </warning>
              </listitem>
              <listitem>
                <para>Expand the configuration to have greater control over different meter
intervals.</para>
                <note>
                  <para>For more information, see the
<xref linkend="telemetry-pipeline-configuration"/>.</para>
                </note>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>If you are using the Kilo version of Telemetry, you can delay or adjust
polling requests by enabling the jitter support. This adds a random
delay on how the polling agents send requests to the service APIs. To
enable jitter, set <literal>shuffle_time_before_polling_task</literal> in the
<literal>ceilometer.conf</literal> configuration file to an integer greater
than 0.</para>
          </step>
          <step>
            <para>If you are using Juno or later releases, based on the number of
resources that will be polled, you can add additional central and
compute agents as necessary. The agents are designed to scale
horizontally.</para>
            <note>
              <para>For more information see, <xref linkend="ha-deploy-services"/>.</para>
            </note>
          </step>
          <step>
            <para>If you are using Juno or later releases, use the <literal>notifier://</literal>
publisher rather than <literal>rpc://</literal> as there is a certain level of overhead
that comes with RPC.</para>
            <note>
              <para>For more information on RPC overhead, see <link xlink:href="https://www.rabbitmq.com/tutorials/tutorial-six-python.html">RPC overhead
info</link>.</para>
            </note>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Data storage</title>
        <procedure>
          <step>
            <para>We recommend that you avoid open-ended queries. In order to get better
performance you can use reasonable time ranges and/or other query
constraints for retrieving measurements.</para>
            <para>For example, this open-ended query might return an unpredictable amount
of data:</para>
            <screen language="console">$ ceilometer sample-list --meter cpu -q 'resource_id=INSTANCE_ID_1'</screen>
            <para>Whereas, this well-formed query returns a more reasonable amount of
data, hence better performance:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ceilometer sample-list --meter cpu -q 'resource_id=INSTANCE_ID_1;timestamp &gt; 2015-05-01T00:00:00;timestamp &lt; 2015-06-01T00:00:00'</screen>
            <note>
              <para>As of the Liberty release, the number of items returned will be
restricted to the value defined by <literal>default_api_return_limit</literal> in the
<literal>ceilometer.conf</literal> configuration file. Alternatively, the value can
be set per query by passing <literal>limit</literal> option in request.</para>
            </note>
          </step>
          <step>
            <para>You can install the API behind <literal>mod_wsgi</literal>, as it provides more
settings to tweak, like <literal>threads</literal> and <literal>processes</literal> in case of
<literal>WSGIDaemon</literal>.</para>
            <note>
              <para>For more information on how to configure <literal>mod_wsgi</literal>, see the
<link xlink:href="http://docs.openstack.org/developer/ceilometer/install/mod_wsgi.html">Telemetry Install Documentation</link>.</para>
            </note>
          </step>
          <step>
            <para>The collection service provided by the Telemetry project is not intended
to be an archival service. Set a Time to Live (TTL) value to expire data
and minimize the database size. If you would like to keep your data for
longer time period, you may consider storing it in a data warehouse
outside of Telemetry.</para>
            <note>
              <para>For more information on how to set the TTL, see
<xref linkend="telemetry-storing-samples"/>.</para>
            </note>
          </step>
          <step>
            <para>We recommend that you do not use SQLAlchemy back end prior to the Juno
release, as it previously contained extraneous relationships to handle
deprecated data models. This resulted in extremely poor query
performance.</para>
          </step>
          <step>
            <para>We recommend that you do not run MongoDB on the same node as the
controller. Keep it on a separate node optimized for fast storage for
better performance. Also it is advisable for the MongoDB node to have a
lot of memory.</para>
            <note>
              <para>For more information on how much memory you need, see <link xlink:href="http://docs.mongodb.org/manual/faq/diagnostics/#how-do-i-calculate-how-much-ram-i-need-for-my-application">MongoDB
FAQ</link>.</para>
            </note>
          </step>
          <step>
            <para>Use replica sets in MongoDB. Replica sets provide high availability
through automatic failover. If your primary node fails, MongoDB will
elect a secondary node to replace the primary node, and your cluster
will remain functional.</para>
            <para>For more information on replica sets, see the <link xlink:href="http://docs.mongodb.org/manual/tutorial/deploy-replica-set/">MongoDB replica sets
docs</link>.</para>
          </step>
          <step>
            <para>Use sharding in MongoDB. Sharding helps in storing data records across
multiple machines and is the MongoDB’s approach to meet the demands of
data growth.</para>
            <para>For more information on sharding, see the <link xlink:href="http://docs.mongodb.org/manual/sharding/">MongoDB sharding
docs</link>.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Database</title>
    <info/>
    <para>The Database service provides database management features.</para>
    <sect1>
      <title>Introduction</title>
      <para>The Database service provides scalable and reliable cloud
provisioning functionality for both relational and non-relational
database engines. Users can quickly and easily use database features
without the burden of handling complex administrative tasks. Cloud
users and database administrators can provision and manage multiple
database instances as needed.</para>
      <para>The Database service provides resource isolation at high performance
levels, and automates complex administrative tasks such as deployment,
configuration, patching, backups, restores, and monitoring.</para>
      <para>You can modify various cluster characteristics by editing the
<literal>/etc/trove/trove.conf</literal> file. A comprehensive list of the Database
service configuration options is described in the <link xlink:href="http://docs.openstack.org/newton/config-reference/database.html">Database service</link>
chapter in the <emphasis>Configuration Reference</emphasis>.</para>
    </sect1>
    <sect1>
      <title>Create a data store</title>
      <para>An administrative user can create data stores for a variety of
databases.</para>
      <para>This section assumes you do not yet have a MySQL data store, and shows
you how to create a MySQL data store and populate it with a MySQL 5.5
data store version.</para>
      <para>
        <emphasis role="bold">To create a data store</emphasis>
      </para>
      <procedure>
        <step>
          <para>
            <emphasis role="bold">Create a trove image</emphasis>
          </para>
          <para>Create an image for the type of database you want to use, for
example, MySQL, MongoDB, Cassandra.</para>
          <para>This image must have the trove guest agent installed, and it must
have the <literal>trove-guestagent.conf</literal> file configured to connect to
your OpenStack environment. To configure <literal>trove-guestagent.conf</literal>,
add the following lines to <literal>trove-guestagent.conf</literal> on the guest
instance you are using to build your image:</para>
          <screen language="ini">rabbit_host = controller
rabbit_password = RABBIT_PASS
nova_proxy_admin_user = admin
nova_proxy_admin_pass = ADMIN_PASS
nova_proxy_admin_tenant_name = service
trove_auth_url = http://controller:35357/v2.0</screen>
          <para>This example assumes you have created a MySQL 5.5 image called
<literal>mysql-5.5.qcow2</literal>.</para>
          <important>
            <para>If you have a guest image that was created with an OpenStack version
before Kilo, modify the guest agent init script for the guest image to
read the configuration files from the directory <literal>/etc/trove/conf.d</literal>.</para>
            <para>For a backwards compatibility with pre-Kilo guest instances, set the
database service configuration options <literal>injected_config_location</literal> to
<literal>/etc/trove</literal> and <literal>guest_info</literal> to <literal>/etc/guest_info</literal>.</para>
          </important>
        </step>
        <step>
          <para>
            <emphasis role="bold">Register image with Image service</emphasis>
          </para>
          <para>You need to register your guest image with the Image service.</para>
          <para>In this example, you use the <command>openstack image create</command>
command to register a <literal>mysql-5.5.qcow2</literal> image.</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack image create mysql-5.5 --disk-format qcow2 --container-format bare --public &lt; mysql-5.5.qcow2
+------------------+------------------------------------------------------+
| Field            | Value                                                |
+------------------+------------------------------------------------------+
| checksum         | 133eae9fb1c98f45894a4e60d8736619                     |
| container_format | bare                                                 |
| created_at       | 2016-12-21T12:10:02Z                                 |
| disk_format      | qcow2                                                |
| file             | /v2/images/d1afb4f0-2360-4400-8d97-846b1ab6af52/file |
| id               | d1afb4f0-2360-4400-8d97-846b1ab6af52                 |
| min_disk         | 0                                                    |
| min_ram          | 0                                                    |
| name             | mysql-5.5                                            |
| owner            | 5669caad86a04256994cdf755df4d3c1                     |
| protected        | False                                                |
| schema           | /v2/schemas/image                                    |
| size             | 13200896                                             |
| status           | active                                               |
| tags             |                                                      |
| updated_at       | 2016-12-21T12:10:03Z                                 |
| virtual_size     | None                                                 |
| visibility       | public                                               |
+------------------+------------------------------------------------------+</screen>
        </step>
        <step>
          <para>
            <emphasis role="bold">Create the data store</emphasis>
          </para>
          <para>Create the data store that will house the new image. To do this, use
the <command>trove-manage</command><command>datastore_update</command> command.</para>
          <para>This example uses the following arguments:</para>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="33.3*"/>
              <colspec colname="c2" colwidth="33.3*"/>
              <colspec colname="c3" colwidth="33.3*"/>
              <thead>
                <row>
                  <entry>
                    <para>Argument</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                  <entry>
                    <para>In this example:</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>config file</para>
                  </entry>
                  <entry>
                    <para>The configuration file to use.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>--config-file=/etc/trove/trove.conf</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>name</para>
                  </entry>
                  <entry>
                    <para>Name you want to use for this data store.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>mysql</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>default version</para>
                  </entry>
                  <entry>
                    <para>You can attach multiple versions/images to a data store. For
example, you might have a MySQL 5.5 version and a MySQL 5.6
version. You can designate one version as the default, which
the system uses if a user does not explicitly request a
specific version.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>""</literal>
                    </para>
                    <para>At this point, you do not yet have a default version, so pass
in an empty string.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>Example:</para>
          <screen language="console">$ trove-manage --config-file=/etc/trove/trove.conf datastore_update mysql ""</screen>
        </step>
        <step>
          <para>
            <emphasis role="bold">Add a version to the new data store</emphasis>
          </para>
          <para>Now that you have a MySQL data store, you can add a version to it,
using the <command>trove-manage</command><command>datastore_version_update</command>
command. The version indicates which guest image to use.</para>
          <para>This example uses the following arguments:</para>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="33.3*"/>
              <colspec colname="c2" colwidth="33.3*"/>
              <colspec colname="c3" colwidth="33.3*"/>
              <thead>
                <row>
                  <entry>
                    <para>Argument</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                  <entry>
                    <para>In this example:</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>config file</para>
                  </entry>
                  <entry>
                    <para>The configuration file to use.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>--config-file=/etc/trove/trove.conf</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>data store</para>
                  </entry>
                  <entry>
                    <para>The name of the data store you just created via
<literal>trove-manage</literal><command>datastore_update</command>.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>mysql</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>version name</para>
                  </entry>
                  <entry>
                    <para>The name of the version you are adding to the data store.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>mysql-5.5</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>data store manager</para>
                  </entry>
                  <entry>
                    <para>Which data store manager to use for this version. Typically,
the data store manager is identified by one of the following
strings, depending on the database:</para>
                    <itemizedlist>
                      <listitem>
                        <para>cassandra</para>
                      </listitem>
                      <listitem>
                        <para>couchbase</para>
                      </listitem>
                      <listitem>
                        <para>couchdb</para>
                      </listitem>
                      <listitem>
                        <para>db2</para>
                      </listitem>
                      <listitem>
                        <para>mariadb</para>
                      </listitem>
                      <listitem>
                        <para>mongodb</para>
                      </listitem>
                      <listitem>
                        <para>mysql</para>
                      </listitem>
                      <listitem>
                        <para>percona</para>
                      </listitem>
                      <listitem>
                        <para>postgresql</para>
                      </listitem>
                      <listitem>
                        <para>pxc</para>
                      </listitem>
                      <listitem>
                        <para>redis</para>
                      </listitem>
                      <listitem>
                        <para>vertica</para>
                      </listitem>
                    </itemizedlist>
                  </entry>
                  <entry>
                    <para>
                      <literal>mysql</literal>
                    </para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>glance ID</para>
                  </entry>
                  <entry>
                    <para>The ID of the guest image you just added to the Image
service. You can get this ID by using the glance
<command>image-show</command> IMAGE_NAME command.</para>
                  </entry>
                  <entry>
                    <para>bb75f870-0c33-4907-8467-1367f8cb15b6</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>packages</para>
                  </entry>
                  <entry>
                    <para>If you want to put additional packages on each guest that
you create with this data store version, you can list the
package names here.</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>""</literal>
                    </para>
                    <para>In this example, the guest image already contains all the
required packages, so leave this argument empty.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>active</para>
                  </entry>
                  <entry>
                    <variablelist>
                      <varlistentry>
                        <term>Set this to either 1 or 0:</term>
                        <listitem>
                          <itemizedlist>
                            <listitem>
                              <para><literal>1</literal> = active</para>
                            </listitem>
                            <listitem>
                              <para><literal>0</literal> = disabled</para>
                            </listitem>
                          </itemizedlist>
                        </listitem>
                      </varlistentry>
                    </variablelist>
                  </entry>
                  <entry>
                    <para>1</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>Example:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ trove-manage --config-file=/etc/trove/trove.conf datastore_version_update mysql mysql-5.5 mysql GLANCE_ID "" 1</screen>
          <para><emphasis role="bold">Optional.</emphasis> Set your new version as the default version. To do
this, use the <command>trove-manage</command><command>datastore_update</command>
command again, this time specifying the version you just created.</para>
          <screen language="console">$ trove-manage --config-file=/etc/trove/trove.conf datastore_update mysql mysql-5.5</screen>
        </step>
        <step>
          <para>
            <emphasis role="bold">Load validation rules for configuration groups</emphasis>
          </para>
          <note>
            <para>
              <emphasis role="bold">Applies only to MySQL and Percona data stores</emphasis>
            </para>
            <itemizedlist>
              <listitem>
                <para>If you just created a MySQL or Percona data store, then you need
to load the appropriate validation rules, as described in this
step.</para>
              </listitem>
              <listitem>
                <para>If you just created a different data store, skip this step.</para>
              </listitem>
            </itemizedlist>
          </note>
          <para><emphasis role="bold">Background.</emphasis> You can manage database configuration tasks by using
configuration groups. Configuration groups let you set configuration
parameters, in bulk, on one or more databases.</para>
          <para>When you set up a configuration group using the trove
<command>configuration-create</command> command, this command compares the configuration
values you are setting against a list of valid configuration values
that are stored in the <literal>validation-rules.json</literal> file.</para>
          <informaltable>
            <tgroup cols="3">
              <colspec colname="c1" colwidth="33.3*"/>
              <colspec colname="c2" colwidth="33.3*"/>
              <colspec colname="c3" colwidth="33.3*"/>
              <thead>
                <row>
                  <entry>
                    <para>Operating System</para>
                  </entry>
                  <entry>
                    <para>Location of <literal>validation-rules.json</literal></para>
                  </entry>
                  <entry>
                    <para>Notes</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>Ubuntu 14.04</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>/usr/lib/python2.7/dist-packages/trove/templates/DATASTORE_NAME</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>DATASTORE_NAME is the name of either the MySQL data store or
the Percona data store. This is typically either <literal>mysql</literal>
or <literal>percona</literal>.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>RHEL 7, CentOS 7, Fedora 20, and Fedora 21</para>
                  </entry>
                  <entry>
                    <para>
                      <literal>/usr/lib/python2.7/site-packages/trove/templates/DATASTORE_NAME</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>DATASTORE_NAME is the name of either the MySQL data store or
the Percona data store. This is typically either <literal>mysql</literal> or <literal>percona</literal>.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable>
          <para>Therefore, as part of creating a data store, you need to load the
<literal>validation-rules.json</literal> file, using the <command>trove-manage</command><command>db_load_datastore_config_parameters</command> command. This command
takes the following arguments:</para>
          <itemizedlist>
            <listitem>
              <para>Data store name</para>
            </listitem>
            <listitem>
              <para>Data store version</para>
            </listitem>
            <listitem>
              <para>Full path to the <literal>validation-rules.json</literal> file</para>
            </listitem>
          </itemizedlist>
          <para>This example loads the <literal>validation-rules.json</literal> file for a MySQL
database on Ubuntu 14.04:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ trove-manage db_load_datastore_config_parameters mysql mysql-5.5 /usr/lib/python2.7/dist-packages/trove/templates/mysql/validation-rules.json</screen>
        </step>
        <step>
          <para>
            <emphasis role="bold">Validate data store</emphasis>
          </para>
          <para>To validate your new data store and version, start by listing the
data stores on your system:</para>
          <screen language="console">$ trove datastore-list
+--------------------------------------+--------------+
|                  id                  |     name     |
+--------------------------------------+--------------+
| 10000000-0000-0000-0000-000000000001 | Legacy MySQL |
| e5dc1da3-f080-4589-a4c2-eff7928f969a |    mysql     |
+--------------------------------------+--------------+</screen>
          <para>Take the ID of the MySQL data store and pass it in with the
<command>datastore-version-list</command> command:</para>
          <screen language="console">$ trove datastore-version-list DATASTORE_ID
+--------------------------------------+-----------+
|                  id                  |    name   |
+--------------------------------------+-----------+
| 36a6306b-efd8-4d83-9b75-8b30dd756381 | mysql-5.5 |
+--------------------------------------+-----------+</screen>
        </step>
      </procedure>
      <sect2>
        <title>Data store classifications</title>
        <para>The Database service supports a variety of both relational and
non-relational database engines, but to a varying degree of support for
each <xref linkend="term-data-store"/>. The Database service project has defined
several classifications that indicate the quality of support for each
data store. Data stores also implement different extensions.
An extension is called a <xref linkend="term-strategy"/> and is classified similar to
data stores.</para>
        <para>Valid classifications for a data store and a strategy are:</para>
        <itemizedlist>
          <listitem>
            <para>Experimental</para>
          </listitem>
          <listitem>
            <para>Technical preview</para>
          </listitem>
          <listitem>
            <para>Stable</para>
          </listitem>
        </itemizedlist>
        <para>Each classification builds on the previous one. This means that a data store
that meets the <literal>technical preview</literal> requirements must also meet all the
requirements for <literal>experimental</literal>, and a data store that meets the <literal>stable</literal>
requirements must also meet all the requirements for <literal>technical preview</literal>.</para>
        <para>
          <emphasis role="bold">Requirements</emphasis>
        </para>
        <itemizedlist>
          <listitem>
            <para>Experimental</para>
            <para>A data store is considered to be <literal>experimental</literal> if it meets these criteria:</para>
            <itemizedlist>
              <listitem>
                <para>It implements a basic subset of the Database service API including
<literal>create</literal> and <literal>delete</literal>.</para>
              </listitem>
              <listitem>
                <para>It has guest agent elements that allow guest agent creation.</para>
              </listitem>
              <listitem>
                <para>It has a definition of supported operating systems.</para>
              </listitem>
              <listitem>
                <para>It meets the other
<link xlink:href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements">Documented Technical Requirements</link>.</para>
              </listitem>
            </itemizedlist>
            <para>A strategy is considered <literal>experimental</literal> if:</para>
            <itemizedlist>
              <listitem>
                <para>It meets the
<link xlink:href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements">Documented Technical Requirements</link>.</para>
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem>
            <para>Technical preview</para>
            <para>A data store is considered to be a <literal>technical preview</literal> if it meets the
requirements of <literal>experimental</literal> and further:</para>
            <itemizedlist>
              <listitem>
                <para>It implements APIs required to plant and start the capabilities of the
data store as defined in the
<link xlink:href="https://wiki.openstack.org/wiki/Trove/DatastoreCompatibilityMatrix">Datastore Compatibility Matrix</link>.</para>
                <note>
                  <para>It is not required that the data store implements all features like
resize, backup, replication, or clustering to meet this classification.</para>
                </note>
              </listitem>
              <listitem>
                <para>It provides a mechanism for building a guest image that allows you to
exercise its capabilities.</para>
              </listitem>
              <listitem>
                <para>It meets the other
<link xlink:href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements">Documented Technical Requirements</link>.</para>
              </listitem>
            </itemizedlist>
            <important>
              <para>A strategy is not normally considered to be <literal>technical
preview</literal>.</para>
            </important>
          </listitem>
          <listitem>
            <para>Stable</para>
            <para>A data store or a strategy is considered <literal>stable</literal> if:</para>
            <itemizedlist>
              <listitem>
                <para>It meets the requirements of <literal>technical preview</literal>.</para>
              </listitem>
              <listitem>
                <para>It meets the other
<link xlink:href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements">Documented Technical Requirements</link>.</para>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
        <para>
          <emphasis role="bold">Initial Classifications</emphasis>
        </para>
        <para>The following table shows the current classification assignments for the
different data stores.</para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="50.0*"/>
            <colspec colname="c2" colwidth="50.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Classification</para>
                </entry>
                <entry>
                  <para>Data store</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>Stable</para>
                </entry>
                <entry>
                  <para>MySQL</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Technical Preview</para>
                </entry>
                <entry>
                  <para>Cassandra, MongoDB</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Experimental</para>
                </entry>
                <entry>
                  <para>All others</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </sect2>
      <sect2>
        <title>Redis data store replication</title>
        <para>Replication strategies are available for Redis with
several commands located in the Redis data store
manager:</para>
        <itemizedlist>
          <listitem>
            <para>
              <command>create</command>
            </para>
          </listitem>
          <listitem>
            <para>
              <command>detach-replica</command>
            </para>
          </listitem>
          <listitem>
            <para>
              <command>eject-replica-source</command>
            </para>
          </listitem>
          <listitem>
            <para>
              <command>promote-to-replica-source</command>
            </para>
          </listitem>
        </itemizedlist>
        <para>Additional arguments for the <command>create</command> command
include <command>--replica_of</command> and
<command>--replica_count</command>.</para>
      </sect2>
      <sect2>
        <title>Redis integration and unit tests</title>
        <para>Unit tests and integration tests are also available for
Redis.</para>
        <procedure>
          <step>
            <para>Install redstack:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ ./redstack install

.. note::

   Redstack is a development script used for integration
   testing and Database service development installations.
   Do not use Redstack in a production environment. For
   more information, see `the Database service
   developer docs &lt;http://docs.openstack.org/developer/trove/dev/install.html#running-redstack-to-install-trove&gt;`_</screen>
          </step>
          <step>
            <para>Start Redis:</para>
            <screen language="console">$ ./redstack kick-start redis</screen>
          </step>
          <step>
            <para>Run integration tests:</para>
            <screen language="console">$ ./redstack int-tests --group=replication</screen>
            <para>You can run <command>--group=redis_supported</command>
instead of <command>--group=replication</command> if needed.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Configure a cluster</title>
      <para>An administrative user can configure various characteristics of a
MongoDB cluster.</para>
      <para>
        <emphasis role="bold">Query routers and config servers</emphasis>
      </para>
      <para><emphasis role="bold">Background.</emphasis> Each cluster includes at least one query router and
one config server. Query routers and config servers count against your
quota. When you delete a cluster, the system deletes the associated
query router(s) and config server(s).</para>
      <para><emphasis role="bold">Configuration.</emphasis> By default, the system creates one query router and
one config server per cluster. You can change this by editing
the <literal>/etc/trove/trove.conf</literal> file. These settings are in the
<literal>mongodb</literal> section of the file:</para>
      <informaltable>
        <tgroup cols="2">
          <colspec colname="c1" colwidth="50.0*"/>
          <colspec colname="c2" colwidth="50.0*"/>
          <thead>
            <row>
              <entry>
                <para>Setting</para>
              </entry>
              <entry>
                <para>Valid values are:</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>num_config_servers_per_cluster</para>
              </entry>
              <entry>
                <para>1 or 3</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>num_query_routers_per_cluster</para>
              </entry>
              <entry>
                <para>1 or 3</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
    </sect1>
  </chapter>
  <chapter>
    <title>Bare Metal</title>
    <info/>
    <para>The Bare Metal service provides physical hardware management features.</para>
    <sect1>
      <title>Introduction</title>
      <para>The Bare Metal service provides physical hardware as opposed to
virtual machines. It also provides several reference drivers, which
leverage common technologies like PXE and IPMI, to cover a wide range
of hardware. The pluggable driver architecture also allows
vendor-specific drivers to be added for improved performance or
functionality not provided by reference drivers. The Bare Metal
service makes physical servers as easy to provision as virtual
machines in a cloud, which in turn will open up new avenues for
enterprises and service providers.</para>
    </sect1>
    <sect1>
      <title>System architecture</title>
      <para>The Bare Metal service is composed of the following components:</para>
      <procedure>
        <step>
          <para>An admin-only RESTful API service, by which privileged users, such
as operators and other services within the cloud control
plane, may interact with the managed bare-metal servers.</para>
        </step>
        <step>
          <para>A conductor service, which conducts all activity related to
bare-metal deployments. Functionality is exposed via the API
service. The Bare Metal service conductor and API service
communicate via RPC.</para>
        </step>
        <step>
          <para>Various drivers that support heterogeneous hardware, which enable
features specific to unique hardware platforms and leverage
divergent capabilities via a common API.</para>
        </step>
        <step>
          <para>A message queue, which is a central hub for passing messages, such
as RabbitMQ. It should use the same implementation as that of the
Compute service.</para>
        </step>
        <step>
          <para>A database for storing information about the resources. Among other
things, this includes the state of the conductors, nodes (physical
servers), and drivers.</para>
        </step>
      </procedure>
      <para>When a user requests to boot an instance, the request is passed to the
Compute service via the Compute service API and scheduler. The Compute
service hands over this request to the Bare Metal service, where the
request passes from the Bare Metal service API, to the conductor which
will invoke a driver to successfully provision a physical server for
the user.</para>
    </sect1>
    <sect1>
      <title>Bare Metal deployment</title>
      <procedure>
        <step>
          <para>PXE deploy process</para>
        </step>
        <step>
          <para>Agent deploy process</para>
        </step>
      </procedure>
    </sect1>
    <sect1>
      <title>Use Bare Metal</title>
      <procedure>
        <step>
          <para>Install the Bare Metal service.</para>
        </step>
        <step>
          <para>Setup the Bare Metal driver in the compute node's <literal>nova.conf</literal> file.</para>
        </step>
        <step>
          <para>Setup TFTP folder and prepare PXE boot loader file.</para>
        </step>
        <step>
          <para>Prepare the bare metal flavor.</para>
        </step>
        <step>
          <para>Register the nodes with correct drivers.</para>
        </step>
        <step>
          <para>Configure the driver information.</para>
        </step>
        <step>
          <para>Register the ports information.</para>
        </step>
        <step>
          <para>Use the <command>openstack server create</command> command to
kick off the bare metal provision.</para>
        </step>
        <step>
          <para>Check nodes' provision state and power state.</para>
        </step>
      </procedure>
      <sect2>
        <title>Use multitenancy with Bare Metal service</title>
        <sect3>
          <title>Use multitenancy with Bare Metal service</title>
          <para>Multitenancy allows creating a dedicated project network that extends the
current Bare Metal (ironic) service capabilities of providing <literal>flat</literal>
networks. Multitenancy works in conjunction with Networking (neutron)
service to allow provisioning of a bare metal server onto the project network.
Therefore, multiple projects can get isolated instances after deployment.</para>
          <para>Bare Metal service provides the <literal>local_link_connection</literal> information to the
Networking service ML2 driver. The ML2 driver uses that information to plug the
specified port to the project network.</para>
          <table>
            <title>local_link_connection fields</title>
            <tgroup cols="2">
              <colspec colname="c1" colwidth="50.0*"/>
              <colspec colname="c2" colwidth="50.0*"/>
              <thead>
                <row>
                  <entry>
                    <para>Field</para>
                  </entry>
                  <entry>
                    <para>Description</para>
                  </entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>
                    <para>
                      <literal>switch_id</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Required. Identifies a switch and can be an LLDP-based MAC address or
an OpenFlow-based <literal>datapath_id</literal>.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>port_id</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Required. Port ID on the switch, for example, Gig0/1.</para>
                  </entry>
                </row>
                <row>
                  <entry>
                    <para>
                      <literal>switch_info</literal>
                    </para>
                  </entry>
                  <entry>
                    <para>Optional. Used to distinguish different switch models or other
vendor specific-identifier.</para>
                  </entry>
                </row>
              </tbody>
            </tgroup>
          </table>
          <sect4>
            <title>Configure Networking service ML2 driver</title>
            <para>To enable the Networking service ML2 driver, edit the
<literal>/etc/neutron/plugins/ml2/ml2_conf.ini</literal> file:</para>
            <procedure>
              <step>
                <para>Add the name of your ML2 driver.</para>
              </step>
              <step>
                <para>Add the vendor ML2 plugin configuration options.</para>
              </step>
            </procedure>
            <screen language="ini">[ml2]
...
mechanism_drivers = my_mechanism_driver

[my_vendor]
param_1 = ...
param_2 = ...
param_3 = ...</screen>
            <para>For more details, see
<link xlink:href="http://docs.openstack.org/newton/networking-guide/config-ml2.html#mechanism-drivers">Networking service mechanism drivers</link>.</para>
          </sect4>
          <sect4>
            <title>Configure Bare Metal service</title>
            <para>After you configure the Networking service ML2 driver, configure Bare Metal
service:</para>
            <procedure>
              <step>
                <para>Edit the <literal>/etc/ironic/ironic.conf</literal> for the <literal>ironic-conductor</literal> service.
Set the <literal>network_interface</literal> node field to a valid network driver that is
used to switch, clean, and provision networks.</para>
                <screen language="ini">[DEFAULT]
...
enabled_network_interfaces=flat,neutron

[neutron]
...
cleaning_network_uuid=$UUID
provisioning_network_uuid=$UUID</screen>
                <warning>
                  <para>The <literal>cleaning_network_uuid</literal> and <literal>provisioning_network_uuid</literal>
parameters are required for the <literal>neutron</literal> network interface. If they are
not set, <literal>ironic-conductor</literal> fails to start.</para>
                </warning>
              </step>
              <step>
                <para>Set <literal>neutron</literal> to use Networking service ML2 driver:</para>
                <screen language="console">$ ironic node-create -n $NAME --network-interface neutron --driver agent_ipmitool</screen>
              </step>
              <step>
                <para>Create a port with appropriate <literal>local_link_connection</literal> information. Set
the <literal>pxe_enabled</literal> port attribute to <literal>True</literal> to create network ports for
for the <literal>pxe_enabled</literal> ports only:</para>
                <screen language="console">$ ironic --ironic-api-version latest port-create -a $HW_MAC_ADDRESS \
  -n $NODE_UUID -l switch_id=$SWITCH_MAC_ADDRESS \
  -l switch_info=$SWITCH_HOSTNAME -l port_id=$SWITCH_PORT --pxe-enabled true</screen>
              </step>
            </procedure>
          </sect4>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Troubleshooting</title>
      <sect2>
        <title>No valid host found error</title>
        <para/>
        <bridgehead renderas="sect3">Problem</bridgehead>
        <para>Sometimes <literal>/var/log/nova/nova-conductor.log</literal> contains the following error:</para>
        <screen language="console">NoValidHost: No valid host was found. There are not enough hosts available.</screen>
        <para>The message <literal>No valid host was found</literal> means that the Compute service
scheduler could not find a bare metal node suitable for booting the new
instance.</para>
        <para>This means there will be some mismatch between resources that the Compute
service expects to find and resources that Bare Metal service advertised to
the Compute service.</para>
        <bridgehead renderas="sect3">Solution</bridgehead>
        <para>If you get this message, check the following:</para>
        <procedure>
          <step>
            <para>Introspection should have succeeded for you before, or you should have
entered the required bare-metal node properties manually.
For each node in the <command>ironic node-list</command> command, use:</para>
            <screen language="console">$ ironic node-show &lt;IRONIC-NODE-UUID&gt;</screen>
            <para>and make sure that <literal>properties</literal> JSON field has valid values for keys
<literal>cpus</literal>, <literal>cpu_arch</literal>, <literal>memory_mb</literal> and <literal>local_gb</literal>.</para>
          </step>
          <step>
            <para>The flavor in the Compute service that you are using does not exceed the
bare-metal node properties above for a required number of nodes. Use:</para>
            <screen language="console">$ openstack flavor show FLAVOR</screen>
          </step>
          <step>
            <para>Make sure that enough nodes are in <literal>available</literal> state according to the
<command>ironic node-list</command> command. Nodes in <literal>manageable</literal> state usually
mean they have failed introspection.</para>
          </step>
          <step>
            <para>Make sure nodes you are going to deploy to are not in maintenance mode.
Use the <command>ironic node-list</command> command to check. A node automatically
going to maintenance mode usually means the incorrect credentials for
this node. Check them and then remove maintenance mode:</para>
            <screen language="console">$ ironic node-set-maintenance &lt;IRONIC-NODE-UUID&gt; off</screen>
          </step>
          <step>
            <para>It takes some time for nodes information to propagate from the Bare Metal
service to the Compute service after introspection. Our tooling usually
accounts for it, but if you did some steps manually there may be a period
of time when nodes are not available to the Compute service yet. Check that
the <command>openstack hypervisor stats show</command> command correctly shows total
amount of resources in your system.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Orchestration</title>
    <info/>
    <para>Orchestration is an orchestration engine that provides the
possibility to launch multiple composite cloud applications based on
templates in the form of text files that can be treated like code. A
native Heat Orchestration Template (HOT) format is evolving, but it
also endeavors to provide compatibility with the AWS CloudFormation
template format, so that many existing CloudFormation templates can
be launched on OpenStack.</para>
    <sect1>
      <title>Introduction</title>
      <para>The OpenStack Orchestration service, a tool for orchestrating clouds,
automatically configures and deploys resources in stacks. The deployments can
be simple, such as deploying WordPress on Ubuntu with an SQL back end, or
complex, such as starting a server group that auto scales by
starting and stopping using real-time CPU loading information from the
Telemetry service.</para>
      <para>Orchestration stacks are defined with templates, which are non-procedural
documents. Templates describe tasks in terms of resources, parameters, inputs,
constraints, and dependencies. When the Orchestration service was originally
introduced, it worked with AWS CloudFormation templates, which are in the JSON
format.</para>
      <para>The Orchestration service also runs Heat Orchestration Template (HOT)
templates that are written in YAML. YAML is a terse notation that loosely
follows structural conventions (colons, returns, indentation) that are similar
to Python or Ruby. Therefore, it is easier to write, parse, grep, generate
with tools, and maintain source-code management systems.</para>
      <para>Orchestration can be accessed through a CLI and RESTful queries.
The Orchestration service provides both an OpenStack-native REST API and a
CloudFormation-compatible Query API. The Orchestration service is also
integrated with the OpenStack dashboard to perform stack functions through
a web interface.</para>
      <para>For more information about using the Orchestration service through the
command line, see the <link xlink:href="http://docs.openstack.org/cli-reference/heat.html">OpenStack Command-Line Interface Reference</link>.</para>
    </sect1>
    <sect1>
      <title>Orchestration authorization model</title>
      <para>The Orchestration authorization model defines the
authorization process for requests during deferred operations.
A common example is an auto-scaling group update. During
the auto-scaling update operation, the Orchestration service
requests resources of other components (such as servers from
Compute or networks from Networking) to extend or reduce the
capacity of an auto-scaling group.</para>
      <para>The Orchestration service provides the following authorization models:</para>
      <itemizedlist>
        <listitem>
          <para>Password authorization</para>
        </listitem>
        <listitem>
          <para>OpenStack Identity trusts authorization</para>
        </listitem>
      </itemizedlist>
      <sect2>
        <title>Password authorization</title>
        <para>The Orchestration service supports password authorization.
Password authorization requires that a user pass a
username and password to the Orchestration service. Encrypted
password are stored in the database, and used for deferred
operations.</para>
        <para>Password authorization involves the following steps:</para>
        <procedure>
          <step>
            <para>A user requests stack creation, by providing a token and
username and password. The Dashboard or
python-heatclient requests the token on the user's behalf.</para>
          </step>
          <step>
            <para>If the stack contains any resources that require deferred
operations, then the orchestration engine fails its validation
checks if the user did not provide a valid username/password.</para>
          </step>
          <step>
            <para>The username/password are encrypted and stored in the Orchestration
database.</para>
          </step>
          <step>
            <para>Orchestration creates a stack.</para>
          </step>
          <step>
            <para>Later, the Orchestration service retrieves the credentials and
requests another token on behalf of the user. The token is not
limited in scope and provides access to all the roles of the stack
owner.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>OpenStack Identity trusts authorization</title>
        <para>A trust is an OpenStack Identity extension that enables delegation,
and optionally impersonation through the OpenStack Identity service.
The key terminology is <emphasis>trustor</emphasis> (the user delegating) and
<emphasis>trustee</emphasis> (the user being delegated to).</para>
        <para>To create a trust, the <emphasis>trustor</emphasis> (in this case, the user creating the
stack in the Orchestration service) provides the OpenStack Identity service
with the following information:</para>
        <itemizedlist>
          <listitem>
            <para>The ID of the <emphasis>trustee</emphasis> (who you want to delegate to, in this case,
the Orchestration service user).</para>
          </listitem>
          <listitem>
            <para>The roles to be delegated. Configure roles through
the <literal>heat.conf</literal> file. Ensure the configuration contains whatever
roles are required to perform the deferred operations on the
user's behalf. For example, launching an OpenStack Compute
instance in response to an auto-scaling event.</para>
          </listitem>
          <listitem>
            <para>Whether to enable impersonation.</para>
          </listitem>
        </itemizedlist>
        <para>The OpenStack Identity service provides a <emphasis>trust id</emphasis>,
which is consumed by <emphasis>only</emphasis> the trustee to obtain a
<emphasis>trust scoped token</emphasis>. This token is limited in scope,
such that the trustee has limited access to those
roles delegated. In addition, the trustee has effective impersonation
of the trustor user if it was selected when creating the trust.
For more information, see <xref linkend="cha.identity"/>.</para>
        <para>Trusts authorization involves the following steps:</para>
        <procedure>
          <step>
            <para>A user creates a stack through an API request (only the token is
required).</para>
          </step>
          <step>
            <para>The Orchestration service uses the token to create a trust
between the stack owner (trustor) and the Orchestration
service user (trustee). The service delegates a special role (or roles)
as defined in the <emphasis>trusts_delegated_roles</emphasis> list in the
Orchestration configuration file. By default, the Orchestration
service sets all the roles from trustor available for trustee.
Deployers might modify this list to reflect a local RBAC policy.
For example, to ensure that the heat process can access only
those services that are expected while impersonating a stack owner.</para>
          </step>
          <step>
            <para>Orchestration stores the encrypted <emphasis>trust id</emphasis> in the Orchestration
database.</para>
          </step>
          <step>
            <para>When a deferred operation is required, the Orchestration service
retrieves the <emphasis>trust id</emphasis> and requests a trust scoped token which
enables the service user to impersonate the stack owner during
the deferred operation. Impersonation is helpful, for example,
so the service user can launch Compute instances on
behalf of the stack owner in response to an auto-scaling event.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Authorization model configuration</title>
        <para>Initially, the password authorization model was the
default authorization model. Since the Kilo release, the
Identity trusts authorization model is enabled for the Orchestration
service by default.</para>
        <para>To enable the password authorization model, change the following
parameter in the <literal>heat.conf</literal> file:</para>
        <screen language="ini">deferred_auth_method=password</screen>
        <para>To enable the trusts authorization model, change the following
parameter in the <literal>heat.conf</literal> file:</para>
        <screen language="ini">deferred_auth_method=trusts</screen>
        <para>To specify the trustor roles that it delegates to trustee during
authorization, specify the <literal>trusts_delegated_roles</literal> parameter
in the <literal>heat.conf</literal> file. If <literal>trusts_delegated_roles</literal> is not
defined, then all the trustor roles are delegated to trustee.</para>
        <note>
          <para>The trustor delegated roles must be pre-configured in the
OpenStack Identity service before using them in the Orchestration service.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>Stack domain users</title>
      <para>Stack domain users allow the Orchestration service to
authorize and start the following operations within booted virtual
machines:</para>
      <itemizedlist>
        <listitem>
          <para>Provide metadata to agents inside instances. Agents poll for changes
and apply the configuration that is expressed in the metadata to the
instance.</para>
        </listitem>
        <listitem>
          <para>Detect when an action is complete. Typically, software configuration
on a virtual machine after it is booted. Compute moves
the VM state to "Active" as soon as it creates it, not when the
Orchestration service has fully configured it.</para>
        </listitem>
        <listitem>
          <para>Provide application level status or meters from inside the instance.
For example, allow auto-scaling actions to be performed in response
to some measure of performance or quality of service.</para>
        </listitem>
      </itemizedlist>
      <para>The Orchestration service provides APIs that enable all of these
operations, but all of those APIs require authentication.
For example, credentials to access the instance that the agent
is running upon. The heat-cfntools agents use signed requests,
which require an ec2 key pair created through Identity.
The key pair is then used to sign requests to the Orchestration
CloudFormation and CloudWatch compatible APIs, which are
authenticated through signature validation. Signature validation
uses the Identity ec2tokens extension.</para>
      <para>Stack domain users encapsulate all stack-defined users (users who are
created as a result of data that is contained in an
Orchestration template) in a separate domain.
The separate domain is created specifically to contain data
related to the Orchestration stacks only. A user is created, which is
the <emphasis>domain admin</emphasis>, and Orchestration uses the <emphasis>domain admin</emphasis> to manage
the lifecycle of the users in the stack <emphasis>user domain</emphasis>.</para>
      <sect2>
        <title>Stack domain users configuration</title>
        <para>To configure stack domain user, the Orchestration service completes the
following tasks:</para>
        <procedure>
          <step>
            <para>A special OpenStack Identity service domain is created. For
example, a domain that is called <literal>heat</literal> and the ID is set with the
<literal>stack_user_domain</literal> option in the <literal>heat.conf</literal> file.</para>
          </step>
          <step>
            <para>A user with sufficient permissions to create and delete projects
and users in the <literal>heat</literal> domain is created.</para>
          </step>
          <step>
            <para>The username and password for the domain admin user is set in the
<literal>heat.conf</literal> file (<literal>stack_domain_admin</literal> and
<literal>stack_domain_admin_password</literal>). This user administers
<emphasis>stack domain users</emphasis> on behalf of stack owners, so they no longer
need to be administrators themselves. The risk of this escalation path
is limited because the <literal>heat_domain_admin</literal> is only given
administrative permission for the <literal>heat</literal> domain.</para>
          </step>
        </procedure>
        <para>To set up stack domain users, complete the following steps:</para>
        <procedure>
          <step>
            <para>Create the domain:</para>
            <para><literal>$OS_TOKEN</literal> refers to a token. For example, the service admin
token or some other valid token for a user with sufficient roles
to create users and domains. <literal>$KS_ENDPOINT_V3</literal> refers to the v3
OpenStack Identity endpoint (for example,
<literal>http://keystone_address:5000/v3</literal> where <emphasis>keystone_address</emphasis> is
the IP address or resolvable name for the Identity
service).</para>
            <screen language="console">$ openstack --os-token $OS_TOKEN --os-url=$KS_ENDPOINT_V3 --os-\
  identity-api-version=3 domain create heat --description "Owns \
  users and projects created by heat"</screen>
            <para>The domain ID is returned by this command, and is referred to as
<literal>$HEAT_DOMAIN_ID</literal> below.</para>
          </step>
          <step>
            <para>Create the user:</para>
            <screen language="console">$ openstack --os-token $OS_TOKEN --os-url=$KS_ENDPOINT_V3 --os-\
  identity-api-version=3 user create --password $PASSWORD --domain \
  $HEAT_DOMAIN_ID heat_domain_admin --description "Manages users \
  and projects created by heat"</screen>
            <para>The user ID is returned by this command and is referred to as
<literal>$DOMAIN_ADMIN_ID</literal> below.</para>
          </step>
          <step>
            <para>Make the user a domain admin:</para>
            <screen language="console">$ openstack --os-token $OS_TOKEN --os-url=$KS_ENDPOINT_V3 --os-\
  identity-api-version=3 role add --user $DOMAIN_ADMIN_ID --domain \
  $HEAT_DOMAIN_ID admin</screen>
            <para>Then you must add the domain ID, username and password from these
steps to the <literal>heat.conf</literal> file:</para>
            <screen language="ini">stack_domain_admin_password = password
stack_domain_admin = heat_domain_admin
stack_user_domain = domain id returned from domain create above</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Usage workflow</title>
        <para>The following steps are run during stack creation:</para>
        <procedure>
          <step>
            <para>Orchestration creates a new <emphasis>stack domain project</emphasis> in the <literal>heat</literal>
domain if the stack contains any resources that require creation
of a <emphasis>stack domain user</emphasis>.</para>
          </step>
          <step>
            <para>For any resources that require a user, the Orchestration service creates
the user in the <emphasis>stack domain project</emphasis>. The <emphasis>stack domain project</emphasis> is
associated with the Orchestration stack in the Orchestration
database, but is separate and unrelated (from an authentication
perspective) to the stack owners project. The users who are created
in the stack domain are still assigned the <literal>heat_stack_user</literal> role, so
the API surface they can access is limited through
the <literal>policy.json</literal> file.
For more  information, see <xref linkend="cha.identity"/>.</para>
          </step>
          <step>
            <para>When API requests are processed, the Orchestration service performs
an internal lookup, and allows stack details for a given stack to be
retrieved. Details are retrieved from the database for
both the stack owner's project (the default
API path to the stack) and the stack domain project, subject to the
<literal>policy.json</literal> restrictions.</para>
          </step>
        </procedure>
        <para>This means there are now two paths that
can result in the same data being retrieved through the Orchestration API.
The following example is for resource-metadata:</para>
        <screen>GET v1/​{stack_owner_project_id}​/stacks/​{stack_name}​/\
​{stack_id}​/resources/​{resource_name}​/metadata</screen>
        <para>or:</para>
        <screen>GET v1/​{stack_domain_project_id}​/stacks/​{stack_name}​/​\
{stack_id}​/resources/​{resource_name}​/metadata</screen>
        <para>The stack owner uses the former (via <literal>openstack stack resource metadata
STACK RESOURCE</literal>), and any agents in the instance
use the latter.</para>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>OpenStack command-line clients</title>
    <info/>
    <sect1>
      <title>Command-line client overview</title>
      <para>OpenStackClient project provides a unified command-line client, which
enables you to access the project API through easy-to-use commands.
Also, most OpenStack project provides a command-line client for each service.
For example, the Compute service provides a <literal>nova</literal> command-line client.</para>
      <para>You can run the commands from the command line, or include the
commands within scripts to automate tasks. If you provide OpenStack
credentials, such as your user name and password, you can run these
commands on any computer.</para>
      <para>Internally, each command uses cURL command-line tools, which embed API
requests. OpenStack APIs are RESTful APIs, and use the HTTP
protocol. They include methods, URIs, media types, and response codes.</para>
      <para>OpenStack APIs are open-source Python clients, and can run on Linux or
Mac OS X systems. On some client commands, you can specify a debug
parameter to show the underlying API request for the command. This is
a good way to become familiar with the OpenStack API calls.</para>
      <para>As a cloud end user, you can use the OpenStack Dashboard to provision
your own resources within the limits set by administrators. You can
modify the examples provided in this section to create other types and
sizes of server instances.</para>
      <sect2>
        <title>Unified command-line client</title>
        <para>You can use the unified <literal>openstack</literal> command (<emphasis role="bold">python-openstackclient</emphasis>)
for the most of OpenStack services.
For more information, see <link xlink:href="http://docs.openstack.org/developer/python-openstackclient/">OpenStackClient document</link>.</para>
      </sect2>
      <sect2>
        <title>Individual command-line clients</title>
        <para>Unless the unified OpenStack Client (<emphasis role="bold">python-openstackclient</emphasis>) is used,
the following table lists the command-line client for each OpenStack
service with its package name and description.</para>
        <table>
          <title>OpenStack services and clients</title>
          <tgroup cols="4">
            <colspec colname="c1" colwidth="20.0*"/>
            <colspec colname="c2" colwidth="20.0*"/>
            <colspec colname="c3" colwidth="20.0*"/>
            <colspec colname="c4" colwidth="40.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Service</para>
                </entry>
                <entry>
                  <para>Client</para>
                </entry>
                <entry>
                  <para>Package</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>Application Catalog service</para>
                </entry>
                <entry>
                  <para>murano</para>
                </entry>
                <entry>
                  <para>python-muranoclient</para>
                </entry>
                <entry>
                  <para>Creates and manages applications.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Bare Metal service</para>
                </entry>
                <entry>
                  <para>ironic</para>
                </entry>
                <entry>
                  <para>python-ironicclient</para>
                </entry>
                <entry>
                  <para>manages and provisions physical machines.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Block Storage service</para>
                </entry>
                <entry>
                  <para>cinder</para>
                </entry>
                <entry>
                  <para>python-cinderclient</para>
                </entry>
                <entry>
                  <para>Creates and manages volumes.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Clustering service</para>
                </entry>
                <entry>
                  <para>senlin</para>
                </entry>
                <entry>
                  <para>python-senlinclient</para>
                </entry>
                <entry>
                  <para>Creates and manages clustering services.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Compute service</para>
                </entry>
                <entry>
                  <para>nova</para>
                </entry>
                <entry>
                  <para>python-novaclient</para>
                </entry>
                <entry>
                  <para>Creates and manages images, instances, and flavors.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Container Infrastructure Management service</para>
                </entry>
                <entry>
                  <para>magnum</para>
                </entry>
                <entry>
                  <para>python-magnumclient</para>
                </entry>
                <entry>
                  <para>Creates and manages containers.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Data Processing service</para>
                </entry>
                <entry>
                  <para>sahara</para>
                </entry>
                <entry>
                  <para>python-saharaclient</para>
                </entry>
                <entry>
                  <para>Creates and manages Hadoop clusters on OpenStack.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Database service</para>
                </entry>
                <entry>
                  <para>trove</para>
                </entry>
                <entry>
                  <para>python-troveclient</para>
                </entry>
                <entry>
                  <para>Creates and manages databases.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Deployment service</para>
                </entry>
                <entry>
                  <para>fuel</para>
                </entry>
                <entry>
                  <para>python-fuelclient</para>
                </entry>
                <entry>
                  <para>Plans deployments.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>DNS service</para>
                </entry>
                <entry>
                  <para>designate</para>
                </entry>
                <entry>
                  <para>python-designateclient</para>
                </entry>
                <entry>
                  <para>Creates and manages self service authoritative DNS.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Image service</para>
                </entry>
                <entry>
                  <para>glance</para>
                </entry>
                <entry>
                  <para>python-glanceclient</para>
                </entry>
                <entry>
                  <para>Creates and manages images.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Key Manager service</para>
                </entry>
                <entry>
                  <para>barbican</para>
                </entry>
                <entry>
                  <para>python-barbicanclient</para>
                </entry>
                <entry>
                  <para>Creates and manages keys.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Monitoring</para>
                </entry>
                <entry>
                  <para>monasca</para>
                </entry>
                <entry>
                  <para>python-monascaclient</para>
                </entry>
                <entry>
                  <para>Monitoring solution.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Networking service</para>
                </entry>
                <entry>
                  <para>neutron</para>
                </entry>
                <entry>
                  <para>python-neutronclient</para>
                </entry>
                <entry>
                  <para>Configures networks for guest servers.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Object Storage service</para>
                </entry>
                <entry>
                  <para>swift</para>
                </entry>
                <entry>
                  <para>python-swiftclient</para>
                </entry>
                <entry>
                  <para>Gathers statistics, lists items, updates metadata, and uploads,
downloads, and deletes files stored by the Object Storage service.
Gains access to an Object Storage installation for ad hoc processing.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Orchestration service</para>
                </entry>
                <entry>
                  <para>heat</para>
                </entry>
                <entry>
                  <para>python-heatclient</para>
                </entry>
                <entry>
                  <para>Launches stacks from templates, views details of running stacks
including events and resources, and updates and deletes stacks.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Rating service</para>
                </entry>
                <entry>
                  <para>cloudkitty</para>
                </entry>
                <entry>
                  <para>python-cloudkittyclient</para>
                </entry>
                <entry>
                  <para>Rating service.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Shared File Systems service</para>
                </entry>
                <entry>
                  <para>manila</para>
                </entry>
                <entry>
                  <para>python-manilaclient</para>
                </entry>
                <entry>
                  <para>Creates and manages shared file systems.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Telemetry service</para>
                </entry>
                <entry>
                  <para>ceilometer</para>
                </entry>
                <entry>
                  <para>python-ceilometerclient</para>
                </entry>
                <entry>
                  <para>Creates and collects measurements across OpenStack.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Telemetry v3</para>
                </entry>
                <entry>
                  <para>gnocchi</para>
                </entry>
                <entry>
                  <para>python-gnocchiclient</para>
                </entry>
                <entry>
                  <para>Creates and collects measurements across OpenStack.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>Workflow service</para>
                </entry>
                <entry>
                  <para>mistral</para>
                </entry>
                <entry>
                  <para>python-mistralclient</para>
                </entry>
                <entry>
                  <para>Workflow service for OpenStack cloud.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </sect2>
    </sect1>
    <sect1>
      <title>Install the OpenStack command-line clients</title>
      <para>Install the prerequisite software and the Python package for each
OpenStack client.</para>
      <sect2>
        <title>Install the prerequisite software</title>
        <para>Most Linux distributions include packaged versions of the command-line
clients that you can install directly, see <xref linkend="installing-from-packages"/>.</para>
        <para>If you need to install the source package for the command-line package,
the following table lists the software needed to run the
command-line clients, and provides installation instructions as needed.</para>
        <table>
          <title>OpenStack command-line clients prerequisites</title>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="20.0*"/>
            <colspec colname="c2" colwidth="80.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Prerequisite</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>Python 2.7 or later</para>
                </entry>
                <entry>
                  <para>Supports Python 2.7, 3.4, and 3.5.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>setuptools package</para>
                </entry>
                <entry>
                  <para>Installed by default on Mac OS X.</para>
                  <para>Many Linux distributions provide packages to make setuptools
easy to install. Search your package manager for setuptools to
find an installation package.
If you cannot find one, download the setuptools package
directly from <link xlink:href="https://pypi.python.org/pypi/setuptools">https://pypi.python.org/pypi/setuptools</link>.</para>
                  <para>The recommended way to install setuptools on Microsoft Windows
is to follow the documentation provided on the setuptools website
(<link xlink:href="https://pypi.python.org/pypi/setuptools">https://pypi.python.org/pypi/setuptools</link>).</para>
                  <para>Another option is to use the unofficial binary installer
maintained by Christoph Gohlke
(<link xlink:href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#setuptools">http://www.lfd.uci.edu/~gohlke/pythonlibs/#setuptools</link>).</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>pip package</para>
                </entry>
                <entry>
                  <para>To install the clients on a Linux, Mac OS X, or Microsoft Windows
system, use pip. It is easy to use, ensures that you get the latest
version of the clients from the <link xlink:href="https://pypi.python.org/">Python Package Index</link>, and lets you update or remove
the packages later on.</para>
                  <para>Since the installation process compiles source files, this requires
the related Python development package for your operating system
and distribution.</para>
                  <para>Install pip through the package manager for your system:</para>
                  <para>
                    <emphasis role="bold">MacOS</emphasis>
                  </para>
                  <screen language="console"># easy_install pip</screen>
                  <para>
                    <emphasis role="bold">Microsoft Windows</emphasis>
                  </para>
                  <para>Ensure that the <literal>C:\Python27\Scripts</literal> directory is defined in the
<literal>PATH</literal> environment variable, and use the <literal>easy_install</literal> command
from the setuptools package:</para>
                  <screen language="console">C:\&gt;easy_install pip</screen>
                  <para>Another option is to use the unofficial binary installer provided by
Christoph Gohlke (<link xlink:href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip">http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip</link>).</para>
                  <para>
                    <emphasis role="bold">Ubuntu or Debian</emphasis>
                  </para>
                  <screen language="console"># apt install python-dev python-pip</screen>
                  <para>Note that extra dependencies may be required, per operating system,
depending on the package being installed, such as is the case with
Tempest.</para>
                  <para>
                    <emphasis role="bold">Red Hat Enterprise Linux, CentOS, or Fedora</emphasis>
                  </para>
                  <para>A packaged version enables you to use yum to install the package:</para>
                  <screen language="console"># yum install python-devel python-pip</screen>
                  <para>There are also packaged versions of the clients available in
<link xlink:href="https://www.rdoproject.org/">RDO</link> that enable yum to install
the clients as described in <xref linkend="installing-from-packages"/>.</para>
                  <para>
                    <emphasis role="bold">SUSE Linux Enterprise Server</emphasis>
                  </para>
                  <para>A packaged version available in <link xlink:href="https://build.opensuse.org/package/show?package=python-pip&amp;project=Cloud:OpenStack:Master">the Open Build Service</link>
enables you to use YaST or zypper to install the package.</para>
                  <para>First, add the Open Build Service repository:</para>
                  <screen language="console"># zypper addrepo -f obs://Cloud:OpenStack:Mitaka/SLE_12_SP1 Mitaka</screen>
                  <para>Then install pip and use it to manage client installation:</para>
                  <screen language="console"># zypper install python-devel python-pip</screen>
                  <para>There are also packaged versions of the clients available that enable
zypper to install the clients as described in <xref linkend="installing-from-packages"/>.</para>
                  <para>
                    <emphasis role="bold">openSUSE</emphasis>
                  </para>
                  <para>You can install pip and use it to manage client installation:</para>
                  <screen language="console"># zypper install python-devel python-pip</screen>
                  <para>There are also packaged versions of the clients available that enable
zypper to install the clients as described in <xref linkend="installing-from-packages"/>.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </sect2>
      <sect2>
        <title>Install the OpenStack client</title>
        <para>The following example shows the command for installing the OpenStack client
with <literal>pip</literal>, which supports multiple services.</para>
        <screen language="console"># pip install python-openstackclient</screen>
        <para>The following individual clients are deprecated in favor of a common client.
Instead of installing and learning all these clients, we recommend
installing and using the OpenStack client. You may need to install an
individual project's client because coverage is not yet sufficient in the
OpenStack client. If you need to install an individual client's project,
replace the <literal>PROJECT</literal> name in this <literal>pip install</literal> command using the
list below.</para>
        <screen language="console"># pip install python-PROJECTclient</screen>
        <itemizedlist>
          <listitem>
            <para><literal>barbican</literal> - Key Manager Service API</para>
          </listitem>
          <listitem>
            <para><literal>ceilometer</literal> - Telemetry API</para>
          </listitem>
          <listitem>
            <para><literal>cinder</literal> - Block Storage API and extensions</para>
          </listitem>
          <listitem>
            <para><literal>cloudkitty</literal> - Rating service API</para>
          </listitem>
          <listitem>
            <para><literal>designate</literal> - DNS service API</para>
          </listitem>
          <listitem>
            <para><literal>fuel</literal> - Deployment service API</para>
          </listitem>
          <listitem>
            <para><literal>glance</literal> - Image service API</para>
          </listitem>
          <listitem>
            <para><literal>gnocchi</literal> - Telemetry API v3</para>
          </listitem>
          <listitem>
            <para><literal>heat</literal> - Orchestration API</para>
          </listitem>
          <listitem>
            <para><literal>magnum</literal> - Container Infrastructure Management service API</para>
          </listitem>
          <listitem>
            <para><literal>manila</literal> - Shared file systems API</para>
          </listitem>
          <listitem>
            <para><literal>mistral</literal> - Workflow service API</para>
          </listitem>
          <listitem>
            <para><literal>monasca</literal> - Monitoring API</para>
          </listitem>
          <listitem>
            <para><literal>murano</literal> - Application catalog API</para>
          </listitem>
          <listitem>
            <para><literal>neutron</literal> - Networking API</para>
          </listitem>
          <listitem>
            <para><literal>nova</literal> - Compute API and extensions</para>
          </listitem>
          <listitem>
            <para><literal>sahara</literal> - Data Processing API</para>
          </listitem>
          <listitem>
            <para><literal>senlin</literal> - Clustering service API</para>
          </listitem>
          <listitem>
            <para><literal>swift</literal> - Object Storage API</para>
          </listitem>
          <listitem>
            <para><literal>trove</literal> - Database service API</para>
          </listitem>
        </itemizedlist>
        <sect3>
          <title>Installing with pip</title>
          <para>Use pip to install the OpenStack clients on a Linux, Mac OS X, or
Microsoft Windows system. It is easy to use and ensures that you get the
latest version of the client from the <link xlink:href="https://pypi.python.org/pypi">Python Package
Index</link>. Also, pip enables you to update
or remove a package.</para>
          <para>Install each client separately by using the following command:</para>
          <itemizedlist>
            <listitem>
              <para>For Mac OS X or Linux:</para>
              <screen language="console"># pip install python-PROJECTclient</screen>
            </listitem>
            <listitem>
              <para>For Microsoft Windows:</para>
              <screen language="console">C:\&gt;pip install python-PROJECTclient</screen>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3 xml:id="installing-from-packages">
          <title>Installing from packages</title>
          <para>RDO, openSUSE, SUSE Linux Enterprise, Debian, and Ubuntu have client packages
that can be installed without <literal>pip</literal>.</para>
          <itemizedlist>
            <listitem>
              <para>On Red Hat Enterprise Linux, CentOS, or Fedora, use <literal>yum</literal> to install
the clients from the packaged versions available in
<link xlink:href="https://www.rdoproject.org/">RDO</link>:</para>
              <screen language="console"># yum install python-PROJECTclient</screen>
            </listitem>
            <listitem>
              <para>For Ubuntu or Debian, use <literal>apt-get</literal> to install the clients from the
packaged versions:</para>
              <screen language="console"># apt-get install python-PROJECTclient</screen>
            </listitem>
            <listitem>
              <para>For openSUSE, use <literal>zypper</literal> to install the clients from the distribution
packages service:</para>
              <screen language="console"># zypper install python-PROJECTclient</screen>
            </listitem>
            <listitem>
              <para>For SUSE Linux Enterprise Server, use <literal>zypper</literal> to install the clients from
the distribution packages in the Open Build Service. First, add the Open
Build Service repository:</para>
              <screen language="console"># zypper addrepo -f obs://Cloud:OpenStack:Mitaka/SLE_12_SP1 Mitaka</screen>
              <para>Then you can install the packages:</para>
              <screen language="console"># zypper install python-PROJECTclient</screen>
            </listitem>
          </itemizedlist>
        </sect3>
      </sect2>
      <sect2>
        <title>Upgrade or remove clients</title>
        <para>To upgrade a client, add the <literal>--upgrade</literal> option to the
<command>pip install</command> command:</para>
        <screen language="console"># pip install --upgrade python-PROJECTclient</screen>
        <para>To remove the client, run the <command>pip uninstall</command> command:</para>
        <screen language="console"># pip uninstall python-PROJECTclient</screen>
      </sect2>
      <sect2>
        <title>What's next</title>
        <para>Before you can run client commands, you must create and source the
<literal>PROJECT-openrc.sh</literal> file to set environment variables. See
 <xref linkend="sec.rcfile"/>.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Discover the version number for a client</title>
      <para>Run the following command to discover the version number for a client:</para>
      <screen language="console">$ PROJECT --version</screen>
      <para>For example, to see the version number for the <literal>openstack</literal> client,
run the following command:</para>
      <screen language="console">$ openstack --version
openstack 3.2.0</screen>
    </sect1>
    <sect1 xml:id="sec.rcfile">
      <title>Set environment variables using the OpenStack RC file</title>
      <para>To set the required environment variables for the OpenStack command-line
clients, you must create an environment file called an OpenStack rc
file, or <literal>openrc.sh</literal> file. If your OpenStack installation provides
it, you can download the file from the OpenStack Dashboard as an
administrative user or any other user. This project-specific environment
file contains the credentials that all OpenStack services use.</para>
      <para>When you source the file, environment variables are set for your current
shell. The variables enable the OpenStack client commands to communicate
with the OpenStack services that run in the cloud.</para>
      <note>
        <para>Defining environment variables using an environment file is not a
common practice on Microsoft Windows. Environment variables are
usually defined in the <menuchoice><guimenu>Advanced</guimenu><guimenu>System Properties</guimenu></menuchoice>
dialog box. One method for using these scripts as-is on Windows is
to install <link xlink:href="https://git-for-windows.github.io/">Git for Windows</link> and using Git Bash to source the environment
variables and to run all CLI commands.</para>
      </note>
      <sect2>
        <title>Download and source the OpenStack RC file</title>
        <procedure>
          <step>
            <para>Log in to the dashboard and from the drop-down list select the project
for which you want to download the OpenStack RC file.</para>
          </step>
          <step>
            <para>On the <guimenu>Project</guimenu> tab, open the <guimenu>Compute</guimenu> tab and
click <guimenu>Access &amp; Security</guimenu>.</para>
          </step>
          <step>
            <para>On the <guimenu>API Access</guimenu> tab, click <guimenu>Download OpenStack
RC File</guimenu> and save the file. The filename will be of the form
<literal>PROJECT-openrc.sh</literal> where <literal>PROJECT</literal> is the name of the project for
which you downloaded the file.</para>
          </step>
          <step>
            <para>Copy the <literal>PROJECT-openrc.sh</literal> file to the computer from which you
want to run OpenStack commands.</para>
            <para>For example, copy the file to the computer from which you want to upload
an image with a <literal>glance</literal> client command.</para>
          </step>
          <step>
            <para>On any shell from which you want to run OpenStack commands, source the
<literal>PROJECT-openrc.sh</literal> file for the respective project.</para>
            <para>In the following example, the <literal>demo-openrc.sh</literal> file is sourced for
the demo project:</para>
            <screen language="console">$ . demo-openrc.sh</screen>
          </step>
          <step>
            <para>When you are prompted for an OpenStack password, enter the password for
the user who downloaded the <literal>PROJECT-openrc.sh</literal> file.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Create and source the OpenStack RC file</title>
        <para>Alternatively, you can create the <literal>PROJECT-openrc.sh</literal> file from
scratch, if you cannot download the file from the dashboard.</para>
        <procedure>
          <step>
            <para>In a text editor, create a file named <literal>PROJECT-openrc.sh</literal> and add
the following authentication information:</para>
            <screen language="shell">export OS_USERNAME=username
export OS_PASSWORD=password
export OS_TENANT_NAME=projectName
export OS_AUTH_URL=https://identityHost:portNumber/v2.0
# The following lines can be omitted
export OS_TENANT_ID=tenantIDString
export OS_REGION_NAME=regionName
export OS_CACERT=/path/to/cacertFile</screen>
            <warning>
              <para>Saving <literal>OS_PASSWORD</literal> in plain text may bring a security risk.
You should protect the file or not save <literal>OS_PASSWORD</literal> into
the file in the production environment.</para>
            </warning>
          </step>
          <step>
            <para>On any shell from which you want to run OpenStack commands, source the
<literal>PROJECT-openrc.sh</literal> file for the respective project. In this
example, you source the <literal>admin-openrc.sh</literal> file for the admin
project:</para>
            <screen language="console">$ . admin-openrc.sh</screen>
          </step>
        </procedure>
        <note>
          <para>You are not prompted for the password with this method. The password
lives in clear text format in the <literal>PROJECT-openrc.sh</literal> file.
Restrict the permissions on this file to avoid security problems.
You can also remove the <literal>OS_PASSWORD</literal> variable from the file, and
use the <literal>--password</literal> parameter with OpenStack client commands
instead.</para>
        </note>
        <note>
          <para>You must set the <literal>OS_CACERT</literal> environment variable when using the
https protocol in the <literal>OS_AUTH_URL</literal> environment setting because
the verification process for the TLS (HTTPS) server certificate uses
the one indicated in the environment. This certificate will be used
when verifying the TLS (HTTPS) server certificate.</para>
        </note>
      </sect2>
      <sect2>
        <title>Override environment variable values</title>
        <para>When you run OpenStack client commands, you can override some
environment variable settings by using the options that are listed at
the end of the <literal>help</literal> output of the various client commands. For
example, you can override the <literal>OS_PASSWORD</literal> setting in the
<literal>PROJECT-openrc.sh</literal> file by specifying a password on a
<command>openstack</command> command, as follows:</para>
        <screen language="console">$ openstack --os-password PASSWORD server list</screen>
        <para>Where <literal>PASSWORD</literal> is your password.</para>
        <para>A user specifies their username and password credentials to interact
with OpenStack, using any client command. These credentials can be
specified using various mechanisms, namely, the environment variable
or command-line argument. It is not safe to specify the password using
either of these methods.</para>
        <para>For example, when you specify your password using the command-line
client with the <literal>--os-password</literal> argument, anyone with access to your
computer can view it in plain text with the <literal>ps</literal> field.</para>
        <para>To avoid storing the password in plain text, you can prompt for the
OpenStack password interactively.</para>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage projects, users, and roles</title>
      <para>As an administrator, you manage projects, users, and
roles. Projects are organizational units in the cloud to which
you can assign users. Projects are also known as <emphasis>projects</emphasis> or
<emphasis>accounts</emphasis>. Users can be members of one or more projects. Roles
define which actions users can perform. You assign roles to
user-project pairs.</para>
      <para>You can define actions for OpenStack service roles in the
<literal>/etc/PROJECT/policy.json</literal> files. For example, define actions for
Compute service roles in the <literal>/etc/nova/policy.json</literal> file.</para>
      <para>You can manage projects, users, and roles independently from each other.</para>
      <para>During cloud set up, the operator defines at least one project, user,
and role.</para>
      <para>You can add, update, and delete projects and users, assign users to
one or more projects, and change or remove the assignment. To enable or
temporarily disable a project or user, update that project or user.
You can also change quotas at the project level.</para>
      <para>Before you can delete a user account, you must remove the user account
from its primary project.</para>
      <para>Before you can run client commands, you must download and
source an OpenStack RC file. See <link xlink:href="http://docs.openstack.org/user-guide/common/cli-set-environment-variables-using-openstack-rc.html#download-and-source-the-openstack-rc-file">Download and source the OpenStack RC file</link>.</para>
      <sect2>
        <title>Projects</title>
        <para>A project is a group of zero or more users. In Compute, a project owns
virtual machines. In Object Storage, a project owns containers. Users
can be associated with more than one project. Each project and user
pairing can have a role associated with it.</para>
        <sect3>
          <title>List projects</title>
          <para>List all projects with their ID, name, and whether they are
enabled or disabled:</para>
          <screen language="console">$ openstack project list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| f7ac731cc11f40efbc03a9f9e1d1d21f | admin              |
| c150ab41f0d9443f8874e32e725a4cc8 | alt_demo           |
| a9debfe41a6d4d09a677da737b907d5e | demo               |
| 9208739195a34c628c58c95d157917d7 | invisible_to_admin |
| 3943a53dc92a49b2827fae94363851e1 | service            |
| 80cab5e1f02045abad92a2864cfd76cb | test_project       |
+----------------------------------+--------------------+</screen>
        </sect3>
        <sect3>
          <title>Create a project</title>
          <para>Create a project named <literal>new-project</literal>:</para>
          <screen language="console">$ openstack project create --description 'my new project' new-project \
  --domain default
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | my new project                   |
| domain_id   | e601210181f54843b51b3edff41d4980 |
| enabled     | True                             |
| id          | 1a4a0618b306462c9830f876b0bd6af2 |
| is_domain   | False                            |
| name        | new-project                      |
| parent_id   | e601210181f54843b51b3edff41d4980 |
+-------------+----------------------------------+</screen>
        </sect3>
        <sect3>
          <title>Update a project</title>
          <para>Specify the project ID to update a project. You can update the name,
description, and enabled status of a project.</para>
          <itemizedlist>
            <listitem>
              <para>To temporarily disable a project:</para>
              <screen language="console">$ openstack project set PROJECT_ID --disable</screen>
            </listitem>
            <listitem>
              <para>To enable a disabled project:</para>
              <screen language="console">$ openstack project set PROJECT_ID --enable</screen>
            </listitem>
            <listitem>
              <para>To update the name of a project:</para>
              <screen language="console">$ openstack project set PROJECT_ID --name project-new</screen>
            </listitem>
            <listitem>
              <para>To verify your changes, show information for the updated project:</para>
              <screen language="console">$ openstack project show PROJECT_ID
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | my new project                   |
| enabled     | True                             |
| id          | 0b0b995694234521bf93c792ed44247f |
| name        | new-project                      |
| properties  |                                  |
+-------------+----------------------------------+</screen>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Delete a project</title>
          <para>Specify the project ID to delete a project:</para>
          <screen language="console">$ openstack project delete PROJECT_ID</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Users</title>
        <sect3>
          <title>List users</title>
          <para>List all users:</para>
          <screen language="console">$ openstack user list
+----------------------------------+----------+
| ID                               | Name     |
+----------------------------------+----------+
| 352b37f5c89144d4ad0534139266d51f | admin    |
| 86c0de739bcb4802b8dc786921355813 | demo     |
| 32ec34aae8ea432e8af560a1cec0e881 | glance   |
| 7047fcb7908e420cb36e13bbd72c972c | nova     |
+----------------------------------+----------+</screen>
        </sect3>
        <sect3>
          <title>Create a user</title>
          <para>To create a user, you must specify a name. Optionally, you can
specify a project ID, password, and email address. It is recommended
that you include the project ID and password because the user cannot
log in to the dashboard without this information.</para>
          <para>Create the <literal>new-user</literal> user:</para>
          <screen language="console">$ openstack user create --project new-project --password PASSWORD new-user
+------------+----------------------------------+
| Field      | Value                            |
+------------+----------------------------------+
| email      | None                             |
| enabled    | True                             |
| id         | 6322872d9c7e445dbbb49c1f9ca28adc |
| name       | new-user                         |
| project_id | 0b0b995694234521bf93c792ed44247f |
| username   | new-user                         |
+------------+----------------------------------+</screen>
        </sect3>
        <sect3>
          <title>Update a user</title>
          <para>You can update the name, email address, and enabled status for a user.</para>
          <itemizedlist>
            <listitem>
              <para>To temporarily disable a user account:</para>
              <screen language="console">$ openstack user set USER_NAME --disable</screen>
              <para>If you disable a user account, the user cannot log in to the
dashboard. However, data for the user account is maintained, so you
can enable the user at any time.</para>
            </listitem>
            <listitem>
              <para>To enable a disabled user account:</para>
              <screen language="console">$ openstack user set USER_NAME --enable</screen>
            </listitem>
            <listitem>
              <para>To change the name and description for a user account:</para>
              <screen language="console">$ openstack user set USER_NAME --name user-new --email new-user@example.com
User has been updated.</screen>
            </listitem>
          </itemizedlist>
        </sect3>
        <sect3>
          <title>Delete a user</title>
          <para>Delete a specified user account:</para>
          <screen language="console">$ openstack user delete USER_NAME</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Roles and role assignments</title>
        <sect3>
          <title>List available roles</title>
          <para>List the available roles:</para>
          <screen language="console">$ openstack role list
+----------------------------------+---------------+
| ID                               | Name          |
+----------------------------------+---------------+
| 71ccc37d41c8491c975ae72676db687f | Member        |
| 149f50a1fe684bfa88dae76a48d26ef7 | ResellerAdmin |
| 9fe2ff9ee4384b1894a90878d3e92bab | _member_      |
| 6ecf391421604da985db2f141e46a7c8 | admin         |
| deb4fffd123c4d02a907c2c74559dccf | anotherrole   |
+----------------------------------+---------------+</screen>
        </sect3>
        <sect3>
          <title>Create a role</title>
          <para>Users can be members of multiple projects. To assign users to multiple
projects, define a role and assign that role to a user-project pair.</para>
          <para>Create the <literal>new-role</literal> role:</para>
          <screen language="console">$ openstack role create new-role
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | a34425c884c74c8881496dc2c2e84ffc |
| name      | new-role                         |
+-----------+----------------------------------+</screen>
        </sect3>
        <sect3>
          <title>Assign a role</title>
          <para>To assign a user to a project, you must assign the role to a
user-project pair. To do this, you need the user, role, and project
IDs.</para>
          <procedure>
            <step>
              <para>List users and note the user ID you want to assign to the role:</para>
              <screen language="console">$ openstack user list
+----------------------------------+----------+
| ID                               | Name     |
+----------------------------------+----------+
| 6ab5800949644c3e8fb86aaeab8275c8 | admin    |
| dfc484b9094f4390b9c51aba49a6df34 | demo     |
| 55389ff02f5e40cf85a053cc1cacb20c | alt_demo |
| bc52bcfd882f4d388485451c4a29f8e0 | nova     |
| 255388ffa6e54ec991f584cb03085e77 | glance   |
| 48b6e6dec364428da89ba67b654fac03 | cinder   |
| c094dd5a8e1d4010832c249d39541316 | neutron  |
| 6322872d9c7e445dbbb49c1f9ca28adc | new-user |
+----------------------------------+----------+</screen>
            </step>
            <step>
              <para>List role IDs and note the role ID you want to assign:</para>
              <screen language="console">$ openstack role list
+----------------------------------+---------------+
| ID                               | Name          |
+----------------------------------+---------------+
| 71ccc37d41c8491c975ae72676db687f | Member        |
| 149f50a1fe684bfa88dae76a48d26ef7 | ResellerAdmin |
| 9fe2ff9ee4384b1894a90878d3e92bab | _member_      |
| 6ecf391421604da985db2f141e46a7c8 | admin         |
| deb4fffd123c4d02a907c2c74559dccf | anotherrole   |
| bef1f95537914b1295da6aa038ef4de6 | new-role      |
+----------------------------------+---------------+</screen>
            </step>
            <step>
              <para>List projects and note the project ID you want to assign to the role:</para>
              <screen language="console">$ openstack project list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| 0b0b995694234521bf93c792ed44247f | new-project        |
| 29c09e68e6f741afa952a837e29c700b | admin              |
| 3a7ab11d3be74d3c9df3ede538840966 | invisible_to_admin |
| 71a2c23bab884c609774c2db6fcee3d0 | service            |
| 87e48a8394e34d13afc2646bc85a0d8c | alt_demo           |
| fef7ae86615f4bf5a37c1196d09bcb95 | demo               |
+----------------------------------+--------------------+</screen>
            </step>
            <step>
              <para>Assign a role to a user-project pair:</para>
              <screen language="console">$ openstack role add --user USER_NAME --project TENANT_ID ROLE_NAME</screen>
              <para>For example, assign the <literal>new-role</literal> role to the <literal>demo</literal> and
<literal>test-project</literal> pair:</para>
              <screen language="console">$ openstack role add --user demo --project test-project new-role</screen>
            </step>
            <step>
              <para>Verify the role assignment:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack role list --user USER_NAME --project TENANT_ID
Listing assignments using role list is deprecated as of the Newton release. Use role assignment list --user &lt;user-name&gt; --project &lt;project-name&gt; --names instead.
+----------------------------------+-------------+---------+------+
| ID                               | Name        | Project | User |
+----------------------------------+-------------+---------+------+
| a34425c884c74c8881496dc2c2e84ffc | new-role    | demo    | demo |
| 04a7e3192c0745a2b1e3d2baf5a3ee0f | Member      | demo    | demo |
| 62bcf3e27eef4f648eb72d1f9920f6e5 | anotherrole | demo    | demo |
+----------------------------------+-------------+---------+------+</screen>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>View role details</title>
          <para>View details for a specified role:</para>
          <screen language="console">$ openstack role show ROLE_NAME
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | a34425c884c74c8881496dc2c2e84ffc |
| name      | new-role                         |
+-----------+----------------------------------+</screen>
        </sect3>
        <sect3>
          <title>Remove a role</title>
          <para>Remove a role from a user-project pair:</para>
          <procedure>
            <step>
              <para>Run the <command>openstack role remove</command> command:</para>
              <screen language="console">$ openstack role remove --user USER_NAME --project TENANT_ID ROLE_NAME</screen>
            </step>
            <step>
              <para>Verify the role removal:</para>
              <screen language="console">$ openstack role list --user USER_NAME --project TENANT_ID</screen>
              <para>If the role was removed, the command output omits the removed role.</para>
            </step>
          </procedure>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage project security</title>
      <para>Security groups are sets of IP filter rules that are applied to all
project instances, which define networking access to the instance. Group
rules are project specific; project members can edit the default rules
for their group and add new rule sets.</para>
      <para>All projects have a <literal>default</literal> security group which is applied to any
instance that has no other defined security group. Unless you change the
default, this security group denies all incoming traffic and allows only
outgoing traffic to your instance.</para>
      <para>You can use the <literal>allow_same_net_traffic</literal> option in the
<literal>/etc/nova/nova.conf</literal> file to globally control whether the rules apply
to hosts which share a network.</para>
      <para>If set to:</para>
      <itemizedlist>
        <listitem>
          <para><literal>True</literal> (default), hosts on the same subnet are not filtered and are
allowed to pass all types of traffic between them. On a flat network,
this allows all instances from all projects unfiltered communication.
With VLAN networking, this allows access between instances within the
same project. You can also simulate this setting by configuring the
default security group to allow all traffic from the subnet.</para>
        </listitem>
        <listitem>
          <para><literal>False</literal>, security groups are enforced for all connections.</para>
        </listitem>
      </itemizedlist>
      <para>Additionally, the number of maximum rules per security group is
controlled by the <literal>security_group_rules</literal> and the number of allowed
security groups per project is controlled by the <literal>security_groups</literal>
quota (see <xref linkend="manage-quotas"/>).</para>
      <sect2>
        <title>List and view current security groups</title>
        <para>From the command-line you can get a list of security groups for the
project, using the <command>openstack</command> and <command>nova</command> commands:</para>
        <procedure>
          <step>
            <para>Ensure your system variables are set for the user and project for
which you are checking security group rules. For example:</para>
            <screen language="console">export OS_USERNAME=demo00
export OS_TENANT_NAME=tenant01</screen>
          </step>
          <step>
            <para>Output security groups, as follows:</para>
            <screen language="console">$ openstack security group list
+--------------------------------------+---------+-------------+
| Id                                   | Name    | Description |
+--------------------------------------+---------+-------------+
| 73580272-d8fa-4927-bd55-c85e43bc4877 | default | default     |
| 6777138a-deb7-4f10-8236-6400e7aff5b0 | open    | all ports   |
+--------------------------------------+---------+-------------+</screen>
          </step>
          <step>
            <para>View the details of a group, as follows:</para>
            <screen language="console">$ openstack security group rule list GROUPNAME</screen>
            <para>For example:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule list open
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| ID                                   | IP Protocol | IP Range  | Port Range      | Remote Security Group |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| 353d0611-3f67-4848-8222-a92adbdb5d3a | udp         | 0.0.0.0/0 | 1:65535         | None                  |
| 63536865-e5b6-4df1-bac5-ca6d97d8f54d | tcp         | 0.0.0.0/0 | 1:65535         | None                  |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+</screen>
            <para>These rules are allow type rules as the default is deny. The first
column is the IP protocol (one of icmp, tcp, or udp). The second and
third columns specify the affected port range. The third column
specifies the IP range in CIDR format. This example shows the full
port range for all protocols allowed from all IPs.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Create a security group</title>
        <para>When adding a new security group, you should pick a descriptive but
brief name. This name shows up in brief descriptions of the instances
that use it where the longer description field often does not. For
example, seeing that an instance is using security group "http" is much
easier to understand than "bobs_group" or "secgrp1".</para>
        <procedure>
          <step>
            <para>Ensure your system variables are set for the user and project for
which you are creating security group rules.</para>
          </step>
          <step>
            <para>Add the new security group, as follows:</para>
            <screen language="console">$ openstack security group create GroupName --description Description</screen>
            <para>For example:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group create global_http --description "Allows Web traffic anywhere on the Internet."
+-----------------+--------------------------------------------------------------------------------------------------------------------------+
| Field           | Value                                                                                                                    |
+-----------------+--------------------------------------------------------------------------------------------------------------------------+
| created_at      | 2016-11-03T13:50:53Z                                                                                                     |
| description     | Allows Web traffic anywhere on the Internet.                                                                             |
| headers         |                                                                                                                          |
| id              | c0b92b20-4575-432a-b4a9-eaf2ad53f696                                                                                     |
| name            | global_http                                                                                                              |
| project_id      | 5669caad86a04256994cdf755df4d3c1                                                                                         |
| project_id      | 5669caad86a04256994cdf755df4d3c1                                                                                         |
| revision_number | 1                                                                                                                        |
| rules           | created_at='2016-11-03T13:50:53Z', direction='egress', ethertype='IPv4', id='4d8cec94-e0ee-4c20-9f56-8fb67c21e4df',      |
|                 | project_id='5669caad86a04256994cdf755df4d3c1', revision_number='1', updated_at='2016-11-03T13:50:53Z'                    |
|                 | created_at='2016-11-03T13:50:53Z', direction='egress', ethertype='IPv6', id='31be2ad1-be14-4aef-9492-ecebede2cf12',      |
|                 | project_id='5669caad86a04256994cdf755df4d3c1', revision_number='1', updated_at='2016-11-03T13:50:53Z'                    |
| updated_at      | 2016-11-03T13:50:53Z                                                                                                     |
+-----------------+--------------------------------------------------------------------------------------------------------------------------+</screen>
          </step>
          <step>
            <para>Add a new group rule, as follows:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule create SEC_GROUP_NAME --protocol PROTOCOL --dst-port FROM_PORT:TO_PORT --remote-ip CIDR</screen>
            <para>The arguments are positional, and the <literal>from-port</literal> and <literal>to-port</literal>
arguments specify the local port range connections are allowed to
access, not the source and destination ports of the connection. For
example:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule create global_http --protocol tcp --dst-port 80:80 --remote-ip 0.0.0.0/0
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| created_at        | 2016-11-06T14:02:00Z                 |
| description       |                                      |
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| headers           |                                      |
| id                | 2ba06233-d5c8-43eb-93a9-8eaa94bc9eb5 |
| port_range_max    | 80                                   |
| port_range_min    | 80                                   |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| protocol          | tcp                                  |
| remote_group_id   | None                                 |
| remote_ip_prefix  | 0.0.0.0/0                            |
| revision_number   | 1                                    |
| security_group_id | c0b92b20-4575-432a-b4a9-eaf2ad53f696 |
| updated_at        | 2016-11-06T14:02:00Z                 |
+-------------------+--------------------------------------+</screen>
            <para>You can create complex rule sets by creating additional rules. For
example, if you want to pass both HTTP and HTTPS traffic, run:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule create global_http --protocol tcp --dst-port 443:443 --remote-ip 0.0.0.0/0
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| created_at        | 2016-11-06T14:09:20Z                 |
| description       |                                      |
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| headers           |                                      |
| id                | 821c3ef6-9b21-426b-be5b-c8a94c2a839c |
| port_range_max    | 443                                  |
| port_range_min    | 443                                  |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| protocol          | tcp                                  |
| remote_group_id   | None                                 |
| remote_ip_prefix  | 0.0.0.0/0                            |
| revision_number   | 1                                    |
| security_group_id | c0b92b20-4575-432a-b4a9-eaf2ad53f696 |
| updated_at        | 2016-11-06T14:09:20Z                 |
+-------------------+--------------------------------------+</screen>
            <para>Despite only outputting the newly added rule, this operation is
additive (both rules are created and enforced).</para>
          </step>
          <step>
            <para>View all rules for the new security group, as follows:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack security group rule list global_http
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| ID                                   | IP Protocol | IP Range  | Port Range      | Remote Security Group |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| 353d0611-3f67-4848-8222-a92adbdb5d3a | tcp         | 0.0.0.0/0 | 80:80           | None                  |
| 63536865-e5b6-4df1-bac5-ca6d97d8f54d | tcp         | 0.0.0.0/0 | 443:443         | None                  |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Delete a security group</title>
        <procedure>
          <step>
            <para>Ensure your system variables are set for the user and project for
which you are deleting a security group.</para>
          </step>
          <step>
            <para>Delete the new security group, as follows:</para>
            <screen language="console">$ openstack security group delete GROUPNAME</screen>
            <para>For example:</para>
            <screen language="console">$ openstack security group delete global_http</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Create security group rules for a cluster of instances</title>
        <para>Source Groups are a special, dynamic way of defining the CIDR of allowed
sources. The user specifies a Source Group (Security Group name), and
all the user's other Instances using the specified Source Group are
selected dynamically. This alleviates the need for individual rules to
allow each new member of the cluster.</para>
        <procedure>
          <step>
            <para>Make sure to set the system variables for the user and project for
which you are creating a security group rule.</para>
          </step>
          <step>
            <para>Add a source group, as follows:</para>
            <screen language="console">$ openstack security group rule create secGroupName --remote-group source-group \
    --protocol ip-protocol --dst-port from-port:to-port</screen>
            <para>For example:</para>
            <screen language="console">$ openstack security group rule create cluster --remote-group global_http \
    --protocol tcp --dst-port 22:22</screen>
            <para>The <literal>cluster</literal> rule allows SSH access from any other instance that
uses the <literal>global_http</literal> group.</para>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage services</title>
      <sect2>
        <title>Create and manage services and service users</title>
        <para>The Identity service enables you to define services, as
follows:</para>
        <itemizedlist>
          <listitem>
            <para>Service catalog template. The Identity service acts
as a service catalog of endpoints for other OpenStack
services. The <literal>/etc/keystone/default_catalog.templates</literal>
template file defines the endpoints for services. When
the Identity service uses a template file back end,
any changes that are made to the endpoints are cached.
These changes do not persist when you restart the
service or reboot the machine.</para>
          </listitem>
          <listitem>
            <para>An SQL back end for the catalog service. When the
Identity service is online, you must add the services
to the catalog. When you deploy a system for
production, use the SQL back end.</para>
          </listitem>
        </itemizedlist>
        <para>The <literal>auth_token</literal> middleware supports the
use of either a shared secret or users for each
service.</para>
        <para>To authenticate users against the Identity service, you must
create a service user for each OpenStack service. For example,
create a service user for the Compute, Block Storage, and
Networking services.</para>
        <para>To configure the OpenStack services with service users,
create a project for all services and create users for each
service. Assign the admin role to each service user and
project pair. This role enables users to validate tokens and
authenticate and authorize other user requests.</para>
        <sect3>
          <title>Create a service</title>
          <procedure>
            <step>
              <para>List the available services:</para>
              <screen language="console">$ openstack service list
+----------------------------------+----------+------------+
| ID                               | Name     | Type       |
+----------------------------------+----------+------------+
| 9816f1faaa7c4842b90fb4821cd09223 | cinder   | volume     |
| 1250f64f31e34dcd9a93d35a075ddbe1 | cinderv2 | volumev2   |
| da8cf9f8546b4a428c43d5e032fe4afc | ec2      | ec2        |
| 5f105eeb55924b7290c8675ad7e294ae | glance   | image      |
| dcaa566e912e4c0e900dc86804e3dde0 | keystone | identity   |
| 4a715cfbc3664e9ebf388534ff2be76a | nova     | compute    |
| 1aed4a6cf7274297ba4026cf5d5e96c5 | novav21  | computev21 |
| bed063c790634c979778551f66c8ede9 | neutron  | network    |
| 6feb2e0b98874d88bee221974770e372 |    s3    |    s3      |
+----------------------------------+----------+------------+</screen>
            </step>
            <step>
              <para>To create a service, run this command:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack service create --name SERVICE_NAME --description SERVICE_DESCRIPTION SERVICE_TYPE</screen>
              <variablelist>
                <varlistentry>
                  <term>The arguments are:</term>
                  <listitem>
                    <itemizedlist>
                      <listitem>
                        <para><literal>service_name</literal>: the unique name of the new service.</para>
                      </listitem>
                      <listitem>
                        <para><literal>service_type</literal>: the service type, such as <literal>identity</literal>,
<literal>compute</literal>, <literal>network</literal>, <literal>image</literal>, <literal>object-store</literal>
or any other service identifier string.</para>
                      </listitem>
                      <listitem>
                        <para><literal>service_description</literal>: the description of the service.</para>
                      </listitem>
                    </itemizedlist>
                  </listitem>
                </varlistentry>
              </variablelist>
              <para>For example, to create a <literal>swift</literal> service of type
<literal>object-store</literal>, run this command:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack service create --name swift --description "object store service" object-store
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | object store service             |
| enabled     | True                             |
| id          | 84c23f4b942c44c38b9c42c5e517cd9a |
| name        | swift                            |
| type        | object-store                     |
+-------------+----------------------------------+</screen>
            </step>
            <step>
              <para>To get details for a service, run this command:</para>
              <screen language="console">$ openstack service show SERVICE_TYPE|SERVICE_NAME|SERVICE_ID</screen>
              <para>For example:</para>
              <screen language="console">$ openstack service show object-store
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | object store service             |
| enabled     | True                             |
| id          | 84c23f4b942c44c38b9c42c5e517cd9a |
| name        | swift                            |
| type        | object-store                     |
+-------------+----------------------------------+</screen>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Create service users</title>
          <procedure>
            <step>
              <para>Create a project for the service users.
Typically, this project is named <literal>service</literal>,
but choose any name you like:</para>
              <screen language="console">$ openstack project create service --domain default
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | None                             |
| domain_id   | e601210181f54843b51b3edff41d4980 |
| enabled     | True                             |
| id          | 3e9f3f5399624b2db548d7f871bd5322 |
| is_domain   | False                            |
| name        | service                          |
| parent_id   | e601210181f54843b51b3edff41d4980 |
+-------------+----------------------------------+</screen>
            </step>
            <step>
              <para>Create service users for the relevant services for your
deployment.</para>
            </step>
            <step>
              <para>Assign the admin role to the user-project pair.</para>
              <screen language="console">$ openstack role add --project service --user SERVICE_USER_NAME admin
+-------+----------------------------------+
| Field | Value                            |
+-------+----------------------------------+
| id    | 233109e756c1465292f31e7662b429b1 |
| name  | admin                            |
+-------+----------------------------------+</screen>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Delete a service</title>
          <para>To delete a specified service, specify its ID.</para>
          <screen language="console">$ openstack service delete SERVICE_TYPE|SERVICE_NAME|SERVICE_ID</screen>
          <para>For example:</para>
          <screen language="console">$ openstack service delete object-store</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Manage Compute services</title>
        <para>You can enable and disable Compute services. The following
examples disable and enable the <literal>nova-compute</literal> service.</para>
        <procedure>
          <step>
            <para>List the Compute services:</para>
            <screen language="console">$ openstack compute service list
+----+--------------+------------+----------+---------+-------+--------------+
| ID | Binary       | Host       | Zone     | Status  | State | Updated At   |
+----+--------------+------------+----------+---------+-------+--------------+
|  4 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | consoleauth  |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  5 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | scheduler    |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  6 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | conductor    |            |          |         |       | 0:44:54.0000 |
|    |              |            |          |         |       | 00           |
|  9 | nova-compute | compute    | nova     | enabled | up    | 2016-10-21T0 |
|    |              |            |          |         |       | 2:35:03.0000 |
|    |              |            |          |         |       | 00           |
+----+--------------+------------+----------+---------+-------+--------------+</screen>
          </step>
          <step>
            <para>Disable a nova service:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack compute service set --disable --disable-reason trial log nova nova-compute
+----------+--------------+----------+-------------------+
| Host     | Binary       | Status   | Disabled Reason   |
+----------+--------------+----------+-------------------+
| compute  | nova-compute | disabled | trial log         |
+----------+--------------+----------+-------------------+</screen>
          </step>
          <step>
            <para>Check the service list:</para>
            <screen language="console">$ openstack compute service list
+----+--------------+------------+----------+---------+-------+--------------+
| ID | Binary       | Host       | Zone     | Status  | State | Updated At   |
+----+--------------+------------+----------+---------+-------+--------------+
|  4 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | consoleauth  |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  5 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | scheduler    |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  6 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | conductor    |            |          |         |       | 0:44:54.0000 |
|    |              |            |          |         |       | 00           |
|  9 | nova-compute | compute    | nova     | disabled| up    | 2016-10-21T0 |
|    |              |            |          |         |       | 2:35:03.0000 |
|    |              |            |          |         |       | 00           |
+----+--------------+------------+----------+---------+-------+--------------+</screen>
          </step>
          <step>
            <para>Enable the service:</para>
            <screen language="console">$ openstack compute service set --enable nova nova-compute
+----------+--------------+---------+
| Host     | Binary       | Status  |
+----------+--------------+---------+
| compute  | nova-compute | enabled |
+----------+--------------+---------+</screen>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage images</title>
      <para>The cloud operator assigns roles to users. Roles determine who can
upload and manage images. The operator might restrict image upload and
management to only cloud administrators or operators.</para>
      <para>You can upload images through the <literal>glance</literal> client or the Image service
API. You can use the <literal>nova</literal> client for the image management.
The latter provides mechanisms to list and delete images, set and delete
image metadata, and create images of a running instance or snapshot and
backup types.</para>
      <para>After you upload an image, you cannot change it.</para>
      <para>For details about image creation, see the <link xlink:href="http://docs.openstack.org/image-guide/">Virtual Machine Image
Guide</link>.</para>
      <sect2>
        <title>List or get details for images (glance)</title>
        <para>To get a list of images and to get further details about a single
image, use <command>openstack image list</command> and <command>openstack image show</command>
commands.</para>
        <screen language="console">$ openstack image list
+--------------------------------------+---------------------------------+--------+
| ID                                   | Name                            | Status |
+--------------------------------------+---------------------------------+--------+
| dfc1dfb0-d7bf-4fff-8994-319dd6f703d7 | cirros-0.3.2-x86_64-uec         | active |
| a3867e29-c7a1-44b0-9e7f-10db587cad20 | cirros-0.3.2-x86_64-uec-kernel  | active |
| 4b916fba-6775-4092-92df-f41df7246a6b | cirros-0.3.2-x86_64-uec-ramdisk | active |
| d07831df-edc3-4817-9881-89141f9134c3 | myCirrosImage                   | active |
+--------------------------------------+---------------------------------+--------+</screen>
        <screen language="console">$ openstack image show myCirrosImage
+------------------+------------------------------------------------------+
| Field            | Value                                                |
+------------------+------------------------------------------------------+
| checksum         | ee1eca47dc88f4879d8a229cc70a07c6                     |
| container_format | ami                                                  |
| created_at       | 2016-08-11T15:07:26Z                                 |
| disk_format      | ami                                                  |
| file             | /v2/images/d07831df-edc3-4817-9881-89141f9134c3/file |
| id               | d07831df-edc3-4817-9881-89141f9134c3                 |
| min_disk         | 0                                                    |
| min_ram          | 0                                                    |
| name             | myCirrosImage                                        |
| owner            | d88310717a8e4ebcae84ed075f82c51e                     |
| protected        | False                                                |
| schema           | /v2/schemas/image                                    |
| size             | 13287936                                             |
| status           | active                                               |
| tags             |                                                      |
| updated_at       | 2016-08-11T15:20:02Z                                 |
| virtual_size     | None                                                 |
| visibility       | private                                              |
+------------------+------------------------------------------------------+</screen>
        <para>When viewing a list of images, you can also use <literal>grep</literal> to filter the
list, as follows:</para>
        <screen language="console">$ openstack image list | grep 'cirros'
| dfc1dfb0-d7bf-4fff-8994-319dd6f703d7 | cirros-0.3.2-x86_64-uec         | active |
| a3867e29-c7a1-44b0-9e7f-10db587cad20 | cirros-0.3.2-x86_64-uec-kernel  | active |
| 4b916fba-6775-4092-92df-f41df7246a6b | cirros-0.3.2-x86_64-uec-ramdisk | active |</screen>
        <note>
          <para>To store location metadata for images, which enables direct file access for a client,
update the <literal>/etc/glance/glance-api.conf</literal> file with the following statements:</para>
          <itemizedlist>
            <listitem>
              <para>
                <literal>show_multiple_locations = True</literal>
              </para>
            </listitem>
            <listitem>
              <para>
                <literal>filesystem_store_metadata_file = filePath</literal>
              </para>
              <para>where filePath points to a JSON file that defines the mount point for OpenStack
images on your system and a unique ID. For example:</para>
            </listitem>
          </itemizedlist>
          <screen language="json">[{
    "id": "2d9bb53f-70ea-4066-a68b-67960eaae673",
    "mountpoint": "/var/lib/glance/images/"
}]</screen>
          <para>After you restart the Image service, you can use the following syntax to view
the image's location information:</para>
          <screen language="console">$ openstack --os-image-api-version 2 image show imageID</screen>
          <para>For example, using the image ID shown above, you would issue the command as follows:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack --os-image-api-version 2 image show 2d9bb53f-70ea-4066-a68b-67960eaae673</screen>
        </note>
      </sect2>
      <sect2>
        <title>Create or update an image (glance)</title>
        <para>To create an image, use <command>openstack image create</command>:</para>
        <screen language="console">$ openstack image create imageName</screen>
        <para>To update an image by name or ID, use <command>openstack image set</command>:</para>
        <screen language="console">$ openstack image set imageName</screen>
        <para>The following list explains the optional arguments that you can use with
the <literal>create</literal> and <literal>set</literal> commands to modify image properties. For
more information, refer to the <link xlink:href="http://docs.openstack.org/developer/python-openstackclient/command-objects/image.html">OpenStack Image command reference</link>.</para>
        <para>The following example shows the command that you would use to upload a
CentOS 6.3 image in qcow2 format and configure it for public access:</para>
        <screen language="console">$ openstack image create --disk-format qcow2 --container-format bare \
  --public --file ./centos63.qcow2 centos63-image</screen>
        <para>The following example shows how to update an existing image with a
properties that describe the disk bus, the CD-ROM bus, and the VIF
model:</para>
        <note>
          <para>When you use OpenStack with VMware vCenter Server, you need to specify
the <literal>vmware_disktype</literal> and <literal>vmware_adaptertype</literal> properties with
<command>openstack image create</command>.
Also, we recommend that you set the <literal>hypervisor_type="vmware"</literal> property.
For more information, see <link xlink:href="http://docs.openstack.org/newton/config-reference/compute/hypervisor-vmware.html#images-with-vmware-vsphere">Images with VMware vSphere</link>
in the OpenStack Configuration Reference.</para>
        </note>
        <screen language="console">$ openstack image set \
    --property hw_disk_bus=scsi \
    --property hw_cdrom_bus=ide \
    --property hw_vif_model=e1000 \
    f16-x86_64-openstack-sda</screen>
        <para>Currently the libvirt virtualization tool determines the disk, CD-ROM,
and VIF device models based on the configured hypervisor type
(<literal>libvirt_type</literal> in <literal>/etc/nova/nova.conf</literal> file). For the sake of optimal
performance, libvirt defaults to using virtio for both disk and VIF
(NIC) models. The disadvantage of this approach is that it is not
possible to run operating systems that lack virtio drivers, for example,
BSD, Solaris, and older versions of Linux and Windows.</para>
        <para>If you specify a disk or CD-ROM bus model that is not supported, see
the <xref linkend="disk-and-cd-rom-bus-model-values-table"/>.
If you specify a VIF model that is not supported, the instance fails to
launch. See the <xref linkend="vif-model-values-table"/>.</para>
        <para>The valid model values depend on the <literal>libvirt_type</literal> setting, as shown
in the following tables.</para>
        <para>
          <emphasis role="bold">Disk and CD-ROM bus model values</emphasis>
        </para>
        <informaltable xml:id="disk-and-cd-rom-bus-model-values-table">
          <tgroup cols="2">
            <colspec colname="c1" colwidth="49.0*"/>
            <colspec colname="c2" colwidth="51.0*"/>
            <thead>
              <row>
                <entry>
                  <para>libvirt_type setting</para>
                </entry>
                <entry>
                  <para>Supported model values</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>qemu or kvm</para>
                </entry>
                <entry>
                  <itemizedlist>
                    <listitem>
                      <para>ide</para>
                    </listitem>
                    <listitem>
                      <para>scsi</para>
                    </listitem>
                    <listitem>
                      <para>virtio</para>
                    </listitem>
                  </itemizedlist>
                </entry>
              </row>
              <row>
                <entry>
                  <para>xen</para>
                </entry>
                <entry>
                  <itemizedlist>
                    <listitem>
                      <para>ide</para>
                    </listitem>
                    <listitem>
                      <para>xen</para>
                    </listitem>
                  </itemizedlist>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          <emphasis role="bold">VIF model values</emphasis>
        </para>
        <informaltable xml:id="vif-model-values-table">
          <tgroup cols="2">
            <colspec colname="c1" colwidth="49.0*"/>
            <colspec colname="c2" colwidth="51.0*"/>
            <thead>
              <row>
                <entry>
                  <para>libvirt_type setting</para>
                </entry>
                <entry>
                  <para>Supported model values</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>qemu or kvm</para>
                </entry>
                <entry>
                  <itemizedlist>
                    <listitem>
                      <para>e1000</para>
                    </listitem>
                    <listitem>
                      <para>ne2k_pci</para>
                    </listitem>
                    <listitem>
                      <para>pcnet</para>
                    </listitem>
                    <listitem>
                      <para>rtl8139</para>
                    </listitem>
                    <listitem>
                      <para>virtio</para>
                    </listitem>
                  </itemizedlist>
                </entry>
              </row>
              <row>
                <entry>
                  <para>xen</para>
                </entry>
                <entry>
                  <itemizedlist>
                    <listitem>
                      <para>e1000</para>
                    </listitem>
                    <listitem>
                      <para>netfront</para>
                    </listitem>
                    <listitem>
                      <para>ne2k_pci</para>
                    </listitem>
                    <listitem>
                      <para>pcnet</para>
                    </listitem>
                    <listitem>
                      <para>rtl8139</para>
                    </listitem>
                  </itemizedlist>
                </entry>
              </row>
              <row>
                <entry>
                  <para>vmware</para>
                </entry>
                <entry>
                  <itemizedlist>
                    <listitem>
                      <para>VirtualE1000</para>
                    </listitem>
                    <listitem>
                      <para>VirtualPCNet32</para>
                    </listitem>
                    <listitem>
                      <para>VirtualVmxnet</para>
                    </listitem>
                  </itemizedlist>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <note>
          <para>By default, hardware properties are retrieved from the image
properties. However, if this information is not available, the
<literal>libosinfo</literal> database provides an alternative source for these
values.</para>
          <para>If the guest operating system is not in the database, or if the use
of <literal>libosinfo</literal> is disabled, the default system values are used.</para>
          <para>Users can set the operating system ID or a <literal>short-id</literal> in image
properties. For example:</para>
          <screen language="console">$ openstack image set --property short-id=fedora23 \
  name-of-my-fedora-image</screen>
          <para>Alternatively, users can set <literal>id</literal> to a URL:</para>
          <screen language="console">$ openstack image set \
  --property id=http://fedoraproject.org/fedora/23 \
  ID-of-my-fedora-image</screen>
        </note>
        <sect3>
          <title>Create an image from ISO image</title>
          <para>You can upload ISO images to the Image service (glance).
You can subsequently boot an ISO image using Compute.</para>
          <para>In the Image service, run the following command:</para>
          <screen language="console">$ openstack image create ISO_IMAGE --file IMAGE.iso \
  --disk-format iso --container-format bare</screen>
          <para>Optionally, to confirm the upload in Image service, run:</para>
          <screen language="console">$ openstack image list</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Troubleshoot image creation</title>
        <para>If you encounter problems in creating an image in the Image service or
Compute, the following information may help you troubleshoot the
creation process.</para>
        <itemizedlist>
          <listitem>
            <para>Ensure that the version of qemu you are using is version 0.14 or
later. Earlier versions of qemu result in an <literal>unknown option -s</literal>
error message in the <literal>/var/log/nova/nova-compute.log</literal> file.</para>
          </listitem>
          <listitem>
            <para>Examine the <literal>/var/log/nova/nova-api.log</literal> and
<literal>/var/log/nova/nova-compute.log</literal> log files for error messages.</para>
          </listitem>
        </itemizedlist>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage volumes</title>
      <para>A volume is a detachable block storage device, similar to a USB hard
drive. You can attach a volume to only one instance. Use  the <literal>openstack</literal>
client commands to create and manage volumes.</para>
      <sect2>
        <title>Migrate a volume</title>
        <para>As an administrator, you can migrate a volume with its data from one
location to another in a manner that is transparent to users and
workloads. You can migrate only detached volumes with no snapshots.</para>
        <para>Possible use cases for data migration include:</para>
        <itemizedlist>
          <listitem>
            <para>Bring down a physical storage device for maintenance without
disrupting workloads.</para>
          </listitem>
          <listitem>
            <para>Modify the properties of a volume.</para>
          </listitem>
          <listitem>
            <para>Free up space in a thinly-provisioned back end.</para>
          </listitem>
        </itemizedlist>
        <para>Migrate a volume with the <command>cinder migrate</command> command, as shown in the
following example:</para>
        <screen language="console">$ cinder migrate --force-host-copy &lt;True|False&gt;
                 --lock-volume &lt;True|False&gt;
                 &lt;volume&gt; &lt;host&gt;</screen>
        <para>In this example, <literal>--force-host-copy True</literal> forces the generic
host-based migration mechanism and bypasses any driver optimizations.
<literal>--lock-volume</literal> applies to the available volume.
To determine whether the termination of volume migration caused by other
commands. <literal>True</literal>  locks the volume state and does not allow the
migration to be aborted.</para>
        <note>
          <para>If the volume has snapshots, the specified host destination cannot accept
the volume. If the user is not an administrator, the migration fails.</para>
        </note>
      </sect2>
      <sect2>
        <title>Create a volume</title>
        <para>This example creates a <literal>my-new-volume</literal> volume based on an image.</para>
        <procedure>
          <step>
            <para>List images, and note the ID of the image that you want to use for your
volume:</para>
            <screen language="console">$ openstack image list
+--------------------------------------+---------------------------------+
| ID                                   | Name                            |
+--------------------------------------+---------------------------------+
| 8bf4dc2a-bf78-4dd1-aefa-f3347cf638c8 | cirros-0.3.4-x86_64-uec         |
| 9ff9bb2e-3a1d-4d98-acb5-b1d3225aca6c | cirros-0.3.4-x86_64-uec-kernel  |
| 4b227119-68a1-4b28-8505-f94c6ea4c6dc | cirros-0.3.4-x86_64-uec-ramdisk |
+--------------------------------------+---------------------------------+</screen>
          </step>
          <step>
            <para>List the availability zones, and note the ID of the availability zone in
which you want to create your volume:</para>
            <screen language="console">$ openstack availability zone list
+------+-----------+
| Name |   Status  |
+------+-----------+
| nova | available |
+------+-----------+</screen>
          </step>
          <step>
            <para>Create a volume with 8 gibibytes (GiB) of space, and specify the
availability zone and image:</para>
            <screen language="console">$ openstack volume create --image 8bf4dc2a-bf78-4dd1-aefa-f3347cf638c8 \
  --size 8 --availability-zone nova my-new-volume

+------------------------------+--------------------------------------+
| Property                     | Value                                |
+------------------------------+--------------------------------------+
| attachments                  | []                                   |
| availability_zone            | nova                                 |
| bootable                     | false                                |
| consistencygroup_id          | None                                 |
| created_at                   | 2016-09-23T07:52:42.000000           |
| description                  | None                                 |
| encrypted                    | False                                |
| id                           | bab4b0e0-ce3d-4d57-bf57-3c51319f5202 |
| metadata                     | {}                                   |
| multiattach                  | False                                |
| name                         | my-new-volume                        |
| os-vol-tenant-attr:tenant_id | 3f670abbe9b34ca5b81db6e7b540b8d8     |
| replication_status           | disabled                             |
| size                         | 8                                    |
| snapshot_id                  | None                                 |
| source_volid                 | None                                 |
| status                       | creating                             |
| updated_at                   | None                                 |
| user_id                      | fe19e3a9f63f4a14bd4697789247bbc5     |
| volume_type                  | lvmdriver-1                          |
+------------------------------+--------------------------------------+</screen>
          </step>
          <step>
            <para>To verify that your volume was created successfully, list the available
volumes:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume list
+--------------------------------------+---------------+-----------+------+-------------+
| ID                                   | DisplayName   |  Status   | Size | Attached to |
+--------------------------------------+---------------+-----------+------+-------------+
| bab4b0e0-ce3d-4d57-bf57-3c51319f5202 | my-new-volume | available | 8    |             |
+--------------------------------------+---------------+-----------+------+-------------+</screen>
            <para>If your volume was created successfully, its status is <literal>available</literal>. If
its status is <literal>error</literal>, you might have exceeded your quota.</para>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Create a volume from specified volume type</title>
        <para>Cinder supports these three ways to specify <literal>volume type</literal> during
volume creation.</para>
        <procedure>
          <step>
            <para>volume_type</para>
          </step>
          <step>
            <para>cinder_img_volume_type (via glance image metadata)</para>
          </step>
          <step>
            <para>default_volume_type (via cinder.conf)</para>
          </step>
        </procedure>
        <sect3>
          <title>volume_type</title>
          <para>User can specify <literal>volume type</literal> when creating a volume.</para>
          <screen language="console">$ openstack volume create -h -f {json,shell,table,value,yaml}
                         -c COLUMN --max-width &lt;integer&gt;
                         --noindent --prefix PREFIX --size &lt;size&gt;
                         --type &lt;volume-type&gt; --image &lt;image&gt;
                         --snapshot &lt;snapshot&gt; --source &lt;volume&gt;
                         --description &lt;description&gt; --user &lt;user&gt;
                         --project &lt;project&gt;
                         --availability-zone &lt;availability-zone&gt;
                         --property &lt;key=value&gt;
                         &lt;name&gt;</screen>
        </sect3>
        <sect3>
          <title>cinder_img_volume_type</title>
          <para>If glance image has <literal>cinder_img_volume_type</literal> property, Cinder uses this
parameter to specify <literal>volume type</literal> when creating a volume.</para>
          <para>Choose glance image which has <literal>cinder_img_volume_type</literal> property and create
a volume from the image.</para>
          <screen language="console">$ openstack image list
+----------------------------------+---------------------------------+--------+
| ID                               | Name                            | Status |
+----------------------------------+---------------------------------+--------+
| 376bd633-c9c9-4c5d-a588-342f4f66 | cirros-0.3.4-x86_64-uec         | active |
| d086                             |                                 |        |
| 2c20fce7-2e68-45ee-ba8d-         | cirros-0.3.4-x86_64-uec-ramdisk | active |
| beba27a91ab5                     |                                 |        |
| a5752de4-9faf-4c47-acbc-         | cirros-0.3.4-x86_64-uec-kernel  | active |
| 78a5efa7cc6e                     |                                 |        |
+----------------------------------+---------------------------------+--------+


$ openstack image show 376bd633-c9c9-4c5d-a588-342f4f66d086
+------------------+-----------------------------------------------------------+
| Field            | Value                                                     |
+------------------+-----------------------------------------------------------+
| checksum         | eb9139e4942121f22bbc2afc0400b2a4                          |
| container_format | ami                                                       |
| created_at       | 2016-10-13T03:28:55Z                                      |
| disk_format      | ami                                                       |
| file             | /v2/images/376bd633-c9c9-4c5d-a588-342f4f66d086/file      |
| id               | 376bd633-c9c9-4c5d-a588-342f4f66d086                      |
| min_disk         | 0                                                         |
| min_ram          | 0                                                         |
| name             | cirros-0.3.4-x86_64-uec                                   |
| owner            | 88ba456e3a884c318394737765e0ef4d                          |
| properties       | kernel_id='a5752de4-9faf-4c47-acbc-78a5efa7cc6e',         |
|                  | ramdisk_id='2c20fce7-2e68-45ee-ba8d-beba27a91ab5'         |
| protected        | False                                                     |
| schema           | /v2/schemas/image                                         |
| size             | 25165824                                                  |
| status           | active                                                    |
| tags             |                                                           |
| updated_at       | 2016-10-13T03:28:55Z                                      |
| virtual_size     | None                                                      |
| visibility       | public                                                    |
+------------------+-----------------------------------------------------------+

$ openstack volume create --image 376bd633-c9c9-4c5d-a588-342f4f66d086 \
  --size 1 --availability-zone nova test
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-10-13T06:29:53.688599           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | e6e6a72d-cda7-442c-830f-f306ea6a03d5 |
| multiattach         | False                                |
| name                | test                                 |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | lvmdriver-1                          |
| updated_at          | None                                 |
| user_id             | 33fdc37314914796883706b33e587d51     |
+---------------------+--------------------------------------+</screen>
        </sect3>
        <sect3>
          <title>default_volume_type</title>
          <para>If above parameters are not set, Cinder uses default_volume_type which is
defined in cinder.conf during volume creation.</para>
          <para>Example cinder.conf file configuration.</para>
          <screen language="console">[default]
default_volume_type = lvmdriver-1</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Attach a volume to an instance</title>
        <procedure>
          <step>
            <para>Attach your volume to a server, specifying the server ID and the volume
ID:</para>
            <screen language="console">$ openstack server add volume 84c6e57d-a6b1-44b6-81eb-fcb36afd31b5 \
  573e024d-5235-49ce-8332-be1576d323f8 --device /dev/vdb</screen>
          </step>
          <step>
            <para>Show information for your volume:</para>
            <screen language="console">$ openstack volume show 573e024d-5235-49ce-8332-be1576d323f8</screen>
            <para>The output shows that the volume is attached to the server with ID
<literal>84c6e57d-a6b1-44b6-81eb-fcb36afd31b5</literal>, is in the nova availability
zone, and is bootable.</para>
            <screen language="console">+------------------------------+-----------------------------------------------+
| Field                        | Value                                         |
+------------------------------+-----------------------------------------------+
| attachments                  | [{u'device': u'/dev/vdb',                     |
|                              |        u'server_id': u'84c6e57d-a             |
|                              |           u'id': u'573e024d-...               |
|                              |        u'volume_id': u'573e024d...            |
| availability_zone            | nova                                          |
| bootable                     | true                                          |
| consistencygroup_id          | None                                          |
| created_at                   | 2016-10-13T06:08:07.000000                    |
| description                  | None                                          |
| encrypted                    | False                                         |
| id                           | 573e024d-5235-49ce-8332-be1576d323f8          |
| multiattach                  | False                                         |
| name                         | my-new-volume                                 |
| os-vol-tenant-attr:tenant_id | 7ef070d3fee24bdfae054c17ad742e28              |
| properties                   |                                               |
| replication_status           | disabled                                      |
| size                         | 8                                             |
| snapshot_id                  | None                                          |
| source_volid                 | None                                          |
| status                       | in-use                                        |
| type                         | lvmdriver-1                                   |
| updated_at                   | 2016-10-13T06:08:11.000000                    |
| user_id                      | 33fdc37314914796883706b33e587d51              |
| volume_image_metadata        |{u'kernel_id': u'df430cc2...,                  |
|                              |        u'image_id': u'397e713c...,            |
|                              |        u'ramdisk_id': u'3cf852bd...,          |
|                              |u'image_name': u'cirros-0.3.2-x86_64-uec'}     |
+------------------------------+-----------------------------------------------+</screen>
          </step>
        </procedure>
      </sect2>
      <sect2 xml:id="resize-a-volume">
        <title>Resize a volume</title>
        <procedure>
          <step>
            <para>To resize your volume, you must first detach it from the server.
To detach the volume from your server, pass the server ID and volume ID
to the following command:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack server remove volume 84c6e57d-a6b1-44b6-81eb-fcb36afd31b5 573e024d-5235-49ce-8332-be1576d323f8</screen>
            <para>This command does not provide any output.</para>
          </step>
          <step>
            <para>List volumes:</para>
            <screen language="console">$ openstack volume list
+----------------+-----------------+-----------+------+-------------+
|       ID       |   Display Name  |  Status   | Size | Attached to |
+----------------+-----------------+-----------+------+-------------+
| 573e024d-52... |  my-new-volume  | available |  8   |             |
| bd7cf584-45... | my-bootable-vol | available |  8   |             |
+----------------+-----------------+-----------+------+-------------+</screen>
            <para>Note that the volume is now available.</para>
          </step>
          <step>
            <para>Resize the volume by passing the volume ID and the new size (a value
greater than the old one) as parameters:</para>
            <screen language="console">$ openstack volume set 573e024d-5235-49ce-8332-be1576d323f8 --size 10</screen>
            <para>This command does not provide any output.</para>
            <note>
              <para>When extending an LVM volume with a snapshot, the volume will be
deactivated. The reactivation is automatic unless
<literal>auto_activation_volume_list</literal> is defined in <literal>lvm.conf</literal>. See
<literal>lvm.conf</literal> for more information.</para>
            </note>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Delete a volume</title>
        <procedure>
          <step>
            <para>To delete your volume, you must first detach it from the server.
To detach the volume from your server and check for the list of existing
volumes, see steps 1 and 2 in <xref linkend="resize-a-volume"/>.</para>
            <para>Delete the volume using either the volume name or ID:</para>
            <screen language="console">$ openstack volume delete my-new-volume</screen>
            <para>This command does not provide any output.</para>
          </step>
          <step>
            <para>List the volumes again, and note that the status of your volume is
<literal>deleting</literal>:</para>
            <screen language="console">$ openstack volume list
+----------------+-----------------+-----------+------+-------------+
|       ID       |   Display Name  |  Status   | Size | Attached to |
+----------------+-----------------+-----------+------+-------------+
| 573e024d-52... |  my-new-volume  |  deleting |  8   |             |
| bd7cf584-45... | my-bootable-vol | available |  8   |             |
+----------------+-----------------+-----------+------+-------------+</screen>
            <para>When the volume is fully deleted, it disappears from the list of
volumes:</para>
            <screen language="console">$ openstack volume list
+----------------+-----------------+-----------+------+-------------+
|       ID       |   Display Name  |  Status   | Size | Attached to |
+----------------+-----------------+-----------+------+-------------+
| bd7cf584-45... | my-bootable-vol | available |  8   |             |
+----------------+-----------------+-----------+------+-------------+</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Transfer a volume</title>
        <para>You can transfer a volume from one owner to another by using the
<command>openstack volume transfer request create</command> command. The volume
donor, or original owner, creates a transfer request and sends the created
transfer ID and authorization key to the volume recipient. The volume
recipient, or new owner, accepts the transfer by using the ID and key.</para>
        <note>
          <para>The procedure for volume transfer is intended for tenants (both the
volume donor and recipient) within the same cloud.</para>
        </note>
        <para>Use cases include:</para>
        <itemizedlist>
          <listitem>
            <para>Create a custom bootable volume or a volume with a large data set and
transfer it to a customer.</para>
          </listitem>
          <listitem>
            <para>For bulk import of data to the cloud, the data ingress system creates
a new Block Storage volume, copies data from the physical device, and
transfers device ownership to the end user.</para>
          </listitem>
        </itemizedlist>
        <sect3>
          <title>Create a volume transfer request</title>
          <procedure>
            <step>
              <para>While logged in as the volume donor, list the available volumes:</para>
              <screen language="console">$ openstack volume list
+-----------------+-----------------+-----------+------+-------------+
|       ID        |   Display Name  |  Status   | Size | Attached to |
+-----------------+-----------------+-----------+------+-------------+
| 72bfce9f-cac... |       None      |   error   |  1   |             |
| a1cdace0-08e... |       None      | available |  1   |             |
+-----------------+-----------------+-----------+------+-------------+</screen>
            </step>
            <step>
              <para>As the volume donor, request a volume transfer authorization code for a
specific volume:</para>
              <screen language="console">  $ openstack volume transfer request create &lt;volume&gt;

&lt;volume&gt;
   Name or ID of volume to transfer.</screen>
              <para>The volume must be in an <literal>available</literal> state or the request will be
denied. If the transfer request is valid in the database (that is, it
has not expired or been deleted), the volume is placed in an
<literal>awaiting-transfer</literal> state. For example:</para>
              <screen language="console">$ openstack volume transfer request create a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f</screen>
              <para>The output shows the volume transfer ID in the <literal>id</literal> row and the
authorization key.</para>
              <screen language="console">+------------+--------------------------------------+
| Field      | Value                                |
+------------+--------------------------------------+
| auth_key   | 0a59e53630f051e2                     |
| created_at | 2016-11-03T11:49:40.346181           |
| id         | 34e29364-142b-4c7b-8d98-88f765bf176f |
| name       | None                                 |
| volume_id  | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f |
+------------+--------------------------------------+</screen>
              <note>
                <para>Optionally, you can specify a name for the transfer by using the
<literal>--name transferName</literal> parameter.</para>
              </note>
              <note>
                <para>While the <literal>auth_key</literal> property is visible in the output of
<literal>openstack volume transfer request create VOLUME_ID</literal>, it will not be
available in subsequent <literal>openstack volume transfer request show TRANSFER_ID</literal>
command.</para>
              </note>
            </step>
            <step>
              <para>Send the volume transfer ID and authorization key to the new owner (for
example, by email).</para>
            </step>
            <step>
              <para>View pending transfers:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume transfer request list
+--------------------------------------+--------------------------------------+------+
|               ID                     |             Volume                   | Name |
+--------------------------------------+--------------------------------------+------+
| 6e4e9aa4-bed5-4f94-8f76-df43232f44dc | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f | None |
+--------------------------------------+--------------------------------------+------+</screen>
            </step>
            <step>
              <para>After the volume recipient, or new owner, accepts the transfer, you can
see that the transfer is no longer available:</para>
              <screen language="console">$ openstack volume transfer request list
+----+-----------+------+
| ID | Volume ID | Name |
+----+-----------+------+
+----+-----------+------+</screen>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Accept a volume transfer request</title>
          <procedure>
            <step>
              <para>As the volume recipient, you must first obtain the transfer ID and
authorization key from the original owner.</para>
            </step>
            <step>
              <para>Accept the request:</para>
              <screen language="console">$ openstack volume transfer request accept transferID authKey</screen>
              <para>For example:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume transfer request accept 6e4e9aa4-bed5-4f94-8f76-df43232f44dc b2c8e585cbc68a80
+-----------+--------------------------------------+
|  Property |                Value                 |
+-----------+--------------------------------------+
|     id    | 6e4e9aa4-bed5-4f94-8f76-df43232f44dc |
|    name   |                 None                 |
| volume_id | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f |
+-----------+--------------------------------------+</screen>
              <note>
                <para>If you do not have a sufficient quota for the transfer, the transfer
is refused.</para>
              </note>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Delete a volume transfer</title>
          <procedure>
            <step>
              <para>List available volumes and their statuses:</para>
              <screen language="console">$ openstack volume list
+-----------------+-----------------+-----------------+------+-------------+
|       ID        |   Display Name  |      Status     | Size | Attached to |
+-----------------+-----------------+-----------------+------+-------------+
| 72bfce9f-cac... |       None      |      error      |  1   |             |
| a1cdace0-08e... |       None      |awaiting-transfer|  1   |             |
+-----------------+-----------------+-----------------+------+-------------+</screen>
            </step>
            <step>
              <para>Find the matching transfer ID:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume transfer request list
+--------------------------------------+--------------------------------------+------+
|               ID                     |             VolumeID                 | Name |
+--------------------------------------+--------------------------------------+------+
| a6da6888-7cdf-4291-9c08-8c1f22426b8a | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f | None |
+--------------------------------------+--------------------------------------+------+</screen>
            </step>
            <step>
              <para>Delete the volume:</para>
              <screen language="console">$ openstack volume transfer request delete &lt;transfer&gt;</screen>
              <variablelist>
                <varlistentry>
                  <term>&lt;transfer&gt;</term>
                  <listitem>
                    <para>Name or ID of transfer to delete.</para>
                  </listitem>
                </varlistentry>
              </variablelist>
              <para>For example:</para>
              <screen language="console">$ openstack volume transfer request delete a6da6888-7cdf-4291-9c08-8c1f22426b8a</screen>
            </step>
            <step>
              <para>Verify that transfer list is now empty and that the volume is again
available for transfer:</para>
              <screen language="console">$ openstack volume transfer request list
+----+-----------+------+
| ID | Volume ID | Name |
+----+-----------+------+
+----+-----------+------+</screen>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack volume list
+-----------------+-----------+--------------+------+-------------+----------+-------------+
|       ID        |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |
+-----------------+-----------+--------------+------+-------------+----------+-------------+
| 72bfce9f-ca...  |   error   |     None     |  1   |     None    |  false   |             |
| a1cdace0-08...  | available |     None     |  1   |     None    |  false   |             |
+-----------------+-----------+--------------+------+-------------+----------+-------------+</screen>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2>
        <title>Manage and unmanage a snapshot</title>
        <para>A snapshot is a point in time version of a volume. As an administrator,
you can manage and unmanage snapshots.</para>
        <sect3>
          <title>Manage a snapshot</title>
          <para>Manage a snapshot with the <command>openstack snapshot set</command> command:</para>
          <screen language="console">$ openstack snapshot set \
  [--name &lt;name&gt;] \
  [--description &lt;description&gt;] \
  [--property &lt;key=value&gt; [...] ] \
  [--state &lt;state&gt;] \
  &lt;snapshot&gt;</screen>
          <para>The arguments to be passed are:</para>
          <variablelist>
            <varlistentry>
              <term>
                <literal>--name</literal>
              </term>
              <listitem>
                <para>New snapshot name</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>--description</literal>
              </term>
              <listitem>
                <para>New snapshot description</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>--property</literal>
              </term>
              <listitem>
                <para>Property to add or modify for this snapshot (repeat option to set
multiple properties)</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>--state</literal>
              </term>
              <listitem>
                <para>New snapshot state. (“available”, “error”, “creating”, “deleting”,
or “error_deleting”)
(admin only) (This option simply changes the state of the snapshot in the
database with no regard to actual status, exercise caution when using)</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>
                <literal>&lt;snapshot&gt;</literal>
              </term>
              <listitem>
                <para>Snapshot to modify (name or ID)</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <screen language="console">$ openstack snapshot set my-snapshot-id</screen>
        </sect3>
        <sect3>
          <title>Unmanage a snapshot</title>
          <para>Unmanage a snapshot with the <command>cinder snapshot-unmanage</command> command:</para>
          <screen language="console">$ cinder snapshot-unmanage SNAPSHOT</screen>
          <para>The arguments to be passed are:</para>
          <variablelist>
            <varlistentry>
              <term>SNAPSHOT</term>
              <listitem>
                <para>Name or ID of the snapshot to unmanage.</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <para>The following example unmanages the <literal>my-snapshot-id</literal> image:</para>
          <screen language="console">$ cinder snapshot-unmanage my-snapshot-id</screen>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage shares</title>
      <para>A share is provided by file storage. You can give access to a share to
instances. To create and manage shares, use <literal>manila</literal> client commands.</para>
      <sect2>
        <title>Migrate a share</title>
        <para>As an administrator, you can migrate a share with its data from one
location to another in a manner that is transparent to users and
workloads.</para>
        <para>Possible use cases for data migration include:</para>
        <itemizedlist>
          <listitem>
            <para>Bring down a physical storage device for maintenance without
disrupting workloads.</para>
          </listitem>
          <listitem>
            <para>Modify the properties of a share.</para>
          </listitem>
          <listitem>
            <para>Free up space in a thinly-provisioned back end.</para>
          </listitem>
        </itemizedlist>
        <para>Migrate a share with the <command>manila migrate</command> command, as shown in the
following example:</para>
        <screen language="console">$ manila migrate shareID destinationHost --force-host-copy True|False</screen>
        <para>In this example, <literal>--force-host-copy True</literal> forces the generic
host-based migration mechanism and bypasses any driver optimizations.
<literal>destinationHost</literal> is in this format <literal>host#pool</literal> which includes
destination host and pool.</para>
        <note>
          <para>If the user is not an administrator, the migration fails.</para>
        </note>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage flavors</title>
      <para>In OpenStack, flavors define the compute, memory, and
storage capacity of nova computing instances. To put it
simply, a flavor is an available hardware configuration for a
server. It defines the <literal>size</literal> of a virtual server
that can be launched.</para>
      <note>
        <para>Flavors can also determine on which compute host a flavor
can be used to launch an instance. For information
about customizing flavors, refer to <xref linkend="compute-flavors"/>.</para>
      </note>
      <para>A flavor consists of the following parameters:</para>
      <variablelist>
        <varlistentry>
          <term>Flavor ID</term>
          <listitem>
            <para>Unique ID (integer or UUID) for the new flavor. If
specifying 'auto', a UUID will be automatically generated.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Name</term>
          <listitem>
            <para>Name for the new flavor.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>VCPUs</term>
          <listitem>
            <para>Number of virtual CPUs to use.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Memory MB</term>
          <listitem>
            <para>Amount of RAM to use (in megabytes).</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Root Disk GB</term>
          <listitem>
            <para>Amount of disk space (in gigabytes) to use for
the root (/) partition.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Ephemeral Disk GB</term>
          <listitem>
            <para>Amount of disk space (in gigabytes) to use for
the ephemeral partition. If unspecified, the value
is <literal>0</literal> by default.
Ephemeral disks offer machine local disk storage
linked to the lifecycle of a VM instance. When a
VM is terminated, all data on the ephemeral disk
is lost. Ephemeral disks are not included in any
snapshots.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Swap</term>
          <listitem>
            <para>Amount of swap space (in megabytes) to use. If
unspecified, the value is <literal>0</literal> by default.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>RXTX Factor</term>
          <listitem>
            <para>Optional property that allows servers with a different bandwidth be
created with the RXTX Factor. The default value is <literal>1.0</literal>. That is,
the new bandwidth is the same as that of the attached network. The
RXTX Factor is available only for Xen or NSX based systems.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Is Public</term>
          <listitem>
            <para>Boolean value defines whether the flavor is available to all users.
Defaults to <literal>True</literal>.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Extra Specs</term>
          <listitem>
            <para>Key and value pairs that define on which compute nodes a
flavor can run. These pairs must match corresponding pairs on
the compute nodes. It can be used to implement special resources, such
as flavors that run on only compute nodes with GPU hardware.</para>
          </listitem>
        </varlistentry>
      </variablelist>
      <para>As of Newton, there are no default flavors.  The following table
lists the default flavors for Mitaka and earlier.</para>
      <informaltable>
        <tgroup cols="4">
          <colspec colname="c1" colwidth="23.5*"/>
          <colspec colname="c2" colwidth="17.6*"/>
          <colspec colname="c3" colwidth="29.4*"/>
          <colspec colname="c4" colwidth="29.4*"/>
          <thead>
            <row>
              <entry>
                <para>Flavor</para>
              </entry>
              <entry>
                <para>VCPUs</para>
              </entry>
              <entry>
                <para>Disk (in GB)</para>
              </entry>
              <entry>
                <para>RAM (in MB)</para>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>
                <para>m1.tiny</para>
              </entry>
              <entry>
                <para>1</para>
              </entry>
              <entry>
                <para>1</para>
              </entry>
              <entry>
                <para>512</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.small</para>
              </entry>
              <entry>
                <para>1</para>
              </entry>
              <entry>
                <para>20</para>
              </entry>
              <entry>
                <para>2048</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.medium</para>
              </entry>
              <entry>
                <para>2</para>
              </entry>
              <entry>
                <para>40</para>
              </entry>
              <entry>
                <para>4096</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.large</para>
              </entry>
              <entry>
                <para>4</para>
              </entry>
              <entry>
                <para>80</para>
              </entry>
              <entry>
                <para>8192</para>
              </entry>
            </row>
            <row>
              <entry>
                <para>m1.xlarge</para>
              </entry>
              <entry>
                <para>8</para>
              </entry>
              <entry>
                <para>160</para>
              </entry>
              <entry>
                <para>16384</para>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
      <para>You can create and manage flavors with the
<command>openstack flavor</command> commands provided by the <literal>python-openstackclient</literal>
package.</para>
      <sect2>
        <title>Create a flavor</title>
        <procedure>
          <step>
            <para>List flavors to show the ID and name, the amount
of memory, the amount of disk space for the root
partition and for the ephemeral partition, the
swap, and the number of virtual CPUs for each
flavor:</para>
            <screen language="console">$ openstack flavor list</screen>
          </step>
          <step>
            <para>To create a flavor, specify a name, ID, RAM
size, disk size, and the number of VCPUs for the
flavor, as follows:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack flavor create FLAVOR_NAME --id FLAVOR_ID --ram RAM_IN_MB --disk ROOT_DISK_IN_GB --vcpus NUMBER_OF_VCPUS</screen>
            <note>
              <para>Unique ID (integer or UUID) for the new flavor. If
specifying 'auto', a UUID will be automatically generated.</para>
            </note>
            <para>Here is an example with additional optional
parameters filled in that creates a public <literal>extra
tiny</literal> flavor that automatically gets an ID
assigned, with 256 MB memory, no disk space, and
one VCPU. The rxtx-factor indicates the slice of
bandwidth that the instances with this flavor can
use (through the Virtual Interface (vif) creation
in the hypervisor):</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ openstack flavor create --public m1.extra_tiny --id auto --ram 256 --disk 0 --vcpus 1 --rxtx-factor 1</screen>
          </step>
          <step>
            <para>If an individual user or group of users needs a custom
flavor that you do not want other projects to have access to,
you can change the flavor's access to make it a private flavor.
See
<link xlink:href="http://docs.openstack.org/ops-guide/ops-user-facing-operations.html#private-flavors">Private Flavors in the OpenStack Operations Guide</link>.</para>
            <para>For a list of optional parameters, run this command:</para>
            <screen language="console">$ openstack help flavor create</screen>
          </step>
          <step>
            <para>After you create a flavor, assign it to a
project by specifying the flavor name or ID and
the project ID:</para>
            <screen language="console">$ nova flavor-access-add FLAVOR TENANT_ID</screen>
          </step>
          <step>
            <para>In addition, you can set or unset <literal>extra_spec</literal> for the existing flavor.
The <literal>extra_spec</literal> metadata keys can influence the instance directly when
it is launched. If a flavor sets the
<literal>extra_spec key/value quota:vif_outbound_peak=65536</literal>, the instance's
outbound peak bandwidth I/O should be LTE 512 Mbps. There are several
aspects that can work for an instance including <literal>CPU limits</literal>,
<literal>Disk tuning</literal>, <literal>Bandwidth I/O</literal>, <literal>Watchdog behavior</literal>, and
<literal>Random-number generator</literal>.
For information about supporting metadata keys, see
<xref linkend="compute-flavors"/>.</para>
            <para>For a list of optional parameters, run this command:</para>
            <screen language="console">$ nova help flavor-key</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Delete a flavor</title>
        <para>Delete a specified flavor, as follows:</para>
        <screen language="console">$ openstack flavor delete FLAVOR_ID</screen>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage the OpenStack environment</title>
      <para>This section includes tasks specific to the OpenStack environment.</para>
      <sect2>
        <title>Select hosts where instances are launched</title>
        <para>With the appropriate permissions, you can select which
host instances are launched on and which roles can boot instances
on this host.</para>
        <procedure>
          <step>
            <para>To select the host where instances are launched, use
the <literal>--availability-zone ZONE:HOST:NODE</literal> parameter on the
<command>openstack server create</command> command.</para>
            <para>For example:</para>
            <screen language="console">$ openstack server create --image IMAGE --flavor m1.tiny \
  --key-name KEY --availability-zone ZONE:HOST:NODE \
  --nic net-id=UUID SERVER</screen>
            <note>
              <para>HOST is an optional parameter. In such cases,
use the <literal>--availability-zone ZONE::NODE</literal>.</para>
            </note>
          </step>
          <step>
            <para>To specify which roles can launch an instance on a
specified host, enable the <literal>create:forced_host</literal> option in
the <literal>policy.json</literal> file. By default, this option is
enabled for only the admin role. If you see <literal>Forbidden (HTTP 403)</literal>
in return, then you are not using admin credentials.</para>
          </step>
          <step>
            <para>To view the list of valid zones, use the
<command>openstack availability zone list</command> command.</para>
            <screen language="console">$ openstack availability zone list
+-----------+-------------+
| Zone Name | Zone Status |
+-----------+-------------+
| zone1     | available   |
| zone2     | available   |
+-----------+-------------+</screen>
          </step>
          <step>
            <para>To view the list of valid compute hosts, use the
<command>openstack host list</command> command.</para>
            <screen language="console">$ openstack host list
+----------------+-------------+----------+
| Host Name      | Service     | Zone     |
+----------------+-------------+----------+
| compute01      | compute     | nova     |
| compute02      | compute     | nova     |
+----------------+-------------+----------+</screen>
          </step>
          <step>
            <para>To view the list of valid compute nodes, use the
<command>openstack hypervisor list</command> command.</para>
            <screen language="console">$ openstack hypervisor list
+----+---------------------+
| ID | Hypervisor Hostname |
+----+---------------------+
|  1 | server2             |
|  2 | server3             |
|  3 | server4             |
+----+---------------------+</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Consider NUMA topology when booting instances</title>
        <para>NUMA topology can exist on both the physical hardware of the host, and the
virtual hardware of the instance. OpenStack Compute uses libvirt to tune
instances to take advantage of NUMA topologies. The libvirt driver boot
process looks at the NUMA topology field of both the instance and the host it
is being booted on, and uses that information to generate an appropriate
configuration.</para>
        <para>If the host is NUMA capable, but the instance has not requested a NUMA
topology, Compute attempts to pack the instance into a single cell.
If this fails, though, Compute will not continue to try.</para>
        <para>If the host is NUMA capable, and the instance has requested a specific NUMA
topology, Compute will try to pin the vCPUs of different NUMA cells
on the instance to the corresponding NUMA cells on the host. It will also
expose the NUMA topology of the instance to the guest OS.</para>
        <para>If you want Compute to pin a particular vCPU as part of this process,
set the <literal>vcpu_pin_set</literal> parameter in the <literal>nova.conf</literal> configuration
file. For more information about the <literal>vcpu_pin_set</literal> parameter, see the
Configuration Reference Guide.</para>
      </sect2>
      <sect2>
        <title>Evacuate instances</title>
        <para>If a hardware malfunction or other error causes a cloud compute node to fail,
you can evacuate instances to make them available again. You can optionally
include the target host on the <command>nova evacuate</command> command. If you omit
the host, the scheduler chooses the target host.</para>
        <para>To preserve user data on the server disk, configure shared storage on the
target host. When you evacuate the instance, Compute detects whether shared
storage is available on the target host. Also, you must validate that the
current VM host is not operational. Otherwise, the evacuation fails.</para>
        <procedure>
          <step>
            <para>To find a host for the evacuated instance, list all hosts:</para>
            <screen language="console">$ openstack host list</screen>
          </step>
          <step>
            <para>Evacuate the instance. You can use the <literal>--password PWD</literal> option
to pass the instance password to the command. If you do not specify a
password, the command generates and prints one after it finishes
successfully. The following command evacuates a server from a failed host
to HOST_B.</para>
            <screen language="console">$ nova evacuate EVACUATED_SERVER_NAME HOST_B</screen>
            <para>The command rebuilds the instance from the original image or volume and
returns a password. The command preserves the original configuration, which
includes the instance ID, name, uid, IP address, and so on.</para>
            <screen language="console">+-----------+--------------+
| Property  |    Value     |
+-----------+--------------+
| adminPass | kRAJpErnT4xZ |
+-----------+--------------+</screen>
          </step>
          <step>
            <para>To preserve the user disk data on the evacuated server, deploy Compute
with a shared file system. To configure your system, see
<xref linkend="section-configuring-compute-migrations"/>.
The following example does not change the password.</para>
            <screen language="console">$ nova evacuate EVACUATED_SERVER_NAME HOST_B --on-shared-storage</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Migrate a single instance to another compute host</title>
        <para>When you want to move an instance from one compute host to another,
you can use the <command>openstack server migrate</command> command. The scheduler
chooses the destination compute host based on its settings. This process does
not assume that the instance has shared storage available on the
target host. If you are using SSH tunneling, you must ensure that
each node is configured with SSH key authentication so that the
Compute service can use SSH to move disks to other nodes.
For more information, see <xref linkend="clinovamigratecfgssh"/>.</para>
        <procedure>
          <step>
            <para>To list the VMs you want to migrate, run:</para>
            <screen language="console">$ openstack server list</screen>
          </step>
          <step>
            <para>Use the <command>openstack server migrate</command> command.</para>
            <screen language="console">$ openstack server migrate --live TARGET_HOST VM_INSTANCE</screen>
          </step>
          <step>
            <para>To migrate an instance and watch the status, use this example script:</para>
            <screen language="bash">#!/bin/bash

# Provide usage
usage() {
echo "Usage: $0 VM_ID"
exit 1
}

[[ $# -eq 0 ]] &amp;&amp; usage

# Migrate the VM to an alternate hypervisor
echo -n "Migrating instance to alternate host"
VM_ID=$1
nova migrate $VM_ID
VM_OUTPUT=`nova show $VM_ID`
VM_STATUS=`echo "$VM_OUTPUT" | grep status | awk '{print $4}'`
while [[ "$VM_STATUS" != "VERIFY_RESIZE" ]]; do
echo -n "."
sleep 2
VM_OUTPUT=`nova show $VM_ID`
VM_STATUS=`echo "$VM_OUTPUT" | grep status | awk '{print $4}'`
done
nova resize-confirm $VM_ID
echo " instance migrated and resized."
echo;

# Show the details for the VM
echo "Updated instance details:"
nova show $VM_ID

# Pause to allow users to examine VM details
read -p "Pausing, press &lt;enter&gt; to exit."</screen>
          </step>
        </procedure>
        <note>
          <para>If you see this error, it means you are either
trying the command with the wrong credentials,
such as a non-admin user, or the <literal>policy.json</literal>
file prevents migration for your user:</para>
          <para>
            <literal>ERROR (Forbidden): Policy doesn't allow compute_extension:admin_actions:migrate
to be performed. (HTTP 403)</literal>
          </para>
        </note>
        <note>
          <para>If you see an error similar to this message, SSH tunneling
was not set up between the compute nodes:</para>
          <para>
            <literal>ProcessExecutionError: Unexpected error while running command.</literal>
          </para>
          <para>
            <literal>Stderr: u Host key verification failed.\r\n</literal>
          </para>
        </note>
        <para>The instance is booted from a new host, but preserves its configuration
including its ID, name, any metadata, IP address, and other properties.</para>
      </sect2>
      <sect2 xml:id="clinovamigratecfgssh">
        <title>Configure SSH between compute nodes</title>
        <para>If you are resizing or migrating an instance
between hypervisors, you might encounter an
SSH (Permission denied) error. Ensure that
each node is configured with SSH key authentication
so that the Compute service can use SSH
to move disks to other nodes.</para>
        <para>To share a key pair between compute nodes,
complete the following steps:</para>
        <procedure>
          <step>
            <para>On the first node, obtain a key pair
(public key and private key). Use the root key
that is in the <literal>/root/.ssh/id_rsa</literal> and
<literal>/root/.ssh/id_ras.pub</literal> directories or
generate a new key pair.</para>
          </step>
          <step>
            <para>Run <command>setenforce 0</command> to put SELinux into
permissive mode.</para>
          </step>
          <step>
            <para>Enable login abilities for the nova user:</para>
            <screen language="console"># usermod -s /bin/bash nova</screen>
            <para>Switch to the nova account.</para>
            <screen language="console"># su nova</screen>
          </step>
          <step>
            <para>As root, create the folder that is needed by SSH and place
the private key that you obtained in step 1 into this
folder:</para>
            <screen language="console">mkdir -p /var/lib/nova/.ssh
cp &lt;private key&gt;  /var/lib/nova/.ssh/id_rsa
echo 'StrictHostKeyChecking no' &gt;&gt; /var/lib/nova/.ssh/config
chmod 600 /var/lib/nova/.ssh/id_rsa /var/lib/nova/.ssh/authorized_keys</screen>
          </step>
          <step>
            <para>Repeat steps 2-4 on each node.</para>
            <note>
              <para>The nodes must share the same key pair, so do not generate
a new key pair for any subsequent nodes.</para>
            </note>
          </step>
          <step>
            <para>From the first node, where you created the SSH key, run:</para>
            <screen language="console">ssh-copy-id -i &lt;pub key&gt; nova@remote-host</screen>
            <para>This command installs your public key in a remote machine's <literal>authorized_keys</literal> folder.</para>
          </step>
          <step>
            <para>Ensure that the nova user can now log in to each node without
using a password:</para>
            <screen language="console"># su nova
$ ssh *computeNodeAddress*
$ exit</screen>
          </step>
          <step>
            <para>As root on each node, restart both libvirt and the Compute services:</para>
            <screen language="console"># systemctl restart libvirtd.service
# systemctl restart openstack-nova-compute.service</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Manage IP addresses</title>
        <para>Each instance has a private, fixed IP address that is assigned when
the instance is launched. In addition, an instance can have a public
or floating IP address. Private IP addresses are used for
communication between instances, and public IP addresses are used
for communication with networks outside the cloud, including the
Internet.</para>
        <itemizedlist>
          <listitem>
            <para>By default, both administrative and end users can associate floating IP
addresses with projects and instances. You can change user permissions for
managing IP addresses by updating the <literal>/etc/nova/policy.json</literal>
file. For basic floating-IP procedures, refer to the <link xlink:href="http://docs.openstack.org/user-guide/configure-access-and-security-for-instances.html#allocate-a-floating-ip-address-to-an-instance">Allocate a
floating address to an instance</link>
section in the OpenStack End User Guide.</para>
          </listitem>
          <listitem>
            <para>For details on creating public networks using OpenStack Networking
(<literal>neutron</literal>), refer to <xref linkend="networking-adv-features"/>.
No floating IP addresses are created by default in OpenStack Networking.</para>
          </listitem>
        </itemizedlist>
        <para>As an administrator using legacy networking (<literal>nova-network</literal>), you
can use the following bulk commands to list, create, and delete ranges
of floating IP addresses. These addresses can then be associated with
instances by end users.</para>
        <sect3>
          <title>List addresses for all projects</title>
          <para>To list all floating IP addresses for all projects, run:</para>
          <screen language="console">$ openstack floating ip list
+------------+---------------+---------------+--------+-----------+
| project_id | address       | instance_uuid | pool   | interface |
+------------+---------------+---------------+--------+-----------+
| None       | 172.24.4.225  | None          | public | eth0      |
| None       | 172.24.4.226  | None          | public | eth0      |
| None       | 172.24.4.227  | None          | public | eth0      |
| None       | 172.24.4.228  | None          | public | eth0      |
| None       | 172.24.4.229  | None          | public | eth0      |
| None       | 172.24.4.230  | None          | public | eth0      |
| None       | 172.24.4.231  | None          | public | eth0      |
| None       | 172.24.4.232  | None          | public | eth0      |
| None       | 172.24.4.233  | None          | public | eth0      |
| None       | 172.24.4.234  | None          | public | eth0      |
| None       | 172.24.4.235  | None          | public | eth0      |
| None       | 172.24.4.236  | None          | public | eth0      |
| None       | 172.24.4.237  | None          | public | eth0      |
| None       | 172.24.4.238  | None          | public | eth0      |
| None       | 192.168.253.1 | None          | test   | eth0      |
| None       | 192.168.253.2 | None          | test   | eth0      |
| None       | 192.168.253.3 | None          | test   | eth0      |
| None       | 192.168.253.4 | None          | test   | eth0      |
| None       | 192.168.253.5 | None          | test   | eth0      |
| None       | 192.168.253.6 | None          | test   | eth0      |
+------------+---------------+---------------+--------+-----------+</screen>
        </sect3>
        <sect3>
          <title>Bulk create floating IP addresses</title>
          <para>To create a range of floating IP addresses, run:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ nova floating-ip-bulk-create [--pool POOL_NAME] [--interface INTERFACE] RANGE_TO_CREATE</screen>
          <para>For example:</para>
          <screen language="console">$ nova floating-ip-bulk-create --pool test 192.168.1.56/29</screen>
          <para>By default, <literal>floating-ip-bulk-create</literal> uses the
<literal>public</literal> pool and <literal>eth0</literal> interface values.</para>
          <note>
            <para>You should use a range of free IP addresses that is valid for your
network. If you are not sure, at least try to avoid the DHCP address
range:</para>
            <itemizedlist>
              <listitem>
                <para>Pick a small range (/29 gives an 8 address range, 6 of
which will be usable).</para>
              </listitem>
              <listitem>
                <para>Use <command>nmap</command> to check a range's availability. For example,
192.168.1.56/29 represents a small range of addresses
(192.168.1.56-63, with 57-62 usable), and you could run the
command <command>nmap -sn 192.168.1.56/29</command> to check whether the entire
range is currently unused.</para>
              </listitem>
            </itemizedlist>
          </note>
        </sect3>
        <sect3>
          <title>Bulk delete floating IP addresses</title>
          <para>To delete a range of floating IP addresses, run:</para>
          <screen language="console">$ openstack floating ip delete RANGE_TO_DELETE</screen>
          <para>For example:</para>
          <screen language="console">$ openstack floating ip delete 192.168.1.56/29</screen>
        </sect3>
      </sect2>
      <sect2>
        <title>Launch and manage stacks using the CLI</title>
        <para>The Orchestration service provides a template-based
orchestration engine. Administrators can use the orchestration engine
to create and manage OpenStack cloud infrastructure resources. For
example, an administrator can define storage, networking, instances,
and applications to use as a repeatable running environment.</para>
        <para>Templates are used to create stacks, which are collections
of resources. For example, a stack might include instances,
floating IPs, volumes, security groups, or users.
The Orchestration service offers access to all OpenStack
core services through a single modular template, with additional
orchestration capabilities such as auto-scaling and basic
high availability.</para>
        <para>For information about:</para>
        <itemizedlist>
          <listitem>
            <para>basic creation and deletion of Orchestration stacks, refer
to the <link xlink:href="http://docs.openstack.org/user-guide/dashboard-stacks.html">OpenStack End User Guide</link></para>
          </listitem>
          <listitem>
            <para><emphasis role="bold">openstack</emphasis> CLI, see the <link xlink:href="http://docs.openstack.org/cli-reference/openstack.html">OpenStack Command-Line Interface
Reference</link></para>
          </listitem>
        </itemizedlist>
        <note>
          <para>The <literal>heat</literal> CLI is deprecated in favor of <literal>python-openstackclient</literal>.
For a Python library, continue using <literal>python-heatclient</literal>.</para>
        </note>
        <para>As an administrator, you can also carry out stack functions
on behalf of your users. For example, to resume, suspend,
or delete a stack, run:</para>
        <screen language="console">$ openstack stack resume STACK
$ openstack stack suspend STACK
$ openstack stack delete STACK</screen>
      </sect2>
    </sect1>
    <sect1 xml:id="manage-quotas">
      <title>Manage quotas</title>
      <para>To prevent system capacities from being exhausted without
notification, you can set up quotas. Quotas are operational
limits. For example, the number of gigabytes allowed for each
project can be controlled so that cloud resources are optimized.
Quotas can be enforced at both the project
and the project-user level.</para>
      <para>Using the command-line interface, you can manage quotas for
the OpenStack Compute service, the OpenStack Block Storage service,
and the OpenStack Networking service.</para>
      <para>The cloud operator typically changes default values because a
project requires more than ten volumes or 1 TB on a compute
node.</para>
      <note>
        <para>To view all projects, run:</para>
        <screen language="console">$ openstack project list
+----------------------------------+----------+
| ID                               | Name     |
+----------------------------------+----------+
| e66d97ac1b704897853412fc8450f7b9 | admin    |
| bf4a37b885fe46bd86e999e50adad1d3 | services |
| 21bd1c7c95234fd28f589b60903606fa | tenant01 |
| f599c5cd1cba4125ae3d7caed08e288c | tenant02 |
+----------------------------------+----------+</screen>
        <para>To display all current users for a project, run:</para>
        <screen language="console">$ openstack user list --project PROJECT_NAME
+----------------------------------+--------+
| ID                               | Name   |
+----------------------------------+--------+
| ea30aa434ab24a139b0e85125ec8a217 | demo00 |
| 4f8113c1d838467cad0c2f337b3dfded | demo01 |
+----------------------------------+--------+</screen>
      </note>
      <para>Use <literal>openstack quota show <replaceable>PROJECT_NAME</replaceable></literal> to list all quotas for a
project.</para>
      <para>Use <literal>openstack quota set <replaceable>PROJECT_NAME</replaceable><replaceable>--parameters</replaceable></literal> to set quota
values.</para>
      <sect2>
        <title>Manage Compute service quotas</title>
        <para>As an administrative user, you can use the <command>nova quota-*</command>
commands, which are provided by the <literal>python-novaclient</literal>
package, to update the Compute service quotas for a specific project or
project user, as well as update the quota defaults for a new project.</para>
        <para>
          <emphasis role="bold">Compute quota descriptions</emphasis>
        </para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="20.0*"/>
            <colspec colname="c2" colwidth="80.0*"/>
            <thead>
              <row>
                <entry>
                  <para>Quota name</para>
                </entry>
                <entry>
                  <para>Description</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>cores</para>
                </entry>
                <entry>
                  <para>Number of instance cores (VCPUs) allowed per project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>fixed-ips</para>
                </entry>
                <entry>
                  <para>Number of fixed IP addresses allowed per project. This number
must be equal to or greater than the number of allowed
instances.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>floating-ips</para>
                </entry>
                <entry>
                  <para>Number of floating IP addresses allowed per project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>injected-file-content-bytes</para>
                </entry>
                <entry>
                  <para>Number of content bytes allowed per injected file.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>injected-file-path-bytes</para>
                </entry>
                <entry>
                  <para>Length of injected file path.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>injected-files</para>
                </entry>
                <entry>
                  <para>Number of injected files allowed per project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>instances</para>
                </entry>
                <entry>
                  <para>Number of instances allowed per project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>key-pairs</para>
                </entry>
                <entry>
                  <para>Number of key pairs allowed per user.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>metadata-items</para>
                </entry>
                <entry>
                  <para>Number of metadata items allowed per instance.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>ram</para>
                </entry>
                <entry>
                  <para>Megabytes of instance ram allowed per project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>security-groups</para>
                </entry>
                <entry>
                  <para>Number of security groups per project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>security-group-rules</para>
                </entry>
                <entry>
                  <para>Number of rules per security group.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>server-groups</para>
                </entry>
                <entry>
                  <para>Number of server groups per project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>server-group-members</para>
                </entry>
                <entry>
                  <para>Number of servers per server group.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <sect3>
          <title>View and update Compute quotas for a project</title>
          <sect4>
            <title>To view and update default quota values</title>
            <procedure>
              <step>
                <para>List all default quotas for all projects:</para>
                <screen language="console">$ openstack quota show --default

+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 10    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</screen>
              </step>
              <step>
                <para>Update a default value for a new project, for example:</para>
                <screen language="console">$ nova quota-class-update --instances 15 default</screen>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>To view quota values for an existing project</title>
            <procedure>
              <step>
                <para>List the currently set quota values for a project:</para>
                <screen language="console">$ openstack quota show TENANT_NAME

+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 10    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</screen>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>To update quota values for an existing project</title>
            <procedure>
              <step>
                <para>Obtain the project ID.</para>
                <screen language="console">$ tenant=$(openstack project show -f value -c id TENANT_NAME)</screen>
              </step>
              <step>
                <para>Update a particular quota value.</para>
                <screen language="console">$ nova quota-update --QUOTA_NAME QUOTA_VALUE TENANT_ID</screen>
                <para>For example:</para>
                <screen language="console">$ nova quota-update --floating-ips 20 TENANT_NAME
$ openstack quota show TENANT_NAME
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 20    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</screen>
                <note>
                  <para>To view a list of options for the <command>nova quota-update</command> command,
run:</para>
                  <screen language="console">$ nova help quota-update</screen>
                </note>
              </step>
            </procedure>
          </sect4>
        </sect3>
        <sect3>
          <title>View and update Compute quotas for a project user</title>
          <sect4>
            <title>To view quota values for a project user</title>
            <procedure>
              <step>
                <para>Place the user ID in a usable variable.</para>
                <screen language="console">$ tenantUser=$(openstack user show -f value -c id USER_NAME)</screen>
              </step>
              <step>
                <para>Place the user's project ID in a usable variable, as follows:</para>
                <screen language="console">$ tenant=$(openstack project show -f value -c id TENANT_NAME)</screen>
              </step>
              <step>
                <para>List the currently set quota values for a project user.</para>
                <screen language="console">$ nova quota-show --user $tenantUser --tenant $tenant</screen>
                <para>For example:</para>
                <screen language="console">$ nova quota-show --user $tenantUser --tenant $tenant
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 20    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</screen>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>To update quota values for a project user</title>
            <procedure>
              <step>
                <para>Place the user ID in a usable variable.</para>
                <screen language="console">$ tenantUser=$(openstack user show -f value -c id USER_NAME)</screen>
              </step>
              <step>
                <para>Place the user's project ID in a usable variable, as follows:</para>
                <screen language="console">$ tenant=$(openstack project show -f value -c id TENANT_NAME)</screen>
              </step>
              <step>
                <para>Update a particular quota value, as follows:</para>
                <screen language="console">$ nova quota-update  --user $tenantUser --QUOTA_NAME QUOTA_VALUE $tenant</screen>
                <para>For example:</para>
                <screen language="console">$ nova quota-update --user $tenantUser --floating-ips 12 $tenant
$ nova quota-show --user $tenantUser --tenant $tenant
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 12    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</screen>
                <note>
                  <para>To view a list of options for the <command>nova quota-update</command> command,
run:</para>
                  <screen language="console">$ nova help quota-update</screen>
                </note>
              </step>
            </procedure>
          </sect4>
          <sect4>
            <title>To display the current quota usage for a project user</title>
            <para>Use <command>nova absolute-limits</command> to get a list of the
current quota values and the current quota usage:</para>
            <screen language="console">$ nova absolute-limits --tenant TENANT_NAME
+--------------------+------+-------+
| Name               | Used | Max   |
+--------------------+------+-------+
| Cores              | 0    | 20    |
| FloatingIps        | 0    | 10    |
| ImageMeta          | -    | 128   |
| Instances          | 0    | 10    |
| Keypairs           | -    | 100   |
| Personality        | -    | 5     |
| Personality Size   | -    | 10240 |
| RAM                | 0    | 51200 |
| SecurityGroupRules | -    | 20    |
| SecurityGroups     | 0    | 10    |
| Server Meta        | -    | 128   |
| ServerGroupMembers | -    | 10    |
| ServerGroups       | 0    | 10    |
+--------------------+------+-------+</screen>
          </sect4>
        </sect3>
      </sect2>
      <sect2>
        <title>Manage Block Storage service quotas</title>
        <para>As an administrative user, you can update the OpenStack Block
Storage service quotas for a project. You can also update the quota
defaults for a new project.</para>
        <para>
          <emphasis role="bold">Block Storage quotas</emphasis>
        </para>
        <informaltable>
          <tgroup cols="2">
            <colspec colname="c1" colwidth="29.7*"/>
            <colspec colname="c2" colwidth="70.3*"/>
            <thead>
              <row>
                <entry>
                  <para>Property name</para>
                </entry>
                <entry>
                  <para>Defines the number of</para>
                </entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <para>gigabytes</para>
                </entry>
                <entry>
                  <para>Volume gigabytes allowed for each project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>snapshots</para>
                </entry>
                <entry>
                  <para>Volume snapshots allowed for each project.</para>
                </entry>
              </row>
              <row>
                <entry>
                  <para>volumes</para>
                </entry>
                <entry>
                  <para>Volumes allowed for each project.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <sect3>
          <title>View Block Storage quotas</title>
          <para>Administrative users can view Block Storage service quotas.</para>
          <procedure>
            <step>
              <para>Obtain the project ID.</para>
              <para>For example:</para>
              <screen language="console">$ project_id=$(openstack project show -f value -c id PROJECT_NAME)</screen>
            </step>
            <step>
              <para>List the default quotas for a project:</para>
              <screen language="console">$ cinder quota-defaults PROJECT_ID</screen>
              <para>For example:</para>
              <screen language="console">$ cinder quota-defaults $project_id
+-----------+-------+
|  Property | Value |
+-----------+-------+
| gigabytes |  1000 |
| snapshots |   10  |
|  volumes  |   10  |
+-----------+-------+</screen>
            </step>
            <step>
              <para>View Block Storage service quotas for a project:</para>
              <screen language="console">$ cinder quota-show PROJECT_ID</screen>
              <para>For example:</para>
              <screen language="console">$ cinder quota-show $project_id
+-----------+-------+
|  Property | Value |
+-----------+-------+
| gigabytes |  1000 |
| snapshots |   10  |
|  volumes  |   10  |
+-----------+-------+</screen>
            </step>
            <step>
              <para>Show the current usage of a per-project quota:</para>
              <screen language="console">$ cinder quota-usage PROJECT_ID</screen>
              <para>For example:</para>
              <screen language="console">$ cinder quota-usage $project_id
+-----------+--------+----------+-------+
|    Type   | In_use | Reserved | Limit |
+-----------+--------+----------+-------+
| gigabytes |   0    |    0     |  1000 |
| snapshots |   0    |    0     |   10  |
|  volumes  |   0    |    0     |   15  |
+-----------+--------+----------+-------+</screen>
            </step>
          </procedure>
        </sect3>
        <sect3>
          <title>Edit and update Block Storage service quotas</title>
          <para>Administrative users can edit and update Block Storage
service quotas.</para>
          <procedure>
            <step>
              <para>To update a default value for a new project,
update the property in the <guimenu>cinder.quota</guimenu>
section of the <literal>/etc/cinder/cinder.conf</literal> file.
For more information, see the <link xlink:href="http://docs.openstack.org/newton/config-reference/block-storage.html">Block Storage service</link>
in OpenStack Configuration Reference.</para>
            </step>
            <step>
              <para>To update Block Storage service quotas for an existing project</para>
              <screen language="console">$ cinder quota-update --QUOTA_NAME QUOTA_VALUE PROJECT_ID</screen>
              <para>Replace <literal>QUOTA_NAME</literal> with the quota that is to be updated,
<literal>QUOTA_VALUE</literal> with the required new value, and <literal>PROJECT_ID</literal>
with the required project ID.</para>
              <para>For example:</para>
              <screen language="console">$ cinder quota-update --volumes 15 $project_id
$ cinder quota-show $project_id
+-----------+-------+
|  Property | Value |
+-----------+-------+
| gigabytes |  1000 |
| snapshots |   10  |
|  volumes  |   15  |
+-----------+-------+</screen>
            </step>
            <step>
              <para>To clear per-project quota limits:</para>
              <screen language="console">$ cinder quota-delete PROJECT_ID</screen>
            </step>
          </procedure>
        </sect3>
      </sect2>
      <sect2>
        <title>Manage Networking service quotas</title>
        <para>A quota limits the number of available resources. A default
quota might be enforced for all projects. When you try to create
more resources than the quota allows, an error occurs:</para>
        <screen language="ini">$ openstack network create test_net
 Quota exceeded for resources: ['network']</screen>
        <para>Per-project quota configuration is also supported by the quota
extension API. See <xref linkend="cfg-quotas-per-tenant"/> for details.</para>
        <sect3>
          <title>Basic quota configuration</title>
          <para>In the Networking default quota mechanism, all projects have
the same quota values, such as the number of resources that a
project can create.</para>
          <para>The quota value is defined in the OpenStack Networking
<literal>/etc/neutron/neutron.conf</literal> configuration file. This example shows the
default quota values:</para>
          <screen language="ini">[quotas]
# number of networks allowed per tenant, and minus means unlimited
quota_network = 10

# number of subnets allowed per tenant, and minus means unlimited
quota_subnet = 10

# number of ports allowed per tenant, and minus means unlimited
quota_port = 50

# default driver to use for quota checks
quota_driver = neutron.quota.ConfDriver</screen>
          <para>OpenStack Networking also supports quotas for L3 resources:
router and floating IP. Add these lines to the
<literal>quotas</literal> section in the <literal>/etc/neutron/neutron.conf</literal> file:</para>
          <screen language="ini">[quotas]
# number of routers allowed per tenant, and minus means unlimited
quota_router = 10

# number of floating IPs allowed per tenant, and minus means unlimited
quota_floatingip = 50</screen>
          <para>OpenStack Networking also supports quotas for security group
resources: number of security groups and the number of rules for
each security group. Add these lines to the
<literal>quotas</literal> section in the <literal>/etc/neutron/neutron.conf</literal> file:</para>
          <screen language="ini">[quotas]
# number of security groups per tenant, and minus means unlimited
quota_security_group = 10

# number of security rules allowed per tenant, and minus means unlimited
quota_security_group_rule = 100</screen>
        </sect3>
        <sect3 xml:id="cfg-quotas-per-tenant">
          <title>Configure per-project quotas</title>
          <para>OpenStack Networking also supports per-project quota limit by
quota extension API.</para>
          <para>Use these commands to manage per-project quotas:</para>
          <variablelist>
            <varlistentry>
              <term>neutron quota-delete</term>
              <listitem>
                <para>Delete defined quotas for a specified project</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>neutron quota-list</term>
              <listitem>
                <para>Lists defined quotas for all projects</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>neutron quota-show</term>
              <listitem>
                <para>Shows quotas for a specified project</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>neutron quota-default-show</term>
              <listitem>
                <para>Show default quotas for a specified tenant</para>
              </listitem>
            </varlistentry>
            <varlistentry>
              <term>neutron quota-update</term>
              <listitem>
                <para>Updates quotas for a specified project</para>
              </listitem>
            </varlistentry>
          </variablelist>
          <para>Only users with the <literal>admin</literal> role can change a quota value. By default,
the default set of quotas are enforced for all projects, so no
<command>quota-create</command> command exists.</para>
          <procedure>
            <step>
              <para>Configure Networking to show per-project quotas</para>
              <para>Set the <literal>quota_driver</literal> option in the <literal>/etc/neutron/neutron.conf</literal> file.</para>
              <screen language="ini">quota_driver = neutron.db.quota_db.DbQuotaDriver</screen>
              <para>When you set this option, the output for Networking commands shows <literal>quotas</literal>.</para>
            </step>
            <step>
              <para>List Networking extensions.</para>
              <para>To list the Networking extensions, run this command:</para>
              <screen language="console">$ openstack extension list --network</screen>
              <para>The command shows the <literal>quotas</literal> extension, which provides
per-project quota management support.</para>
              <note>
                <para>Many of the extensions shown below are supported in the Mitaka release and later.</para>
              </note>
              <screen language="console">+------------------------+------------------------+--------------------------+
| Name                   | Alias                  | Description              |
+------------------------+------------------------+--------------------------+
| ...                    | ...                    | ...                      |
| Quota management       | quotas                 | Expose functions for     |
| support                |                        | quotas management per    |
|                        |                        | tenant                   |
| ...                    | ...                    | ...                      |
+------------------------+------------------------+--------------------------+</screen>
            </step>
            <step>
              <para>Show information for the quotas extension.</para>
              <para>To show information for the <literal>quotas</literal> extension, run this command:</para>
              <screen language="console">$ neutron ext-show quotas
+-------------+------------------------------------------------------------+
| Field       | Value                                                      |
+-------------+------------------------------------------------------------+
| alias       | quotas                                                     |
| description | Expose functions for quotas management per tenant          |
| links       |                                                            |
| name        | Quota management support                                   |
| namespace   | http://docs.openstack.org/network/ext/quotas-sets/api/v2.0 |
| updated     | 2012-07-29T10:00:00-00:00                                  |
+-------------+------------------------------------------------------------+</screen>
              <note>
                <para>Only some plug-ins support per-project quotas.
Specifically, Open vSwitch, Linux Bridge, and VMware NSX
support them, but new versions of other plug-ins might
bring additional functionality. See the documentation for
each plug-in.</para>
              </note>
            </step>
            <step>
              <para>List projects who have per-project quota support.</para>
              <para>The <command>neutron quota-list</command> command lists projects for which the
per-project quota is enabled. The command does not list projects with
default quota support. You must be an administrative user to run this
command:</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ neutron quota-list
+------------+---------+------+--------+--------+----------------------------------+
| floatingip | network | port | router | subnet | tenant_id                        |
+------------+---------+------+--------+--------+----------------------------------+
|         20 |       5 |   20 |     10 |      5 | 6f88036c45344d9999a1f971e4882723 |
|         25 |      10 |   30 |     10 |     10 | bff5c9455ee24231b5bc713c1b96d422 |
+------------+---------+------+--------+--------+----------------------------------+</screen>
            </step>
            <step>
              <para>Show per-project quota values.</para>
              <para>The <command>neutron quota-show</command> command reports the current
set of quota limits for the specified project.
Non-administrative users can run this command without the
<literal>--tenant_id</literal> parameter. If per-project quota limits are
not enabled for the project, the command shows the default
set of quotas.</para>
              <note>
                <para>Additional quotas added in the Mitaka release include <literal>security_group</literal>,
<literal>security_group_rule</literal>, <literal>subnet</literal>, and <literal>subnetpool</literal>.</para>
              </note>
              <screen language="console">$ neutron quota-show --tenant_id 6f88036c45344d9999a1f971e4882723
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 10    |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10    |
| subnetpool          | -1    |
+---------------------+-------+</screen>
              <para>The following command shows the command output for a
non-administrative user.</para>
              <screen language="console">$ neutron quota-show
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 10    |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10    |
| subnetpool          | -1    |
+---------------------+-------+</screen>
            </step>
            <step>
              <para>Update quota values for a specified project.</para>
              <para>Use the <command>neutron quota-update</command> command to
update a quota for a specified project.</para>
              <screen language="console">$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 --network 5
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 5     |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10    |
| subnetpool          | -1    |
+---------------------+-------+</screen>
              <para>You can update quotas for multiple resources through one
command.</para>
              <screen language="console"><?dbsuse-fo font-size="8pt"?>$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 --subnet 5 --port 20
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 5     |
| port                | 20    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 5     |
| subnetpool          | -1    |
+---------------------+-------+</screen>
              <para>To update the limits for an L3 resource such as, router
or floating IP, you must define new values for the quotas
after the <literal>--</literal> directive.</para>
              <para>This example updates the limit of the number of floating
IPs for the specified project.</para>
              <screen language="console">$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 --floatingip 20
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 20    |
| network             | 5     |
| port                | 20    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 5     |
| subnetpool          | -1    |
+---------------------+-------+</screen>
              <para>You can update the limits of multiple resources by
including L2 resources and L3 resource through one
command:</para>
              <screen language="console">$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 \
  --network 3 --subnet 3 --port 3 --floatingip 3 --router 3
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 3     |
| network             | 3     |
| port                | 3     |
| rbac_policy         | 10    |
| router              | 3     |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 3     |
| subnetpool          | -1    |
+---------------------+-------+</screen>
            </step>
            <step>
              <para>Delete per-project quota values.</para>
              <para>To clear per-project quota limits, use the
<command>neutron quota-delete</command> command.</para>
              <screen language="console">$ neutron quota-delete --tenant_id 6f88036c45344d9999a1f971e4882723
 Deleted quota: 6f88036c45344d9999a1f971e4882723</screen>
              <para>After you run this command, you can see that quota
values for the project are reset to the default values.</para>
              <screen language="console">$ neutron quota-show --tenant_id 6f88036c45344d9999a1f971e4882723
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 10    |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10     |
| subnetpool          | -1    |
+---------------------+-------+</screen>
            </step>
          </procedure>
        </sect3>
      </sect2>
    </sect1>
    <sect1>
      <title>Analyze log files</title>
      <para>Use the swift command-line client for Object Storage to analyze log files.</para>
      <para>The swift client is simple to use, scalable, and flexible.</para>
      <para>Use the swift client <literal>-o</literal> or <literal>-output</literal> option to get
short answers to questions about logs.</para>
      <para>You can use the <literal>-o</literal> or <literal>--output</literal> option with a single object
download to redirect the command output to a specific file or to STDOUT
(<literal>-</literal>). The ability to redirect the output to STDOUT enables you to
pipe (<literal>|</literal>) data without saving it to disk first.</para>
      <sect2>
        <title>Upload and analyze log files</title>
        <procedure>
          <step>
            <para>This example assumes that <literal>logtest</literal> directory contains the
following log files.</para>
            <screen language="console">2010-11-16-21_access.log
2010-11-16-22_access.log
2010-11-15-21_access.log
2010-11-15-22_access.log</screen>
            <para>Each file uses the following line format.</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>Nov 15 21:53:52 lucid64 proxy-server - 127.0.0.1 15/Nov/2010/22/53/52 DELETE /v1/AUTH_cd4f57824deb4248a533f2c28bf156d3/2eefc05599d44df38a7f18b0b42ffedd HTTP/1.0 204 - \
 - test%3Atester%2CAUTH_tkcdab3c6296e249d7b7e2454ee57266ff - - - txaba5984c-aac7-460e-b04b-afc43f0c6571 - 0.0432</screen>
          </step>
          <step>
            <para>Change into the <literal>logtest</literal> directory:</para>
            <screen language="console">$ cd logtest</screen>
          </step>
          <step>
            <para>Upload the log files into the <literal>logtest</literal> container:</para>
            <screen language="console"><?dbsuse-fo font-size="8pt"?>$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing upload logtest *.log</screen>
            <screen language="console">2010-11-16-21_access.log
2010-11-16-22_access.log
2010-11-15-21_access.log
2010-11-15-22_access.log</screen>
          </step>
          <step>
            <para>Get statistics for the account:</para>
            <screen language="console">$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing \
-q stat</screen>
            <screen language="console">Account: AUTH_cd4f57824deb4248a533f2c28bf156d3
Containers: 1
Objects: 4
Bytes: 5888268</screen>
          </step>
          <step>
            <para>Get statistics for the <literal>logtest</literal> container:</para>
            <screen language="console">$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing \
stat logtest</screen>
            <screen language="console">Account: AUTH_cd4f57824deb4248a533f2c28bf156d3
Container: logtest
Objects: 4
Bytes: 5864468
Read ACL:
Write ACL:</screen>
          </step>
          <step>
            <para>List all objects in the logtest container:</para>
            <screen language="console">$ swift -A http:///swift-auth.com:11000/v1.0 -U test:tester -K testing \
list logtest</screen>
            <screen language="console">2010-11-15-21_access.log
2010-11-15-22_access.log
2010-11-16-21_access.log
2010-11-16-22_access.log</screen>
          </step>
        </procedure>
      </sect2>
      <sect2>
        <title>Download and analyze an object</title>
        <para>This example uses the <literal>-o</literal> option and a hyphen (<literal>-</literal>) to get
information about an object.</para>
        <para>Use the <command>swift download</command> command to download the object. On this
command, stream the output to <literal>awk</literal> to break down requests by return
code and the date <literal>2200 on November 16th, 2010</literal>.</para>
        <para>Using the log line format, find the request type in column 9 and the
return code in column 12.</para>
        <para>After <literal>awk</literal> processes the output, it pipes it to <literal>sort</literal> and <literal>uniq
-c</literal> to sum up the number of occurrences for each request type and
return code combination.</para>
        <procedure>
          <step>
            <para>Download an object:</para>
            <screen language="console">$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing \
     download -o - logtest 2010-11-16-22_access.log | awk '{ print \
     $9"-"$12}' | sort | uniq -c</screen>
            <screen language="console">805 DELETE-204
12 DELETE-404
2 DELETE-409
723 GET-200
142 GET-204
74 GET-206
80 GET-304
34 GET-401
5 GET-403
18 GET-404
166 GET-412
2 GET-416
50 HEAD-200
17 HEAD-204
20 HEAD-401
8 HEAD-404
30 POST-202
25 POST-204
22 POST-400
6 POST-404
842 PUT-201
2 PUT-202
32 PUT-400
4 PUT-403
4 PUT-404
2 PUT-411
6 PUT-412
6 PUT-413
2 PUT-422
8 PUT-499</screen>
          </step>
          <step>
            <para>Discover how many PUT requests are in each log file.</para>
            <para>Use a bash for loop with awk and swift with the <literal>-o</literal> or
<literal>--output</literal> option and a hyphen (<literal>-</literal>) to discover how many
PUT requests are in each log file.</para>
            <para>Run the <command>swift list</command> command to list objects in the logtest
container. Then, for each item in the list, run the
<command>swift download -o -</command> command. Pipe the output into grep to
filter the PUT requests. Finally, pipe into <literal>wc -l</literal> to count the lines.</para>
            <screen language="console">$ for f in `swift -A http://swift-auth.com:11000/v1.0 -U test:tester \
 -K testing list logtest` ; \
        do  echo -ne "PUTS - " ; swift -A \
        http://swift-auth.com:11000/v1.0 -U test:tester \
        -K testing download -o -  logtest $f | grep PUT | wc -l ; \
    done</screen>
            <screen language="console">2010-11-15-21_access.log - PUTS - 402
2010-11-15-22_access.log - PUTS - 1091
2010-11-16-21_access.log - PUTS - 892
2010-11-16-22_access.log - PUTS - 910</screen>
          </step>
          <step>
            <para>List the object names that begin with a specified string.</para>
          </step>
          <step>
            <para>Run the <command>swift list -p 2010-11-15</command> command to list objects
in the logtest container that begin with the <literal>2010-11-15</literal> string.</para>
          </step>
          <step>
            <para>For each item in the list, run the <command>swift download -o -</command> command.</para>
          </step>
          <step>
            <para>Pipe the output to <command>grep</command> and <command>wc</command>.
Use the <command>echo</command> command to display the object name.</para>
            <screen language="console">$ for f in `swift -A http://swift-auth.com:11000/v1.0 -U test:tester \
 -K testing list -p 2010-11-15 logtest` ; \
        do  echo -ne "$f - PUTS - " ; swift -A \
        http://127.0.0.1:11000/v1.0 -U test:tester \
        -K testing download -o - logtest $f | grep PUT | wc -l ; \
      done</screen>
            <screen language="console">2010-11-15-21_access.log - PUTS - 402
2010-11-15-22_access.log - PUTS - 910</screen>
          </step>
        </procedure>
      </sect2>
    </sect1>
    <sect1>
      <title>Manage Block Storage scheduling</title>
      <para>As an administrative user, you have some control over which volume
back end your volumes reside on. You can specify affinity or
anti-affinity between two volumes. Affinity between volumes means
that they are stored on the same back end, whereas anti-affinity
means that they are stored on different back ends.</para>
      <para>For information on how to set up multiple back ends for Cinder,
refer to <xref linkend="multi-backend"/>.</para>
      <sect2>
        <title>Example Usages</title>
        <procedure>
          <step>
            <para>Create a new volume on the same back end as Volume_A:</para>
            <screen language="console">$ openstack volume create --hint same_host=Volume_A-UUID \
  --size SIZE VOLUME_NAME</screen>
          </step>
          <step>
            <para>Create a new volume on a different back end than Volume_A:</para>
            <screen language="console">$ openstack volume create --hint different_host=Volume_A-UUID \
  --size SIZE VOLUME_NAME</screen>
          </step>
          <step>
            <para>Create a new volume on the same back end as Volume_A and Volume_B:</para>
            <screen language="console">$ openstack volume create --hint same_host=Volume_A-UUID \
  --hint same_host=Volume_B-UUID --size SIZE VOLUME_NAME</screen>
            <para>Or:</para>
            <screen language="console">$ openstack volume create --hint same_host="[Volume_A-UUID, \
  Volume_B-UUID]" --size SIZE VOLUME_NAME</screen>
          </step>
          <step>
            <para>Create a new volume on a different back end than both Volume_A and
Volume_B:</para>
            <screen language="console">$ openstack volume create --hint different_host=Volume_A-UUID \
  --hint different_host=Volume_B-UUID --size SIZE VOLUME_NAME</screen>
            <para>Or:</para>
            <screen language="console">$ openstack volume create --hint different_host="[Volume_A-UUID, \
  Volume_B-UUID]" --size SIZE VOLUME_NAME</screen>
          </step>
        </procedure>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Cross-project features</title>
    <info/>
    <para>Many features are common to all the OpenStack services and are consistent in
their configuration and deployment patterns. Unless explicitly noted, you can
safely assume that the features in this chapter are supported and configured
in a consistent manner.</para>
    <sect1>
      <title>Cross-origin resource sharing</title>
      <note>
        <para>This is a new feature in OpenStack Liberty.</para>
      </note>
      <para>OpenStack supports <xref linkend="term-cross-origin-resource-sharing-cors"/>, a W3C
specification defining a contract by which the single-origin policy of a user
agent (usually a browser) may be relaxed. It permits the javascript engine
to access an API that does not reside on the same domain, protocol, or port.</para>
      <para>This feature is most useful to organizations which maintain one or more
custom user interfaces for OpenStack, as it permits those interfaces to access
the services directly, rather than requiring an intermediate proxy server. It
can, however, also be misused by malicious actors; please review the
security advisory below for more information.</para>
      <sect2>
        <title>Enabling CORS with configuration</title>
        <para>In most cases, CORS support is built directly into the service itself. To
enable it, simply follow the configuration options exposed in the default
configuration file, or add it yourself according to the pattern below.</para>
        <screen language="ini"><?dbsuse-fo font-size="8pt"?>[cors]
allowed_origin = https://first_ui.example.com
max_age = 3600
allow_methods = GET,POST,PUT,DELETE
allow_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header
expose_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header</screen>
        <para>Additional origins can be explicitly added. To express this in
your configuration file, first begin with a <literal>[cors]</literal> group as above,
into which you place your default configuration values. Then, add as many
additional configuration groups as necessary, naming them
<literal>[cors.{something}]</literal> (each name must be unique). The purpose of the
suffix to <literal>cors.</literal> is legibility, we recommend using a reasonable
human-readable string:</para>
        <screen language="ini">[cors.ironic_webclient]
# CORS Configuration for a hypothetical ironic webclient, which overrides
# authentication
allowed_origin = https://ironic.example.com:443
allow_credentials = True

[cors.horizon]
# CORS Configuration for horizon, which uses global options.
allowed_origin = https://horizon.example.com:443

[cors.wildcard]
# CORS Configuration for the CORS specified domain wildcard, which only
# permits HTTP GET requests.
allowed_origin = *
allow_methods = GET</screen>
        <para>For more information about CORS configuration,
see <link xlink:href="http://docs.openstack.org/newton/config-reference/common-configurations/cors.html">cross-origin resource sharing</link>
in OpenStack Configuration Reference.</para>
      </sect2>
      <sect2>
        <title>Enabling CORS with PasteDeploy</title>
        <para>CORS can also be configured using PasteDeploy. First of all, ensure that
OpenStack's <literal>oslo_middleware</literal> package (version 2.4.0 or later) is
available in the Python environment that is running the service. Then,
add the following configuration block to your <literal>paste.ini</literal> file.</para>
        <screen language="ini"><?dbsuse-fo font-size="8pt"?>[filter:cors]
paste.filter_factory = oslo_middleware.cors:filter_factory
allowed_origin = https://website.example.com:443
max_age = 3600
allow_methods = GET,POST,PUT,DELETE
allow_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header
expose_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header</screen>
        <note>
          <para>To add an additional domain in oslo_middleware v2.4.0, add
another filter. In v3.0.0 and after, you may add multiple domains
in the above <literal>allowed_origin</literal> field, separated by commas.</para>
        </note>
      </sect2>
      <sect2>
        <title>Security concerns</title>
        <para>CORS specifies a wildcard character <literal>*</literal>, which permits access to all user
agents, regardless of domain, protocol, or host. While there are valid use
cases for this approach, it also permits a malicious actor to create a
convincing facsimile of a user interface, and trick users into revealing
authentication credentials. Please carefully evaluate your use case and the
relevant documentation for any risk to your organization.</para>
        <note>
          <para>The CORS specification does not support using this wildcard as
a part of a URI. Setting <literal>allowed_origin</literal> to <literal>*</literal> would work, while
<literal>*.openstack.org</literal> would not.</para>
        </note>
      </sect2>
      <sect2>
        <title>Troubleshooting</title>
        <para>CORS is very easy to get wrong, as even one incorrect property will violate
the prescribed contract. Here are some steps you can take to troubleshoot
your configuration.</para>
        <sect3>
          <title>Check the service log</title>
          <para>The CORS middleware used by OpenStack provides verbose debug logging that
should reveal most configuration problems. Here are some example log
messages, and how to resolve them.</para>
        </sect3>
        <sect3>
          <title>Problem</title>
          <para>
            <literal>CORS request from origin 'http://example.com' not permitted.</literal>
          </para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>A request was received from the origin <literal>http://example.com</literal>, however this
origin was not found in the permitted list. The cause may be a superfluous
port notation (ports 80 and 443 do not need to be specified). To correct,
ensure that the configuration property for this host is identical to the
host indicated in the log message.</para>
        </sect3>
        <sect3>
          <title>Problem</title>
          <para>
            <literal>Request method 'DELETE' not in permitted list: GET,PUT,POST</literal>
          </para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>A user agent has requested permission to perform a DELETE request, however
the CORS configuration for the domain does not permit this. To correct, add
this method to the <literal>allow_methods</literal> configuration property.</para>
        </sect3>
        <sect3>
          <title>Problem</title>
          <para>
            <literal>Request header 'X-Custom-Header' not in permitted list: X-Other-Header</literal>
          </para>
        </sect3>
        <sect3>
          <title>Solution</title>
          <para>A request was received with the header <literal>X-Custom-Header</literal>, which is not
permitted. Add this header to the <literal>allow_headers</literal> configuration
property.</para>
        </sect3>
        <sect3>
          <title>Open your browser's console log</title>
          <para>Most browsers provide helpful debug output when a CORS request is rejected.
Usually this happens when a request was successful, but the return headers on
the response do not permit access to a property which the browser is trying
to access.</para>
        </sect3>
        <sect3>
          <title>Manually construct a CORS request</title>
          <para>By using <literal>curl</literal> or a similar tool, you can trigger a CORS response with a
properly constructed HTTP request. An example request and response might look
like this.</para>
          <para>Request example:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>$ curl -I -X OPTIONS https://api.example.com/api -H "Origin: https://ui.example.com"</screen>
          <para>Response example:</para>
          <screen language="console"><?dbsuse-fo font-size="8pt"?>HTTP/1.1 204 No Content
Content-Length: 0
Access-Control-Allow-Origin: https://ui.example.com
Access-Control-Allow-Methods: GET,POST,PUT,DELETE
Access-Control-Expose-Headers: origin,authorization,accept,x-total,x-limit,x-marker,x-client,content-type
Access-Control-Allow-Headers: origin,authorization,accept,x-total,x-limit,x-marker,x-client,content-type
Access-Control-Max-Age: 3600</screen>
          <para>If the service does not return any access control headers, check the service
log, such as <literal>/var/log/upstart/ironic-api.log</literal> for an indication on what
went wrong.</para>
        </sect3>
      </sect2>
    </sect1>
  </chapter>
  <chapter>
    <title>Appendix</title>
    <info/>
    <sect1>
      <title>Community support</title>
      <para>The following resources are available to help you run and use OpenStack.
The OpenStack community constantly improves and adds to the main
features of OpenStack, but if you have any questions, do not hesitate to
ask. Use the following resources to get OpenStack support and
troubleshoot your installations.</para>
      <sect2>
        <title>Documentation</title>
        <para>For the available OpenStack documentation, see
<link xlink:href="http://docs.openstack.org">docs.openstack.org</link>.</para>
        <para>To provide feedback on documentation, join and use the
<link xlink:href="mailto:openstack-docs@lists.openstack.org">openstack-docs@lists.openstack.org</link> mailing list at <link xlink:href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs">OpenStack
Documentation Mailing
List</link>,
join our IRC channel <literal>#openstack-doc</literal> on the freenode IRC network,
or <link xlink:href="https://bugs.launchpad.net/openstack-manuals/+filebug">report a
bug</link>.</para>
        <para>The following books explain how to install an OpenStack cloud and its
associated components:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/newton/install-guide-obs/">Installation Tutorial for openSUSE Leap 42.2 and SUSE Linux Enterprise
Server 12 SP2</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/newton/install-guide-rdo/">Installation Tutorial for Red Hat Enterprise Linux 7 and CentOS 7</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/newton/install-guide-ubuntu/">Installation Tutorial for Ubuntu 16.04 (LTS)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/newton/install-guide-debconf/">Installation Tutorial for Debian with Debconf</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/newton/install-guide-debian/">Installation Tutorial for Debian</link>
            </para>
          </listitem>
        </itemizedlist>
        <para>The following books explain how to configure and run an OpenStack cloud:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/arch-design/">Architecture Design Guide</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/admin-guide/">Administrator Guide</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/newton/config-reference/">Configuration Reference</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/ops/">Operations Guide</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/newton/networking-guide">Networking Guide</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/ha-guide/">High Availability Guide</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/sec/">Security Guide</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/image-guide/">Virtual Machine Image Guide</link>
            </para>
          </listitem>
        </itemizedlist>
        <para>The following books explain how to use the OpenStack Dashboard and
command-line clients:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/user-guide/">End User Guide</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/cli-reference/">Command-Line Interface Reference</link>
            </para>
          </listitem>
        </itemizedlist>
        <para>The following documentation provides reference and guidance information
for the OpenStack APIs:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="http://developer.openstack.org/api-guide/quick-start/">API Guide</link>
            </para>
          </listitem>
        </itemizedlist>
        <para>The following guide provides how to contribute to OpenStack documentation:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="http://docs.openstack.org/contributor-guide/">Documentation Contributor Guide</link>
            </para>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>ask.openstack.org</title>
        <para>During the set up or testing of OpenStack, you might have questions
about how a specific task is completed or be in a situation where a
feature does not work correctly. Use the
<link xlink:href="https://ask.openstack.org">ask.openstack.org</link> site to ask questions
and get answers. When you visit the <link xlink:href="https://ask.openstack.org">https://ask.openstack.org</link> site, scan
the recently asked questions to see whether your question has already
been answered. If not, ask a new question. Be sure to give a clear,
concise summary in the title and provide as much detail as possible in
the description. Paste in your command output or stack traces, links to
screen shots, and any other information which might be useful.</para>
      </sect2>
      <sect2>
        <title>OpenStack mailing lists</title>
        <para>A great way to get answers and insights is to post your question or
problematic scenario to the OpenStack mailing list. You can learn from
and help others who might have similar issues. To subscribe or view the
archives, go to
<link xlink:href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack">http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack</link>. If you are
interested in the other mailing lists for specific projects or development,
refer to <link xlink:href="https://wiki.openstack.org/wiki/Mailing_Lists">Mailing Lists</link>.</para>
      </sect2>
      <sect2>
        <title>The OpenStack wiki</title>
        <para>The <link xlink:href="https://wiki.openstack.org/">OpenStack wiki</link> contains a broad
range of topics but some of the information can be difficult to find or
is a few pages deep. Fortunately, the wiki search feature enables you to
search by title or content. If you search for specific information, such
as about networking or OpenStack Compute, you can find a large amount
of relevant material. More is being added all the time, so be sure to
check back often. You can find the search box in the upper-right corner
of any OpenStack wiki page.</para>
      </sect2>
      <sect2>
        <title>The Launchpad Bugs area</title>
        <para>The OpenStack community values your set up and testing efforts and wants
your feedback. To log a bug, you must sign up for a Launchpad account at
<link xlink:href="https://launchpad.net/+login">https://launchpad.net/+login</link>. You can view existing bugs and report bugs
in the Launchpad Bugs area. Use the search feature to determine whether
the bug has already been reported or already been fixed. If it still
seems like your bug is unreported, fill out a bug report.</para>
        <para>Some tips:</para>
        <itemizedlist>
          <listitem>
            <para>Give a clear, concise summary.</para>
          </listitem>
          <listitem>
            <para>Provide as much detail as possible in the description. Paste in your
command output or stack traces, links to screen shots, and any other
information which might be useful.</para>
          </listitem>
          <listitem>
            <para>Be sure to include the software and package versions that you are
using, especially if you are using a development branch, such as,
<literal>"Kilo release" vs git commit bc79c3ecc55929bac585d04a03475b72e06a3208</literal>.</para>
          </listitem>
          <listitem>
            <para>Any deployment-specific information is helpful, such as whether you
are using Ubuntu 14.04 or are performing a multi-node installation.</para>
          </listitem>
        </itemizedlist>
        <para>The following Launchpad Bugs areas are available:</para>
        <itemizedlist>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/cinder">Bugs: OpenStack Block Storage
(cinder)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/nova">Bugs: OpenStack Compute (nova)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/horizon">Bugs: OpenStack Dashboard
(horizon)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/keystone">Bugs: OpenStack Identity
(keystone)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/glance">Bugs: OpenStack Image service
(glance)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/neutron">Bugs: OpenStack Networking
(neutron)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/swift">Bugs: OpenStack Object Storage
(swift)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/murano">Bugs: Application catalog (murano)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/ironic">Bugs: Bare metal service (ironic)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/senlin">Bugs: Clustering service (senlin)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/magnum">Bugs: Container Infrastructure Management service (magnum)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/sahara">Bugs: Data processing service
(sahara)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/trove">Bugs: Database service (trove)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/fuel">Bugs: Deployment service (fuel)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/designate">Bugs: DNS service (designate)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/barbican">Bugs: Key Manager Service (barbican)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/monasca">Bugs: Monitoring (monasca)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/heat">Bugs: Orchestration (heat)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/cloudkitty">Bugs: Rating (cloudkitty)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/manila">Bugs: Shared file systems (manila)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/ceilometer">Bugs: Telemetry
(ceilometer)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/gnocchi">Bugs: Telemetry v3
(gnocchi)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/mistral">Bugs: Workflow service
(mistral)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/zaqar">Bugs: Messaging service
(zaqar)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/openstack-api-site">Bugs: OpenStack API Documentation
(developer.openstack.org)</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <link xlink:href="https://bugs.launchpad.net/openstack-manuals">Bugs: OpenStack Documentation
(docs.openstack.org)</link>
            </para>
          </listitem>
        </itemizedlist>
      </sect2>
      <sect2>
        <title>The OpenStack IRC channel</title>
        <para>The OpenStack community lives in the #openstack IRC channel on the
Freenode network. You can hang out, ask questions, or get immediate
feedback for urgent and pressing issues. To install an IRC client or use
a browser-based client, go to
<link xlink:href="https://webchat.freenode.net">https://webchat.freenode.net/</link>. You can
also use Colloquy (Mac OS X, <link xlink:href="http://colloquy.info/">http://colloquy.info/</link>), mIRC (Windows,
<link xlink:href="http://www.mirc.com/">http://www.mirc.com/</link>), or XChat (Linux). When you are in the IRC channel
and want to share code or command output, the generally accepted method
is to use a Paste Bin. The OpenStack project has one at
<link xlink:href="http://paste.openstack.org">http://paste.openstack.org</link>. Just paste your longer amounts of text or
logs in the web form and you get a URL that you can paste into the
channel. The OpenStack IRC channel is <literal>#openstack</literal> on
<literal>irc.freenode.net</literal>. You can find a list of all OpenStack IRC channels
at <link xlink:href="https://wiki.openstack.org/wiki/IRC">https://wiki.openstack.org/wiki/IRC</link>.</para>
      </sect2>
      <sect2>
        <title>Documentation feedback</title>
        <para>To provide feedback on documentation, join and use the
<link xlink:href="mailto:openstack-docs@lists.openstack.org">openstack-docs@lists.openstack.org</link> mailing list at <link xlink:href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs">OpenStack
Documentation Mailing
List</link>,
or <link xlink:href="https://bugs.launchpad.net/openstack-manuals/+filebug">report a
bug</link>.</para>
      </sect2>
      <sect2>
        <title>OpenStack distribution packages</title>
        <para>The following Linux distributions provide community-supported packages
for OpenStack:</para>
        <itemizedlist>
          <listitem>
            <para>
              <emphasis role="bold">Debian:</emphasis>
              <link xlink:href="https://wiki.debian.org/OpenStack">https://wiki.debian.org/OpenStack</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <emphasis role="bold">CentOS, Fedora, and Red Hat Enterprise Linux:</emphasis>
              <link xlink:href="https://www.rdoproject.org/">https://www.rdoproject.org/</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <emphasis role="bold">openSUSE and SUSE Linux Enterprise Server:</emphasis>
              <link xlink:href="https://en.opensuse.org/Portal:OpenStack">https://en.opensuse.org/Portal:OpenStack</link>
            </para>
          </listitem>
          <listitem>
            <para>
              <emphasis role="bold">Ubuntu:</emphasis>
              <link xlink:href="https://wiki.ubuntu.com/ServerTeam/CloudArchive">https://wiki.ubuntu.com/ServerTeam/CloudArchive</link>
            </para>
          </listitem>
        </itemizedlist>
      </sect2>
    </sect1>
  </chapter>
  <glossary>
    <title>Glossary</title>
    <info/>
    <para>This glossary offers a list of terms and definitions to define a
vocabulary for OpenStack-related concepts.</para>
    <para>To add to OpenStack glossary, clone the <link xlink:href="https://git.openstack.org/cgit/openstack/openstack-manuals">openstack/openstack-manuals
repository</link> and
update the source file <literal>doc/common/glossary.rst</literal> through the
OpenStack contribution process.</para>
    <glossdiv>
      <title>0-9</title>
      <info/>
      <glossentry>
        <glossterm>6to4</glossterm>
        <glossdef>
          <para>A mechanism that allows IPv6 packets to be transmitted
over an IPv4 network, providing a strategy for migrating to
IPv6.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>A</title>
      <info/>
      <glossentry>
        <glossterm>absolute limit</glossterm>
        <glossdef>
          <para>Impassable limits for guest VMs. Settings include total RAM
size, maximum number of vCPUs, and maximum disk size.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>access control list (ACL)</glossterm>
        <glossdef>
          <para>A list of permissions attached to an object. An ACL specifies
which users or system processes have access to objects. It also
defines which operations can be performed on specified objects. Each
entry in a typical ACL specifies a subject and an operation. For
instance, the ACL entry <literal>(Alice, delete)</literal> for a file gives
Alice permission to delete the file.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>access key</glossterm>
        <glossdef>
          <para>Alternative term for an Amazon EC2 access key. See EC2 access
key.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>account</glossterm>
        <glossdef>
          <para>The Object Storage context of an account. Do not confuse with a
user account from an authentication service, such as Active Directory,
/etc/passwd, OpenLDAP, OpenStack Identity, and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>account auditor</glossterm>
        <glossdef>
          <para>Checks for missing replicas and incorrect or corrupted objects
in a specified Object Storage account by running queries against the
back-end SQLite database.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>account database</glossterm>
        <glossdef>
          <para>A SQLite database that contains Object Storage accounts and
related metadata and that the accounts server accesses.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>account reaper</glossterm>
        <glossdef>
          <para>An Object Storage worker that scans for and deletes account
databases and that the account server has marked for deletion.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>account server</glossterm>
        <glossdef>
          <para>Lists containers in Object Storage and stores container
information in the account database.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>account service</glossterm>
        <glossdef>
          <para>An Object Storage component that provides account services such
as list, create, modify, and audit. Do not confuse with OpenStack
Identity service, OpenLDAP, or similar user-account services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>accounting</glossterm>
        <glossdef>
          <para>The Compute service provides accounting information through the
event notification and system usage data facilities.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Active Directory</glossterm>
        <glossdef>
          <para>Authentication and identity service by Microsoft, based on LDAP.
Supported in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>active/active configuration</glossterm>
        <glossdef>
          <para>In a high-availability setup with an active/active
configuration, several systems share the load together and if one
fails, the load is distributed to the remaining systems.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>active/passive configuration</glossterm>
        <glossdef>
          <para>In a high-availability setup with an active/passive
configuration, systems are set up to bring additional resources online
to replace those that have failed.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>address pool</glossterm>
        <glossdef>
          <para>A group of fixed and/or floating IP addresses that are assigned
to a project and can be used by or assigned to the VM instances in a
project.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Address Resolution Protocol (ARP)</glossterm>
        <glossdef>
          <para>The protocol by which layer-3 IP addresses are resolved into
layer-2 link local addresses.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>admin API</glossterm>
        <glossdef>
          <para>A subset of API calls that are accessible to authorized
administrators and are generally not accessible to end users or the
public Internet. They can exist as a separate service (keystone) or
can be a subset of another API (nova).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>admin server</glossterm>
        <glossdef>
          <para>In the context of the Identity service, the worker process that
provides access to the admin API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>administrator</glossterm>
        <glossdef>
          <para>The person responsible for installing, configuring,
and managing an OpenStack cloud.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Advanced Message Queuing Protocol (AMQP)</glossterm>
        <glossdef>
          <para>The open standard messaging protocol used by OpenStack
components for intra-service communications, provided by RabbitMQ,
Qpid, or ZeroMQ.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Advanced RISC Machine (ARM)</glossterm>
        <glossdef>
          <para>Lower power consumption CPU often found in mobile and embedded
devices. Supported by OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>alert</glossterm>
        <glossdef>
          <para>The Compute service can send alerts through its notification
system, which includes a facility to create custom notification
drivers. Alerts can be sent to and displayed on the dashboard.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>allocate</glossterm>
        <glossdef>
          <para>The process of taking a floating IP address from the address
pool so it can be associated with a fixed IP on a guest VM
instance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Amazon Kernel Image (AKI)</glossterm>
        <glossdef>
          <para>Both a VM container format and disk format. Supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Amazon Machine Image (AMI)</glossterm>
        <glossdef>
          <para>Both a VM container format and disk format. Supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Amazon Ramdisk Image (ARI)</glossterm>
        <glossdef>
          <para>Both a VM container format and disk format. Supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Anvil</glossterm>
        <glossdef>
          <para>A project that ports the shell script-based project named
DevStack to Python.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>aodh</glossterm>
        <glossdef>
          <para>Part of the OpenStack <xref linkend="term-telemetry-service-telemetry"/>; provides alarming functionality.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Apache</glossterm>
        <glossdef>
          <para>The Apache Software Foundation supports the Apache community of
open-source software projects. These projects provide software
products for the public good.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Apache License 2.0</glossterm>
        <glossdef>
          <para>All OpenStack core projects are provided under the terms of the
Apache License 2.0 license.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Apache Web Server</glossterm>
        <glossdef>
          <para>The most common web server software currently used on the
Internet.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>API endpoint</glossterm>
        <glossdef>
          <para>The daemon, worker, or service that a client communicates with
to access an API. API endpoints can provide any number of services,
such as authentication, sales data, performance meters, Compute VM
commands, census data, and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>API extension</glossterm>
        <glossdef>
          <para>Custom modules that extend some OpenStack core APIs.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>API extension plug-in</glossterm>
        <glossdef>
          <para>Alternative term for a Networking plug-in or Networking API
extension.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>API key</glossterm>
        <glossdef>
          <para>Alternative term for an API token.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>API server</glossterm>
        <glossdef>
          <para>Any node running a daemon or worker that provides an API
endpoint.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>API token</glossterm>
        <glossdef>
          <para>Passed to API requests and used by OpenStack to verify that the
client is authorized to run the requested operation.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>API version</glossterm>
        <glossdef>
          <para>In OpenStack, the API version for a project is part of the URL.
For example, <literal>example.com/nova/v1/foobar</literal>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>applet</glossterm>
        <glossdef>
          <para>A Java program that can be embedded into a web page.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-application-catalog-service-murano">
        <glossterm>Application Catalog service (murano)</glossterm>
        <glossdef>
          <para>The project that provides an application catalog service so that users
can compose and deploy composite environments on an application
abstraction level while managing the application lifecycle.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-application-programming-interface-api">
        <glossterm>Application Programming Interface (API)</glossterm>
        <glossdef>
          <para>A collection of specifications used to access a service,
application, or program. Includes service calls, required parameters
for each call, and the expected return values.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>application server</glossterm>
        <glossdef>
          <para>A piece of software that makes available another piece of
software over a network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Application Service Provider (ASP)</glossterm>
        <glossdef>
          <para>Companies that rent specialized applications that help
businesses and organizations provide additional services
with lower cost.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>arptables</glossterm>
        <glossdef>
          <para>Tool used for maintaining Address Resolution Protocol packet
filter rules in the Linux kernel firewall modules. Used along with
iptables, ebtables, and ip6tables in Compute to provide firewall
services for VMs.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>associate</glossterm>
        <glossdef>
          <para>The process associating a Compute floating IP address with a
fixed IP address.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Asynchronous JavaScript and XML (AJAX)</glossterm>
        <glossdef>
          <para>A group of interrelated web development techniques used on the
client-side to create asynchronous web applications. Used extensively
in horizon.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ATA over Ethernet (AoE)</glossterm>
        <glossdef>
          <para>A disk storage protocol tunneled within Ethernet.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>attach</glossterm>
        <glossdef>
          <para>The process of connecting a VIF or vNIC to a L2 network in
Networking. In the context of Compute, this process connects a storage
volume to an instance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>attachment (network)</glossterm>
        <glossdef>
          <para>Association of an interface ID to a logical port. Plugs an
interface into a port.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>auditing</glossterm>
        <glossdef>
          <para>Provided in Compute through the system usage data
facility.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>auditor</glossterm>
        <glossdef>
          <para>A worker process that verifies the integrity of Object Storage
objects, containers, and accounts. Auditors is the collective term for
the Object Storage account auditor, container auditor, and object
auditor.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Austin</glossterm>
        <glossdef>
          <para>The code name for the initial release of
OpenStack. The first design summit took place in
Austin, Texas, US.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>auth node</glossterm>
        <glossdef>
          <para>Alternative term for an Object Storage authorization
node.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>authentication</glossterm>
        <glossdef>
          <para>The process that confirms that the user, process, or client is
really who they say they are through private key, secret token,
password, fingerprint, or similar method.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>authentication token</glossterm>
        <glossdef>
          <para>A string of text provided to the client after authentication.
Must be provided by the user or process in subsequent requests to the
API endpoint.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>AuthN</glossterm>
        <glossdef>
          <para>The Identity service component that provides authentication
services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>authorization</glossterm>
        <glossdef>
          <para>The act of verifying that a user, process, or client is
authorized to perform an action.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>authorization node</glossterm>
        <glossdef>
          <para>An Object Storage node that provides authorization
services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>AuthZ</glossterm>
        <glossdef>
          <para>The Identity component that provides high-level
authorization services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Auto ACK</glossterm>
        <glossdef>
          <para>Configuration setting within RabbitMQ that enables or disables
message acknowledgment. Enabled by default.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>auto declare</glossterm>
        <glossdef>
          <para>A Compute RabbitMQ setting that determines whether a message
exchange is automatically created when the program starts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>availability zone</glossterm>
        <glossdef>
          <para>An Amazon EC2 concept of an isolated area that is used for fault
tolerance. Do not confuse with an OpenStack Compute zone or
cell.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>AWS CloudFormation template</glossterm>
        <glossdef>
          <para>AWS CloudFormation allows Amazon Web Services (AWS) users to create and manage a
collection of related resources. The Orchestration service
supports a CloudFormation-compatible format (CFN).</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>B</title>
      <info/>
      <glossentry>
        <glossterm>back end</glossterm>
        <glossdef>
          <para>Interactions and processes that are obfuscated from the user,
such as Compute volume mount, data transmission to an iSCSI target by
a daemon, or Object Storage object integrity checks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>back-end catalog</glossterm>
        <glossdef>
          <para>The storage method used by the Identity service catalog service
to store and retrieve information about API endpoints that are
available to the client. Examples include an SQL database, LDAP
database, or KVS back end.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>back-end store</glossterm>
        <glossdef>
          <para>The persistent data store used to save and retrieve information
for a service, such as lists of Object Storage objects, current state
of guest VMs, lists of user names, and so on. Also, the method that the
Image service uses to get and store VM images. Options include Object
Storage, locally mounted file system, RADOS block devices, VMware
datastore, and HTTP.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-backup-restore-and-disaster-recovery-service-freezer">
        <glossterm>Backup, Restore, and Disaster Recovery service (freezer)</glossterm>
        <glossdef>
          <para>The project that provides integrated tooling for backing up, restoring,
and recovering file systems, instances, or database backups.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>bandwidth</glossterm>
        <glossdef>
          <para>The amount of available data used by communication resources,
such as the Internet. Represents the amount of data that is used to
download things or the amount of data available to download.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>barbican</glossterm>
        <glossdef>
          <para>Code name of the <xref linkend="term-key-manager-service-barbican"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>bare</glossterm>
        <glossdef>
          <para>An Image service container format that indicates that no
container exists for the VM image.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-bare-metal-service-ironic">
        <glossterm>Bare Metal service (ironic)</glossterm>
        <glossdef>
          <para>The OpenStack service that provides a service and associated libraries
capable of managing and provisioning physical machines in a
security-aware and fault-tolerant manner.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>base image</glossterm>
        <glossdef>
          <para>An OpenStack-provided image.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Bell-LaPadula model</glossterm>
        <glossdef>
          <para>A security model that focuses on data confidentiality
and controlled access to classified information.
This model divides the entities into subjects and objects.
The clearance of a subject is compared to the classification of the
object to determine if the subject is authorized for the specific access mode.
The clearance or classification scheme is expressed in terms of a lattice.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-benchmark-service-rally">
        <glossterm>Benchmark service (rally)</glossterm>
        <glossdef>
          <para>OpenStack project that provides a framework for
performance analysis and benchmarking of individual
OpenStack components as well as full production OpenStack
cloud deployments.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Bexar</glossterm>
        <glossdef>
          <para>A grouped release of projects related to
OpenStack that came out in February of 2011. It
included only Compute (nova) and Object Storage (swift).
Bexar is the code name for the second release of
OpenStack. The design summit took place in
San Antonio, Texas, US, which is the county seat for Bexar county.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>binary</glossterm>
        <glossdef>
          <para>Information that consists solely of ones and zeroes, which is
the language of computers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>bit</glossterm>
        <glossdef>
          <para>A bit is a single digit number that is in base of 2 (either a
zero or one). Bandwidth usage is measured in bits per second.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>bits per second (BPS)</glossterm>
        <glossdef>
          <para>The universal measurement of how quickly data is transferred
from place to place.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>block device</glossterm>
        <glossdef>
          <para>A device that moves data in the form of blocks. These device
nodes interface the devices, such as hard disks, CD-ROM drives, flash
drives, and other addressable regions of memory.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>block migration</glossterm>
        <glossdef>
          <para>A method of VM live migration used by KVM to evacuate instances
from one host to another with very little downtime during a
user-initiated switchover. Does not require shared storage. Supported
by Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Block Storage API</glossterm>
        <glossdef>
          <para>An API on a separate endpoint for attaching,
detaching, and creating block storage for compute
VMs.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-block-storage-service-cinder">
        <glossterm>Block Storage service (cinder)</glossterm>
        <glossdef>
          <para>The OpenStack service that implement services and libraries to provide
on-demand, self-service access to Block Storage resources via abstraction
and automation on top of other block storage devices.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>BMC (Baseboard Management Controller)</glossterm>
        <glossdef>
          <para>The intelligence in the IPMI architecture, which is a specialized
micro-controller that is embedded on the motherboard of a computer
and acts as a server. Manages the interface between system management
software and platform hardware.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>bootable disk image</glossterm>
        <glossdef>
          <para>A type of VM image that exists as a single, bootable
file.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Bootstrap Protocol (BOOTP)</glossterm>
        <glossdef>
          <para>A network protocol used by a network client to obtain an IP
address from a configuration server. Provided in Compute through the
dnsmasq daemon when using either the FlatDHCP manager or VLAN manager
network manager.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Border Gateway Protocol (BGP)</glossterm>
        <glossdef>
          <para>The Border Gateway Protocol is a dynamic routing protocol
that connects autonomous systems.  Considered the
backbone of the Internet, this protocol connects disparate
networks to form a larger network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>browser</glossterm>
        <glossdef>
          <para>Any client software that enables a computer or device to access
the Internet.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>builder file</glossterm>
        <glossdef>
          <para>Contains configuration information that Object Storage uses to
reconfigure a ring or to re-create it from scratch after a serious
failure.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>bursting</glossterm>
        <glossdef>
          <para>The practice of utilizing a secondary environment to
elastically build instances on-demand when the primary
environment is resource constrained.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>button class</glossterm>
        <glossdef>
          <para>A group of related button types within horizon. Buttons to
start, stop, and suspend VMs are in one class. Buttons to associate
and disassociate floating IP addresses are in another class, and so
on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>byte</glossterm>
        <glossdef>
          <para>Set of bits that make up a single character; there are usually 8
bits to a byte.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>C</title>
      <info/>
      <glossentry>
        <glossterm>cache pruner</glossterm>
        <glossdef>
          <para>A program that keeps the Image service VM image cache at or
below its configured maximum size.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Cactus</glossterm>
        <glossdef>
          <para>An OpenStack grouped release of projects that came out in the
spring of 2011. It included Compute (nova), Object Storage (swift),
and the Image service (glance).
Cactus is a city in Texas, US and is the code name for
the third release of OpenStack. When OpenStack releases went
from three to six months long, the code name of the release
changed to match a geography nearest the previous
summit.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>CALL</glossterm>
        <glossdef>
          <para>One of the RPC primitives used by the OpenStack message queue
software. Sends a message and waits for a response.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>capability</glossterm>
        <glossdef>
          <para>Defines resources for a cell, including CPU, storage, and
networking. Can apply to the specific services within a cell or a
whole cell.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>capacity cache</glossterm>
        <glossdef>
          <para>A Compute back-end database table that contains the current
workload, amount of free RAM, and number of VMs running on each host.
Used to determine on which host a VM starts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>capacity updater</glossterm>
        <glossdef>
          <para>A notification driver that monitors VM instances and updates the
capacity cache as needed.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>CAST</glossterm>
        <glossdef>
          <para>One of the RPC primitives used by the OpenStack message queue
software. Sends a message and does not wait for a response.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>catalog</glossterm>
        <glossdef>
          <para>A list of API endpoints that are available to a user after
authentication with the Identity service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>catalog service</glossterm>
        <glossdef>
          <para>An Identity service that lists API endpoints that are available
to a user after authentication with the Identity service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ceilometer</glossterm>
        <glossdef>
          <para>Part of the OpenStack <xref linkend="term-telemetry-service-telemetry"/>; gathers and stores metrics from other
OpenStack services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cell</glossterm>
        <glossdef>
          <para>Provides logical partitioning of Compute resources in a child
and parent relationship. Requests are passed from parent cells to
child cells if the parent cannot provide the requested
resource.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cell forwarding</glossterm>
        <glossdef>
          <para>A Compute option that enables parent cells to pass resource
requests to child cells if the parent cannot provide the requested
resource.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cell manager</glossterm>
        <glossdef>
          <para>The Compute component that contains a list of the current
capabilities of each host within the cell and routes requests as
appropriate.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>CentOS</glossterm>
        <glossdef>
          <para>A Linux distribution that is compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Ceph</glossterm>
        <glossdef>
          <para>Massively scalable distributed storage system that consists of
an object store, block store, and POSIX-compatible distributed file
system. Compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>CephFS</glossterm>
        <glossdef>
          <para>The POSIX-compliant file system provided by Ceph.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-certificate-authority-ca">
        <glossterm>certificate authority (CA)</glossterm>
        <glossdef>
          <para>In cryptography, an entity that issues digital certificates. The digital
certificate certifies the ownership of a public key by the named
subject of the certificate. This enables others (relying parties) to
rely upon signatures or assertions made by the private key that
corresponds to the certified public key. In this model of trust
relationships, a CA is a trusted third party for both the subject
(owner) of the certificate and the party relying upon the certificate.
CAs are characteristic of many public key infrastructure (PKI)
schemes.
In OpenStack, a simple certificate authority is provided by Compute for
cloudpipe VPNs and VM image decryption.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Challenge-Handshake Authentication Protocol (CHAP)</glossterm>
        <glossdef>
          <para>An iSCSI authentication method supported by Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>chance scheduler</glossterm>
        <glossdef>
          <para>A scheduling method used by Compute that randomly chooses an
available host from the pool.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>changes since</glossterm>
        <glossdef>
          <para>A Compute API parameter that downloads changes to the requested
item since your last request, instead of downloading a new, fresh set
of data and comparing it against the old data.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Chef</glossterm>
        <glossdef>
          <para>An operating system configuration management tool supporting
OpenStack deployments.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>child cell</glossterm>
        <glossdef>
          <para>If a requested resource such as CPU time, disk storage, or
memory is not available in the parent cell, the request is forwarded
to its associated child cells. If the child cell can fulfill the
request, it does. Otherwise, it attempts to pass the request to any of
its children.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cinder</glossterm>
        <glossdef>
          <para>Codename for <xref linkend="term-block-storage-service-cinder"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>CirrOS</glossterm>
        <glossdef>
          <para>A minimal Linux distribution designed for use as a test
image on clouds such as OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Cisco neutron plug-in</glossterm>
        <glossdef>
          <para>A Networking plug-in for Cisco devices and technologies,
including UCS and Nexus.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cloud architect</glossterm>
        <glossdef>
          <para>A person who plans, designs, and oversees the creation of
clouds.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Cloud Auditing Data Federation (CADF)</glossterm>
        <glossdef>
          <para>Cloud Auditing Data Federation (CADF) is a
specification for audit event data. CADF is
supported by OpenStack Identity.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cloud computing</glossterm>
        <glossdef>
          <para>A model that enables access to a shared pool of configurable
computing resources, such as networks, servers, storage, applications,
and services, that can be rapidly provisioned and released with
minimal management effort or service provider interaction.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-cloud-controller">
        <glossterm>cloud controller</glossterm>
        <glossdef>
          <para>Collection of Compute components that represent the global state
of the cloud; talks to services, such as Identity authentication,
Object Storage, and node/storage workers through a
queue.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cloud controller node</glossterm>
        <glossdef>
          <para>A node that runs network, volume, API, scheduler, and image
services. Each service may be broken out into separate nodes for
scalability or availability.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Cloud Data Management Interface (CDMI)</glossterm>
        <glossdef>
          <para>SINA standard that defines a RESTful API for managing objects in
the cloud, currently unsupported in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Cloud Infrastructure Management Interface (CIMI)</glossterm>
        <glossdef>
          <para>An in-progress specification for cloud management. Currently
unsupported in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cloud-init</glossterm>
        <glossdef>
          <para>A package commonly installed in VM images that performs
initialization of an instance after boot using information that it
retrieves from the metadata service, such as the SSH public key and
user data.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cloudadmin</glossterm>
        <glossdef>
          <para>One of the default roles in the Compute RBAC system. Grants
complete system access.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Cloudbase-Init</glossterm>
        <glossdef>
          <para>A Windows project providing guest initialization features,
similar to cloud-init.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cloudpipe</glossterm>
        <glossdef>
          <para>A compute service that creates VPNs on a per-project
basis.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cloudpipe image</glossterm>
        <glossdef>
          <para>A pre-made VM image that serves as a cloudpipe server.
Essentially, OpenVPN running on Linux.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-clustering-service-senlin">
        <glossterm>Clustering service (senlin)</glossterm>
        <glossdef>
          <para>The project that implements clustering services and libraries
for the management of groups of homogeneous objects exposed
by other OpenStack services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>command filter</glossterm>
        <glossdef>
          <para>Lists allowed commands within the Compute rootwrap
facility.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Common Internet File System (CIFS)</glossterm>
        <glossdef>
          <para>A file sharing protocol. It is a public or open variation of the
original Server Message Block (SMB) protocol developed and used by
Microsoft. Like the SMB protocol, CIFS runs at a higher level and uses
the TCP/IP protocol.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-common-libraries-oslo">
        <glossterm>Common Libraries (oslo)</glossterm>
        <glossdef>
          <para>The project that produces a set of python libraries containing code
shared by OpenStack projects. The APIs provided by these libraries
should be high quality, stable, consistent, documented and generally
applicable.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>community project</glossterm>
        <glossdef>
          <para>A project that is not officially endorsed by the OpenStack
Foundation. If the project is successful enough, it might be elevated
to an incubated project and then to a core project, or it might be
merged with the main code trunk.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>compression</glossterm>
        <glossdef>
          <para>Reducing the size of files by special encoding, the file can be
decompressed again to its original content. OpenStack supports
compression at the Linux file system level but does not support
compression for things such as Object Storage objects or Image service
VM images.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-compute-api-nova-api">
        <glossterm>Compute API (Nova API)</glossterm>
        <glossdef>
          <para>The nova-api daemon provides access to nova services. Can communicate with
other APIs, such as the Amazon EC2 API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>compute controller</glossterm>
        <glossdef>
          <para>The Compute component that chooses suitable hosts on which to
start VM instances.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>compute host</glossterm>
        <glossdef>
          <para>Physical host dedicated to running compute nodes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>compute node</glossterm>
        <glossdef>
          <para>A node that runs the nova-compute daemon that manages VM
instances that provide a wide
range of services, such as web applications and analytics.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-compute-service-nova">
        <glossterm>Compute service (nova)</glossterm>
        <glossdef>
          <para>The OpenStack core project that implements services and associated
libraries to provide massively-scalable, on-demand, self-service
access to compute resources, including bare metal, virtual machines,
and containers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>compute worker</glossterm>
        <glossdef>
          <para>The Compute component that runs on each compute node and manages
the VM instance lifecycle, including run, reboot, terminate,
attach/detach volumes, and so on. Provided by the nova-compute daemon.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>concatenated object</glossterm>
        <glossdef>
          <para>A set of segment objects that Object Storage combines and sends
to the client.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>conductor</glossterm>
        <glossdef>
          <para>In Compute, conductor is the process that proxies database
requests from the compute process. Using conductor improves security
because compute nodes do not need direct access to the
database.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>congress</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-governance-service-congress"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>consistency window</glossterm>
        <glossdef>
          <para>The amount of time it takes for a new Object Storage object to
become accessible to all clients.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>console log</glossterm>
        <glossdef>
          <para>Contains the output from a Linux VM console in Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>container</glossterm>
        <glossdef>
          <para>Organizes and stores objects in Object Storage. Similar to the
concept of a Linux directory but cannot be nested. Alternative term
for an Image service container format.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>container auditor</glossterm>
        <glossdef>
          <para>Checks for missing replicas or incorrect objects in specified
Object Storage containers through queries to the SQLite back-end
database.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>container database</glossterm>
        <glossdef>
          <para>A SQLite database that stores Object Storage containers and
container metadata. The container server accesses this
database.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>container format</glossterm>
        <glossdef>
          <para>A wrapper used by the Image service that contains a VM image and
its associated metadata, such as machine state, OS disk size, and so
on.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-container-infrastructure-management-service-magnum">
        <glossterm>Container Infrastructure Management service (magnum)</glossterm>
        <glossdef>
          <para>The project which provides a set of services for provisioning, scaling,
and managing container orchestration engines.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>container server</glossterm>
        <glossdef>
          <para>An Object Storage server that manages containers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>container service</glossterm>
        <glossdef>
          <para>The Object Storage component that provides container services,
such as create, delete, list, and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>content delivery network (CDN)</glossterm>
        <glossdef>
          <para>A content delivery network is a specialized network that is
used to distribute content to clients, typically located
close to the client for increased performance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>controller node</glossterm>
        <glossdef>
          <para>Alternative term for a cloud controller node.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>core API</glossterm>
        <glossdef>
          <para>Depending on context, the core API is either the OpenStack API
or the main API of a specific core project, such as Compute,
Networking, Image service, and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>core service</glossterm>
        <glossdef>
          <para>An official OpenStack service defined as core by
DefCore Committee. Currently, consists of
Block Storage service (cinder), Compute service (nova),
Identity service (keystone), Image service (glance),
Networking service (neutron), and Object Storage service (swift).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>cost</glossterm>
        <glossdef>
          <para>Under the Compute distributed scheduler, this is calculated by
looking at the capabilities of each host relative to the flavor of the
VM instance being requested.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>credentials</glossterm>
        <glossdef>
          <para>Data that is only known to or accessible by a user and
used to verify that the user is who he says he is.
Credentials are presented to the server during
authentication. Examples include a password, secret key,
digital certificate, and fingerprint.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-cross-origin-resource-sharing-cors">
        <glossterm>Cross-Origin Resource Sharing (CORS)</glossterm>
        <glossdef>
          <para>A mechanism that allows many resources (for example,
fonts, JavaScript) on a web page to be requested from
another domain outside the domain from which the resource
originated. In particular, JavaScript's AJAX calls can use
the XMLHttpRequest mechanism.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Crowbar</glossterm>
        <glossdef>
          <para>An open source community project by Dell that aims to provide
all necessary services to quickly deploy clouds.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>current workload</glossterm>
        <glossdef>
          <para>An element of the Compute capacity cache that is calculated
based on the number of build, snapshot, migrate, and resize operations
currently in progress on a given host.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>customer</glossterm>
        <glossdef>
          <para>Alternative term for project.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>customization module</glossterm>
        <glossdef>
          <para>A user-created Python module that is loaded by horizon to change
the look and feel of the dashboard.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>D</title>
      <info/>
      <glossentry>
        <glossterm>daemon</glossterm>
        <glossdef>
          <para>A process that runs in the background and waits for requests.
May or may not listen on a TCP or UDP port. Do not confuse with a
worker.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-dashboard-horizon">
        <glossterm>Dashboard (horizon)</glossterm>
        <glossdef>
          <para>OpenStack project which provides an extensible, unified, web-based
user interface for all OpenStack services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>data encryption</glossterm>
        <glossdef>
          <para>Both Image service and Compute support encrypted virtual machine
(VM) images (but not instances). In-transit data encryption is
supported in OpenStack using technologies such as HTTPS, SSL, TLS, and
SSH. Object Storage does not support object encryption at the
application level but may support storage that uses disk encryption.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Data loss prevention (DLP) software</glossterm>
        <glossdef>
          <para>Software programs used to protect sensitive information
and prevent it from leaking outside a network boundary
through the detection and denying of the data transportation.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-data-processing-service-sahara">
        <glossterm>Data Processing service (sahara)</glossterm>
        <glossdef>
          <para>OpenStack project that provides a scalable
data-processing stack and associated management
interfaces.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-data-store">
        <glossterm>data store</glossterm>
        <glossdef>
          <para>A database engine supported by the Database service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>database ID</glossterm>
        <glossdef>
          <para>A unique ID given to each replica of an Object Storage
database.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>database replicator</glossterm>
        <glossdef>
          <para>An Object Storage component that copies changes in the account,
container, and object databases to other nodes.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-database-service-trove">
        <glossterm>Database service (trove)</glossterm>
        <glossdef>
          <para>An integrated project that provides scalable and reliable
Cloud Database-as-a-Service functionality for both
relational and non-relational database engines.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>deallocate</glossterm>
        <glossdef>
          <para>The process of removing the association between a floating IP
address and a fixed IP address. Once this association is removed, the
floating IP returns to the address pool.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Debian</glossterm>
        <glossdef>
          <para>A Linux distribution that is compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>deduplication</glossterm>
        <glossdef>
          <para>The process of finding duplicate data at the disk block, file,
and/or object level to minimize storage use—currently unsupported
within OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>default panel</glossterm>
        <glossdef>
          <para>The default panel that is displayed when a user accesses the
dashboard.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>default project</glossterm>
        <glossdef>
          <para>New users are assigned to this project if no project is specified
when a user is created.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>default token</glossterm>
        <glossdef>
          <para>An Identity service token that is not associated with a specific
project and is exchanged for a scoped token.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>delayed delete</glossterm>
        <glossdef>
          <para>An option within Image service so that an image is deleted after
a predefined number of seconds instead of immediately.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>delivery mode</glossterm>
        <glossdef>
          <para>Setting for the Compute RabbitMQ message delivery mode; can be
set to either transient or persistent.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>denial of service (DoS)</glossterm>
        <glossdef>
          <para>Denial of service (DoS) is a short form for
denial-of-service attack. This is a malicious attempt to
prevent legitimate users from using a service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>deprecated auth</glossterm>
        <glossdef>
          <para>An option within Compute that enables administrators to create
and manage users through the <literal>nova-manage</literal> command as
opposed to using the Identity service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>designate</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-dns-service-designate"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Desktop-as-a-Service</glossterm>
        <glossdef>
          <para>A platform that provides a suite of desktop environments
that users access to receive a desktop experience from
any location. This may provide general use, development, or
even homogeneous testing environments.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>developer</glossterm>
        <glossdef>
          <para>One of the default roles in the Compute RBAC system and the
default role assigned to a new user.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>device ID</glossterm>
        <glossdef>
          <para>Maps Object Storage partitions to physical storage
devices.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>device weight</glossterm>
        <glossdef>
          <para>Distributes partitions proportionately across Object Storage
devices based on the storage capacity of each device.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>DevStack</glossterm>
        <glossdef>
          <para>Community project that uses shell scripts to quickly build
complete OpenStack development environments.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>DHCP agent</glossterm>
        <glossdef>
          <para>OpenStack Networking agent that provides DHCP services
for virtual networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Diablo</glossterm>
        <glossdef>
          <para>A grouped release of projects related to OpenStack that came out
in the fall of 2011, the fourth release of OpenStack. It included
Compute (nova 2011.3), Object Storage (swift 1.4.3), and the Image
service (glance).
Diablo is the code name for the fourth release of
OpenStack. The design summit took place in
the Bay Area near Santa Clara,
California, US and Diablo is a nearby city.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>direct consumer</glossterm>
        <glossdef>
          <para>An element of the Compute RabbitMQ that comes to life when a RPC
call is executed. It connects to a direct exchange through a unique
exclusive queue, sends the message, and terminates.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>direct exchange</glossterm>
        <glossdef>
          <para>A routing table that is created within the Compute RabbitMQ
during RPC calls; one is created for each RPC call that is
invoked.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>direct publisher</glossterm>
        <glossdef>
          <para>Element of RabbitMQ that provides a response to an incoming MQ
message.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>disassociate</glossterm>
        <glossdef>
          <para>The process of removing the association between a floating IP
address and fixed IP and thus returning the floating IP address to the
address pool.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Discretionary Access Control (DAC)</glossterm>
        <glossdef>
          <para>Governs the ability of subjects to access objects, while enabling
users to make policy decisions and assign security attributes.
The traditional UNIX system of users, groups, and read-write-execute
permissions is an example of DAC.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>disk encryption</glossterm>
        <glossdef>
          <para>The ability to encrypt data at the file system, disk partition,
or whole-disk level. Supported within Compute VMs.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>disk format</glossterm>
        <glossdef>
          <para>The underlying format that a disk image for a VM is stored as
within the Image service back-end store. For example, AMI, ISO, QCOW2,
VMDK, and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>dispersion</glossterm>
        <glossdef>
          <para>In Object Storage, tools to test and ensure dispersion of
objects and containers to ensure fault tolerance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>distributed virtual router (DVR)</glossterm>
        <glossdef>
          <para>Mechanism for highly available multi-host routing when using
OpenStack Networking (neutron).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Django</glossterm>
        <glossdef>
          <para>A web framework used extensively in horizon.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>DNS record</glossterm>
        <glossdef>
          <para>A record that specifies information about a particular domain
and belongs to the domain.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-dns-service-designate">
        <glossterm>DNS service (designate)</glossterm>
        <glossdef>
          <para>OpenStack project that provides scalable, on demand, self
service access to authoritative DNS services, in a
technology-agnostic manner.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>dnsmasq</glossterm>
        <glossdef>
          <para>Daemon that provides DNS, DHCP, BOOTP, and TFTP services for
virtual networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>domain</glossterm>
        <glossdef>
          <para>An Identity API v3 entity. Represents a collection of
projects, groups and users that defines administrative boundaries for
managing OpenStack Identity entities.
On the Internet, separates a website from other sites. Often,
the domain name has two or more parts that are separated by dots.
For example, yahoo.com, usa.gov, harvard.edu, or
mail.yahoo.com.
Also, a domain is an entity or container of all DNS-related
information containing one or more records.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Domain Name System (DNS)</glossterm>
        <glossdef>
          <para>A system by which Internet domain name-to-address and
address-to-name resolutions are determined.
DNS helps navigate the Internet by translating the IP address
into an address that is easier to remember. For example, translating
111.111.111.1 into www.yahoo.com.
All domains and their components, such as mail servers, utilize
DNS to resolve to the appropriate locations. DNS servers are usually
set up in a master-slave relationship such that failure of the master
invokes the slave. DNS servers might also be clustered or replicated
such that changes made to one DNS server are automatically propagated
to other active servers.
In Compute, the support that enables associating DNS entries
with floating IP addresses, nodes, or cells so that hostnames are
consistent across reboots.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>download</glossterm>
        <glossdef>
          <para>The transfer of data, usually in the form of files, from one
computer to another.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>durable exchange</glossterm>
        <glossdef>
          <para>The Compute RabbitMQ message exchange that remains active when
the server restarts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>durable queue</glossterm>
        <glossdef>
          <para>A Compute RabbitMQ message queue that remains active when the
server restarts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Dynamic Host Configuration Protocol (DHCP)</glossterm>
        <glossdef>
          <para>A network protocol that configures devices that are connected to a
network so that they can communicate on that network by using the
Internet Protocol (IP). The protocol is implemented in a client-server
model where DHCP clients request configuration data, such as an IP
address, a default route, and one or more DNS server addresses from a
DHCP server.
A method to automatically configure networking for a host at
boot time. Provided by both Networking and Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Dynamic HyperText Markup Language (DHTML)</glossterm>
        <glossdef>
          <para>Pages that use HTML, JavaScript, and Cascading Style Sheets to
enable users to interact with a web page or show simple
animation.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>E</title>
      <info/>
      <glossentry>
        <glossterm>east-west traffic</glossterm>
        <glossdef>
          <para>Network traffic between servers in the same cloud or data center.
See also north-south traffic.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>EBS boot volume</glossterm>
        <glossdef>
          <para>An Amazon EBS storage volume that contains a bootable VM image,
currently unsupported in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ebtables</glossterm>
        <glossdef>
          <para>Filtering tool for a Linux bridging firewall, enabling
filtering of network traffic passing through a Linux bridge.
Used in Compute along with arptables, iptables, and ip6tables
to ensure isolation of network communications.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>EC2</glossterm>
        <glossdef>
          <para>The Amazon commercial compute product, similar to
Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>EC2 access key</glossterm>
        <glossdef>
          <para>Used along with an EC2 secret key to access the Compute EC2
API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>EC2 API</glossterm>
        <glossdef>
          <para>OpenStack supports accessing the Amazon EC2 API through
Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>EC2 Compatibility API</glossterm>
        <glossdef>
          <para>A Compute component that enables OpenStack to communicate with
Amazon EC2.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>EC2 secret key</glossterm>
        <glossdef>
          <para>Used along with an EC2 access key when communicating with the
Compute EC2 API; used to digitally sign each request.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Elastic Block Storage (EBS)</glossterm>
        <glossdef>
          <para>The Amazon commercial block storage product.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>encapsulation</glossterm>
        <glossdef>
          <para>The practice of placing one packet type within another for
the purposes of abstracting or securing data. Examples
include GRE, MPLS, or IPsec.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>encryption</glossterm>
        <glossdef>
          <para>OpenStack supports encryption technologies such as HTTPS, SSH,
SSL, TLS, digital certificates, and data encryption.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>endpoint</glossterm>
        <glossdef>
          <para>See API endpoint.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>endpoint registry</glossterm>
        <glossdef>
          <para>Alternative term for an Identity service catalog.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>endpoint template</glossterm>
        <glossdef>
          <para>A list of URL and port number endpoints that indicate where a
service, such as Object Storage, Compute, Identity, and so on, can be
accessed.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>entity</glossterm>
        <glossdef>
          <para>Any piece of hardware or software that wants to connect to the
network services provided by Networking, the network connectivity
service. An entity can make use of Networking by implementing a
VIF.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ephemeral image</glossterm>
        <glossdef>
          <para>A VM image that does not save changes made to its volumes and
reverts them to their original state after the instance is
terminated.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ephemeral volume</glossterm>
        <glossdef>
          <para>Volume that does not save the changes made to it and reverts to
its original state when the current user relinquishes control.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Essex</glossterm>
        <glossdef>
          <para>A grouped release of projects related to OpenStack that came out
in April 2012, the fifth release of OpenStack. It included Compute
(nova 2012.1), Object Storage (swift 1.4.8), Image (glance), Identity
(keystone), and Dashboard (horizon).
Essex is the code name for the fifth release of
OpenStack. The design summit took place in
Boston, Massachusetts, US and Essex is a nearby city.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ESXi</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ETag</glossterm>
        <glossdef>
          <para>MD5 hash of an object within Object Storage, used to ensure data
integrity.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>euca2ools</glossterm>
        <glossdef>
          <para>A collection of command-line tools for administering VMs; most
are compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Eucalyptus Kernel Image (EKI)</glossterm>
        <glossdef>
          <para>Used along with an ERI to create an EMI.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Eucalyptus Machine Image (EMI)</glossterm>
        <glossdef>
          <para>VM image container format supported by Image service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Eucalyptus Ramdisk Image (ERI)</glossterm>
        <glossdef>
          <para>Used along with an EKI to create an EMI.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>evacuate</glossterm>
        <glossdef>
          <para>The process of migrating one or all virtual machine (VM)
instances from one host to another, compatible with both shared
storage live migration and block migration.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>exchange</glossterm>
        <glossdef>
          <para>Alternative term for a RabbitMQ message exchange.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>exchange type</glossterm>
        <glossdef>
          <para>A routing algorithm in the Compute RabbitMQ.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>exclusive queue</glossterm>
        <glossdef>
          <para>Connected to by a direct consumer in RabbitMQ—Compute, the
message can be consumed only by the current connection.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>extended attributes (xattr)</glossterm>
        <glossdef>
          <para>File system option that enables storage of additional
information beyond owner, group, permissions, modification time, and
so on. The underlying Object Storage file system must support extended
attributes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>extension</glossterm>
        <glossdef>
          <para>Alternative term for an API extension or plug-in. In the context
of Identity service, this is a call that is specific to the
implementation, such as adding support for OpenID.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>external network</glossterm>
        <glossdef>
          <para>A network segment typically used for instance Internet
access.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>extra specs</glossterm>
        <glossdef>
          <para>Specifies additional requirements when Compute determines where
to start a new instance. Examples include a minimum amount of network
bandwidth or a GPU.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>F</title>
      <info/>
      <glossentry>
        <glossterm>FakeLDAP</glossterm>
        <glossdef>
          <para>An easy method to create a local LDAP directory for testing
Identity and Compute. Requires Redis.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>fan-out exchange</glossterm>
        <glossdef>
          <para>Within RabbitMQ and Compute, it is the messaging interface that
is used by the scheduler service to receive capability messages from
the compute, volume, and network nodes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>federated identity</glossterm>
        <glossdef>
          <para>A method to establish trusts between identity providers and the
OpenStack cloud.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Fedora</glossterm>
        <glossdef>
          <para>A Linux distribution compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Fibre Channel</glossterm>
        <glossdef>
          <para>Storage protocol similar in concept to TCP/IP; encapsulates SCSI
commands and data.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Fibre Channel over Ethernet (FCoE)</glossterm>
        <glossdef>
          <para>The fibre channel protocol tunneled within Ethernet.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>fill-first scheduler</glossterm>
        <glossdef>
          <para>The Compute scheduling method that attempts to fill a host with
VMs rather than starting new VMs on a variety of hosts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>filter</glossterm>
        <glossdef>
          <para>The step in the Compute scheduling process when hosts that
cannot run VMs are eliminated and not chosen.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>firewall</glossterm>
        <glossdef>
          <para>Used to restrict communications between hosts and/or nodes,
implemented in Compute using iptables, arptables, ip6tables, and
ebtables.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>FireWall-as-a-Service (FWaaS)</glossterm>
        <glossdef>
          <para>A Networking extension that provides perimeter firewall
functionality.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>fixed IP address</glossterm>
        <glossdef>
          <para>An IP address that is associated with the same instance each
time that instance boots, is generally not accessible to end users or
the public Internet, and is used for management of the
instance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Flat Manager</glossterm>
        <glossdef>
          <para>The Compute component that gives IP addresses to authorized
nodes and assumes DHCP, DNS, and routing configuration and services
are provided by something else.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>flat mode injection</glossterm>
        <glossdef>
          <para>A Compute networking method where the OS network configuration
information is injected into the VM image before the instance
starts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>flat network</glossterm>
        <glossdef>
          <para>Virtual network type that uses neither VLANs nor tunnels to
segregate project traffic. Each flat network typically requires
a separate underlying physical interface defined by bridge
mappings. However, a flat network can contain multiple
subnets.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>FlatDHCP Manager</glossterm>
        <glossdef>
          <para>The Compute component that provides dnsmasq (DHCP, DNS, BOOTP,
TFTP) and radvd (routing) services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>flavor</glossterm>
        <glossdef>
          <para>Alternative term for a VM instance type.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>flavor ID</glossterm>
        <glossdef>
          <para>UUID for each Compute or Image service VM flavor or instance
type.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>floating IP address</glossterm>
        <glossdef>
          <para>An IP address that a project can associate with a VM so that the
instance has the same public IP address each time that it boots. You
create a pool of floating IP addresses and assign them to instances as
they are launched to maintain a consistent IP address for maintaining
DNS assignment.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Folsom</glossterm>
        <glossdef>
          <para>A grouped release of projects related to OpenStack that came out
in the fall of 2012, the sixth release of OpenStack. It includes
Compute (nova), Object Storage (swift), Identity (keystone),
Networking (neutron), Image service (glance), and Volumes or Block
Storage (cinder).
Folsom is the code name for the sixth release of
OpenStack. The design summit took place in
San Francisco, California, US and Folsom is a nearby city.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>FormPost</glossterm>
        <glossdef>
          <para>Object Storage middleware that uploads (posts) an image through
a form on a web page.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>freezer</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-backup-restore-and-disaster-recovery-service-freezer"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>front end</glossterm>
        <glossdef>
          <para>The point where a user interacts with a service; can be an API
endpoint, the dashboard, or a command-line tool.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>G</title>
      <info/>
      <glossentry>
        <glossterm>gateway</glossterm>
        <glossdef>
          <para>An IP address, typically assigned to a router, that
passes network traffic between different networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>generic receive offload (GRO)</glossterm>
        <glossdef>
          <para>Feature of certain network interface drivers that
combines many smaller received packets into a large packet
before delivery to the kernel IP stack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>generic routing encapsulation (GRE)</glossterm>
        <glossdef>
          <para>Protocol that encapsulates a wide variety of network
layer protocols inside virtual point-to-point links.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>glance</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-image-service-glance"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>glance API server</glossterm>
        <glossdef>
          <para>Alternative name for the <xref linkend="term-image-api"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>glance registry</glossterm>
        <glossdef>
          <para>Alternative term for the Image service <xref linkend="term-image-registry"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>global endpoint template</glossterm>
        <glossdef>
          <para>The Identity service endpoint template that contains services
available to all projects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>GlusterFS</glossterm>
        <glossdef>
          <para>A file system designed to aggregate NAS hosts, compatible with
OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>gnocchi</glossterm>
        <glossdef>
          <para>Part of the OpenStack <xref linkend="term-telemetry-service-telemetry"/>; provides an indexer and time-series
database.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>golden image</glossterm>
        <glossdef>
          <para>A method of operating system installation where a finalized disk
image is created and then used by all nodes without
modification.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-governance-service-congress">
        <glossterm>Governance service (congress)</glossterm>
        <glossdef>
          <para>The project that provides Governance-as-a-Service across
any collection of cloud services in order to monitor,
enforce, and audit policy over dynamic infrastructure.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Graphic Interchange Format (GIF)</glossterm>
        <glossdef>
          <para>A type of image file that is commonly used for animated images
on web pages.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Graphics Processing Unit (GPU)</glossterm>
        <glossdef>
          <para>Choosing a host based on the existence of a GPU is currently
unsupported in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Green Threads</glossterm>
        <glossdef>
          <para>The cooperative threading model used by Python; reduces race
conditions and only context switches when specific library calls are
made. Each OpenStack service is its own thread.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Grizzly</glossterm>
        <glossdef>
          <para>The code name for the seventh release of
OpenStack. The design summit took place in
San Diego, California, US and Grizzly is an element of the state flag of
California.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Group</glossterm>
        <glossdef>
          <para>An Identity v3 API entity. Represents a collection of users that is
owned by a specific domain.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>guest OS</glossterm>
        <glossdef>
          <para>An operating system instance running under the control of a
hypervisor.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>H</title>
      <info/>
      <glossentry>
        <glossterm>Hadoop</glossterm>
        <glossdef>
          <para>Apache Hadoop is an open source software framework that supports
data-intensive distributed applications.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Hadoop Distributed File System (HDFS)</glossterm>
        <glossdef>
          <para>A distributed, highly fault-tolerant file system designed to run
on low-cost commodity hardware.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>handover</glossterm>
        <glossdef>
          <para>An object state in Object Storage where a new replica of the
object is automatically created due to a drive failure.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-haproxy">
        <glossterm>HAProxy</glossterm>
        <glossdef>
          <para>Provides a high availability load balancer and proxy server for
TCP and HTTP-based applications that spreads requests across
multiple servers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>hard reboot</glossterm>
        <glossdef>
          <para>A type of reboot where a physical or virtual power button is
pressed as opposed to a graceful, proper shutdown of the operating
system.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Havana</glossterm>
        <glossdef>
          <para>The code name for the eighth release of OpenStack. The
design summit took place in Portland, Oregon, US and Havana is
an unincorporated community in Oregon.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>health monitor</glossterm>
        <glossdef>
          <para>Determines whether back-end members of a VIP pool can
process a request. A pool can have several health monitors
associated with it. When a pool has several monitors
associated with it, all monitors check each member of the
pool. All monitors must declare a member to be healthy for
it to stay active.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>heat</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-orchestration-service-heat"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Heat Orchestration Template (HOT)</glossterm>
        <glossdef>
          <para>Heat input in the format native to OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>high availability (HA)</glossterm>
        <glossdef>
          <para>A high availability system design approach and associated
service implementation ensures that a prearranged level of
operational performance will be met during a contractual
measurement period. High availability systems seek to
minimize system downtime and data loss.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>horizon</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-dashboard-horizon"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>horizon plug-in</glossterm>
        <glossdef>
          <para>A plug-in for the OpenStack Dashboard (horizon).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>host</glossterm>
        <glossdef>
          <para>A physical computer, not a VM instance (node).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>host aggregate</glossterm>
        <glossdef>
          <para>A method to further subdivide availability zones into hypervisor
pools, a collection of common hosts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Host Bus Adapter (HBA)</glossterm>
        <glossdef>
          <para>Device plugged into a PCI slot, such as a fibre channel or
network card.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>hybrid cloud</glossterm>
        <glossdef>
          <para>A hybrid cloud is a composition of two or more clouds
(private, community or public) that remain distinct entities
but are bound together, offering the benefits of multiple
deployment models.  Hybrid cloud can also mean the ability
to connect colocation, managed and/or dedicated services
with cloud resources.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Hyper-V</glossterm>
        <glossdef>
          <para>One of the hypervisors supported by OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>hyperlink</glossterm>
        <glossdef>
          <para>Any kind of text that contains a link to some other site,
commonly found in documents where clicking on a word or words opens up
a different website.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Hypertext Transfer Protocol (HTTP)</glossterm>
        <glossdef>
          <para>An application protocol for distributed, collaborative,
hypermedia information systems. It is the foundation of data
communication for the World Wide Web. Hypertext is structured
text that uses logical links (hyperlinks) between nodes containing
text. HTTP is the protocol to exchange or transfer hypertext.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Hypertext Transfer Protocol Secure (HTTPS)</glossterm>
        <glossdef>
          <para>An encrypted communications protocol for secure communication
over a computer network, with especially wide deployment on the
Internet. Technically, it is not a protocol in and of itself;
rather, it is the result of simply layering the Hypertext Transfer
Protocol (HTTP) on top of the TLS or SSL protocol, thus adding the
security capabilities of TLS or SSL to standard HTTP communications.
Most OpenStack API endpoints and many inter-component communications
support HTTPS communication.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>hypervisor</glossterm>
        <glossdef>
          <para>Software that arbitrates and controls VM access to the actual
underlying hardware.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>hypervisor pool</glossterm>
        <glossdef>
          <para>A collection of hypervisors grouped together through host
aggregates.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>I</title>
      <info/>
      <glossentry>
        <glossterm>Icehouse</glossterm>
        <glossdef>
          <para>The code name for the ninth release of OpenStack. The
design summit took place in Hong Kong and Ice House is a
street in that city.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ID number</glossterm>
        <glossdef>
          <para>Unique numeric ID associated with each user in Identity,
conceptually similar to a Linux or LDAP UID.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Identity API</glossterm>
        <glossdef>
          <para>Alternative term for the Identity service API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Identity back end</glossterm>
        <glossdef>
          <para>The source used by Identity service to retrieve user
information; an OpenLDAP server, for example.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>identity provider</glossterm>
        <glossdef>
          <para>A directory service, which allows users to login with a user
name and password. It is a typical source of authentication
tokens.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-identity-service-keystone">
        <glossterm>Identity service (keystone)</glossterm>
        <glossdef>
          <para>The project that facilitates API client authentication, service
discovery, distributed multi-tenant authorization, and auditing.
It provides a central directory of users mapped to the OpenStack
services they can access. It also registers endpoints for OpenStack
services and acts as a common authentication system.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Identity service API</glossterm>
        <glossdef>
          <para>The API used to access the OpenStack Identity service provided
through keystone.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image</glossterm>
        <glossdef>
          <para>A collection of files for a specific operating system (OS) that
you use to create or rebuild a server. OpenStack provides pre-built
images. You can also create custom images, or snapshots, from servers
that you have launched. Custom images can be used for data backups or
as "gold" images for additional servers.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-image-api">
        <glossterm>Image API</glossterm>
        <glossdef>
          <para>The Image service API endpoint for management of VM
images.
Processes client requests for VMs, updates Image service
metadata on the registry server, and communicates with the store
adapter to upload VM images from the back-end store.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image cache</glossterm>
        <glossdef>
          <para>Used by Image service to obtain images on the local host rather
than re-downloading them from the image server each time one is
requested.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image ID</glossterm>
        <glossdef>
          <para>Combination of a URI and UUID used to access Image service VM
images through the image API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image membership</glossterm>
        <glossdef>
          <para>A list of projects that can access a given VM image within Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image owner</glossterm>
        <glossdef>
          <para>The project who owns an Image service virtual machine
image.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-image-registry">
        <glossterm>image registry</glossterm>
        <glossdef>
          <para>A list of VM images that are available through Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-image-service-glance">
        <glossterm>Image service (glance)</glossterm>
        <glossdef>
          <para>The OpenStack service that provide services and associated libraries
to store, browse, share, distribute and manage bootable disk images,
other data closely associated with initializing compute resources,
and metadata definitions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image status</glossterm>
        <glossdef>
          <para>The current status of a VM image in Image service, not to be
confused with the status of a running instance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image store</glossterm>
        <glossdef>
          <para>The back-end store used by Image service to store VM images,
options include Object Storage, locally mounted file system,
RADOS block devices, VMware datastore, or HTTP.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>image UUID</glossterm>
        <glossdef>
          <para>UUID used by Image service to uniquely identify each VM
image.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>incubated project</glossterm>
        <glossdef>
          <para>A community project may be elevated to this status and is then
promoted to a core project.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-infrastructure-optimization-service-watcher">
        <glossterm>Infrastructure Optimization service (watcher)</glossterm>
        <glossdef>
          <para>OpenStack project that aims to provide a flexible and scalable resource
optimization service for multi-tenant OpenStack-based clouds.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-infrastructure-as-a-service-iaas">
        <glossterm>Infrastructure-as-a-Service (IaaS)</glossterm>
        <glossdef>
          <para>IaaS is a provisioning model in which an organization outsources
physical components of a data center, such as storage, hardware,
servers, and networking components. A service provider owns the
equipment and is responsible for housing, operating and maintaining
it. The client typically pays on a per-use basis.
IaaS is a model for providing cloud services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ingress filtering</glossterm>
        <glossdef>
          <para>The process of filtering incoming network traffic. Supported by
Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>INI format</glossterm>
        <glossdef>
          <para>The OpenStack configuration files use an INI format to
describe options and their values. It consists of sections
and key value pairs.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>injection</glossterm>
        <glossdef>
          <para>The process of putting a file into a virtual machine image
before the instance is started.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-input-output-operations-per-second-iops">
        <glossterm>Input/Output Operations Per Second (IOPS)</glossterm>
        <glossdef>
          <para>IOPS are a common performance measurement used to benchmark computer
storage devices like hard disk drives, solid state drives, and
storage area networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>instance</glossterm>
        <glossdef>
          <para>A running VM, or a VM in a known state such as suspended, that
can be used like a hardware server.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>instance ID</glossterm>
        <glossdef>
          <para>Alternative term for instance UUID.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>instance state</glossterm>
        <glossdef>
          <para>The current state of a guest VM image.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>instance tunnels network</glossterm>
        <glossdef>
          <para>A network segment used for instance traffic tunnels
between compute nodes and the network node.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>instance type</glossterm>
        <glossdef>
          <para>Describes the parameters of the various virtual machine images
that are available to users; includes parameters such as CPU, storage,
and memory. Alternative term for flavor.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>instance type ID</glossterm>
        <glossdef>
          <para>Alternative term for a flavor ID.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>instance UUID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each guest VM instance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Intelligent Platform Management Interface (IPMI)</glossterm>
        <glossdef>
          <para>IPMI is a standardized computer system interface used by system
administrators for out-of-band management of computer systems and
monitoring of their operation. In layman's terms, it is a way to
manage a computer using a direct network connection, whether it is
turned on or not; connecting to the hardware rather than an operating
system or login shell.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>interface</glossterm>
        <glossdef>
          <para>A physical or virtual device that provides connectivity
to another device or medium.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>interface ID</glossterm>
        <glossdef>
          <para>Unique ID for a Networking VIF or vNIC in the form of a
UUID.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Internet Control Message Protocol (ICMP)</glossterm>
        <glossdef>
          <para>A network protocol used by network devices for control messages.
For example, <command>ping</command> uses ICMP to test
connectivity.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Internet protocol (IP)</glossterm>
        <glossdef>
          <para>Principal communications protocol in the internet protocol
suite for relaying datagrams across network boundaries.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Internet Service Provider (ISP)</glossterm>
        <glossdef>
          <para>Any business that provides Internet access to individuals or
businesses.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Internet Small Computer System Interface (iSCSI)</glossterm>
        <glossdef>
          <para>Storage protocol that encapsulates SCSI frames for transport
over IP networks.
Supported by Compute, Object Storage, and Image service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>IP address</glossterm>
        <glossdef>
          <para>Number that is unique to every computer system on the Internet.
Two versions of the Internet Protocol (IP) are in use for addresses:
IPv4 and IPv6.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>IP Address Management (IPAM)</glossterm>
        <glossdef>
          <para>The process of automating IP address allocation, deallocation,
and management. Currently provided by Compute, melange, and
Networking.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ip6tables</glossterm>
        <glossdef>
          <para>Tool used to set up, maintain, and inspect the tables of IPv6
packet filter rules in the Linux kernel. In OpenStack Compute,
ip6tables is used along with arptables, ebtables, and iptables to
create firewalls for both nodes and VMs.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ipset</glossterm>
        <glossdef>
          <para>Extension to iptables that allows creation of firewall rules
that match entire "sets" of IP addresses simultaneously. These
sets reside in indexed data structures to increase efficiency,
particularly on systems with a large quantity of rules.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>iptables</glossterm>
        <glossdef>
          <para>Used along with arptables and ebtables, iptables create
firewalls in Compute. iptables are the tables provided by the Linux
kernel firewall (implemented as different Netfilter modules) and the
chains and rules it stores. Different kernel modules and programs are
currently used for different protocols: iptables applies to IPv4,
ip6tables to IPv6, arptables to ARP, and ebtables to Ethernet frames.
Requires root privilege to manipulate.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ironic</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-bare-metal-service-ironic"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-iscsi-qualified-name-iqn">
        <glossterm>iSCSI Qualified Name (IQN)</glossterm>
        <glossdef>
          <para>IQN is the format most commonly used for iSCSI names, which uniquely
identify nodes in an iSCSI network.
All IQNs follow the pattern iqn.yyyy-mm.domain:identifier, where
'yyyy-mm' is the year and month in which the domain was registered,
'domain' is the reversed domain name of the issuing organization, and
'identifier' is an optional string which makes each IQN under the same
domain unique. For example, 'iqn.2015-10.org.openstack.408ae959bce1'.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ISO9660</glossterm>
        <glossdef>
          <para>One of the VM image disk formats supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>itsec</glossterm>
        <glossdef>
          <para>A default role in the Compute RBAC system that can quarantine an
instance in any project.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>J</title>
      <info/>
      <glossentry>
        <glossterm>Java</glossterm>
        <glossdef>
          <para>A programming language that is used to create systems that
involve more than one computer by way of a network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>JavaScript</glossterm>
        <glossdef>
          <para>A scripting language that is used to build web pages.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>JavaScript Object Notation (JSON)</glossterm>
        <glossdef>
          <para>One of the supported response formats in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Jenkins</glossterm>
        <glossdef>
          <para>Tool used to run jobs automatically for OpenStack
development.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>jumbo frame</glossterm>
        <glossdef>
          <para>Feature in modern Ethernet networks that supports frames up to
approximately 9000 bytes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Juno</glossterm>
        <glossdef>
          <para>The code name for the tenth release of OpenStack. The
design summit took place in Atlanta, Georgia, US and Juno is
an unincorporated community in Georgia.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>K</title>
      <info/>
      <glossentry>
        <glossterm>Kerberos</glossterm>
        <glossdef>
          <para>A network authentication protocol which works on the basis of
tickets. Kerberos allows nodes communication over a non-secure
network, and allows nodes to prove their identity to one another in a
secure manner.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>kernel-based VM (KVM)</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor. KVM is a full
virtualization solution for Linux on x86 hardware containing
virtualization extensions (Intel VT or AMD-V), ARM, IBM
Power, and IBM zSeries. It consists of a loadable kernel
module, that provides the core virtualization infrastructure
and a processor specific module.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-key-manager-service-barbican">
        <glossterm>Key Manager service (barbican)</glossterm>
        <glossdef>
          <para>The project that produces a secret storage and
generation system capable of providing key management for
services wishing to enable encryption features.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>keystone</glossterm>
        <glossdef>
          <para>Codename of the <xref linkend="term-identity-service-keystone"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Kickstart</glossterm>
        <glossdef>
          <para>A tool to automate system configuration and installation on Red
Hat, Fedora, and CentOS-based Linux distributions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Kilo</glossterm>
        <glossdef>
          <para>The code name for the eleventh release of OpenStack. The
design summit took place in Paris, France. Due to delays in the name
selection, the release was known only as K. Because <literal>k</literal> is the
unit symbol for kilo and the reference artifact is stored near Paris
in the Pavillon de Breteuil in Sèvres, the community chose Kilo as
the release name.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>L</title>
      <info/>
      <glossentry>
        <glossterm>large object</glossterm>
        <glossdef>
          <para>An object within Object Storage that is larger than 5 GB.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Launchpad</glossterm>
        <glossdef>
          <para>The collaboration site for OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Layer-2 (L2) agent</glossterm>
        <glossdef>
          <para>OpenStack Networking agent that provides layer-2
connectivity for virtual networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Layer-2 network</glossterm>
        <glossdef>
          <para>Term used in the OSI network architecture for the data link
layer. The data link layer is responsible for media access
control, flow control and detecting and possibly correcting
errors that may occur in the physical layer.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Layer-3 (L3) agent</glossterm>
        <glossdef>
          <para>OpenStack Networking agent that provides layer-3
(routing) services for virtual networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Layer-3 network</glossterm>
        <glossdef>
          <para>Term used in the OSI network architecture for the network
layer. The network layer is responsible for packet
forwarding including routing from one node to another.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Liberty</glossterm>
        <glossdef>
          <para>The code name for the twelfth release of OpenStack. The
design summit took place in Vancouver, Canada and Liberty is
the name of a village in the Canadian province of
Saskatchewan.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>libvirt</glossterm>
        <glossdef>
          <para>Virtualization API library used by OpenStack to interact with
many of its supported hypervisors.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Lightweight Directory Access Protocol (LDAP)</glossterm>
        <glossdef>
          <para>An application protocol for accessing and maintaining distributed
directory information services over an IP network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Linux bridge</glossterm>
        <glossdef>
          <para>Software that enables multiple VMs to share a single physical
NIC within Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Linux Bridge neutron plug-in</glossterm>
        <glossdef>
          <para>Enables a Linux bridge to understand a Networking port,
interface attachment, and other abstractions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Linux containers (LXC)</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>live migration</glossterm>
        <glossdef>
          <para>The ability within Compute to move running virtual machine
instances from one host to another with only a small service
interruption during switchover.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>load balancer</glossterm>
        <glossdef>
          <para>A load balancer is a logical device that belongs to a cloud
account. It is used to distribute workloads between multiple back-end
systems or services, based on the criteria defined as part of its
configuration.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>load balancing</glossterm>
        <glossdef>
          <para>The process of spreading client requests between two or more
nodes to improve performance and availability.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Load-Balancer-as-a-Service (LBaaS)</glossterm>
        <glossdef>
          <para>Enables Networking to distribute incoming requests evenly
between designated instances.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-load-balancing-service-octavia">
        <glossterm>Load-balancing service (octavia)</glossterm>
        <glossdef>
          <para>The project that aims to rovide scalable, on demand, self service
access to load-balancer services, in technology-agnostic manner.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-logical-volume-manager-lvm">
        <glossterm>Logical Volume Manager (LVM)</glossterm>
        <glossdef>
          <para>Provides a method of allocating space on mass-storage
devices that is more flexible than conventional partitioning
schemes.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>M</title>
      <info/>
      <glossentry>
        <glossterm>magnum</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-container-infrastructure-management-service-magnum"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>management API</glossterm>
        <glossdef>
          <para>Alternative term for an admin API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>management network</glossterm>
        <glossdef>
          <para>A network segment used for administration, not accessible to the
public Internet.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>manager</glossterm>
        <glossdef>
          <para>Logical groupings of related code, such as the Block Storage
volume manager or network manager.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>manifest</glossterm>
        <glossdef>
          <para>Used to track segments of a large object within Object
Storage.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>manifest object</glossterm>
        <glossdef>
          <para>A special Object Storage object that contains the manifest for a
large object.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>manila</glossterm>
        <glossdef>
          <para>Codename for OpenStack <xref linkend="term-shared-file-systems-service-manila"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>manila-share</glossterm>
        <glossdef>
          <para>Responsible for managing Shared File System Service devices, specifically
the back-end devices.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>maximum transmission unit (MTU)</glossterm>
        <glossdef>
          <para>Maximum frame or packet size for a particular network
medium. Typically 1500 bytes for Ethernet networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>mechanism driver</glossterm>
        <glossdef>
          <para>A driver for the Modular Layer 2 (ML2) neutron plug-in that
provides layer-2 connectivity for virtual instances. A
single OpenStack installation can use multiple mechanism
drivers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>melange</glossterm>
        <glossdef>
          <para>Project name for OpenStack Network Information Service. To be
merged with Networking.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>membership</glossterm>
        <glossdef>
          <para>The association between an Image service VM image and a project.
Enables images to be shared with specified projects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>membership list</glossterm>
        <glossdef>
          <para>A list of projects that can access a given VM image within Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>memcached</glossterm>
        <glossdef>
          <para>A distributed memory object caching system that is used by
Object Storage for caching.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>memory overcommit</glossterm>
        <glossdef>
          <para>The ability to start new VM instances based on the actual memory
usage of a host, as opposed to basing the decision on the amount of
RAM each running instance thinks it has available. Also known as RAM
overcommit.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>message broker</glossterm>
        <glossdef>
          <para>The software package used to provide AMQP messaging capabilities
within Compute. Default package is RabbitMQ.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>message bus</glossterm>
        <glossdef>
          <para>The main virtual communication line used by all AMQP messages
for inter-cloud communications within Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>message queue</glossterm>
        <glossdef>
          <para>Passes requests from clients to the appropriate workers and
returns the output to the client after the job completes.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-message-service-zaqar">
        <glossterm>Message service (zaqar)</glossterm>
        <glossdef>
          <para>The project that provides a messaging service that affords a
variety of distributed application patterns in an efficient,
scalable and highly available manner, and to create and maintain
associated Python libraries and documentation.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Meta-Data Server (MDS)</glossterm>
        <glossdef>
          <para>Stores CephFS metadata.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Metadata agent</glossterm>
        <glossdef>
          <para>OpenStack Networking agent that provides metadata
services for instances.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>migration</glossterm>
        <glossdef>
          <para>The process of moving a VM instance from one host to
another.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>mistral</glossterm>
        <glossdef>
          <para>Code name for <xref linkend="term-workflow-service-mistral"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Mitaka</glossterm>
        <glossdef>
          <para>The code name for the thirteenth release of OpenStack.
The design summit took place in Tokyo, Japan. Mitaka
is a city in Tokyo.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Modular Layer 2 (ML2) neutron plug-in</glossterm>
        <glossdef>
          <para>Can concurrently use multiple layer-2 networking technologies,
such as 802.1Q and VXLAN, in Networking.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>monasca</glossterm>
        <glossdef>
          <para>Codename for OpenStack <xref linkend="term-monitoring-monasca"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Monitor (LBaaS)</glossterm>
        <glossdef>
          <para>LBaaS feature that provides availability monitoring using the
<literal>ping</literal> command, TCP, and HTTP/HTTPS GET.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Monitor (Mon)</glossterm>
        <glossdef>
          <para>A Ceph component that communicates with external clients, checks
data state and consistency, and performs quorum functions.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-monitoring-monasca">
        <glossterm>Monitoring (monasca)</glossterm>
        <glossdef>
          <para>The OpenStack service that provides a multi-tenant, highly scalable,
performant, fault-tolerant monitoring-as-a-service solution for metrics,
complex event processing and logging. To build an extensible platform for
advanced monitoring services that can be used by both operators and
tenants to gain operational insight and visibility, ensuring availability
and stability.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>multi-factor authentication</glossterm>
        <glossdef>
          <para>Authentication method that uses two or more credentials, such as
a password and a private key. Currently not supported in
Identity.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>multi-host</glossterm>
        <glossdef>
          <para>High-availability mode for legacy (nova) networking.
Each compute node handles NAT and DHCP and acts as a gateway
for all of the VMs on it. A networking failure on one compute
node doesn't affect VMs on other compute nodes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>multinic</glossterm>
        <glossdef>
          <para>Facility in Compute that allows each virtual machine instance to
have more than one VIF connected to it.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>murano</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-application-catalog-service-murano"/>.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>N</title>
      <info/>
      <glossentry>
        <glossterm>Nebula</glossterm>
        <glossdef>
          <para>Released as open source by NASA in 2010 and is the basis for
Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>netadmin</glossterm>
        <glossdef>
          <para>One of the default roles in the Compute RBAC system. Enables the
user to allocate publicly accessible IP addresses to instances and
change firewall rules.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>NetApp volume driver</glossterm>
        <glossdef>
          <para>Enables Compute to communicate with NetApp storage devices
through the NetApp OnCommand
Provisioning Manager.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network</glossterm>
        <glossdef>
          <para>A virtual network that provides connectivity between entities.
For example, a collection of virtual ports that share network
connectivity. In Networking terminology, a network is always a layer-2
network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Network Address Translation (NAT)</glossterm>
        <glossdef>
          <para>Process of modifying IP address information while in transit.
Supported by Compute and Networking.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network controller</glossterm>
        <glossdef>
          <para>A Compute daemon that orchestrates the network configuration of
nodes, including IP addresses, VLANs, and bridging. Also manages
routing for both public and private networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Network File System (NFS)</glossterm>
        <glossdef>
          <para>A method for making file systems available over the network.
Supported by OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network ID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each network segment within Networking.
Same as network UUID.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network manager</glossterm>
        <glossdef>
          <para>The Compute component that manages various network components,
such as firewall rules, IP address allocation, and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network namespace</glossterm>
        <glossdef>
          <para>Linux kernel feature that provides independent virtual
networking instances on a single host with separate routing
tables and interfaces. Similar to virtual routing and forwarding
(VRF) services on physical network equipment.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network node</glossterm>
        <glossdef>
          <para>Any compute node that runs the network worker daemon.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network segment</glossterm>
        <glossdef>
          <para>Represents a virtual, isolated OSI layer-2 subnet in
Networking.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Network Service Header (NSH)</glossterm>
        <glossdef>
          <para>Provides a mechanism for metadata exchange along the
instantiated service path.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Network Time Protocol (NTP)</glossterm>
        <glossdef>
          <para>Method of keeping a clock for a host or node correct via
communication with a trusted, accurate time source.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network UUID</glossterm>
        <glossdef>
          <para>Unique ID for a Networking network segment.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>network worker</glossterm>
        <glossdef>
          <para>The <literal>nova-network</literal> worker daemon; provides
services such as giving an IP address to a booting nova
instance.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-networking-api-neutron-api">
        <glossterm>Networking API (Neutron API)</glossterm>
        <glossdef>
          <para>API used to access OpenStack Networking. Provides an extensible
architecture to enable custom plug-in creation.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-networking-service-neutron">
        <glossterm>Networking service (neutron)</glossterm>
        <glossdef>
          <para>The OpenStack project which implements services and associated
libraries to provide on-demand, scalable, and technology-agnostic
network abstraction.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>neutron</glossterm>
        <glossdef>
          <para>Codename for OpenStack <xref linkend="term-networking-service-neutron"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>neutron API</glossterm>
        <glossdef>
          <para>An alternative name for <xref linkend="term-networking-api-neutron-api"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>neutron manager</glossterm>
        <glossdef>
          <para>Enables Compute and Networking integration, which enables
Networking to perform network management for guest VMs.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>neutron plug-in</glossterm>
        <glossdef>
          <para>Interface within Networking that enables organizations to create
custom plug-ins for advanced features, such as QoS, ACLs, or
IDS.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Newton</glossterm>
        <glossdef>
          <para>The code name for the fourteenth release of OpenStack. The
design summit took place in Austin, Texas, US. The
release is named after "Newton House" which is located at
1013 E. Ninth St., Austin, TX. which is listed on the
National Register of Historic Places.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Nexenta volume driver</glossterm>
        <glossdef>
          <para>Provides support for NexentaStor devices in Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-nfv-orchestration-service-tacker">
        <glossterm>NFV Orchestration Service (tacker)</glossterm>
        <glossdef>
          <para>OpenStack service that aims to implement Network Function Virtualization
(NFV) Orchestration services and libraries for end-to-end life-cycle
management of Network Services and Virtual Network Functions (VNFs).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Nginx</glossterm>
        <glossdef>
          <para>An HTTP and reverse proxy server, a mail proxy server, and a generic
TCP/UDP proxy server.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>No ACK</glossterm>
        <glossdef>
          <para>Disables server-side message acknowledgment in the Compute
RabbitMQ. Increases performance but decreases reliability.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>node</glossterm>
        <glossdef>
          <para>A VM instance that runs on a host.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>non-durable exchange</glossterm>
        <glossdef>
          <para>Message exchange that is cleared when the service restarts. Its
data is not written to persistent storage.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>non-durable queue</glossterm>
        <glossdef>
          <para>Message queue that is cleared when the service restarts. Its
data is not written to persistent storage.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>non-persistent volume</glossterm>
        <glossdef>
          <para>Alternative term for an ephemeral volume.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>north-south traffic</glossterm>
        <glossdef>
          <para>Network traffic between a user or client (north) and a
server (south), or traffic into the cloud (south) and
out of the cloud (north). See also east-west traffic.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>nova</glossterm>
        <glossdef>
          <para>Codename for OpenStack <xref linkend="term-compute-service-nova"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Nova API</glossterm>
        <glossdef>
          <para>Alternative term for the <xref linkend="term-compute-api-nova-api"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>nova-network</glossterm>
        <glossdef>
          <para>A Compute component that manages IP address allocation,
firewalls, and other network-related tasks. This is the legacy
networking option and an alternative to Networking.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>O</title>
      <info/>
      <glossentry>
        <glossterm>object</glossterm>
        <glossdef>
          <para>A BLOB of data held by Object Storage; can be in any
format.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>object auditor</glossterm>
        <glossdef>
          <para>Opens all objects for an object server and verifies the MD5
hash, size, and metadata for each object.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>object expiration</glossterm>
        <glossdef>
          <para>A configurable option within Object Storage to automatically
delete objects after a specified amount of time has passed or a
certain date is reached.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>object hash</glossterm>
        <glossdef>
          <para>Unique ID for an Object Storage object.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>object path hash</glossterm>
        <glossdef>
          <para>Used by Object Storage to determine the location of an object in
the ring. Maps objects to partitions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>object replicator</glossterm>
        <glossdef>
          <para>An Object Storage component that copies an object to remote
partitions for fault tolerance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>object server</glossterm>
        <glossdef>
          <para>An Object Storage component that is responsible for managing
objects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Object Storage API</glossterm>
        <glossdef>
          <para>API used to access OpenStack <xref linkend="term-object-storage-service-swift"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Object Storage Device (OSD)</glossterm>
        <glossdef>
          <para>The Ceph storage daemon.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-object-storage-service-swift">
        <glossterm>Object Storage service (swift)</glossterm>
        <glossdef>
          <para>The OpenStack core project that provides eventually consistent
and redundant storage and retrieval of fixed digital content.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>object versioning</glossterm>
        <glossdef>
          <para>Allows a user to set a flag on an <xref linkend="term-object-storage-service-swift"/> container so that all objects within the container are
versioned.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Ocata</glossterm>
        <glossdef>
          <para>The code name for the fifteenth release of OpenStack. The
design summit will take place in Barcelona, Spain. Ocata is
a beach north of Barcelona.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-octavia">
        <glossterm>Octavia</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-load-balancing-service-octavia"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Oldie</glossterm>
        <glossdef>
          <para>Term for an <xref linkend="term-object-storage-service-swift"/>
process that runs for a long time.  Can indicate a hung process.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Open Cloud Computing Interface (OCCI)</glossterm>
        <glossdef>
          <para>A standardized interface for managing compute, data, and network
resources, currently unsupported in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Open Virtualization Format (OVF)</glossterm>
        <glossdef>
          <para>Standard for packaging VM images. Supported in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Open vSwitch</glossterm>
        <glossdef>
          <para>Open vSwitch is a production quality, multilayer virtual
switch licensed under the open source Apache 2.0 license. It
is designed to enable massive network automation through
programmatic extension, while still supporting standard
management interfaces and protocols (for example NetFlow,
sFlow, SPAN, RSPAN, CLI, LACP, 802.1ag).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Open vSwitch (OVS) agent</glossterm>
        <glossdef>
          <para>Provides an interface to the underlying Open vSwitch service for
the Networking plug-in.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Open vSwitch neutron plug-in</glossterm>
        <glossdef>
          <para>Provides support for Open vSwitch in Networking.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>OpenLDAP</glossterm>
        <glossdef>
          <para>An open source LDAP server. Supported by both Compute and
Identity.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>OpenStack</glossterm>
        <glossdef>
          <para>OpenStack is a cloud operating system that controls large pools
of compute, storage, and networking resources throughout a data
center, all managed through a dashboard that gives administrators
control while empowering their users to provision resources through a
web interface. OpenStack is an open source project licensed under the
Apache License 2.0.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>OpenStack code name</glossterm>
        <glossdef>
          <para>Each OpenStack release has a code name. Code names ascend in
alphabetical order: Austin, Bexar, Cactus, Diablo, Essex,
Folsom, Grizzly, Havana, Icehouse, Juno, Kilo, Liberty,
Mitaka, Newton, Ocata, Pike, and Queens.
Code names are cities or counties near where the
corresponding OpenStack design summit took place. An
exception, called the Waldon exception, is granted to
elements of the state flag that sound especially cool. Code
names are chosen by popular vote.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>openSUSE</glossterm>
        <glossdef>
          <para>A Linux distribution that is compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>operator</glossterm>
        <glossdef>
          <para>The person responsible for planning and maintaining an OpenStack
installation.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>optional service</glossterm>
        <glossdef>
          <para>An official OpenStack service defined as optional by
DefCore Committee. Currently, consists of
Dashboard (horizon), Telemetry service (Telemetry),
Orchestration service (heat), Database service (trove),
Bare Metal service (ironic), and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-orchestration-service-heat">
        <glossterm>Orchestration service (heat)</glossterm>
        <glossdef>
          <para>The OpenStack service which orchestrates composite cloud
applications using a declarative template format through
an OpenStack-native REST API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>orphan</glossterm>
        <glossdef>
          <para>In the context of Object Storage, this is a process that is not
terminated after an upgrade, restart, or reload of the service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Oslo</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-common-libraries-oslo"/>.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>P</title>
      <info/>
      <glossentry>
        <glossterm>panko</glossterm>
        <glossdef>
          <para>Part of the OpenStack <xref linkend="term-telemetry-service-telemetry"/>; provides event storage.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>parent cell</glossterm>
        <glossdef>
          <para>If a requested resource, such as CPU time, disk storage, or
memory, is not available in the parent cell, the request is forwarded
to associated child cells.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>partition</glossterm>
        <glossdef>
          <para>A unit of storage within Object Storage used to store objects.
It exists on top of devices and is replicated for fault
tolerance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>partition index</glossterm>
        <glossdef>
          <para>Contains the locations of all Object Storage partitions within
the ring.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>partition shift value</glossterm>
        <glossdef>
          <para>Used by Object Storage to determine which partition data should
reside on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>path MTU discovery (PMTUD)</glossterm>
        <glossdef>
          <para>Mechanism in IP networks to detect end-to-end MTU and adjust
packet size accordingly.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>pause</glossterm>
        <glossdef>
          <para>A VM state where no changes occur (no changes in memory, network
communications stop, etc); the VM is frozen but not shut down.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>PCI passthrough</glossterm>
        <glossdef>
          <para>Gives guest VMs exclusive access to a PCI device. Currently
supported in OpenStack Havana and later releases.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>persistent message</glossterm>
        <glossdef>
          <para>A message that is stored both in memory and on disk. The message
is not lost after a failure or restart.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>persistent volume</glossterm>
        <glossdef>
          <para>Changes to these types of disk volumes are saved.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>personality file</glossterm>
        <glossdef>
          <para>A file used to customize a Compute instance. It can be used to
inject SSH keys or a specific network configuration.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Pike</glossterm>
        <glossdef>
          <para>The code name for the sixteenth release of OpenStack. The design
summit will take place in Boston, Massachusetts, US. The release
is named after the Massachusetts Turnpike, abbreviated commonly
as the Mass Pike, which is the eastermost stretch of
Interstate 90.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Platform-as-a-Service (PaaS)</glossterm>
        <glossdef>
          <para>Provides to the consumer the ability to deploy applications
through a programming language or tools supported by the cloud
platform provider. An example of Platform-as-a-Service is an
Eclipse/Java programming platform provided with no downloads
required.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>plug-in</glossterm>
        <glossdef>
          <para>Software component providing the actual implementation for
Networking APIs, or for Compute APIs, depending on the context.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>policy service</glossterm>
        <glossdef>
          <para>Component of Identity that provides a rule-management
interface and a rule-based authorization engine.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>policy-based routing (PBR)</glossterm>
        <glossdef>
          <para>Provides a mechanism to implement packet forwarding and routing
according to the policies defined by the network administrator.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>pool</glossterm>
        <glossdef>
          <para>A logical set of devices, such as web servers, that you
group together to receive and process traffic. The load
balancing function chooses which member of the pool handles
the new requests or connections received on the VIP
address. Each VIP has one pool.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>pool member</glossterm>
        <glossdef>
          <para>An application that runs on the back-end server in a
load-balancing system.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>port</glossterm>
        <glossdef>
          <para>A virtual network port within Networking; VIFs / vNICs are
connected to a port.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>port UUID</glossterm>
        <glossdef>
          <para>Unique ID for a Networking port.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>preseed</glossterm>
        <glossdef>
          <para>A tool to automate system configuration and installation on
Debian-based Linux distributions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>private image</glossterm>
        <glossdef>
          <para>An Image service VM image that is only available to specified
projects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>private IP address</glossterm>
        <glossdef>
          <para>An IP address used for management and administration, not
available to the public Internet.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>private network</glossterm>
        <glossdef>
          <para>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. A private network interface can be a flat or VLAN network
interface. A flat network interface is controlled by the
flat_interface with flat managers. A VLAN network interface is
controlled by the <literal>vlan_interface</literal> option with VLAN
managers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>project</glossterm>
        <glossdef>
          <para>Projects represent the base unit of “ownership” in OpenStack,
in that all resources in OpenStack should be owned by a specific project.
In OpenStack Identity, a project must be owned by a specific domain.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-project-id">
        <glossterm>project ID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each project by the Identity service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>project VPN</glossterm>
        <glossdef>
          <para>Alternative term for a cloudpipe.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>promiscuous mode</glossterm>
        <glossdef>
          <para>Causes the network interface to pass all traffic it
receives to the host rather than passing only the frames
addressed to it.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>protected property</glossterm>
        <glossdef>
          <para>Generally, extra properties on an Image service image to
which only cloud administrators have access. Limits which user
roles can perform CRUD operations on that property. The cloud
administrator can configure any image property as
protected.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>provider</glossterm>
        <glossdef>
          <para>An administrator who has access to all hosts and
instances.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>proxy node</glossterm>
        <glossdef>
          <para>A node that provides the Object Storage proxy service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>proxy server</glossterm>
        <glossdef>
          <para>Users of Object Storage interact with the service through the
proxy server, which in turn looks up the location of the requested
data within the ring and returns the results to the user.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>public API</glossterm>
        <glossdef>
          <para>An API endpoint used for both service-to-service communication
and end-user interactions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>public image</glossterm>
        <glossdef>
          <para>An Image service VM image that is available to all
projects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>public IP address</glossterm>
        <glossdef>
          <para>An IP address that is accessible to end-users.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>public key authentication</glossterm>
        <glossdef>
          <para>Authentication method that uses keys rather than
passwords.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>public network</glossterm>
        <glossdef>
          <para>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. The public network interface is controlled by the
<literal>public_interface</literal> option.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Puppet</glossterm>
        <glossdef>
          <para>An operating system configuration-management tool supported by
OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Python</glossterm>
        <glossdef>
          <para>Programming language used extensively in OpenStack.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>Q</title>
      <info/>
      <glossentry>
        <glossterm>QEMU Copy On Write 2 (QCOW2)</glossterm>
        <glossdef>
          <para>One of the VM image disk formats supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Qpid</glossterm>
        <glossdef>
          <para>Message queue software supported by OpenStack; an alternative to
RabbitMQ.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-quality-of-service-qos">
        <glossterm>Quality of Service (QoS)</glossterm>
        <glossdef>
          <para>The ability to guarantee certain network or storage requirements to
satisfy a Service Level Agreement (SLA) between an application provider
and end users.
Typically includes performance requirements like networking bandwidth,
latency, jitter correction, and reliability as well as storage
performance in Input/Output Operations Per Second (IOPS), throttling
agreements, and performance expectations at peak load.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>quarantine</glossterm>
        <glossdef>
          <para>If Object Storage finds objects, containers, or accounts that
are corrupt, they are placed in this state, are not replicated, cannot
be read by clients, and a correct copy is re-replicated.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Queens</glossterm>
        <glossdef>
          <para>The code name for the seventeenth release of OpenStack. The
design summit will take place in Sydney, Australia. The release
is named after the Queens Pound river in the South Coast region
of New South Wales.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Quick EMUlator (QEMU)</glossterm>
        <glossdef>
          <para>QEMU is a generic and open source machine emulator and
virtualizer.
One of the hypervisors supported by OpenStack, generally used
for development purposes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>quota</glossterm>
        <glossdef>
          <para>In Compute and Block Storage, the ability to set resource limits
on a per-project basis.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>R</title>
      <info/>
      <glossentry>
        <glossterm>RabbitMQ</glossterm>
        <glossdef>
          <para>The default message queue software used by OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Rackspace Cloud Files</glossterm>
        <glossdef>
          <para>Released as open source by Rackspace in 2010; the basis for
Object Storage.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>RADOS Block Device (RBD)</glossterm>
        <glossdef>
          <para>Ceph component that enables a Linux block device to be striped
over multiple distributed data stores.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>radvd</glossterm>
        <glossdef>
          <para>The router advertisement daemon, used by the Compute VLAN
manager and FlatDHCP manager to provide routing services for VM
instances.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>rally</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-benchmark-service-rally"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>RAM filter</glossterm>
        <glossdef>
          <para>The Compute setting that enables or disables RAM
overcommitment.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>RAM overcommit</glossterm>
        <glossdef>
          <para>The ability to start new VM instances based on the actual memory
usage of a host, as opposed to basing the decision on the amount of
RAM each running instance thinks it has available. Also known as
memory overcommit.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>rate limit</glossterm>
        <glossdef>
          <para>Configurable option within Object Storage to limit database
writes on a per-account and/or per-container basis.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>raw</glossterm>
        <glossdef>
          <para>One of the VM image disk formats supported by Image service; an
unstructured disk image.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>rebalance</glossterm>
        <glossdef>
          <para>The process of distributing Object Storage partitions across all
drives in the ring; used during initial ring creation and after ring
reconfiguration.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>reboot</glossterm>
        <glossdef>
          <para>Either a soft or hard reboot of a server. With a soft reboot,
the operating system is signaled to restart, which enables a graceful
shutdown of all processes. A hard reboot is the equivalent of power
cycling the server. The virtualization platform should ensure that the
reboot action has completed successfully, even in cases in which the
underlying domain/VM is paused or halted/stopped.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>rebuild</glossterm>
        <glossdef>
          <para>Removes all data on the server and replaces it with the
specified image. Server ID and IP addresses remain the same.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Recon</glossterm>
        <glossdef>
          <para>An Object Storage component that collects meters.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>record</glossterm>
        <glossdef>
          <para>Belongs to a particular domain and is used to specify
information about the domain.
There are several types of DNS records. Each record type contains
particular information used to describe the purpose of that record.
Examples include mail exchange (MX) records, which specify the mail
server for a particular domain; and name server (NS) records, which
specify the authoritative name servers for a domain.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>record ID</glossterm>
        <glossdef>
          <para>A number within a database that is incremented each time a
change is made. Used by Object Storage when replicating.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Red Hat Enterprise Linux (RHEL)</glossterm>
        <glossdef>
          <para>A Linux distribution that is compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>reference architecture</glossterm>
        <glossdef>
          <para>A recommended architecture for an OpenStack cloud.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>region</glossterm>
        <glossdef>
          <para>A discrete OpenStack environment with dedicated API endpoints
that typically shares only the Identity (keystone) with other
regions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>registry</glossterm>
        <glossdef>
          <para>Alternative term for the Image service registry.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>registry server</glossterm>
        <glossdef>
          <para>An Image service that provides VM image metadata information to
clients.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Reliable, Autonomic Distributed Object Store</glossterm>
        <glossdef>
          <para>(RADOS)</para>
          <para>A collection of components that provides object storage within
Ceph. Similar to OpenStack Object Storage.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-remote-procedure-call-rpc">
        <glossterm>Remote Procedure Call (RPC)</glossterm>
        <glossdef>
          <para>The method used by the Compute RabbitMQ for intra-service
communications.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>replica</glossterm>
        <glossdef>
          <para>Provides data redundancy and fault tolerance by creating copies
of Object Storage objects, accounts, and containers so that they are
not lost when the underlying storage fails.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>replica count</glossterm>
        <glossdef>
          <para>The number of replicas of the data in an Object Storage
ring.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>replication</glossterm>
        <glossdef>
          <para>The process of copying data to a separate physical device for
fault tolerance and performance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>replicator</glossterm>
        <glossdef>
          <para>The Object Storage back-end process that creates and manages
object replicas.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>request ID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each request sent to Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>rescue image</glossterm>
        <glossdef>
          <para>A special type of VM image that is booted when an instance is
placed into rescue mode. Allows an administrator to mount the file
systems for an instance to correct the problem.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>resize</glossterm>
        <glossdef>
          <para>Converts an existing server to a different flavor, which scales
the server up or down. The original server is saved to enable rollback
if a problem occurs. All resizes must be tested and explicitly
confirmed, at which time the original server is removed.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>RESTful</glossterm>
        <glossdef>
          <para>A kind of web service API that uses REST, or Representational
State Transfer. REST is the style of architecture for hypermedia
systems that is used for the World Wide Web.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ring</glossterm>
        <glossdef>
          <para>An entity that maps Object Storage data to partitions. A
separate ring exists for each service, such as account, object, and
container.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ring builder</glossterm>
        <glossdef>
          <para>Builds and manages rings within Object Storage, assigns
partitions to devices, and pushes the configuration to other storage
nodes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>role</glossterm>
        <glossdef>
          <para>A personality that a user assumes to perform a specific set of
operations. A role includes a set of rights and privileges. A user
assuming that role inherits those rights and privileges.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Role Based Access Control (RBAC)</glossterm>
        <glossdef>
          <para>Provides a predefined list of actions that the user can perform,
such as start or stop VMs, reset passwords, and so on. Supported in
both Identity and Compute and can be configured using the dashboard.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>role ID</glossterm>
        <glossdef>
          <para>Alphanumeric ID assigned to each Identity service role.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-root-cause-analysis-rca-service-vitrage">
        <glossterm>Root Cause Analysis (RCA) service (Vitrage)</glossterm>
        <glossdef>
          <para>OpenStack project that aims to organize, analyze and visualize OpenStack
alarms and events, yield insights regarding the root cause of problems
and deduce their existence before they are directly detected.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>rootwrap</glossterm>
        <glossdef>
          <para>A feature of Compute that allows the unprivileged "nova" user to
run a specified list of commands as the Linux root user.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>round-robin scheduler</glossterm>
        <glossdef>
          <para>Type of Compute scheduler that evenly distributes instances
among available hosts.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>router</glossterm>
        <glossdef>
          <para>A physical or virtual network device that passes network
traffic between different networks.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>routing key</glossterm>
        <glossdef>
          <para>The Compute direct exchanges, fanout exchanges, and topic
exchanges use this key to determine how to process a message;
processing varies depending on exchange type.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>RPC driver</glossterm>
        <glossdef>
          <para>Modular system that allows the underlying message queue software
of Compute to be changed. For example, from RabbitMQ to ZeroMQ or
Qpid.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>rsync</glossterm>
        <glossdef>
          <para>Used by Object Storage to push object replicas.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>RXTX cap</glossterm>
        <glossdef>
          <para>Absolute limit on the amount of network traffic a Compute VM
instance can send and receive.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>RXTX quota</glossterm>
        <glossdef>
          <para>Soft limit on the amount of network traffic a Compute VM
instance can send and receive.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>S</title>
      <info/>
      <glossentry>
        <glossterm>sahara</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-data-processing-service-sahara"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>SAML assertion</glossterm>
        <glossdef>
          <para>Contains information about a user as provided by the identity
provider. It is an indication that a user has been authenticated.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>scheduler manager</glossterm>
        <glossdef>
          <para>A Compute component that determines where VM instances should
start. Uses modular design to support a variety of scheduler
types.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>scoped token</glossterm>
        <glossdef>
          <para>An Identity service API access token that is associated with a
specific project.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>scrubber</glossterm>
        <glossdef>
          <para>Checks for and deletes unused VMs; the component of Image
service that implements delayed delete.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>secret key</glossterm>
        <glossdef>
          <para>String of text known only by the user; used along with an access
key to make requests to the Compute API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>secure boot</glossterm>
        <glossdef>
          <para>Process whereby the system firmware validates the authenticity of
the code involved in the boot process.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>secure shell (SSH)</glossterm>
        <glossdef>
          <para>Open source tool used to access remote hosts through an
encrypted communications channel, SSH key injection is supported by
Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>security group</glossterm>
        <glossdef>
          <para>A set of network traffic filtering rules that are applied to a
Compute instance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>segmented object</glossterm>
        <glossdef>
          <para>An Object Storage large object that has been broken up into
pieces. The re-assembled object is called a concatenated
object.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>self-service</glossterm>
        <glossdef>
          <para>For IaaS, ability for a regular (non-privileged) account to
manage a virtual infrastructure component such as networks without
involving an administrator.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>SELinux</glossterm>
        <glossdef>
          <para>Linux kernel security module that provides the mechanism for
supporting access control policies.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>senlin</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-clustering-service-senlin"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>server</glossterm>
        <glossdef>
          <para>Computer that provides explicit services to the client software
running on that system, often managing a variety of computer
operations.
A server is a VM instance in the Compute system. Flavor and
image are requisite elements when creating a server.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>server image</glossterm>
        <glossdef>
          <para>Alternative term for a VM image.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>server UUID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each guest VM instance.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-service">
        <glossterm>service</glossterm>
        <glossdef>
          <para>An OpenStack service, such as Compute, Object Storage, or Image
service. Provides one or more endpoints through which users can access
resources and perform operations.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>service catalog</glossterm>
        <glossdef>
          <para>Alternative term for the Identity service catalog.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Service Function Chain (SFC)</glossterm>
        <glossdef>
          <para>For a given service, SFC is the abstracted view of the required
service functions and the order in which they are to be applied.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>service ID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each service that is available in the
Identity service catalog.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Service Level Agreement (SLA)</glossterm>
        <glossdef>
          <para>Contractual obligations that ensure the availability of a
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>service project</glossterm>
        <glossdef>
          <para>Special project that contains all services that are listed in the
catalog.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>service provider</glossterm>
        <glossdef>
          <para>A system that provides services to other system entities. In
case of federated identity, OpenStack Identity is the service
provider.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>service registration</glossterm>
        <glossdef>
          <para>An Identity service feature that enables services, such as
Compute, to automatically register with the catalog.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>service token</glossterm>
        <glossdef>
          <para>An administrator-defined token used by Compute to communicate
securely with the Identity service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>session back end</glossterm>
        <glossdef>
          <para>The method of storage used by horizon to track client sessions,
such as local memory, cookies, a database, or memcached.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>session persistence</glossterm>
        <glossdef>
          <para>A feature of the load-balancing service. It attempts to force
subsequent connections to a service to be redirected to the same node
as long as it is online.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>session storage</glossterm>
        <glossdef>
          <para>A horizon component that stores and tracks client session
information. Implemented through the Django sessions framework.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>share</glossterm>
        <glossdef>
          <para>A remote, mountable file system in the context of the <xref linkend="term-shared-file-systems-service-manila"/>. You can
mount a share to, and access a share from, several hosts by several
users at a time.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>share network</glossterm>
        <glossdef>
          <para>An entity in the context of the <xref linkend="term-shared-file-systems-service-manila"/> that encapsulates
interaction with the Networking service. If the driver you selected
runs in the mode requiring such kind of interaction, you need to
specify the share network to create a share.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Shared File Systems API</glossterm>
        <glossdef>
          <para>A Shared File Systems service that provides a stable RESTful API.
The service authenticates and routes requests throughout the Shared
File Systems service. There is python-manilaclient to interact with
the API.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-shared-file-systems-service-manila">
        <glossterm>Shared File Systems service (manila)</glossterm>
        <glossdef>
          <para>The service that provides a set of services for
management of shared file systems in a multi-tenant cloud
environment, similar to how OpenStack provides block-based storage
management through the OpenStack <xref linkend="term-block-storage-service-cinder"/> project.
With the Shared File Systems service, you can create a remote file
system and mount the file system on your instances. You can also
read and write data from your instances to and from your file system.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>shared IP address</glossterm>
        <glossdef>
          <para>An IP address that can be assigned to a VM instance within the
shared IP group. Public IP addresses can be shared across multiple
servers for use in various high-availability scenarios. When an IP
address is shared to another server, the cloud network restrictions
are modified to enable each server to listen to and respond on that IP
address. You can optionally specify that the target server network
configuration be modified. Shared IP addresses can be used with many
standard heartbeat facilities, such as keepalive, that monitor for
failure and manage IP failover.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>shared IP group</glossterm>
        <glossdef>
          <para>A collection of servers that can share IPs with other members of
the group. Any server in a group can share one or more public IPs with
any other server in the group. With the exception of the first server
in a shared IP group, servers must be launched into shared IP groups.
A server may be a member of only one shared IP group.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>shared storage</glossterm>
        <glossdef>
          <para>Block storage that is simultaneously accessible by multiple
clients, for example, NFS.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Sheepdog</glossterm>
        <glossdef>
          <para>Distributed block storage system for QEMU, supported by
OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Simple Cloud Identity Management (SCIM)</glossterm>
        <glossdef>
          <para>Specification for managing identity in the cloud, currently
unsupported by OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Simple Protocol for Independent Computing Environments (SPICE)</glossterm>
        <glossdef>
          <para>SPICE provides remote desktop access to guest virtual machines. It
is an alternative to VNC. SPICE is supported by OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Single-root I/O Virtualization (SR-IOV)</glossterm>
        <glossdef>
          <para>A specification that, when implemented by a physical PCIe
device, enables it to appear as multiple separate PCIe devices. This
enables multiple virtualized guests to share direct access to the
physical device, offering improved performance over an equivalent
virtual device. Currently supported in OpenStack Havana and later
releases.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>SmokeStack</glossterm>
        <glossdef>
          <para>Runs automated tests against the core OpenStack API; written in
Rails.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>snapshot</glossterm>
        <glossdef>
          <para>A point-in-time copy of an OpenStack storage volume or image.
Use storage volume snapshots to back up volumes. Use image snapshots
to back up data, or as "gold" images for additional servers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>soft reboot</glossterm>
        <glossdef>
          <para>A controlled reboot where a VM instance is properly restarted
through operating system commands.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-software-development-lifecycle-automation-service-solum">
        <glossterm>Software Development Lifecycle Automation service (solum)</glossterm>
        <glossdef>
          <para>OpenStack project that aims to make cloud services easier to
consume and integrate with application development process
by automating the source-to-image process, and simplifying
app-centric deployment.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Software-defined networking (SDN)</glossterm>
        <glossdef>
          <para>Provides an approach for network administrators to manage computer
network services through abstraction of lower-level functionality.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>SolidFire Volume Driver</glossterm>
        <glossdef>
          <para>The Block Storage driver for the SolidFire iSCSI storage
appliance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>solum</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-software-development-lifecycle-automation-service-solum"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>spread-first scheduler</glossterm>
        <glossdef>
          <para>The Compute VM scheduling algorithm that attempts to start a new
VM on the host with the least amount of load.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>SQLAlchemy</glossterm>
        <glossdef>
          <para>An open source SQL toolkit for Python, used in OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>SQLite</glossterm>
        <glossdef>
          <para>A lightweight SQL database, used as the default persistent
storage method in many OpenStack services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>stack</glossterm>
        <glossdef>
          <para>A set of OpenStack resources created and managed by the
Orchestration service according to a given template (either an
AWS CloudFormation template or a Heat Orchestration
Template (HOT)).</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>StackTach</glossterm>
        <glossdef>
          <para>Community project that captures Compute AMQP communications;
useful for debugging.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>static IP address</glossterm>
        <glossdef>
          <para>Alternative term for a fixed IP address.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>StaticWeb</glossterm>
        <glossdef>
          <para>WSGI middleware component of Object Storage that serves
container data as a static web page.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>storage back end</glossterm>
        <glossdef>
          <para>The method that a service uses for persistent storage, such as
iSCSI, NFS, or local disk.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>storage manager</glossterm>
        <glossdef>
          <para>A XenAPI component that provides a pluggable interface to
support a wide variety of persistent storage back ends.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>storage manager back end</glossterm>
        <glossdef>
          <para>A persistent storage method supported by XenAPI, such as iSCSI
or NFS.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>storage node</glossterm>
        <glossdef>
          <para>An Object Storage node that provides container services, account
services, and object services; controls the account databases,
container databases, and object storage.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>storage services</glossterm>
        <glossdef>
          <para>Collective name for the Object Storage object services,
container services, and account services.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-strategy">
        <glossterm>strategy</glossterm>
        <glossdef>
          <para>Specifies the authentication source used by Image service or
Identity. In the Database service, it refers to the extensions
implemented for a data store.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>subdomain</glossterm>
        <glossdef>
          <para>A domain within a parent domain. Subdomains cannot be
registered. Subdomains enable you to delegate domains. Subdomains can
themselves have subdomains, so third-level, fourth-level, fifth-level,
and deeper levels of nesting are possible.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>subnet</glossterm>
        <glossdef>
          <para>Logical subdivision of an IP network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>SUSE Linux Enterprise Server (SLES)</glossterm>
        <glossdef>
          <para>A Linux distribution that is compatible with OpenStack.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>suspend</glossterm>
        <glossdef>
          <para>Alternative term for a paused VM instance.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>swap</glossterm>
        <glossdef>
          <para>Disk-based virtual memory used by operating systems to provide
more memory than is actually available on the system.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>swauth</glossterm>
        <glossdef>
          <para>An authentication and authorization service for Object Storage,
implemented through WSGI middleware; uses Object Storage itself as the
persistent backing store.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>swift</glossterm>
        <glossdef>
          <para>Codename for OpenStack <xref linkend="term-object-storage-service-swift"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>swift All in One (SAIO)</glossterm>
        <glossdef>
          <para>Creates a full Object Storage development environment within a
single VM.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>swift middleware</glossterm>
        <glossdef>
          <para>Collective term for Object Storage components that provide
additional functionality.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>swift proxy server</glossterm>
        <glossdef>
          <para>Acts as the gatekeeper to Object Storage and is responsible for
authenticating the user.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>swift storage node</glossterm>
        <glossdef>
          <para>A node that runs Object Storage account, container, and object
services.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>sync point</glossterm>
        <glossdef>
          <para>Point in time since the last container and accounts database
sync among nodes within Object Storage.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>sysadmin</glossterm>
        <glossdef>
          <para>One of the default roles in the Compute RBAC system. Enables a
user to add other users to a project, interact with VM images that are
associated with the project, and start and stop VM instances.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>system usage</glossterm>
        <glossdef>
          <para>A Compute component that, along with the notification system,
collects meters and usage information. This information can be used
for billing.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>T</title>
      <info/>
      <glossentry>
        <glossterm>tacker</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-nfv-orchestration-service-tacker"/></para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-telemetry-service-telemetry">
        <glossterm>Telemetry service (telemetry)</glossterm>
        <glossdef>
          <para>The OpenStack project which collects measurements of the utilization
of the physical and virtual resources comprising deployed clouds,
persists this data for subsequent retrieval and analysis, and triggers
actions when defined criteria are met.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>TempAuth</glossterm>
        <glossdef>
          <para>An authentication facility within Object Storage that enables
Object Storage itself to perform authentication and authorization.
Frequently used in testing and development.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Tempest</glossterm>
        <glossdef>
          <para>Automated software test suite designed to run against the trunk
of the OpenStack core project.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>TempURL</glossterm>
        <glossdef>
          <para>An Object Storage middleware component that enables creation of
URLs for temporary object access.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>tenant</glossterm>
        <glossdef>
          <para>A group of users; used to isolate access to Compute resources.
An alternative term for a project.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Tenant API</glossterm>
        <glossdef>
          <para>An API that is accessible to projects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>tenant endpoint</glossterm>
        <glossdef>
          <para>An Identity service API endpoint that is associated with one or
more projects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>tenant ID</glossterm>
        <glossdef>
          <para>An alternative term for <xref linkend="term-project-id"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>token</glossterm>
        <glossdef>
          <para>An alpha-numeric string of text used to access OpenStack APIs
and resources.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>token services</glossterm>
        <glossdef>
          <para>An Identity service component that manages and validates tokens
after a user or project has been authenticated.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>tombstone</glossterm>
        <glossdef>
          <para>Used to mark Object Storage objects that have been
deleted; ensures that the object is not updated on another node after
it has been deleted.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>topic publisher</glossterm>
        <glossdef>
          <para>A process that is created when a RPC call is executed; used to
push the message to the topic exchange.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Torpedo</glossterm>
        <glossdef>
          <para>Community project used to run automated tests against the
OpenStack API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>transaction ID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each Object Storage request; used for
debugging and tracing.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>transient</glossterm>
        <glossdef>
          <para>Alternative term for non-durable.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>transient exchange</glossterm>
        <glossdef>
          <para>Alternative term for a non-durable exchange.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>transient message</glossterm>
        <glossdef>
          <para>A message that is stored in memory and is lost after the server
is restarted.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>transient queue</glossterm>
        <glossdef>
          <para>Alternative term for a non-durable queue.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>TripleO</glossterm>
        <glossdef>
          <para>OpenStack-on-OpenStack program. The code name for the
OpenStack Deployment program.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>trove</glossterm>
        <glossdef>
          <para>Codename for OpenStack <xref linkend="term-database-service-trove"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>trusted platform module (TPM)</glossterm>
        <glossdef>
          <para>Specialized microprocessor for incorporating cryptographic keys
into devices for authenticating and securing a hardware platform.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>U</title>
      <info/>
      <glossentry>
        <glossterm>Ubuntu</glossterm>
        <glossdef>
          <para>A Debian-based Linux distribution.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>unscoped token</glossterm>
        <glossdef>
          <para>Alternative term for an Identity service default token.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>updater</glossterm>
        <glossdef>
          <para>Collective term for a group of Object Storage components that
processes queued and failed updates for containers and objects.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>user</glossterm>
        <glossdef>
          <para>In OpenStack Identity,  entities represent individual API
consumers and are owned by a specific domain. In OpenStack Compute,
a user can be associated with roles, projects, or both.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>user data</glossterm>
        <glossdef>
          <para>A blob of data that the user can specify when they launch
an instance. The instance can access this data through the
metadata service or config drive.
Commonly used to pass a shell script that the instance runs on boot.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>User Mode Linux (UML)</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>V</title>
      <info/>
      <glossentry>
        <glossterm>VIF UUID</glossterm>
        <glossdef>
          <para>Unique ID assigned to each Networking VIF.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Virtual Central Processing Unit (vCPU)</glossterm>
        <glossdef>
          <para>Subdivides physical CPUs. Instances can then use those
divisions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Virtual Disk Image (VDI)</glossterm>
        <glossdef>
          <para>One of the VM image disk formats supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Virtual Extensible LAN (VXLAN)</glossterm>
        <glossdef>
          <para>A network virtualization technology that attempts to reduce the
scalability problems associated with large cloud computing
deployments. It uses a VLAN-like encapsulation technique to
encapsulate Ethernet frames within UDP packets.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Virtual Hard Disk (VHD)</glossterm>
        <glossdef>
          <para>One of the VM image disk formats supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual IP address (VIP)</glossterm>
        <glossdef>
          <para>An Internet Protocol (IP) address configured on the load
balancer for use by clients connecting to a service that is load
balanced. Incoming connections are distributed to back-end nodes based
on the configuration of the load balancer.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual machine (VM)</glossterm>
        <glossdef>
          <para>An operating system instance that runs on top of a hypervisor.
Multiple VMs can run at the same time on the same physical
host.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual network</glossterm>
        <glossdef>
          <para>An L2 network segment within Networking.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Virtual Network Computing (VNC)</glossterm>
        <glossdef>
          <para>Open source GUI and CLI tools used for remote console access to
VMs. Supported by Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Virtual Network InterFace (VIF)</glossterm>
        <glossdef>
          <para>An interface that is plugged into a port in a Networking
network. Typically a virtual network interface belonging to a
VM.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual networking</glossterm>
        <glossdef>
          <para>A generic term for virtualization of network functions
such as switching, routing, load balancing, and security using
a combination of VMs and overlays on physical network
infrastructure.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual port</glossterm>
        <glossdef>
          <para>Attachment point where a virtual interface connects to a virtual
network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual private network (VPN)</glossterm>
        <glossdef>
          <para>Provided by Compute in the form of cloudpipes, specialized
instances that are used to create VPNs on a per-project basis.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual server</glossterm>
        <glossdef>
          <para>Alternative term for a VM or guest.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual switch (vSwitch)</glossterm>
        <glossdef>
          <para>Software that runs on a host or node and provides the features
and functions of a hardware-based network switch.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>virtual VLAN</glossterm>
        <glossdef>
          <para>Alternative term for a virtual network.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VirtualBox</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Vitrage</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-root-cause-analysis-rca-service-vitrage"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VLAN manager</glossterm>
        <glossdef>
          <para>A Compute component that provides dnsmasq and radvd and sets up
forwarding to and from cloudpipe instances.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VLAN network</glossterm>
        <glossdef>
          <para>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. A VLAN network is a private network interface, which is
controlled by the <literal>vlan_interface</literal> option with VLAN
managers.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VM disk (VMDK)</glossterm>
        <glossdef>
          <para>One of the VM image disk formats supported by Image
service.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VM image</glossterm>
        <glossdef>
          <para>Alternative term for an image.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VM Remote Control (VMRC)</glossterm>
        <glossdef>
          <para>Method to access VM instance consoles using a web browser.
Supported by Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VMware API</glossterm>
        <glossdef>
          <para>Supports interaction with VMware products in Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VMware NSX Neutron plug-in</glossterm>
        <glossdef>
          <para>Provides support for VMware NSX in Neutron.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>VNC proxy</glossterm>
        <glossdef>
          <para>A Compute component that provides users access to the consoles
of their VM instances through VNC or VMRC.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume</glossterm>
        <glossdef>
          <para>Disk-based data storage generally represented as an iSCSI target
with a file system that supports extended attributes; can be
persistent or ephemeral.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Volume API</glossterm>
        <glossdef>
          <para>Alternative name for the Block Storage API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume controller</glossterm>
        <glossdef>
          <para>A Block Storage component that oversees and coordinates storage
volume actions.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume driver</glossterm>
        <glossdef>
          <para>Alternative term for a volume plug-in.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume ID</glossterm>
        <glossdef>
          <para>Unique ID applied to each storage volume under the Block Storage
control.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume manager</glossterm>
        <glossdef>
          <para>A Block Storage component that creates, attaches, and detaches
persistent storage volumes.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume node</glossterm>
        <glossdef>
          <para>A Block Storage node that runs the cinder-volume daemon.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume plug-in</glossterm>
        <glossdef>
          <para>Provides support for new and specialized types of back-end
storage for the Block Storage volume manager.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>volume worker</glossterm>
        <glossdef>
          <para>A cinder component that interacts with back-end storage to manage
the creation and deletion of volumes and the creation of compute
volumes, provided by the cinder-volume daemon.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>vSphere</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>W</title>
      <info/>
      <glossentry>
        <glossterm>Watcher</glossterm>
        <glossdef>
          <para>Code name for the <xref linkend="term-infrastructure-optimization-service-watcher"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>weight</glossterm>
        <glossdef>
          <para>Used by Object Storage devices to determine which storage
devices are suitable for the job. Devices are weighted by size.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>weighted cost</glossterm>
        <glossdef>
          <para>The sum of each cost used when deciding where to start a new VM
instance in Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>weighting</glossterm>
        <glossdef>
          <para>A Compute process that determines the suitability of the VM
instances for a job for a particular host. For example, not enough RAM
on the host, too many CPUs on the host, and so on.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>worker</glossterm>
        <glossdef>
          <para>A daemon that listens to a queue and carries out tasks in
response to messages. For example, the cinder-volume worker manages volume
creation and deletion on storage arrays.</para>
        </glossdef>
      </glossentry>
      <glossentry xml:id="term-workflow-service-mistral">
        <glossterm>Workflow service (mistral)</glossterm>
        <glossdef>
          <para>The OpenStack service that provides a simple YAML-based language to
write workflows (tasks and transition rules) and a service that
allows to upload them, modify, run them at scale and in a highly
available manner, manage and monitor workflow execution state and state
of individual tasks.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>X</title>
      <info/>
      <glossentry>
        <glossterm>Xen</glossterm>
        <glossdef>
          <para>Xen is a hypervisor using a microkernel design, providing
services that allow multiple computer operating systems to
execute on the same computer hardware concurrently.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Xen API</glossterm>
        <glossdef>
          <para>The Xen administrative API, which is supported by
Compute.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Xen Cloud Platform (XCP)</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Xen Storage Manager Volume Driver</glossterm>
        <glossdef>
          <para>A Block Storage volume plug-in that enables communication with
the Xen Storage Manager API.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>XenServer</glossterm>
        <glossdef>
          <para>An OpenStack-supported hypervisor.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>XFS</glossterm>
        <glossdef>
          <para>High-performance 64-bit file system created by Silicon
Graphics. Excels in parallel I/O operations and data
consistency.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
    <glossdiv>
      <title>Z</title>
      <info/>
      <glossentry>
        <glossterm>zaqar</glossterm>
        <glossdef>
          <para>Codename for the <xref linkend="term-message-service-zaqar"/>.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>ZeroMQ</glossterm>
        <glossdef>
          <para>Message queue software supported by OpenStack. An alternative to
RabbitMQ. Also spelled 0MQ.</para>
        </glossdef>
      </glossentry>
      <glossentry>
        <glossterm>Zuul</glossterm>
        <glossdef>
          <para>Tool used in OpenStack development to ensure correctly ordered
testing of changes in parallel.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
  </glossary>
</book>
